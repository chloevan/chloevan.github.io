<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>신경 스타일 전이 on Data Science | ChloEvan</title>
    <link>https://chloevan.github.io/tags/%EC%8B%A0%EA%B2%BD-%EC%8A%A4%ED%83%80%EC%9D%BC-%EC%A0%84%EC%9D%B4/</link>
    <description>Recent content in 신경 스타일 전이 on Data Science | ChloEvan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 02 May 2020 15:20:30 +0900</lastBuildDate>
    
        <atom:link href="https://chloevan.github.io/tags/%EC%8B%A0%EA%B2%BD-%EC%8A%A4%ED%83%80%EC%9D%BC-%EC%A0%84%EC%9D%B4/rss.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch8.3.2 - 컨볼루션 신경망을 사용한 신경 스타일 전이</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch8_3_2_neural_style_transfer/</link>
      <pubDate>Sat, 02 May 2020 15:20:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch8_3_2_neural_style_transfer/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.2 - 다항분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/&#34;&gt;Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/&#34;&gt;Tensorflow 2.0 Tutorial ch6.1-2 - CNN 이론&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_3_fashion_mnist_with_cnn/&#34;&gt;Tensorflow 2.0 Tutorial ch6.3 - Fashion MNIST with CNN 실습&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_4_improve_performance/&#34;&gt;Tensorflow 2.0 Tutorial ch6.4 - 모형의 성능 높이기&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (1)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (2)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_3_sentimentanalysis/&#34;&gt;Tensorflow 2.0 Tutorial ch7.3 - 긍정, 부정 감성 분석&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (1) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (2) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_1_tensorflow_hub/&#34;&gt;Tensorflow 2.0 Tutorial ch8.1 - 텐서플로 허브&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_2_transfer_learning/&#34;&gt;Tensorflow 2.0 Tutorial ch8.2 - 전이 학습과 &amp;amp; Kaggle 대회&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_3_1_texture_synthesis/&#34;&gt;Tensorflow 2.0 Tutorial ch8.3.1 - 컨볼루션 신경망을 사용한 텍스처 합성&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요&#34;&gt;I. 개요&lt;/h2&gt;
&lt;p&gt;2015년, 딥러닝과 예술의 만남으로 큰 화제가 되었던 신경 스타일 전이 논문&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;은 반 고흐의 (별이 빛나는 밤에)라는 그림과 풍경 사진을 합성해서 반 고흐가 그린 것 같은 스타일의 풍경 이미지를 만들었고, &lt;a href=&#34;https://prisma-ai.com/&#34;&gt;프리즈마&lt;/a&gt;등의 앱은 이 알고리즘을 빠르게 탑재해서 인기를 끌었습니다.&lt;/p&gt;
&lt;p&gt;본 포스트에서는 텍스처 합성에 대해 알아본 뒤 2장의 이미지에서 각각 스타일과 내용을 가져와서 합성하는 신경 스타일 전이에 대해 다루도록 합니다.&lt;/p&gt;
&lt;h2 id=&#34;ii-컨볼루션-신경망을-사용한-신경-스타일-전이&#34;&gt;II. 컨볼루션 신경망을 사용한 신경 스타일 전이&lt;/h2&gt;
&lt;p&gt;신경 스타일 전이는 지난 시간에 배운 &lt;code&gt;Gram Matrix&lt;/code&gt;를 이용해서 텍스처 합성에 한가지를 추가한 것입니다. 바로 &lt;code&gt;content&lt;/code&gt; 텍스처입니다.&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;먼저, 타깃 텍스처를 만들기 위해서 &lt;code&gt;style&lt;/code&gt; 텍스처와 &lt;code&gt;Gram Matrix&lt;/code&gt;의 &lt;code&gt;MSE&lt;/code&gt;를 구합니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Content&lt;/code&gt; 텍스처와는 픽셀 값의 차이인 &lt;code&gt;MSE&lt;/code&gt;를 구합니다.&lt;/li&gt;
&lt;li&gt;여기서 사용하는 특징 추출값을 위한 레이어는 서로 다르게 설정할 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;그 외의 이론적인 내용은 319-320 페이지를 참조하시기를 바랍니다.&lt;/p&gt;
&lt;h3 id=&#34;1-원본-텍스처-불러오기&#34;&gt;(1) 원본 텍스처 불러오기&lt;/h3&gt;
&lt;p&gt;먼저 &lt;code&gt;content&lt;/code&gt; 원본 텍스처를 불러옵니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 텐서플로 2 버전 선택&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
    &lt;span style=&#34;color:#75715e&#34;&gt;# %tensorflow_version only exists in Colab.&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;tensorflow_version &lt;span style=&#34;color:#ae81ff&#34;&gt;2.&lt;/span&gt;x
&lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Exception&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;pass&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow_hub &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; hub
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; cv2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;2-첫번째-이미지-타깃-텍스쳐-함수-정의-및-실행&#34;&gt;(2) 첫번째 이미지 타깃 텍스쳐 함수 정의 및 실행&lt;/h3&gt;
&lt;p&gt;이전 시간에 배웠던 내용의 전체코드가 필요합니다. 복습을 하면서 다시한번 실습하기를 바랍니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;style_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;style.jpg&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://bit.ly/2mGfZIq&amp;#39;&lt;/span&gt;)

style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(style_path)
style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(style_image, dsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;))
style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; style_image &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(style_image)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;matplotlib.image.AxesImage at 0x7fe1d74332e8&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_03_2/output_7_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;합성 하려고 하는 첫번째 사진입니다.&lt;/p&gt;
&lt;h3 id=&#34;3-함수-정의&#34;&gt;(3) 함수 정의&lt;/h3&gt;
&lt;p&gt;아래와 같이 함수를 정의합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Gram Matrix 함수 정의&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;gram_matrix&lt;/span&gt;(input_tensor):
    channels &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(input_tensor&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
    a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(input_tensor, [&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, channels])
    n &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape(a)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
    gram &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;matmul(a, a, transpose_a&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; gram &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(n, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)

&lt;span style=&#34;color:#75715e&#34;&gt;# 타깃 텍스처 gram matrix 함수 정의&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_outputs&lt;/span&gt;(image):
    image_batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(image, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
    output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model(preprocess_input(image_batch &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;))
    outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [gram_matrix(out) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; out &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; output]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; outputs

&lt;span style=&#34;color:#75715e&#34;&gt;# MSE 구하는 함수 (원본 텍스처 gram matrix - 타깃 텍스처 gram matrix)&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_loss&lt;/span&gt;(outputs, style_outputs):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_sum([tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_mean((o&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;s)&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; o,s &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(outputs, style_outputs)])
  
&lt;span style=&#34;color:#75715e&#34;&gt;# 0.0~1.0 사이의 컬러값 정의 함수&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clip_0_1&lt;/span&gt;(image):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clip_by_value(image, clip_value_min&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.0&lt;/span&gt;, clip_value_max&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# variation loss 함수 정의&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;high_pass_x_y&lt;/span&gt;(image):
  x_var &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; image[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:, :] &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; image[:, :&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, :]
  y_var &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; image[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:, :, :] &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; image[:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, :, :]
  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; x_var, y_var

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;total_variation_loss&lt;/span&gt;(image):
  x_deltas, y_deltas &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; high_pass_x_y(image)
  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_mean(x_deltas&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_mean(y_deltas&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;4-원본-텍스처에-대한-gram-matrix-계산&#34;&gt;(4) 원본 텍스처에 대한 &lt;code&gt;Gram Matrix&lt;/code&gt; 계산&lt;/h3&gt;
&lt;p&gt;자세한 설명은 이전 포스트를 참조합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 특징 추출 모델 만들기&lt;/span&gt;
vgg &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; VGG19(include_top&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False, weights&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;imagenet&amp;#39;&lt;/span&gt;)
style_layers &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;block1_conv1&amp;#39;&lt;/span&gt;, 
                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;block2_conv1&amp;#39;&lt;/span&gt;, 
                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;block3_conv1&amp;#39;&lt;/span&gt;, 
                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;block4_conv1&amp;#39;&lt;/span&gt;, 
                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;block5_conv1&amp;#39;&lt;/span&gt;]
vgg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trainable &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; False
outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [vgg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_layer(name)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;output &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; name &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; style_layers]
model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Model([vgg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;input], outputs)

&lt;span style=&#34;color:#75715e&#34;&gt;# 원본 텍스처에서 Gram Matrix 계산&lt;/span&gt;
style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(style_path)
style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(style_image, dsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;))
style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; style_image &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;

style_batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; style_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;)
style_batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(style_batch, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
style_output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model(preprocess_input(style_batch &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;))

style_outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [gram_matrix(out) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; out &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; style_output]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;5-content-이미지-확인&#34;&gt;(5) Content 이미지 확인&lt;/h3&gt;
&lt;p&gt;합성할 &lt;code&gt;Content&lt;/code&gt; 이미지를 다운로드 받습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;content_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;content.jpg&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://bit.ly/2mAfUX1&amp;#39;&lt;/span&gt;)

content_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(content_path)
max_dim &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;512&lt;/span&gt;
long_dim &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; max(content_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
scale &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; max_dim &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; long_dim
new_height &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(content_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; scale)
new_width &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(content_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; scale)

content_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(content_image, dsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(new_width, new_height))
content_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; content_image &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;))
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(content_image)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;matplotlib.image.AxesImage at 0x7fe3aa115ef0&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_03_2/output_14_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;여기에서 가로와 세로 중 가장 긴 축을 512 픽셀에 맞춰서 리사이즈 합니다. &lt;code&gt;VGG-19&lt;/code&gt; 네트워크는 32보다 큰 이미지는 모두 받을 수 있기 때문에 적절한 퍼포먼스를 유지하기 위해 적당히 크게 설정합니다.&lt;/p&gt;
&lt;p&gt;여기서 주의해야 할 점은 &lt;code&gt;content&lt;/code&gt; 텍스처와 타깃 텍스처의 크기가 같아야 한다는 점입니다. 이 둘은 서로 특징 추출값의 픽셀을 &lt;code&gt;MSE&lt;/code&gt;로 비교하기 때문에 크기가 다르면 안됩니다. 반면 &lt;code&gt;style&lt;/code&gt; 텍스처는 타깃 텍스처와 크기가 달라도 상관없습니다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Gram Matrix&lt;/code&gt; 계산값은 각 레이어의 &lt;code&gt;[채널 수]X[채널 수]&lt;/code&gt;만큼의 값을 서로 비교하기 때문입니다.&lt;/p&gt;
&lt;h3 id=&#34;6-content-특징-추출-모델-만들기&#34;&gt;(6) &lt;code&gt;content&lt;/code&gt; 특징 추출 모델 만들기&lt;/h3&gt;
&lt;p&gt;이제 &lt;code&gt;content&lt;/code&gt;의 특징을 추출하기 위한 모델을 만들어야 하는데, 모델을 정의하는 방식은 다음과 같습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;content_batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; content_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;)
content_batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(content_batch, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)

content_layers&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;block5_conv2&amp;#39;&lt;/span&gt;]

vgg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trainable &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; False
outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [vgg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_layer(name)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;output &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; name &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; content_layers]
model_content &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Model([vgg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;input], outputs)
content_output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model_content(preprocess_input(content_batch &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;content&lt;/code&gt;특징 추출을 위해 선택한 레이어는 &lt;code&gt;block5_conv1&lt;/code&gt; 바로 뒤에 있는 &lt;code&gt;block5_conv2&lt;/code&gt; 레이어입니다. 위에서 &lt;code&gt;style&lt;/code&gt; 특징을 추출하는 모델과 별도의 모델을 만들어서 &lt;code&gt;model_content&lt;/code&gt;에 저장하고, 이 모델을 사용해 &lt;code&gt;content&lt;/code&gt; 텍스처에서 미리 특징을 추출해서 &lt;code&gt;content_output&lt;/code&gt; 변수에 저장합니다. &lt;code&gt;style_outputs&lt;/code&gt;처럼 이 값도 여기서 한 번만 계산해놓으면 바뀌지 않고 계속 사용됩니다.&lt;/p&gt;
&lt;h3 id=&#34;7-타깃-텍스처-업데이트-함수-정의&#34;&gt;(7) 타깃 텍스처 업데이트 함수 정의&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;먼저, 타깃 텍스처에서 &lt;code&gt;gram matrix&lt;/code&gt;을 구하는 함수가 필요합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;MSE&lt;/code&gt;를 구하는 함수가 필요한데, 원본 텍스처의 &lt;code&gt;Gram Matrix&lt;/code&gt; 값과, 타깃 텍스처의 &lt;code&gt;Gram Matrix&lt;/code&gt; 사이의 MSE 함수가 필요합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이 때, &lt;code&gt;MSE&lt;/code&gt; 값이 0.0에서 1.0사이의 컬러 값이어야 하기 때문에 그 이하나 이상으로 값이 넘어가지 않도록 해주는 함수가 필요합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 타깃 텍스처 gram matrix 함수 정의&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;gram_matrix&lt;/span&gt;(input_tensor):
    channels &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(input_tensor&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
    a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(input_tensor, [&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, channels])
    n &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape(a)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
    gram &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;matmul(a, a, transpose_a&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; gram &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(n, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_outputs&lt;/span&gt;(image):
    image_batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(image, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
    output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model(preprocess_input(image_batch &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;))
    outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [gram_matrix(out) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; out &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; output]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; outputs

&lt;span style=&#34;color:#75715e&#34;&gt;# MSE 구하는 함수 (원본 텍스처 gram matrix - 타깃 텍스처 gram matrix)&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_loss&lt;/span&gt;(outputs, style_outputs):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_sum([tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_mean((o&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;s)&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; o,s &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(outputs, style_outputs)])
  
&lt;span style=&#34;color:#75715e&#34;&gt;# 0.0~1.0 사이의 컬러값 정의 함수&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clip_0_1&lt;/span&gt;(image):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clip_by_value(image, clip_value_min&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.0&lt;/span&gt;, clip_value_max&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;8-content-output-loss-함수-정의&#34;&gt;(8) content output, loss 함수 정의&lt;/h3&gt;
&lt;p&gt;이제 &lt;code&gt;style&lt;/code&gt;에서 했던 것처럼 &lt;code&gt;content&lt;/code&gt; 전용의 &lt;code&gt;output&lt;/code&gt;과 &lt;code&gt;loss&lt;/code&gt; 함수를 정의합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_content_output&lt;/span&gt;(image):
  image_batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(image, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
  output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model_content(preprocess_input(image_batch &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;))
  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; output

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_content_loss&lt;/span&gt;(image, content_output):
  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_sum(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_mean(image&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;content_output)&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# 0.0~1.0 사이의 컬러값 정의 함수&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clip_0_1&lt;/span&gt;(image):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clip_by_value(image, clip_value_min&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.0&lt;/span&gt;, clip_value_max&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;get_content_loss&lt;/code&gt;함수에서는 타깃 텍스처와 &lt;code&gt;content&lt;/code&gt; 텍스처의 &lt;code&gt;MSE&lt;/code&gt;를 구합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;9-content-loss-손실-계산식에-추가&#34;&gt;(9) Content loss 손실 계산식에 추가&lt;/h3&gt;
&lt;p&gt;이제, &lt;code&gt;content loss&lt;/code&gt;를 계산식에 추가하고, 모델의 하이퍼파라미터인 &lt;code&gt;Adam Optimizer&lt;/code&gt;의 학습률과 각 &lt;code&gt;loss&lt;/code&gt;의 가중치들을 신경 스타일 전이 과제에 맞게 조정합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;opt &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(learning_rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.001&lt;/span&gt;, beta_1&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.99&lt;/span&gt;, epsilon&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1e-1&lt;/span&gt;)

total_variation_weight &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1e9&lt;/span&gt;
style_weight &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1e-2&lt;/span&gt;
content_weight &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1e4&lt;/span&gt;

&lt;span style=&#34;color:#a6e22e&#34;&gt;@tf.function&lt;/span&gt;()
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;train_step&lt;/span&gt;(image):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;GradientTape() &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tape:
        outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_outputs(image)
        output2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_content_output(image)
        loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; style_weight &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; get_loss(outputs, style_outputs)
        loss &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; content_weight &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; get_content_loss(output2, content_output)
        loss &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; total_variation_weight &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; total_variation_loss(image)

    grad &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tape&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gradient(loss, image)
    opt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply_gradients([(grad, image)])
    image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;assign(clip_0_1(image))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;10-신경-스타일-전이-알고리즘-직접-실행&#34;&gt;(10) 신경 스타일 전이 알고리즘 직접 실행&lt;/h3&gt;
&lt;p&gt;이제 신경 스타일 전이 알고리즘을 직접 실행해보겠습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; IPython.display &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; display
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; time
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; imageio

start &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time()

&lt;span style=&#34;color:#75715e&#34;&gt;# target_image = tf.random.uniform(content_image.shape)&lt;/span&gt;
image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Variable(content_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;))

epochs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;
steps_per_epoch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;

step &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(epochs):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; m &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(steps_per_epoch):
        step &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
        train_step(image)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;.&amp;#34;&lt;/span&gt;, end&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; epochs &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:
        imageio&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imwrite(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;style_{0}_content_{1}_transfer_epoch_{2}.png&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(style_weight, content_weight, n), image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_value()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy())
    display&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clear_output(wait&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;))
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_value())
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Train step: {}&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(step))
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

end &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time()
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Total time: {:.1f}&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(end&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;start))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_03_2/output_27_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Total time: 123.6
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;option-그림-824-원본-소스코드&#34;&gt;Option, 그림 8.24 원본 소스코드&lt;/h2&gt;
&lt;p&gt;그림 8.24(교재 299p)에서는 첫 번째 레이어에서 활성화되는 64개 뉴런의 특징 추출값을 모두 표시했습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(style_path)
style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(style_image, dsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;))
style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; style_image &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;

style_batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; style_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;)
style_batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(style_batch, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
style_output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model(preprocess_input(style_batch &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;))

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;))

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(style_output[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]):
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(style_output[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][:,:,:,c], &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;), cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_03_2/output_29_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;iii-연습-파일&#34;&gt;III. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch8_3_2_neural_style_transfer.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;vi-reference&#34;&gt;VI. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_3_1_texture_synthesis/&#34;&gt;Tensorflow 2.0 Tutorial ch8.3.1 - 컨볼루션 신경망을 사용한 텍스처 합성&lt;/a&gt; 에서 &lt;code&gt;Gram Matrix&lt;/code&gt;에 대해 다뤘다. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch8.3.1 - 컨볼루션 신경망을 사용한 텍스처 합성</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch8_3_1_texture_synthesis/</link>
      <pubDate>Fri, 01 May 2020 17:20:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch8_3_1_texture_synthesis/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.2 - 다항분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/&#34;&gt;Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/&#34;&gt;Tensorflow 2.0 Tutorial ch6.1-2 - CNN 이론&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_3_fashion_mnist_with_cnn/&#34;&gt;Tensorflow 2.0 Tutorial ch6.3 - Fashion MNIST with CNN 실습&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_4_improve_performance/&#34;&gt;Tensorflow 2.0 Tutorial ch6.4 - 모형의 성능 높이기&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (1)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (2)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_3_sentimentanalysis/&#34;&gt;Tensorflow 2.0 Tutorial ch7.3 - 긍정, 부정 감성 분석&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (1) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (2) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_1_tensorflow_hub/&#34;&gt;Tensorflow 2.0 Tutorial ch8.1 - 텐서플로 허브&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_2_transfer_learning/&#34;&gt;Tensorflow 2.0 Tutorial ch8.2 - 전이 학습과 &amp;amp; Kaggle 대회&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요&#34;&gt;I. 개요&lt;/h2&gt;
&lt;p&gt;2015년, 딥러닝과 예술의 만남으로 큰 화제가 되었던 신경 스타일 전이 논문&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;은 반 고흐의 (별이 빛나는 밤에)라는 그림과 풍경 사진을 합성해서 반 고흐가 그린 것 같은 스타일의 풍경 이미지를 만들었고, &lt;a href=&#34;https://prisma-ai.com/&#34;&gt;프리즈마&lt;/a&gt;등의 앱은 이 알고리즘을 빠르게 탑재해서 인기를 끌었습니다.&lt;/p&gt;
&lt;p&gt;본 포스트에서는 텍스처 합성에 대해 알아본 뒤 2장의 이미지에서 각각 스타일과 내용을 가져와서 합성하는 신경 스타일 전이에 대해 다루도록 합니다.&lt;/p&gt;
&lt;h2 id=&#34;ii-컨볼루션-신경망을-사용한-텍스처-합성&#34;&gt;II. 컨볼루션 신경망을 사용한 텍스처 합성&lt;/h2&gt;
&lt;p&gt;텍스처(Texture)는 넓은 의미로는 단순히 이미지만, 컴퓨터 비전에서 쓰이는 좁은 의미로는 지역적으로는 비교적 다양한 값을 가지면서 전체적으로는 비슷한 모습을 보이는 이미지를 뜻합니다.&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;돌, 나무, 구름, 섬유 등의 텍스처에서는 위 조건에 해당하는 일정한 패턴을 관찰할 수 있으며, 이 패턴은 전체적으로 비슷하면서도 지역적으로는 서로 조금씩 다릅니다.&lt;/p&gt;
&lt;h3 id=&#34;1-텍스처-합성-방법론&#34;&gt;(1) 텍스처 합성 방법론&lt;/h3&gt;
&lt;p&gt;텍스처 합성 방법론은 크게 두가지입니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;첫번째, 픽셀이나 이미지를 잘게 쪼갠 단위인 &lt;code&gt;Patch&lt;/code&gt;(조각)을 재배열하는 방법입니다. Patch Match 알고리즘을 최적화한 버전입니다.&lt;/li&gt;
&lt;li&gt;두번째, 파라미터에 의한 텍스처 모델링입니다. 먼저 원본 텍스처의 공간적인 통계값(Spatial Statistics)을 사람이 정교하게 만든 여러 개의 필터로 구합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;특히, 교재는 필터 부분을 딥러닝이 가장 제일 잘하는 것으로 설명하고 있고, 여기에 관한 그림 및 이론적인 설명으로 297-300페이제 걸쳐서 설명을 하고 있습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;주요 논문은 &lt;a href=&#34;https://papers.nips.cc/paper/5633-texture-synthesis-using-convolutional-neural-networks.pdf&#34;&gt;Texture Synthesis Using Convolutional Neural Networks&lt;/a&gt; 입니다.&lt;/li&gt;
&lt;li&gt;Gram Matrix을 활용합니다.&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;이 부분은 교재를 참고하시기를 바랍니다.&lt;/p&gt;
&lt;h3 id=&#34;2-원본-텍스처-이미지-불러오기&#34;&gt;(2) 원본 텍스처 이미지 불러오기&lt;/h3&gt;
&lt;p&gt;이제 실습 코드로 진행해봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 텐서플로 2 버전 선택&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
    &lt;span style=&#34;color:#75715e&#34;&gt;# %tensorflow_version only exists in Colab.&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;tensorflow_version &lt;span style=&#34;color:#ae81ff&#34;&gt;2.&lt;/span&gt;x
&lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Exception&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;pass&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow_hub &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; hub

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; cv2

style_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;style.jpg&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://bit.ly/2mGfZIq&amp;#39;&lt;/span&gt;)
style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(style_path)
style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(style_image, dsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;))
style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; style_image &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(style_image)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from http://bit.ly/2mGfZIq
344064/337723 [==============================] - 0s 0us/step





&amp;lt;matplotlib.image.AxesImage at 0x7fbf05a4b668&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_03_1/output_6_2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;tf.keras.utils.get_file()&lt;/code&gt; 함수로 파일을 다운로드한 뒤에 &lt;code&gt;OpenCV&lt;/code&gt;로 이미지의 크기를 (224, 224)로 조정합니다. 더 큰 크기로 지정해도 상관없지만 일단은 작은 크기에서 어떻게 동작하는지 확인해보고, 큰 크기의 이미지는 다음 절의 신경 스타일 전이에서 시도합니다.&lt;/p&gt;
&lt;h3 id=&#34;3-타깃-텍스처-만들기&#34;&gt;(3) 타깃 텍스처 만들기&lt;/h3&gt;
&lt;p&gt;그 다음으로는 타깃 텍스처로 사용할 이미지를 만듭니다. 타깃 텍스처는 랜덤 노이즈 이미지에서 시작하며, 랜덤 노이지를 만드는 방법 &lt;code&gt;3.3.1&lt;/code&gt;절의 난수생성에서 배운 걸 응용합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;target_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uniform(style_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(target_image[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,:])

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(target_image)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;tf.Tensor([0.06687331 0.9121063  0.9395486 ], shape=(3,), dtype=float32)





&amp;lt;matplotlib.image.AxesImage at 0x7fbf055b5eb8&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_03_1/output_9_2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;style_image&lt;/code&gt;와 같은 차원을 가지는 랜덤 노이즈를 생성합니다. 컬러 이미지이기 때문에 차원 수는 (224, 224, 3)으로 마지막에 &lt;code&gt;RGB&lt;/code&gt; 차원을 나타내는 3이 붙습니다. 타깃 텍스처의 첫 번째 픽셀(좌측 최상단)의 값을 출력해보면 0~1 사이의 &lt;code&gt;RGB&lt;/code&gt;컬러 값을 확인할 수 있습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras.applications &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; VGG19
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras.applications.vgg19 &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; preprocess_input

vgg &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; VGG19(include_top&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False, weights&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;imagenet&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; layer &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; vgg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers:
  &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(layer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;name)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5
80142336/80134624 [==============================] - 2s 0us/step
input_1
block1_conv1
block1_conv2
block1_pool
block2_conv1
block2_conv2
block2_pool
block3_conv1
block3_conv2
block3_conv3
block3_conv4
block3_pool
block4_conv1
block4_conv2
block4_conv3
block4_conv4
block4_pool
block5_conv1
block5_conv2
block5_conv3
block5_conv4
block5_pool
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;전체 네트워크를 불러올 필요가 없이 때문에 &lt;code&gt;include_top&lt;/code&gt;인수를 &lt;code&gt;False&lt;/code&gt;로 지정해서 마지막의 &lt;code&gt;Dense&lt;/code&gt;레이어를 제외한 나머지 레이어를 불러와 &lt;code&gt;vgg&lt;/code&gt; 변수에 저장합니다. &lt;code&gt;vgg&lt;/code&gt; 변수에 저장된 네트워크에는 특징 추출기의 역할을 하는 컨볼루션 레이어와 풀링 레이어를 포함하고 있습니다. 이 중에서 선택적으로 사용할수도 있지만, &lt;code&gt;Gram Matrix&lt;/code&gt;가 지역적인 구조와 전체적인 구조를 모두 잡아낼 수 있도록 앞쪽과 뒤쪽의 레이어를 모두 사용하는 것이 좋습니다.&lt;/p&gt;
&lt;h3 id=&#34;4-특징-추출-모델-만들기&#34;&gt;(4) 특징 추출 모델 만들기&lt;/h3&gt;
&lt;p&gt;위 내용을 기반으로 특징 추출 모델을 만들어보도록 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;style_layers &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;block1_conv1&amp;#39;&lt;/span&gt;, 
                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;block2_conv1&amp;#39;&lt;/span&gt;, 
                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;block3_conv1&amp;#39;&lt;/span&gt;, 
                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;block4_conv1&amp;#39;&lt;/span&gt;, 
                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;block5_conv1&amp;#39;&lt;/span&gt;]

vgg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trainable &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; False
outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [vgg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_layer(name)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;output &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; name &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; style_layers]
model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Model([vgg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;input], outputs)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;위 코드는 이미지를 입력하면 다섯 개의 레이어에서 출력되는 특징 추출값을 얻을 수 있는 모델입니다.&lt;/li&gt;
&lt;li&gt;이 모델은 &lt;code&gt;model&lt;/code&gt;이라는 변수에 저장합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;5-gram-matrix-함수-정의&#34;&gt;(5) Gram Matrix 함수 정의&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Gram Matrix&lt;/code&gt;를 계산하는 함수를 정의합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;gram_matrix&lt;/span&gt;(input_tensor):
    channels &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(input_tensor&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
    a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(input_tensor, [&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, channels])
    n &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape(a)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
    gram &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;matmul(a, a, transpose_a&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; gram &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(n, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;먼저 입력된 특징 추출값의 형태를 벡터로 변환시킵니다. 예를 들어, 첫 번째 레이어인 &lt;code&gt;block1_conv1&lt;/code&gt;를 통과한 특정 추출값의 차원 수는 (224, 224, 64)입니다.&lt;/li&gt;
&lt;li&gt;이것을 맨 뒤의 차원(채널)인 64만 남기고 나머지를 1차원의 벡터로 만들면 차원 수는 (50176, 64)가 됩니다.&lt;/li&gt;
&lt;li&gt;이렇게 만든 행렬은 자기 자신의 전치행렬과 행렬곱하는 부분은 &lt;code&gt;gram = tf.matmul(a, a, transpose_a = True)&lt;/code&gt;입니다. &lt;code&gt;transpose_a&lt;/code&gt;라는 인수에 &lt;code&gt;True&lt;/code&gt;값을 넣어서 행렬곱을 할 때 전치행렬을 자동으로 만들어서 계산해도 됩니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;transpose_a&lt;/code&gt;가 &lt;code&gt;True&lt;/code&gt;이기 때문에 행렬곱 계산 결과의 차원은 &lt;code&gt;[64,50176]X[50176,64] = [64,64]&lt;/code&gt;가 됩니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;(224, 224, 64)&lt;/code&gt;가 &lt;code&gt;[64, 64]&lt;/code&gt;로 줄어듭니다.&lt;/li&gt;
&lt;li&gt;마지막 &lt;code&gt;return&lt;/code&gt;문에서는 1차원 벡터의 길이인 &lt;code&gt;50,176&lt;/code&gt;으로 &lt;code&gt;Gram Matrix&lt;/code&gt;값을 나눕니다.&lt;/li&gt;
&lt;li&gt;이렇게 나누지 않으면 앞쪽에 오는 레이어일수록 특징 추출값의 이미지가 크기 때문에 &lt;code&gt;Gram Matrix&lt;/code&gt;값도 커져서 큰 영향을 줍니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;6-원본-텍스처에서-gram-matrix-계산&#34;&gt;(6) 원본 텍스처에서 Gram Matrix 계산&lt;/h3&gt;
&lt;p&gt;원본 텍스처에서 &lt;code&gt;Gram Matrix&lt;/code&gt; 계산합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(style_path)
style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(style_image, dsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;))
style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; style_image &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;

style_batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; style_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;)
style_batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(style_batch, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
style_output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model(preprocess_input(style_batch &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;style_output&lt;/code&gt;은 다섯 레이어를 통과한 특징 추출값으로 구성되어 있습니다. 그중 하나를 &lt;code&gt;matplotlib.pyplot&lt;/code&gt;으로 출력합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(style_output[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(style_output[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][:,:,:,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;), cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;(1, 224, 224, 64)





&amp;lt;matplotlib.image.AxesImage at 0x7fbef01cf5f8&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_03_1/output_21_2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;특징 추출값 [1, 224, 224, 64]을 확인할 수 있습니다. 이렇게 처리된 원본 텍스처의 &lt;code&gt;Gram Matrix&lt;/code&gt;값을 계산합니다. 또 값이 어떻게 나오는지 그래프로 분포를 확인해봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;style_outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [gram_matrix(out) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; out &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; style_output]

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;):
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    array &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sorted(style_outputs[c]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tolist())
    array &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; array[::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;bar(range(style_outputs[c]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]), array)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(style_layers[c])
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_03_1/output_23_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Gram Matrix&lt;/code&gt; 값은 레이어마다 다르게 나오고 최대값에서도 차이가 나는 것을 확인할 수 있습니다. 즉, 이 말은 각 레이어에서 계산되는 &lt;code&gt;Gram Matrix&lt;/code&gt;값에 가중치를 곱해주는 방법으로 특정한 레이어가 너무 큰 영향을 끼치지 못하도록 제어를 해야 합니다.&lt;/p&gt;
&lt;p&gt;따라서, 타깃 텍스처를 업데이트 하기 위해 몇 가지 함수를 설정해야 합니다.&lt;/p&gt;
&lt;h3 id=&#34;7-타깃-텍스처-업데이트-함수-정의&#34;&gt;(7) 타깃 텍스처 업데이트 함수 정의&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;먼저, 타깃 텍스처에서 &lt;code&gt;gram matrix&lt;/code&gt;을 구하는 함수가 필요합니다.&lt;/li&gt;
&lt;li&gt;MSE를 구하는 함수가 필요한데, 원본 텍스처의 Gram Matrix 값과, 타깃 텍스처의 Gram Matrix 사이의 &lt;code&gt;MSE&lt;/code&gt; 함수가 필요합니다.&lt;/li&gt;
&lt;li&gt;이 때, MSE 값이 0.0에서 1.0사이의 컬러 값이어야 하기 때문에 그 이하나 이상으로 값이 넘어가지 않도록 해주는 함수가 필요합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 타깃 텍스처 gram matrix 함수 정의&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_outputs&lt;/span&gt;(image):
    image_batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(image, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
    output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model(preprocess_input(image_batch &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;))
    outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [gram_matrix(out) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; out &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; output]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; outputs

&lt;span style=&#34;color:#75715e&#34;&gt;# MSE 구하는 함수 (원본 텍스처 gram matrix - 타깃 텍스처 gram matrix)&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_loss&lt;/span&gt;(outputs, style_outputs):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_sum([tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_mean((o&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;s)&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; o,s &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(outputs, style_outputs)])
  
&lt;span style=&#34;color:#75715e&#34;&gt;# 0.0~1.0 사이의 컬러값 정의 함수&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clip_0_1&lt;/span&gt;(image):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clip_by_value(image, clip_value_min&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.0&lt;/span&gt;, clip_value_max&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;8-이미지-업데이트-함수-정의&#34;&gt;(8) 이미지 업데이트 함수 정의&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;지금까지 배워온 딥러닝과의 차이점&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;tf.keras를 이용해 모델 정의하고 &lt;code&gt;fit()&lt;/code&gt; 함수를 이용해 가중치가 주어진 과제를 잘 수행하도록 하는 것&lt;/li&gt;
&lt;li&gt;그런데, 이번 포스트에서는 학습해야 할 가중치가 존재하지 않음&lt;/li&gt;
&lt;li&gt;존재하는 것은 2개의 이미지와 &lt;code&gt;Gram Matrix&lt;/code&gt;의 차이인 MSE 뿐&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;GradientType&lt;/code&gt;은 이런 상황에 대한 간편한 해결책임. 자동 미분을 통해 입력에 대한 손실을 구한 뒤 다른 변수에 대한 &lt;code&gt;Gradient(기울기)&lt;/code&gt;를 계산함. 여기에서 다른 변수는 입력이 될 수도 있고, 가중치가 될 수도 있음.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;중요한 점은 &lt;code&gt;GradientType&lt;/code&gt;의 계산 과정 안에 묶인 변수에 대한 &lt;code&gt;Gradient&lt;/code&gt;여야 함.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;opt &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(learning_rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, beta_1&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.99&lt;/span&gt;, epsilon&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1e-1&lt;/span&gt;)

&lt;span style=&#34;color:#a6e22e&#34;&gt;@tf.function&lt;/span&gt;()
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;train_step&lt;/span&gt;(image):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;GradientTape() &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tape:
        outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_outputs(image)
        loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_loss(outputs, style_outputs)

    grad &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tape&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gradient(loss, image)
    opt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply_gradients([(grad, image)])
    image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;assign(clip_0_1(image))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;첫 줄에서 최적화 함수(&lt;code&gt;optimizer&lt;/code&gt;)를 정의함. 논문에서는 &lt;code&gt;L-BFGS&lt;/code&gt;라는 최적화 함수를 썼지만, &lt;code&gt;Adam Optimizer&lt;/code&gt;를 사용해도 속도는 더 빠르고 결과물은 비슷하게 나옵니다.&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;tf.function()&lt;/code&gt; 함수는 &lt;code&gt;train_step(image)&lt;/code&gt; 함수를 인수로 받아서 &lt;code&gt;Autograph&lt;/code&gt;라는 강력한 기능을 추가합니다. &lt;code&gt;Autograph&lt;/code&gt;는 파이썬 문법으로 텐서플로의 핵심인 그래프(&lt;code&gt;Graph&lt;/code&gt;)를 컨트롤 할 수 있게 해줍니다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;2.0&lt;/code&gt; 버전을 위해 즉시 실행 모드(&lt;code&gt;Eager Execution&lt;/code&gt;)와 &lt;code&gt;tf.function&lt;/code&gt; 장식자가 나오면서 이런 불편함이 개선됩니다. &lt;code&gt;tf.function&lt;/code&gt;은 해당 장식자를 사용한 함수에서 호출되는 다른 함수도 그래프에 자동으로 포함시킵니다. 그리고 &lt;code&gt;GradientTape&lt;/code&gt;은 계산에 관계되는 모든 변수와 연산을 추적하기 때문에 퍼포먼스에 영향을 주는데 &lt;code&gt;tf.function&lt;/code&gt;장식자를 붙이면 이 연산들을 고성능의 그래프 연산으로 변환하기 때문에 퍼포먼스를 개선할 수 있습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;GradientTape() &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tape:
  outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_outputs(image)
  loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_loss(outputs, style_outputs)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;GradientTape()&lt;/code&gt;는 보통 &lt;code&gt;with&lt;/code&gt;와 함께 사용합니다. &lt;code&gt;tape&lt;/code&gt;라는 이름으로 새로운 &lt;code&gt;GradientTape&lt;/code&gt;의 인스턴스를 생성해서 참조합니다. 앞에서 설명한대로 &lt;code&gt;get_outputs(image)&lt;/code&gt;, &lt;code&gt;get_loss(outputs, style_outputs)&lt;/code&gt; 함수는 &lt;code&gt;tf.function&lt;/code&gt; 장식자를 쓰지 않았지만, 호출한 함수에 장식자가 붙었기 때문에 텐서플로의 그래프에 자동으로 포함됩니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;grad &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tape&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gradient(loss, image)
opt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply_gradients([(grad, image)])
image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;assign(clip_0_1(image))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;tape.gradient(loss, image)&lt;/code&gt;는 &lt;code&gt;with&lt;/code&gt; 구문 안에서 발생한 계산을 추적해서 입력값인 &lt;code&gt;image&lt;/code&gt;에 대한 &lt;code&gt;loss&lt;/code&gt;의 &lt;code&gt;gradient&lt;/code&gt;를 계산합니다.&lt;/li&gt;
&lt;li&gt;이렇게 계산된 &lt;code&gt;gradient&lt;/code&gt;는 변수 &lt;code&gt;grad&lt;/code&gt;에 저장되고 &lt;code&gt;Adam Optimizer&lt;/code&gt;를 통해 &lt;code&gt;image&lt;/code&gt;에 영향을 줍니다. 즉, 입력값인 &lt;code&gt;image&lt;/code&gt;는 이 계산으로 변화가 됩니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;clip_0_1(image)&lt;/code&gt;함수의 계산 결과를 &lt;code&gt;image&lt;/code&gt;에 다시 넣어서 컬러값이 &lt;code&gt;0.0&lt;/code&gt;과 &lt;code&gt;1.0&lt;/code&gt; 사이에 머물게 합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;9-텍스처-합성-알고리즘-실행&#34;&gt;(9) 텍스처 합성 알고리즘 실행&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;이제 앞에서 정의한 &lt;code&gt;train_step(image)&lt;/code&gt; 함수를 반복적으로 실행해서 텍스처를 합성합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; IPython.display &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; display
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; time
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; imageio

start &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time()

image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Variable(target_image)

epochs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;
steps_per_epoch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;

step &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(epochs):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; m &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(steps_per_epoch):
        step &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
        train_step(image)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; epochs &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:
        imageio&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imwrite(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;style_epoch_{0}.png&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(n), image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_value()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy())
    display&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clear_output(wait&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_value())
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Train step: {}&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(step))
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

end &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time()
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Total time: {:.1f}&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(end&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;start))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_03_1/output_32_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Total time: 119.2
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;먼저 첫 줄에서는 새로운 텍스처 출력을 나타내고 이전 이전 텍스처 출력을 지우기 위해 &lt;code&gt;IPython.display&lt;/code&gt;에서 &lt;code&gt;display&lt;/code&gt;를 임포트합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;실행 시간을 추적하기 위해 &lt;code&gt;time&lt;/code&gt;을, 합성된 텍스처 이미지를 저장하기 위해 &lt;code&gt;imageio&lt;/code&gt;를 import 합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Variable(target_image)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;타깃 텍스처에 &lt;code&gt;tf.Variable&lt;/code&gt;을 씌워서 &lt;code&gt;image&lt;/code&gt;라는 변수로 저장합니다. 텐서플로에서 그래프 연산을 하는 &lt;code&gt;tensor&lt;/code&gt;는 &lt;code&gt;tf.Variable&lt;/code&gt;이나 &lt;code&gt;tf.Constant&lt;/code&gt; 등에 저장되어야 합니다. (&lt;code&gt;tf.keras&lt;/code&gt;)에서는 넘파이 &lt;code&gt;array&lt;/code&gt;를 넘겨도 자동으로 이런 변환을 해줬지만 여기서는 직접 해야 합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;중첩 for 문에서는 에포크당 100 step씩 train_step(image)함수를 실행시킵니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;10-variation-loss-함수-정의&#34;&gt;(10) variation loss 함수 정의&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;매끄러운 원본과 달리 자글자글한 노이즈가 보입니다. 이러한 이미지에 생기는 노이즈를 개선하기 위해서 전체 손실에 &lt;code&gt;variation loss&lt;/code&gt;라는 것을 추가해볼 수 있습니다. &lt;code&gt;variation loss&lt;/code&gt;란 어떤 픽셀과 바로 옆에 인접한 픽셀의 차이입니다. 이 차이가 작을수록 이미지는 매끄럽게 보입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;high_pass_x_y&lt;/span&gt;(image):
  x_var &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; image[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:, :] &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; image[:, :&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, :]
  y_var &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; image[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:, :, :] &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; image[:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, :, :]
  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; x_var, y_var

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;total_variation_loss&lt;/span&gt;(image):
  x_deltas, y_deltas &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; high_pass_x_y(image)
  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_mean(x_deltas&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_mean(y_deltas&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;high_pass_x_y(image)&lt;/code&gt; 함수에서는 입력된 &lt;code&gt;image&lt;/code&gt;의 &lt;code&gt;x축 방향&lt;/code&gt;과 &lt;code&gt;y축 방향&lt;/code&gt;의 차이를 구합니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;x_var&lt;/code&gt;는 &lt;code&gt;image(224, 224, 3)&lt;/code&gt;의 &lt;code&gt;Shape&lt;/code&gt;일 때 &lt;code&gt;(224, 223, 3)&lt;/code&gt;이 되고, &lt;code&gt;y_var&lt;/code&gt;는 &lt;code&gt;(223, 224, 3)&lt;/code&gt;으로 각각 x와 y의 방향으로 1픽셀씩 작은 image가 됩니다.&lt;/li&gt;
&lt;li&gt;total_variation_loss(image) 함수에서는 이렇게 구한 x, y축 방향의 차이를 제곱해서 평균을 낸 다음에 합해서 반환합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;왜 &lt;code&gt;variation loss&lt;/code&gt;가 필요한지 원본 텍스처와 타깃 텍스처, 그리고 랜덤 노이즈 텍스처의 &lt;code&gt;variation loss&lt;/code&gt;를 비교합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;target :&amp;#39;&lt;/span&gt;, total_variation_loss(image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_value()))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;noise : &amp;#39;&lt;/span&gt;, total_variation_loss(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uniform(style_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;original : &amp;#39;&lt;/span&gt;, total_variation_loss(style_image))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;target : tf.Tensor(0.101396605, shape=(), dtype=float32)
noise :  tf.Tensor(0.3360309, shape=(), dtype=float32)
original :  tf.Tensor(0.03641251305469578, shape=(), dtype=float64)
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;위 결과값은 타깃 텍스처의 &lt;code&gt;variation loss&lt;/code&gt;는 랜덤 노이즈의 1/3 정도로 작지만, 원본 텍스처보다는 3배 정도 큽니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;11-각-손실의-가중치-추가&#34;&gt;(11) 각 손실의 가중치 추가&lt;/h3&gt;
&lt;p&gt;이 차이가 줄어들게 된다면 타깃 텍스처는 원본 텍스처에 더 가까운 모습을 보일 것이라고 가정하고, &lt;code&gt;variation loss&lt;/code&gt;를 전체 손실 계산식에 추가합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;total_variation_weight &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1e9&lt;/span&gt;
style_weight &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1e-1&lt;/span&gt;

&lt;span style=&#34;color:#a6e22e&#34;&gt;@tf.function&lt;/span&gt;()
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;train_step&lt;/span&gt;(image):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;GradientTape() &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tape:
        outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_outputs(image)
        loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; style_weight &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; get_loss(outputs, style_outputs)
        loss &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; total_variation_weight &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; total_variation_loss(image)

    grad &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tape&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gradient(loss, image)
    opt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply_gradients([(grad, image)])
    image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;assign(clip_0_1(image))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;지금까지 구한 &lt;code&gt;Gram Matrix&lt;/code&gt;는 &lt;code&gt;style loss&lt;/code&gt;라고 부릅니다. 이 &lt;code&gt;style loss&lt;/code&gt;와 새로 추가된 &lt;code&gt;variation loss&lt;/code&gt;에 각각 가중치를 곱해서 전체 손실에 더합니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;variation loss&lt;/code&gt;는 &lt;code&gt;Gram Matrix&lt;/code&gt; 계산값에 비해 작기 때문에 큰 가중치를 곱하고, 반대로 &lt;code&gt;style loss&lt;/code&gt;는 값을 줄여줍니다. 여기에 들어가는 가중치인 &lt;code&gt;total_variation_weight&lt;/code&gt;와 &lt;code&gt;style_weight&lt;/code&gt;는 적절한 값을 찾을 때까지 꾸준한 실험이 필요합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;12-variation-loss를-추가한-텍스처-합성-알고리즘-실행&#34;&gt;(12) variation loss를 추가한 텍스처 합성 알고리즘 실행&lt;/h3&gt;
&lt;p&gt;개선된 결과를 얻을 수 있는지, 결과값의 &lt;code&gt;variation loss&lt;/code&gt;를 출력하면 다음과 같습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;start &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time()

target_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uniform(style_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Variable(target_image)

epochs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;
steps_per_epoch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;

step &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(epochs):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; m &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(steps_per_epoch):
        step &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
        train_step(image)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; epochs &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:
        imageio&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imwrite(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;style_epoch_{0}.png&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(n), image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_value()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy())
    display&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clear_output(wait&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_value())
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Train step: {}&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(step))
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

end &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time()
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Total time: {:.1f}&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(end&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;start))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_03_1/output_43_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Total time: 119.7
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;확실히 좀 더 개선된 결과를 얻을 수 있습니다. 이렇게 결과값의 &lt;code&gt;variation loss&lt;/code&gt;를 출력해보면 다음과 같습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;target :&amp;#39;&lt;/span&gt;, total_variation_loss(image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_value()))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;original : &amp;#39;&lt;/span&gt;, total_variation_loss(style_image))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;target : tf.Tensor(0.030996362, shape=(), dtype=float32)
original :  tf.Tensor(0.03641251305469578, shape=(), dtype=float64)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;타깃 텍스처의 &lt;code&gt;variation loss&lt;/code&gt;가 원본 텍스처보다도 더 작아진 것을 확인할 수 있습니다. 결과 이미지도 &lt;code&gt;style loss&lt;/code&gt;만 사용했을 때 보다 매끄럽게 변한 것 같습니다.&lt;/p&gt;
&lt;h3 id=&#34;13-결론&#34;&gt;(13) 결론&lt;/h3&gt;
&lt;p&gt;지금까지 배운 것은 &lt;code&gt;style loss&lt;/code&gt;와 &lt;code&gt;variation loss&lt;/code&gt;를 이용하여 텍스쳐 합성 방법을 알아보도록 합니다.&lt;/p&gt;
&lt;h2 id=&#34;iii-연습-파일&#34;&gt;III. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch8_3_1_Texture_Synthesis.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;vi-reference&#34;&gt;VI. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Leon A. Gatys, Alexander S. Ecker, Matthias Bethge., (2015). A Neural Algorithm of Artistic Style. &lt;a href=&#34;https://arxiv.org/abs/1508.06576&#34;&gt;https://arxiv.org/abs/1508.06576&lt;/a&gt; &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.textures.com/&#34;&gt;https://www.textures.com/&lt;/a&gt; 에서 텍스처 이미지를 다양하게 확인할 수 있습니다. &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Gram Matrix는 앞에서 본 각 뉴런의 특징 추출값을 1차원의 벡터로 변환한 다음에, 벡터를 쌓아올린 행렬을 그 자신의 전치(&lt;code&gt;transpose&lt;/code&gt;) 행렬과 행렬곱해서 얻는 값입니다. &lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Ivanov, S. (2017). &amp;ldquo;Picking an optimizer for Style Transfer&amp;rdquo;. Retrieved from &lt;a href=&#34;https://blog.slavv.com/picking-an-optimizer-for-style-transfer-86e7b8cba84b&#34;&gt;https://blog.slavv.com/picking-an-optimizer-for-style-transfer-86e7b8cba84b&lt;/a&gt; &lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
  </channel>
</rss>