<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>다항회귀 on Data Science | ChloEvan</title>
    <link>https://chloevan.github.io/tags/%EB%8B%A4%ED%95%AD%ED%9A%8C%EA%B7%80/</link>
    <description>Recent content in 다항회귀 on Data Science | ChloEvan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 16 Apr 2020 20:00:30 +0900</lastBuildDate>
    
        <atom:link href="https://chloevan.github.io/tags/%EB%8B%A4%ED%95%AD%ED%9A%8C%EA%B7%80/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/</link>
      <pubDate>Thu, 16 Apr 2020 20:00:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요-및-데이터-불러오기&#34;&gt;I. 개요 및 데이터 불러오기&lt;/h2&gt;
&lt;p&gt;딥러닝 네트워크를 이용한 회귀를 통해 보스턴 주택 가격 데이터세트(&lt;code&gt;Boston Housing Dataset&lt;/code&gt;)을 이용한 주택 가격 예측 네트워크를 만들어본다.&lt;/p&gt;
&lt;p&gt;데이터세트에 기본적인 설명은 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1978년 미국 보스턴 지역의 주택 가격&lt;/li&gt;
&lt;li&gt;506개의 타운의 주택 가격 중앙값을, 1,000달러 단위로 표현&lt;/li&gt;
&lt;li&gt;범죄율&lt;/li&gt;
&lt;li&gt;주택당 방 개수&lt;/li&gt;
&lt;li&gt;고속도로까지의 거리 등&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras.datasets &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; boston_housing
(train_X, train_Y), (test_X, test_Y) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; boston_housing&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load_data()

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(len(train_X), len(test_X))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_X[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;404 102
[  1.23247   0.        8.14      0.        0.538     6.142    91.7
   3.9769    4.      307.       21.      396.9      18.72   ]
15.2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;보스턴 주택 가격 데이터세트는 &lt;code&gt;keras&lt;/code&gt;에 기본으로 탑재되어 있다. &lt;code&gt;load_data()&lt;/code&gt; 함수를 사용해 데이터를 불러올 수 있는데, 이 때 훈련(&lt;code&gt;train&lt;/code&gt;) 데이터와 테스트(&lt;code&gt;test&lt;/code&gt;) 데이터를 나누게 된다.&lt;/p&gt;
&lt;h2 id=&#34;ii-데이터-분리훈련데이터--테스트데이터&#34;&gt;II. 데이터 분리(훈련데이터 &amp;amp; 테스트데이터)&lt;/h2&gt;
&lt;p&gt;교재 &lt;code&gt;P.91-2&lt;/code&gt;에 보면, 훈련 데이터, 검증 데이터, 테스트 데이터의 역할에 비교적 이해하기 쉽게 기술이 되어 있습니다. 이 부분을 처음 접하시는 분들은 꼭 한번 읽어보시기를 바랍니다.&lt;/p&gt;
&lt;p&gt;딥러닝과 관련해서 한가지 알아두면 좋은 것은 딥러닝 네트워크의 가중치에 영향을 주는 데이터는 훈련 데이터인데, 만약 교차검증(&lt;code&gt;cross-validation&lt;/code&gt;)기법을 통하면 훈련 데이터 중 일부를 검증 데이터로 주는 비율을 바꿔가면서 학습시킬 수 있습니다.&lt;/p&gt;
&lt;p&gt;보스턴 주택 가격 데이터세트는 훈련 데이터가 &lt;code&gt;404&lt;/code&gt;개, 테스트 데이터가 &lt;code&gt;102&lt;/code&gt;개이며, 비율로 따지면 약 &lt;code&gt;80:20&lt;/code&gt; 정도입니다.&lt;/p&gt;
&lt;p&gt;보스턴 주택 가격 데이터 속성은 아래와 같습니다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;속성&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;내용&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;CRIM&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;범죄율&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;ZN&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;25,000평방피트당 주거지역의 비율&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;INDUS&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;비소매 상업지구 비율(단위: 에이커)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;CHAS&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;찰스강에 인접해 있으면 1, 그렇지 않으면 0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;NOX&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;일산화질소 농도(단위:0.1ppm)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;RM&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;주택당 방의 수&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;AGE&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1940년 이전에 건설된 주택의 비율&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;DIS&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5개의 보스턴 직업고용센터와의 거리(가중 평균)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;RAD&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;고속도로 접근성&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;TAX&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;재산세율&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;PTRATIO&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;학생/교사비율&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;B&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;흑인비율&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;LSTAT&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;하위계층비율&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;MEDV&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;타운의 주택 가격 중앙값(단위: 1,000달러&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;딥러닝 모형을 만들기전, 데이터 전처리를 진행해야 하는데 이것과 관련한 논쟁거리를 하나 소개합니다.&lt;/p&gt;
&lt;h2 id=&#34;iii-언제-데이터-정규화를-해야할까&#34;&gt;III. 언제 데이터 정규화를 해야할까?&lt;/h2&gt;
&lt;p&gt;데이터 정규화의 기본적인 방법은 각 데이터에서 평균값을 뺀 다음 표준편차로 나눕니다. 그런데, 한가지 궁금한 것이 있다면, 데이터 정규화를 훈련 데이터와 테스트 데이터를 나누기 전에 해야 하는 것이 맞는 것인지, 아니면 나눈 후에 하는 것이 맞는 것인지, 헷갈릴 때가 종종 있습니다.&lt;/p&gt;
&lt;p&gt;스택오버플로우에 이러한 내용을 토대로 나온 좋은 토론글이 있습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://bit.ly/2JDmJ1D&#34;&gt;Normalize data before or after split of training and testing data?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;순서는 다음과 같습니다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;먼저 데이터를 분리합니다.&lt;/li&gt;
&lt;li&gt;훈련데이터를 가지고 정규화를 진행합니다.&lt;/li&gt;
&lt;li&gt;정규화를 진행한 이후, 훈련데이터 정규화로 나온 값의 평균과 분산을 확인합니다.&lt;/li&gt;
&lt;li&gt;훈련데이터 평균과 분산을 가지고 테스트 데이터를 정규화합니다.&lt;/li&gt;
&lt;li&gt;모형을 생성합니다.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;검증 데이터도 마찬가지입니다. 이제 코드를 작성합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 4.12 데이터 전처리(정규화)&lt;/span&gt;
x_mean &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
x_std &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;std(axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
train_X &lt;span style=&#34;color:#f92672&#34;&gt;-=&lt;/span&gt; x_mean
train_X &lt;span style=&#34;color:#f92672&#34;&gt;/=&lt;/span&gt; x_std
test_X &lt;span style=&#34;color:#f92672&#34;&gt;-=&lt;/span&gt; x_mean
test_X &lt;span style=&#34;color:#f92672&#34;&gt;/=&lt;/span&gt; x_std

y_mean &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_Y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
y_std &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_Y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;std(axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
train_Y &lt;span style=&#34;color:#f92672&#34;&gt;-=&lt;/span&gt; y_mean
train_Y &lt;span style=&#34;color:#f92672&#34;&gt;/=&lt;/span&gt; y_std
test_Y &lt;span style=&#34;color:#f92672&#34;&gt;-=&lt;/span&gt; y_mean
test_Y &lt;span style=&#34;color:#f92672&#34;&gt;/=&lt;/span&gt; y_std

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_X[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[-0.27224633 -0.48361547 -0.43576161 -0.25683275 -0.1652266  -0.1764426
  0.81306188  0.1166983  -0.62624905 -0.59517003  1.14850044  0.44807713
  0.8252202 ]
-0.7821526033779157
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;iv-딥러닝-네트워크-학습&#34;&gt;IV. 딥러닝 네트워크 학습&lt;/h2&gt;
&lt;p&gt;정규화가 완료된 이후에는 시퀀셜 모델을 활용하여 딥러닝 네트워크를 학습 시킵니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;52&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;13&lt;/span&gt;, )), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;39&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;26&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(lr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.07&lt;/span&gt;), loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mse&amp;#39;&lt;/span&gt;)
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential_1&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_4 (Dense)              (None, 52)                728       
_________________________________________________________________
dense_5 (Dense)              (None, 39)                2067      
_________________________________________________________________
dense_6 (Dense)              (None, 26)                1040      
_________________________________________________________________
dense_7 (Dense)              (None, 1)                 27        
=================================================================
Total params: 3,862
Trainable params: 3,862
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;코드 설명은 다음과 같습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;첫 번째 레이어에서는 X 데이터의 속성을 모두 불러오기 위해 &lt;code&gt;input_shape&lt;/code&gt;의 첫 번째 차원을 13으로 지정합니다.&lt;/li&gt;
&lt;li&gt;마지막 레이어는 주택가격인 Y값 1개만 예측하면 되기 때문에 뉴런의 수가 1개입니다.&lt;/li&gt;
&lt;li&gt;활성화함수로는 &lt;code&gt;relu&lt;/code&gt;만 사용합니다.&lt;/li&gt;
&lt;li&gt;모델 정의가 끝나면 &lt;code&gt;model.fit()&lt;/code&gt; 함수로 회귀 모델을 학습시킵니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;1-그림-45-출력-코드&#34;&gt;(1) 그림 4.5. 출력 코드&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 그림 4.5 출력 코드&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; math
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sigmoid&lt;/span&gt;(x):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; math&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;x))

x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.01&lt;/span&gt;)
sigmoid_x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [sigmoid(z) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; z &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; x]
tanh_x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [math&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tanh(z) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; z &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; x]
relu &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; z &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; z &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; z &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; x]

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axhline(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axvline(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(x, sigmoid_x, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sigmoid&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(x, tanh_x, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;tanh&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(x, relu, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g.&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_04_03/output_8_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_X, train_Y, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/25
10/10 [==============================] - 0s 5ms/step - loss: 0.2009 - val_loss: 0.4002
Epoch 2/25
10/10 [==============================] - 0s 5ms/step - loss: 0.2382 - val_loss: 0.2915
Epoch 3/25
10/10 [==============================] - 0s 5ms/step - loss: 0.2133 - val_loss: 0.2996
Epoch 4/25
10/10 [==============================] - 0s 5ms/step - loss: 0.2024 - val_loss: 0.3201
Epoch 5/25
10/10 [==============================] - 0s 4ms/step - loss: 0.1887 - val_loss: 0.3605
Epoch 6/25
10/10 [==============================] - 0s 5ms/step - loss: 0.2041 - val_loss: 0.3185
Epoch 7/25
10/10 [==============================] - 0s 4ms/step - loss: 0.1815 - val_loss: 0.2961
Epoch 8/25
10/10 [==============================] - 0s 5ms/step - loss: 0.1984 - val_loss: 0.3034
Epoch 9/25
10/10 [==============================] - 0s 5ms/step - loss: 0.2154 - val_loss: 0.3473
Epoch 10/25
10/10 [==============================] - 0s 5ms/step - loss: 0.2441 - val_loss: 0.3394
Epoch 11/25
10/10 [==============================] - 0s 5ms/step - loss: 0.2401 - val_loss: 0.3083
Epoch 12/25
10/10 [==============================] - 0s 5ms/step - loss: 0.1671 - val_loss: 0.3178
Epoch 13/25
10/10 [==============================] - 0s 4ms/step - loss: 0.1613 - val_loss: 0.2963
Epoch 14/25
10/10 [==============================] - 0s 4ms/step - loss: 0.1587 - val_loss: 0.2522
Epoch 15/25
10/10 [==============================] - 0s 5ms/step - loss: 0.1973 - val_loss: 0.3850
Epoch 16/25
10/10 [==============================] - 0s 4ms/step - loss: 0.2309 - val_loss: 0.4120
Epoch 17/25
10/10 [==============================] - 0s 5ms/step - loss: 0.1818 - val_loss: 0.2867
Epoch 18/25
10/10 [==============================] - 0s 6ms/step - loss: 0.1592 - val_loss: 0.2601
Epoch 19/25
10/10 [==============================] - 0s 4ms/step - loss: 0.1483 - val_loss: 0.2544
Epoch 20/25
10/10 [==============================] - 0s 5ms/step - loss: 0.1416 - val_loss: 0.2757
Epoch 21/25
10/10 [==============================] - 0s 4ms/step - loss: 0.1475 - val_loss: 0.2622
Epoch 22/25
10/10 [==============================] - 0s 4ms/step - loss: 0.1441 - val_loss: 0.2380
Epoch 23/25
10/10 [==============================] - 0s 4ms/step - loss: 0.1692 - val_loss: 0.2581
Epoch 24/25
10/10 [==============================] - 0s 5ms/step - loss: 0.1739 - val_loss: 0.2449
Epoch 25/25
10/10 [==============================] - 0s 5ms/step - loss: 0.1652 - val_loss: 0.3004
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;코드 설명 및 출력 결과에 대한 해석은 다음과 같습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;validation_split&lt;/code&gt;은 훈련데이터에서 일정 비율로 떼서 학습 결과를 검증하기 위한 것입니다. 출력의 경향을 보면, &lt;code&gt;loss&lt;/code&gt;는 꾸준하게 감소하지만, &lt;code&gt;val_loss&lt;/code&gt;는 &lt;code&gt;loss&lt;/code&gt;보다 높은 값을 유지하는 것을 볼 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;이를 시각화하면 다음과 같습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_04_03/output_11_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;훈련 데이터의 손실은 꾸준히 감소하지만, 검증데이터의 손실이 항상 감소하는 것은 아닙니다. 모형이 마음에 드는 것이나 일단 회귀 모형을 평가해봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(test_X, test_Y)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;4/4 [==============================] - 0s 2ms/step - loss: 8023.7656





8023.765625
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;테스트 데이터의 손실은 &lt;code&gt;0.9155&lt;/code&gt;가 나옵니다. 위 그래프에서 훈련 데이터가 보여주는 &lt;code&gt;0.6&lt;/code&gt; 정도의 낮은 손실과는 거리가 있어 보입니다.&lt;/p&gt;
&lt;p&gt;네트워크가 &lt;code&gt;Y&lt;/code&gt;값을 얼마나 잘 예측하는지 확인해보기 위해 실제 주택 가격과 예측 주택 가격을 &lt;code&gt;1:1&lt;/code&gt;로 비교해봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt

pred_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(test_X)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;))
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(test_Y, pred_Y, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b.&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis([min(test_Y), max(test_Y), min(test_Y), max(test_Y)])

&lt;span style=&#34;color:#75715e&#34;&gt;# y=x에 해당하는 대각선&lt;/span&gt;
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot([min(test_Y), max(test_Y)], [min(test_Y), max(test_Y)], ls&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;--&amp;#34;&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;.3&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;test_Y&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pred_Y&amp;#39;&lt;/span&gt;)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_04_03/output_15_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;v-모형-업그레이드&#34;&gt;V. 모형 업그레이드&lt;/h2&gt;
&lt;p&gt;검증 데이터와 테스트 데이터에 대해 모두 좋은 예측 성적을 내려면 어떻게 해야 할까요? 검증 데이터와 테스트 데이터는 훈련 데이터아 달리 네트워크의 가중치에 영향을 미치지 않는다는 공통점이 있으니, 이를 활용합니다. 이 때, 검증 데이터에 대한 성적이 좋아지려면 &lt;code&gt;val_loss&lt;/code&gt;가 높아지지 않도록, 즉 네트워크가 훈련 데이터에 과적합되지 않도록 학습 도중에 끼어들어서 학습을 멈추도록 합니다.&lt;/p&gt;
&lt;p&gt;학습 도중에 끼어들기 위해서는 콜백(&lt;code&gt;callback&lt;/code&gt;) 함수를 사용합니다. 콜백 함수는 모델을 학습할 때 에포크가 끝날 때마다 호출됩니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;52&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;13&lt;/span&gt;, )), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;39&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;26&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(lr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.07&lt;/span&gt;), loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mse&amp;#39;&lt;/span&gt;)
history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_X, train_Y, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;, 
                    callbacks&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;callbacks&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;EarlyStopping(patience&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, monitor&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/25
10/10 [==============================] - 0s 10ms/step - loss: 1.2692 - val_loss: 0.6573
Epoch 2/25
10/10 [==============================] - 0s 4ms/step - loss: 0.3468 - val_loss: 0.3027
Epoch 3/25
10/10 [==============================] - 0s 4ms/step - loss: 0.2343 - val_loss: 0.3601
Epoch 4/25
10/10 [==============================] - 0s 4ms/step - loss: 0.2485 - val_loss: 0.2040
Epoch 5/25
10/10 [==============================] - 0s 4ms/step - loss: 0.1606 - val_loss: 0.1463
Epoch 6/25
10/10 [==============================] - 0s 5ms/step - loss: 0.1371 - val_loss: 0.1716
Epoch 7/25
10/10 [==============================] - 0s 5ms/step - loss: 0.1561 - val_loss: 0.1441
Epoch 8/25
10/10 [==============================] - 0s 5ms/step - loss: 0.1223 - val_loss: 0.1498
Epoch 9/25
10/10 [==============================] - 0s 4ms/step - loss: 0.0983 - val_loss: 0.1318
Epoch 10/25
10/10 [==============================] - 0s 4ms/step - loss: 0.0915 - val_loss: 0.1206
Epoch 11/25
10/10 [==============================] - 0s 4ms/step - loss: 0.0849 - val_loss: 0.1418
Epoch 12/25
10/10 [==============================] - 0s 4ms/step - loss: 0.1200 - val_loss: 0.2197
Epoch 13/25
10/10 [==============================] - 0s 5ms/step - loss: 0.1105 - val_loss: 0.1319
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;tf.keras.callbacks.EarlyStopping&lt;/code&gt;는 말 그대로 학습을 일찍 멈추는 기능을 하는 함수로, &lt;code&gt;patience&lt;/code&gt;는 몇 번의 에포크를 기준으로 삼을 것인지, &lt;code&gt;monitor&lt;/code&gt;는 어떤 값을 지켜볼 것인지에 대한 인수입니다. 여기서는 &lt;code&gt;val_loss&lt;/code&gt;가 3회의 에포크를 수행하는 동안 최고 기록을 갱신하지 못하면 학습을 멈춥니다. 즉, 10 에포크에서 &lt;code&gt;0.1206&lt;/code&gt;이 최고치인데, 11, 12, 13에서 갱신하지 못했기 때문에 학습을 멈췄습니다.&lt;/p&gt;
&lt;p&gt;이를 다시 시각화하면 아래와 같습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_04_03/output_19_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;검증 데이터의 손실에서 뚜렷한 증가세는 조금 덜 보입니다. 모형을 평가한뒤 다시 실제 주택 가격과 예측 주택 가격을 1:1로 시각홰봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(test_X, test_Y)
pred_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(test_X)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;))
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(test_Y, pred_Y, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b.&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis([min(test_Y), max(test_Y), min(test_Y), max(test_Y)])

&lt;span style=&#34;color:#75715e&#34;&gt;# y=x에 해당하는 대각선&lt;/span&gt;
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot([min(test_Y), max(test_Y)], [min(test_Y), max(test_Y)], ls&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;--&amp;#34;&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;.3&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;test_Y&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pred_Y&amp;#39;&lt;/span&gt;)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;4/4 [==============================] - 0s 2ms/step - loss: 0.3753
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_04_03/output_21_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;조금 더 모형이 다듬어진 것을 볼 수 있습니다. 이렇게 EarlyStopping을 활용하면 과적합 방지도 가능한 기법을 배웠습니다.&lt;/p&gt;
&lt;p&gt;이제 분류로 넘어갑니다.&lt;/p&gt;
&lt;h2 id=&#34;vi-연습-파일&#34;&gt;VI. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch4_4_boston_housing_deeplearning.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;vii-reference&#34;&gt;VII. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/</link>
      <pubDate>Wed, 15 Apr 2020 20:40:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요-및-소스코드&#34;&gt;I. 개요 및 소스코드&lt;/h2&gt;
&lt;p&gt;회귀 모형에서도 딥러닝 네트워크를 만들 수 있습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np

X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.78&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1.26&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.03&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1.11&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.24&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.24&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.47&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.77&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.37&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.85&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.41&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.27&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.02&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.76&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2.66&lt;/span&gt;]
Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;12.27&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;14.44&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;11.87&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;18.75&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;17.52&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;16.37&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;19.78&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;19.51&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;12.65&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;14.74&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10.72&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;21.94&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;12.83&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;15.51&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;17.14&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;14.42&lt;/span&gt;]

model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;tanh&amp;#39;&lt;/span&gt;, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,)), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;SGD(lr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;), loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mse&amp;#39;&lt;/span&gt;)

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense (Dense)                (None, 6)                 12        
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 7         
=================================================================
Total params: 19
Trainable params: 19
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;ii-활성화-함수-tanh&#34;&gt;II. 활성화 함수: tanh&lt;/h2&gt;
&lt;p&gt;딥러닝 &lt;code&gt;model&lt;/code&gt;은 2개의 &lt;code&gt;Dense&lt;/code&gt; 레이어로 구성됩니다. 첫번재 Dense 레이어는 활성화함수로 &lt;code&gt;tanh&lt;/code&gt;를 사용했습니다. &lt;code&gt;tanh&lt;/code&gt;는 삼각함수 중 탄젠트 함수와 연관이 있으며 실수 입력을 받아 -1과 1 사이의 출력을 반환합니다.[^1]&lt;/p&gt;
&lt;p&gt;$$ tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} $$&lt;/p&gt;
&lt;p&gt;각각의 활성화함수에 관한 출력 범위는 그림을 참조하시기를 바랍니다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_04_03/activation_functions.png&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;첫번째 레이어에는 6개의 뉴런을 할당합니다. 뉴런이 많을수록 딥러닝 네트워크의 표현력이 좋아지지만 너무 많으면 학습이 제대로 안 되거나 과적합(&lt;code&gt;overfitting&lt;/code&gt;)이 될 수 있습니다. 두 번째 레이어는 &lt;code&gt;X&lt;/code&gt; 입력값에 대한 하나의 &lt;code&gt;Y&lt;/code&gt;값만 출력해야 하기 때문에 뉴런 수가 &lt;code&gt;1&lt;/code&gt;개입니다.&lt;/p&gt;
&lt;h2 id=&#34;iii-학습에-대한-설명-및-소스코드-구현&#34;&gt;III. 학습에 대한 설명 및 소스코드 구현&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;optimizer&lt;/code&gt;의 손실은 &lt;code&gt;mse&lt;/code&gt;, 즉 평균 제곱 오차 (&lt;code&gt;Mean Squared Error&lt;/code&gt;)로서, 잔차의 제곱의 평균이 되기 때문에 손실을 줄이는 쪽으로 학습하면 앞에서 구한 선형 회귀 및 다항 회귀와 동일하게 잔차를 줄이는 방향으로 학습합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(X, Y, epochs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/10
1/1 [==============================] - 0s 2ms/step - loss: 255.1181
Epoch 2/10
1/1 [==============================] - 0s 1ms/step - loss: 126.4362
Epoch 3/10
1/1 [==============================] - 0s 1ms/step - loss: 14.2495
Epoch 4/10
1/1 [==============================] - 0s 1ms/step - loss: 9.5839
Epoch 5/10
1/1 [==============================] - 0s 1ms/step - loss: 9.5322
Epoch 6/10
1/1 [==============================] - 0s 1ms/step - loss: 9.5078
Epoch 7/10
1/1 [==============================] - 0s 2ms/step - loss: 9.4812
Epoch 8/10
1/1 [==============================] - 0s 1ms/step - loss: 9.4519
Epoch 9/10
1/1 [==============================] - 0s 1ms/step - loss: 9.4196
Epoch 10/10
1/1 [==============================] - 0s 1ms/step - loss: 9.3841





&amp;lt;tensorflow.python.keras.callbacks.History at 0x7fa6a124c630&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;X&lt;/code&gt;를 입력하면 &lt;code&gt;Y&lt;/code&gt;가 정답이 되도록 10회 학습시킵니다. 손실에 거의 변화가 없으면 학습이 거의 다 된것입니다.&lt;/p&gt;
&lt;h2 id=&#34;iv-모형-예측-및-시각화&#34;&gt;IV. 모형 예측 및 시각화&lt;/h2&gt;
&lt;p&gt;모형 예측 후 학습이 잘 된 것인지 확인하려면 그래프를 그려봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(X)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;array([[15.816551],
       [15.68471 ],
       [15.11817 ],
       [15.910349],
       [15.238623],
       [15.843683],
       [15.923513],
       [15.865143],
       [15.692286],
       [15.898527],
       [15.628548],
       [15.886652],
       [15.91959 ],
       [15.912346],
       [15.699751],
       [14.232035]], dtype=float32)
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt

line_x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(min(X), max(X), &lt;span style=&#34;color:#ae81ff&#34;&gt;0.01&lt;/span&gt;)
line_y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(line_x)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(line_x, line_y, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r-&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(X, Y, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bo&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Population Growth Rate(%)&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Elderly Population Rate(%)&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_04_03/output_7_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;다항 회귀에서 구했던 2차함수와 비슷한 곡선이 나왔는데, 차이점은 딥러닝 네트워크는 좀 더 직선에 가까운 완만한 형태라는 것을 확인하였습니다. 손실도 직선과 2차 함수와 비슷한 크기가 되기 때문에 2차 함수와 비슷한 성능으로 &lt;code&gt;X&lt;/code&gt; 데이터에 대해서 &lt;code&gt;Y&lt;/code&gt;를 예측한다고 결론 내릴 수 있습니다.&lt;/p&gt;
&lt;h2 id=&#34;v-연습-파일&#34;&gt;V. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch4_3_regression_with_deeplearning.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;vi-reference&#34;&gt;VI. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch4.2 - 다항 회귀</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/</link>
      <pubDate>Wed, 15 Apr 2020 13:40:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-기본개념&#34;&gt;I. 기본개념&lt;/h2&gt;
&lt;p&gt;비선형 회귀(Nonlinear Regression)는 선형 회귀로는 표현할 수 없는 데이터의 경향성을 설명하기 위한 회귀입니다. 이 가운데 $x^2$, $x^3$ 등의 다항식을 이용한 회귀를 다항회귀(Polynomial Regression)라고 합니다.&lt;/p&gt;
&lt;p&gt;즉, 회귀선이 직선 대신 2차 함수, 3차 함수 등의 곡선이 됩니다.&lt;/p&gt;
&lt;p&gt;2차 함수 이상의 그래프를 그려도 데이터의 경향성이 잘 나타나는지 확인합니다. 텐서플로를 이용해서 소스코드를 작업합니다.&lt;/p&gt;
&lt;h2 id=&#34;ii-2차함수-소스코드-및-손실량&#34;&gt;II. 2차함수 소스코드 및 손실량&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np

&lt;span style=&#34;color:#75715e&#34;&gt;# 모듈을 가져옵니다. &lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; random
X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.78&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1.26&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.03&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1.11&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.24&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.24&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.47&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.77&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.37&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.85&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.41&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.27&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.02&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.76&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2.66&lt;/span&gt;]
Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;12.27&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;14.44&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;11.87&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;18.75&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;17.52&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;16.37&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;19.78&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;19.51&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;12.65&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;14.74&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10.72&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;21.94&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;12.83&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;15.51&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;17.14&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;14.42&lt;/span&gt;]

&lt;span style=&#34;color:#75715e&#34;&gt;# a와 b, c를 랜덤한 값으로 초기화합니다.&lt;/span&gt;
a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Variable(random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random())
b &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Variable(random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random())
c &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Variable(random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random())

&lt;span style=&#34;color:#75715e&#34;&gt;# 잔차의 제곱의 평균을 반환하는 함수입니다. &lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;compute_loss&lt;/span&gt;(): 
  &lt;span style=&#34;color:#75715e&#34;&gt;# 책의 본문(p, 83)은 아래처럼 되어 있지만, 에러가 날 것이다. &lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;# y_pred = a*X**2 + b*X + c&lt;/span&gt;
  y_pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; a &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; X &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; X &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; X &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; c 
  loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_mean((Y &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; y_pred) &lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; loss

optimizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(lr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.07&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;): 
  &lt;span style=&#34;color:#75715e&#34;&gt;# 잔차의 제곱의 평균을 최소화합니다. &lt;/span&gt;
  optimizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;minimize(compute_loss, var_list&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[a, b, c])

  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;99&lt;/span&gt;: 
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(i, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;a:&amp;#39;&lt;/span&gt;, a&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy(), &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b:&amp;#39;&lt;/span&gt;, b&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy(), &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;c:&amp;#39;&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy(), &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss:&amp;#39;&lt;/span&gt;, compute_loss()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy())

line_x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(min(X), max(X), &lt;span style=&#34;color:#ae81ff&#34;&gt;0.01&lt;/span&gt;)
line_y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; a &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; line_x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; line_x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; line_x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; c

&lt;span style=&#34;color:#75715e&#34;&gt;# 그래프를 그립니다.&lt;/span&gt;
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(line_x,line_y,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r-&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(X,Y,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bo&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Population Growth Rate (%)&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Elderly Population Rate (%)&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;99 a: 3.840222 b: -5.386301 c: 6.4142933 loss: 69.31381
199 a: 2.823892 b: -4.6838207 c: 10.26055 loss: 31.852983
299 a: 1.3373799 b: -2.4428246 c: 12.872813 loss: 16.335335
399 a: 0.36516348 b: -0.95042753 c: 14.520345 loss: 11.102524
499 a: -0.16323428 b: -0.13958982 c: 15.417201 loss: 9.763081
599 a: -0.41179818 b: 0.24179395 c: 15.83927 loss: 9.500618
699 a: -0.5134157 b: 0.39770818 c: 16.01183 loss: 9.461109
799 a: -0.5495791 b: 0.4531944 c: 16.07324 loss: 9.456543
899 a: -0.56077087 b: 0.47036672 c: 16.092247 loss: 9.45614
999 a: -0.5637749 b: 0.47497624 c: 16.097347 loss: 9.456112
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_04_02/output_2_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;달라진 소스코드는 a와 b를 각각 2차항과 1차항의 계수로 바꿨다는 것입니다. &lt;code&gt;X&lt;/code&gt;를 추가하였는데,
기존 &lt;code&gt;a * X + b&lt;/code&gt; 코드를 새로운 코드 &lt;code&gt;a * X * X + b * X + c &lt;/code&gt;로 바꾼 것이 중요합니다. 그러나 결과는 직선 회귀선보다 손실이 소량 감소한 것을 확인 할 수 있습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/#iii-%ED%85%90%EC%84%9C%ED%94%8C%EB%A1%9C%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%ED%9A%8C%EA%B7%80%EC%84%A0-%EA%B5%AC%ED%95%98%EA%B8%B0&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;와 비교해서 확인해봅니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;iii-3차함수-소스코드-및-손실량&#34;&gt;III. 3차함수 소스코드 및 손실량&lt;/h3&gt;
&lt;p&gt;그렇다면, 3차함수($ax^3+bx^2+cx+d$)의 경우는 어떨까요? 기존코드를 최대한 활용해서 손실량을 확인해봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np

&lt;span style=&#34;color:#75715e&#34;&gt;# 모듈을 가져옵니다. &lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; random
X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.78&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1.26&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.03&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1.11&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.24&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.24&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.47&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.77&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.37&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.85&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.41&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.27&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.02&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.76&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2.66&lt;/span&gt;]
Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;12.27&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;14.44&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;11.87&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;18.75&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;17.52&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;16.37&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;19.78&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;19.51&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;12.65&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;14.74&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10.72&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;21.94&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;12.83&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;15.51&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;17.14&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;14.42&lt;/span&gt;]

&lt;span style=&#34;color:#75715e&#34;&gt;# a와 b, c를 랜덤한 값으로 초기화합니다.&lt;/span&gt;
a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Variable(random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random())
b &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Variable(random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random())
c &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Variable(random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random())
d &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Variable(random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random())

&lt;span style=&#34;color:#75715e&#34;&gt;# 잔차의 제곱의 평균을 반환하는 함수입니다. &lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;compute_loss&lt;/span&gt;(): 
  &lt;span style=&#34;color:#75715e&#34;&gt;# 책의 본문(p, 83)은 아래처럼 되어 있지만, 에러가 날 것이다. &lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;# y_pred = a*X**2 + b*X + c&lt;/span&gt;
  y_pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; a &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; X &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; X &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; X &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; X &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; X &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; X &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; d
  loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_mean((Y &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; y_pred) &lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; loss

optimizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(lr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.07&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;): 
  &lt;span style=&#34;color:#75715e&#34;&gt;# 잔차의 제곱의 평균을 최소화합니다. &lt;/span&gt;
  optimizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;minimize(compute_loss, var_list&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[a, b, c])

  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;99&lt;/span&gt;: 
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(i, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;a:&amp;#39;&lt;/span&gt;, a&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy(), &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b:&amp;#39;&lt;/span&gt;, b&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy(), &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;c:&amp;#39;&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy(), &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;d:&amp;#39;&lt;/span&gt;, d&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy(),&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss:&amp;#39;&lt;/span&gt;, compute_loss()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy())

line_x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(min(X), max(X), &lt;span style=&#34;color:#ae81ff&#34;&gt;0.01&lt;/span&gt;)
line_y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; a &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; line_x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; line_x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; line_x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; line_x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; line_x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; line_x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; d

&lt;span style=&#34;color:#75715e&#34;&gt;# 그래프를 그립니다.&lt;/span&gt;
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(line_x,line_y,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r-&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(X,Y,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bo&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Population Growth Rate (%)&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Elderly Population Rate (%)&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;99 a: -1.0329757 b: 6.6740055 c: -4.583161 d: 0.52839094 loss: 160.23645
199 a: -2.6273808 b: 11.315129 c: -5.680506 d: 0.52839094 loss: 138.63791
299 a: -3.9567773 b: 14.502094 c: -4.9157133 d: 0.52839094 loss: 130.275
399 a: -4.8310013 b: 16.512175 c: -4.2031274 d: 0.52839094 loss: 127.39865
499 a: -5.3181896 b: 17.629168 c: -3.7981315 d: 0.52839094 loss: 126.6281
599 a: -5.554209 b: 18.170454 c: -3.6022978 d: 0.52839094 loss: 126.46801
699 a: -5.6541195 b: 18.399607 c: -3.5194376 d: 0.52839094 loss: 126.4422
799 a: -5.6911244 b: 18.484484 c: -3.4887505 d: 0.52839094 loss: 126.43897
899 a: -5.703112 b: 18.511978 c: -3.478811 d: 0.52839094 loss: 126.43866
999 a: -5.7064986 b: 18.519741 c: -3.4760025 d: 0.52839094 loss: 126.43864
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_04_02/output_4_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;3차 함수가 그려졌지만, 데이터의 경향성을 잘 설명한다보 보기 어렵고, 손실도 매우 커졌음을 확인할 수 있습니다.&lt;/p&gt;
&lt;p&gt;1차 함수부터 3차 함수까지 소스코드를 작업한 가장 큰 이유는 &lt;strong&gt;어느 것이 가장 적절한 회귀식인지 즉시 알기는 어렵기 때문에 식을 계속 바꿔가며 최적의 회귀식을 찾기 위해 노력해야 한다는 점입니다.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;딥러닝을 활용한 회귀는 어떻게 될까요? 또한 무엇을 고려해야 할까요?&lt;/p&gt;
&lt;p&gt;다음장에서 조금 더 구체적으로 배우도록 합니다.&lt;/p&gt;
&lt;h2 id=&#34;vi-연습-파일&#34;&gt;VI. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch4_2_multiple_linear_regression.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v-reference&#34;&gt;V. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>