<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Transfer Learning on Data Science | ChloEvan</title>
    <link>https://chloevan.github.io/tags/transfer-learning/</link>
    <description>Recent content in Transfer Learning on Data Science | ChloEvan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 03 May 2020 15:20:30 +0900</lastBuildDate>
    
        <atom:link href="https://chloevan.github.io/tags/transfer-learning/rss.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch9.1-2 - 오토인코더 &amp; MNIST</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch9_1_auto_encoder/</link>
      <pubDate>Sun, 03 May 2020 15:20:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch9_1_auto_encoder/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.2 - 다항분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/&#34;&gt;Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/&#34;&gt;Tensorflow 2.0 Tutorial ch6.1-2 - CNN 이론&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_3_fashion_mnist_with_cnn/&#34;&gt;Tensorflow 2.0 Tutorial ch6.3 - Fashion MNIST with CNN 실습&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_4_improve_performance/&#34;&gt;Tensorflow 2.0 Tutorial ch6.4 - 모형의 성능 높이기&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (1)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (2)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_3_sentimentanalysis/&#34;&gt;Tensorflow 2.0 Tutorial ch7.3 - 긍정, 부정 감성 분석&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (1) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (2) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_1_tensorflow_hub/&#34;&gt;Tensorflow 2.0 Tutorial ch8.1 - 텐서플로 허브&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_2_transfer_learning/&#34;&gt;Tensorflow 2.0 Tutorial ch8.2 - 전이 학습과 &amp;amp; Kaggle 대회&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_3_1_texture_synthesis/&#34;&gt;Tensorflow 2.0 Tutorial ch8.3.1 - 컨볼루션 신경망을 사용한 텍스처 합성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_3_2_neural_style_transfer/&#34;&gt;Tensorflow 2.0 Tutorial ch8.3.2 - 컨볼루션 신경망을 사용한 신경 스타일 전이&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요&#34;&gt;I. 개요&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;오토인코더(&lt;code&gt;AutoEncoder&lt;/code&gt;)는 입력에 대한 출력을 학습해야 한다는 점은 기존 지도학습 네트워크와 동일합니다.&lt;/li&gt;
&lt;li&gt;그러나 그 출력이 입력과 동일하다는 점이 조금 다릅니다.&lt;/li&gt;
&lt;li&gt;오토인코더는 자기 자신을 재생성하는 네트워크입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_01-2/tutorial_01.png&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;위 그림에서 보는 것처럼, 오토인코더는 크게 3가지 부분으로 구성됩니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;z&lt;/code&gt;는 잠재 변수(&lt;code&gt;Latent Vector&lt;/code&gt;)를 중심으로, 입력에 가까운 부분을 인코더(&lt;code&gt;Encoder&lt;/code&gt;), 출력에 가까운 부분을 디코더(&lt;code&gt;Decoder&lt;/code&gt;)라 분류합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;인코더의 역할은 &lt;code&gt;입력&lt;/code&gt;에서 &lt;code&gt;잠재 변수&lt;/code&gt;를 만드는 것입니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;디코더의 역할은 &lt;code&gt;잠재 변수&lt;/code&gt;를 &lt;code&gt;출력&lt;/code&gt;으로 만드는 것입니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;위 그림이 잠재변수를 기준으로 하나의 대칭구조를 이루는 것처럼, 레이어 역시 대칭되는 구조로 쌓아올려서 만듭니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;음. 조금 쉽게 얘기하면, 오토인코더는 일종의 파일 압축과 유사합니다. 압축 파일은 압축하기 전과 압축을 해제한 뒤의 내용이 동일합니다. 컴퓨터공학 용어로 이러한 내용을 비손실 압축이라고 합니다. 내용적으로는 그러합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;그러나, &lt;code&gt;$x$&lt;/code&gt;와 &lt;code&gt;$x^i$&lt;/code&gt;의 차이점처럼 유사하지만 동일하지는 않습니다. 즉, 오토인코더는 손실 압축이라고 표현합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;딥러닝 생성 모델 중 최근 가장 주목받고 있는 적대적 생성 모델(&lt;code&gt;Generative Adversarial Network&lt;/code&gt; 이하 &lt;code&gt;GAN&lt;/code&gt;)의 생성자에서는 랜덤하게 생성된 변수를 잠재변수처럼 활용해서 새로운 이미지를 얻습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ii-mnist-데이터세트에-적용하기&#34;&gt;II. MNIST 데이터세트에 적용하기&lt;/h2&gt;
&lt;p&gt;6장에서 다룬 MNIST 데이터셋을 활용해서 재실습하도록 합니다.&lt;/p&gt;
&lt;h3 id=&#34;1-모듈-설치-및-데이터세트-확인&#34;&gt;(1) 모듈 설치 및 데이터세트 확인&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;데이터는 (&lt;code&gt;train_X&lt;/code&gt;, &lt;code&gt;train_Y&lt;/code&gt;), (&lt;code&gt;test_X&lt;/code&gt;, &lt;code&gt;test_Y&lt;/code&gt;)처럼 훈련 데이터와 테스트 데이터의 튜플 쌍으로 불러 올 수 있습니다.&lt;/li&gt;
&lt;li&gt;데이터를 로드한 후에 &lt;code&gt;train_X&lt;/code&gt;와 &lt;code&gt;test_X&lt;/code&gt;를 255.0으로 나눠서 픽셀 정규화를 하게 됩니다.&lt;/li&gt;
&lt;li&gt;데이터가 잘 불러와졌는지 시각화를 통해 확인합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 텐서플로 2 버전 선택&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
    &lt;span style=&#34;color:#75715e&#34;&gt;# %tensorflow_version only exists in Colab.&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;tensorflow_version &lt;span style=&#34;color:#ae81ff&#34;&gt;2.&lt;/span&gt;x
&lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Exception&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;pass&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow_hub &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; hub
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; cv2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;(train_X, train_Y), (test_X, test_Y) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;datasets&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mnist&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load_data()
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, train_Y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
11493376/11490434 [==============================] - 0s 0us/step
(60000, 28, 28) (60000,)
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_X &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(train_X[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;), cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;colorbar()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_01-2/output_7_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;5
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;MNIST&lt;/code&gt;는 &lt;code&gt;Fashion MNIST&lt;/code&gt;처럼 가로와 세로가 각각 28픽셀인 흑백 이미지를 입력으로 하고, 0~9까지의 숫자를 출력으로 합니다. (5장과 6장 참조)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-dense-오토인코더-모델-정의&#34;&gt;(2) Dense 오토인코더 모델 정의&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Dense 오토인코더&lt;/code&gt; 모델을 다음과 같이 정의합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;)
test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, train_Y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;(60000, 784) (60000,)
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;784&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;784&lt;/span&gt;,)),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;784&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sigmoid&amp;#39;&lt;/span&gt;)
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(), loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mse&amp;#39;&lt;/span&gt;)
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential_1&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_3 (Dense)              (None, 784)               615440    
_________________________________________________________________
dense_4 (Dense)              (None, 64)                50240     
_________________________________________________________________
dense_5 (Dense)              (None, 784)               50960     
=================================================================
Total params: 716,640
Trainable params: 716,640
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;입력데이터를 처리하기 위해 &lt;code&gt;Flatten&lt;/code&gt;레이어를 사용하는 대신 &lt;code&gt;train_X&lt;/code&gt;와 &lt;code&gt;test_X&lt;/code&gt;의 차원을 직접 &lt;code&gt;reshape()&lt;/code&gt; 함수로 변환했습니다. 그 이유는 입력과 출력의 형태가 같아야 하기 때문입니다.&lt;/li&gt;
&lt;li&gt;입력을 변환하지 않은 채로 &lt;code&gt;Flatten&lt;/code&gt;레이어를 넣어서 (28, 28) 차원의 입력을 넣으면 뒤에서도 출력의 차원을 (28, 28)로 맞추기 위해 &lt;code&gt;Reshape&lt;/code&gt; 레이어를 사용해야 하는 번거로움이 있습니다. (구조에 대한 이해 필요)&lt;/li&gt;
&lt;li&gt;dense와 dense_2의 레이어는 뉴런의 수가 같아서 대칭을 이루며, 각각 인코더와 디코더의 역할을 합니다.&lt;/li&gt;
&lt;li&gt;desne_1는 잠재변수로 뉴런의 수가 적은 것을 확인할 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3-dense-오토-인코더-모델-학습&#34;&gt;(3) Dense 오토 인코더 모델 학습&lt;/h3&gt;
&lt;p&gt;이제 모형을 학습시킵니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_X, train_X, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/10
235/235 [==============================] - 1s 5ms/step - loss: 0.0507
Epoch 2/10
235/235 [==============================] - 1s 5ms/step - loss: 0.0178
Epoch 3/10
235/235 [==============================] - 1s 5ms/step - loss: 0.0122
Epoch 4/10
235/235 [==============================] - 1s 5ms/step - loss: 0.0101
Epoch 5/10
235/235 [==============================] - 1s 5ms/step - loss: 0.0089
Epoch 6/10
235/235 [==============================] - 1s 5ms/step - loss: 0.0082
Epoch 7/10
235/235 [==============================] - 1s 5ms/step - loss: 0.0077
Epoch 8/10
235/235 [==============================] - 1s 5ms/step - loss: 0.0073
Epoch 9/10
235/235 [==============================] - 1s 5ms/step - loss: 0.0069
Epoch 10/10
235/235 [==============================] - 1s 5ms/step - loss: 0.0067





&amp;lt;tensorflow.python.keras.callbacks.History at 0x7f63a332b0b8&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;4-모형-시각화&#34;&gt;(4) 모형 시각화&lt;/h3&gt;
&lt;p&gt;실제로 모형이 잘 학습되었는지 시각화를 통해 확인합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; random

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;):
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    rand_index &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randint(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(test_X[rand_index]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;), cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)
    
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(test_X[rand_index], axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(img&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;), cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)
    
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(test_X, test_X)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_01-2/output_16_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;313/313 [==============================] - 1s 2ms/step - loss: 0.0063





0.006336142309010029
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;5-cnn-모형-신경망-업데이트&#34;&gt;(5) CNN 모형 신경망 업데이트&lt;/h3&gt;
&lt;p&gt;더 좋은 성과를 내기 위해 CNN을 활용하도록 합니다. 모형 정의를 다시 해봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)

model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Flatten(),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Reshape(target_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;)),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2DTranspose(filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2DTranspose(filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sigmoid&amp;#39;&lt;/span&gt;)
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(), loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mse&amp;#39;&lt;/span&gt;)
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential_2&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 14, 14, 32)        160       
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 7, 7, 64)          8256      
_________________________________________________________________
flatten (Flatten)            (None, 3136)              0         
_________________________________________________________________
dense_6 (Dense)              (None, 64)                200768    
_________________________________________________________________
dense_7 (Dense)              (None, 3136)              203840    
_________________________________________________________________
reshape (Reshape)            (None, 7, 7, 64)          0         
_________________________________________________________________
conv2d_transpose (Conv2DTran (None, 14, 14, 32)        8224      
_________________________________________________________________
conv2d_transpose_1 (Conv2DTr (None, 28, 28, 1)         129       
=================================================================
Total params: 421,377
Trainable params: 421,377
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;하나씩 살펴보도록 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;먼저, &lt;code&gt;train_X&lt;/code&gt;와 &lt;code&gt;train_Y&lt;/code&gt;부분에 대한 설명입니다.&lt;/li&gt;
&lt;li&gt;흑백 이미지이기 때문에 마지막 차원의 수는 1입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)),
tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),
&lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Conv2D 레이어를 2개 쌓았습니다.&lt;/li&gt;
&lt;li&gt;그런데, 풀링 레이어가 빠져 있습니다. 대신에 &lt;code&gt;kernel_size=2&lt;/code&gt;, &lt;code&gt;strides=(2,2)&lt;/code&gt;로 설정해서 풀링 레이어를 쓰는 것과 같은 효과를 줍니다.&lt;/li&gt;
&lt;li&gt;Conv2D를 통과할 때마다 50%씩 감소하여 두번째 &lt;code&gt;Conv2D&lt;/code&gt;를 통과하면 이미지의 크지는 &lt;code&gt;7X7&lt;/code&gt;이 됩니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;, 
tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Flatten(),
tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),
&lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;3차원의 데이터를 1차원으로 바꿔주기 위해 &lt;code&gt;Flatten()&lt;/code&gt;을 통과해야 합니다.&lt;/li&gt;
&lt;li&gt;그 다음에는 잠재 변수를 만들기 위해 &lt;code&gt;Dense&lt;/code&gt; 오토인코더와 동일한 크기로 64개의 뉴런을 가지는 &lt;code&gt;Dense&lt;/code&gt;레이어를 배치합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;잠재 변수를 만든 다음에는 디코더를 만듭니다. 디코더는 인코더와 대칭이 되도록 다시 쌓아올립니다. 잠재변수 레이어와 연결된 레이어는 &lt;code&gt;7X7&lt;/code&gt; 이미지를 만들기 위해 64개의 채널만큼 가지고 있는 &lt;code&gt;Conv2D&lt;/code&gt;레이어입니다.&lt;/li&gt;
&lt;li&gt;레이어와 뉴런수를 동일하게 만들기 위해서 &lt;code&gt;Dense&lt;/code&gt;레이어의 뉴런 수를 &lt;code&gt;7*7*64&lt;/code&gt;로 넣습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Reshape(target_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;1차원인 데이터를 3차원으로 바꿔주기 위해 64개의 채널만큼 &lt;code&gt;Reshape&lt;/code&gt;레이어를 사용합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2DTranspose(filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2DTranspose(filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sigmoid&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;마지막으로 이어지는 2개의 레이어는 &lt;code&gt;Conv2DTranspose&lt;/code&gt;입니다.&lt;/li&gt;
&lt;li&gt;Conv2D레이어가 하는 일의 반대되는 계산으로 이해하면 됩니다. (즉, 이 함수를 쓰는 이유는 대칭 구조를 만들기 위함입니다.)&lt;/li&gt;
&lt;li&gt;필터의 개수가 1인 것은 흑백이인 출력 이미지와 같습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;6-cnn-모형-학습&#34;&gt;(6) CNN 모형 학습&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;이제 모형을 학습시킵니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_X, train_X, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/10
235/235 [==============================] - 2s 9ms/step - loss: 0.0757
Epoch 2/10
235/235 [==============================] - 2s 8ms/step - loss: 0.0322
Epoch 3/10
235/235 [==============================] - 2s 8ms/step - loss: 0.0247
Epoch 4/10
235/235 [==============================] - 2s 9ms/step - loss: 0.0222
Epoch 5/10
235/235 [==============================] - 2s 8ms/step - loss: 0.0211
Epoch 6/10
235/235 [==============================] - 2s 8ms/step - loss: 0.0204
Epoch 7/10
235/235 [==============================] - 2s 8ms/step - loss: 0.0200
Epoch 8/10
235/235 [==============================] - 2s 9ms/step - loss: 0.0197
Epoch 9/10
235/235 [==============================] - 2s 8ms/step - loss: 0.0195
Epoch 10/10
235/235 [==============================] - 2s 9ms/step - loss: 0.0193





&amp;lt;tensorflow.python.keras.callbacks.History at 0x7f63a0fa5438&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;7-오토인코더의-이미지-재생성-및-모형-성능-평가&#34;&gt;(7) 오토인코더의 이미지 재생성 및 모형 성능 평가&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;얼마나 잘 재현하는지 확인해봅니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; random

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;):
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    rand_index &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randint(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(test_X[rand_index]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;), cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)
    
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(test_X[rand_index], axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(img&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;), cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)
    
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(test_X, test_X)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_01-2/output_23_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;313/313 [==============================] - 1s 3ms/step - loss: 0.0188





0.01879417710006237
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;보면 알겠지만, 조금 이상합니다. 왜 이상할까요? 이 때 한번 고민해야 하는 것이 &lt;code&gt;활성화함수(=activation)&lt;/code&gt;입니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;마지막 레이어를 제외하면 &lt;code&gt;relu&lt;/code&gt;를 사용했습니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;relu&lt;/code&gt;는 양수는 그대로 반환하고 0이나 음수가 들어오면 0을 반환합니다. 즉, 이말은 뉴런의 계산값 중 음수가 되는 결과가 많을 경우 뉴런의 출력은 무조건 0이 됩니다.&lt;/li&gt;
&lt;li&gt;출력이 0인건 알겠는데, 왜 그게 문제가 될까요? 출력은 다음 레이어의 가중치에 곱해지기 때문에 출력이 0이면 가중치의 효과를 모두 0으로 만들어버립니다. (교재 340페이지 문제점에 대해 이미지로 표현되었으니 꼭 확인 바랍니다.&lt;/li&gt;
&lt;li&gt;이러한 문제점을 해결하고자 &lt;code&gt;elu&lt;/code&gt;라는 개념이 도입되었습니다. (이론은 교재 340페이지를 확인합니다!)
&lt;ul&gt;
&lt;li&gt;간단하게 표현하면 &lt;code&gt;Relu&lt;/code&gt;와 다르게 &lt;code&gt;elu&lt;/code&gt;는 0으로 수렴하지 않고 &lt;code&gt;-1&lt;/code&gt;로 수렴하게 됩니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;8-elu의-적용&#34;&gt;(8) elu의 적용&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;이제 &lt;code&gt;elu&lt;/code&gt;로 바꾼 후 모형을 재학습 시킵니다.&lt;/li&gt;
&lt;li&gt;반복되는 내용이기 때문에 전체 코드로 시각화까지 확인합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)

model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;elu&amp;#39;&lt;/span&gt;, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;elu&amp;#39;&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Flatten(),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;elu&amp;#39;&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;elu&amp;#39;&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Reshape(target_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;)),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2DTranspose(filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;elu&amp;#39;&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2DTranspose(filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sigmoid&amp;#39;&lt;/span&gt;)
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(), loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mse&amp;#39;&lt;/span&gt;)
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_X, train_X, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;)

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; random

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;):
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    rand_index &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randint(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(test_X[rand_index]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;), cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)
    
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(test_X[rand_index], axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(img&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;), cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)
    
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(test_X, test_X)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential_4&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_4 (Conv2D)            (None, 14, 14, 32)        160       
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 7, 7, 64)          8256      
_________________________________________________________________
flatten_2 (Flatten)          (None, 3136)              0         
_________________________________________________________________
dense_10 (Dense)             (None, 64)                200768    
_________________________________________________________________
dense_11 (Dense)             (None, 3136)              203840    
_________________________________________________________________
reshape_2 (Reshape)          (None, 7, 7, 64)          0         
_________________________________________________________________
conv2d_transpose_4 (Conv2DTr (None, 14, 14, 32)        8224      
_________________________________________________________________
conv2d_transpose_5 (Conv2DTr (None, 28, 28, 1)         129       
=================================================================
Total params: 421,377
Trainable params: 421,377
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
235/235 [==============================] - 2s 9ms/step - loss: 0.0574
Epoch 2/10
235/235 [==============================] - 2s 9ms/step - loss: 0.0194
Epoch 3/10
235/235 [==============================] - 2s 9ms/step - loss: 0.0123
Epoch 4/10
235/235 [==============================] - 2s 9ms/step - loss: 0.0103
Epoch 5/10
235/235 [==============================] - 2s 9ms/step - loss: 0.0094
Epoch 6/10
235/235 [==============================] - 2s 8ms/step - loss: 0.0089
Epoch 7/10
235/235 [==============================] - 2s 9ms/step - loss: 0.0085
Epoch 8/10
235/235 [==============================] - 2s 9ms/step - loss: 0.0081
Epoch 9/10
235/235 [==============================] - 2s 9ms/step - loss: 0.0077
Epoch 10/10
235/235 [==============================] - 2s 9ms/step - loss: 0.0075
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_01-2/output_26_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;313/313 [==============================] - 1s 3ms/step - loss: 0.0072





0.007230293471366167
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;relu&lt;/code&gt;와 다르게 이전의 각진 모습은 거의 찾아볼 수 없고, &lt;code&gt;loss&lt;/code&gt; 역시 보다 낮게 측정된 것을 확인할 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;iii-연습-파일&#34;&gt;III. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch9_1_auto_encoder.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;vi-reference&#34;&gt;VI. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch8.3.2 - 컨볼루션 신경망을 사용한 신경 스타일 전이</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch8_3_2_neural_style_transfer/</link>
      <pubDate>Sat, 02 May 2020 15:20:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch8_3_2_neural_style_transfer/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.2 - 다항분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/&#34;&gt;Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/&#34;&gt;Tensorflow 2.0 Tutorial ch6.1-2 - CNN 이론&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_3_fashion_mnist_with_cnn/&#34;&gt;Tensorflow 2.0 Tutorial ch6.3 - Fashion MNIST with CNN 실습&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_4_improve_performance/&#34;&gt;Tensorflow 2.0 Tutorial ch6.4 - 모형의 성능 높이기&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (1)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (2)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_3_sentimentanalysis/&#34;&gt;Tensorflow 2.0 Tutorial ch7.3 - 긍정, 부정 감성 분석&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (1) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (2) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_1_tensorflow_hub/&#34;&gt;Tensorflow 2.0 Tutorial ch8.1 - 텐서플로 허브&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_2_transfer_learning/&#34;&gt;Tensorflow 2.0 Tutorial ch8.2 - 전이 학습과 &amp;amp; Kaggle 대회&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_3_1_texture_synthesis/&#34;&gt;Tensorflow 2.0 Tutorial ch8.3.1 - 컨볼루션 신경망을 사용한 텍스처 합성&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요&#34;&gt;I. 개요&lt;/h2&gt;
&lt;p&gt;2015년, 딥러닝과 예술의 만남으로 큰 화제가 되었던 신경 스타일 전이 논문&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;은 반 고흐의 (별이 빛나는 밤에)라는 그림과 풍경 사진을 합성해서 반 고흐가 그린 것 같은 스타일의 풍경 이미지를 만들었고, &lt;a href=&#34;https://prisma-ai.com/&#34;&gt;프리즈마&lt;/a&gt;등의 앱은 이 알고리즘을 빠르게 탑재해서 인기를 끌었습니다.&lt;/p&gt;
&lt;p&gt;본 포스트에서는 텍스처 합성에 대해 알아본 뒤 2장의 이미지에서 각각 스타일과 내용을 가져와서 합성하는 신경 스타일 전이에 대해 다루도록 합니다.&lt;/p&gt;
&lt;h2 id=&#34;ii-컨볼루션-신경망을-사용한-신경-스타일-전이&#34;&gt;II. 컨볼루션 신경망을 사용한 신경 스타일 전이&lt;/h2&gt;
&lt;p&gt;신경 스타일 전이는 지난 시간에 배운 &lt;code&gt;Gram Matrix&lt;/code&gt;를 이용해서 텍스처 합성에 한가지를 추가한 것입니다. 바로 &lt;code&gt;content&lt;/code&gt; 텍스처입니다.&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;먼저, 타깃 텍스처를 만들기 위해서 &lt;code&gt;style&lt;/code&gt; 텍스처와 &lt;code&gt;Gram Matrix&lt;/code&gt;의 &lt;code&gt;MSE&lt;/code&gt;를 구합니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Content&lt;/code&gt; 텍스처와는 픽셀 값의 차이인 &lt;code&gt;MSE&lt;/code&gt;를 구합니다.&lt;/li&gt;
&lt;li&gt;여기서 사용하는 특징 추출값을 위한 레이어는 서로 다르게 설정할 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;그 외의 이론적인 내용은 319-320 페이지를 참조하시기를 바랍니다.&lt;/p&gt;
&lt;h3 id=&#34;1-원본-텍스처-불러오기&#34;&gt;(1) 원본 텍스처 불러오기&lt;/h3&gt;
&lt;p&gt;먼저 &lt;code&gt;content&lt;/code&gt; 원본 텍스처를 불러옵니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 텐서플로 2 버전 선택&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
    &lt;span style=&#34;color:#75715e&#34;&gt;# %tensorflow_version only exists in Colab.&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;tensorflow_version &lt;span style=&#34;color:#ae81ff&#34;&gt;2.&lt;/span&gt;x
&lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Exception&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;pass&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow_hub &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; hub
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; cv2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;2-첫번째-이미지-타깃-텍스쳐-함수-정의-및-실행&#34;&gt;(2) 첫번째 이미지 타깃 텍스쳐 함수 정의 및 실행&lt;/h3&gt;
&lt;p&gt;이전 시간에 배웠던 내용의 전체코드가 필요합니다. 복습을 하면서 다시한번 실습하기를 바랍니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;style_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;style.jpg&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://bit.ly/2mGfZIq&amp;#39;&lt;/span&gt;)

style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(style_path)
style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(style_image, dsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;))
style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; style_image &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(style_image)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;matplotlib.image.AxesImage at 0x7fe1d74332e8&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_03_2/output_7_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;합성 하려고 하는 첫번째 사진입니다.&lt;/p&gt;
&lt;h3 id=&#34;3-함수-정의&#34;&gt;(3) 함수 정의&lt;/h3&gt;
&lt;p&gt;아래와 같이 함수를 정의합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Gram Matrix 함수 정의&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;gram_matrix&lt;/span&gt;(input_tensor):
    channels &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(input_tensor&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
    a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(input_tensor, [&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, channels])
    n &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape(a)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
    gram &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;matmul(a, a, transpose_a&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; gram &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(n, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)

&lt;span style=&#34;color:#75715e&#34;&gt;# 타깃 텍스처 gram matrix 함수 정의&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_outputs&lt;/span&gt;(image):
    image_batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(image, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
    output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model(preprocess_input(image_batch &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;))
    outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [gram_matrix(out) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; out &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; output]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; outputs

&lt;span style=&#34;color:#75715e&#34;&gt;# MSE 구하는 함수 (원본 텍스처 gram matrix - 타깃 텍스처 gram matrix)&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_loss&lt;/span&gt;(outputs, style_outputs):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_sum([tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_mean((o&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;s)&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; o,s &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(outputs, style_outputs)])
  
&lt;span style=&#34;color:#75715e&#34;&gt;# 0.0~1.0 사이의 컬러값 정의 함수&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clip_0_1&lt;/span&gt;(image):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clip_by_value(image, clip_value_min&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.0&lt;/span&gt;, clip_value_max&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# variation loss 함수 정의&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;high_pass_x_y&lt;/span&gt;(image):
  x_var &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; image[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:, :] &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; image[:, :&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, :]
  y_var &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; image[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:, :, :] &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; image[:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, :, :]
  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; x_var, y_var

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;total_variation_loss&lt;/span&gt;(image):
  x_deltas, y_deltas &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; high_pass_x_y(image)
  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_mean(x_deltas&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_mean(y_deltas&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;4-원본-텍스처에-대한-gram-matrix-계산&#34;&gt;(4) 원본 텍스처에 대한 &lt;code&gt;Gram Matrix&lt;/code&gt; 계산&lt;/h3&gt;
&lt;p&gt;자세한 설명은 이전 포스트를 참조합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 특징 추출 모델 만들기&lt;/span&gt;
vgg &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; VGG19(include_top&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False, weights&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;imagenet&amp;#39;&lt;/span&gt;)
style_layers &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;block1_conv1&amp;#39;&lt;/span&gt;, 
                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;block2_conv1&amp;#39;&lt;/span&gt;, 
                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;block3_conv1&amp;#39;&lt;/span&gt;, 
                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;block4_conv1&amp;#39;&lt;/span&gt;, 
                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;block5_conv1&amp;#39;&lt;/span&gt;]
vgg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trainable &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; False
outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [vgg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_layer(name)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;output &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; name &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; style_layers]
model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Model([vgg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;input], outputs)

&lt;span style=&#34;color:#75715e&#34;&gt;# 원본 텍스처에서 Gram Matrix 계산&lt;/span&gt;
style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(style_path)
style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(style_image, dsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;))
style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; style_image &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;

style_batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; style_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;)
style_batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(style_batch, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
style_output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model(preprocess_input(style_batch &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;))

style_outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [gram_matrix(out) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; out &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; style_output]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;5-content-이미지-확인&#34;&gt;(5) Content 이미지 확인&lt;/h3&gt;
&lt;p&gt;합성할 &lt;code&gt;Content&lt;/code&gt; 이미지를 다운로드 받습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;content_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;content.jpg&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://bit.ly/2mAfUX1&amp;#39;&lt;/span&gt;)

content_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(content_path)
max_dim &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;512&lt;/span&gt;
long_dim &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; max(content_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
scale &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; max_dim &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; long_dim
new_height &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(content_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; scale)
new_width &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(content_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; scale)

content_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(content_image, dsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(new_width, new_height))
content_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; content_image &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;))
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(content_image)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;matplotlib.image.AxesImage at 0x7fe3aa115ef0&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_03_2/output_14_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;여기에서 가로와 세로 중 가장 긴 축을 512 픽셀에 맞춰서 리사이즈 합니다. &lt;code&gt;VGG-19&lt;/code&gt; 네트워크는 32보다 큰 이미지는 모두 받을 수 있기 때문에 적절한 퍼포먼스를 유지하기 위해 적당히 크게 설정합니다.&lt;/p&gt;
&lt;p&gt;여기서 주의해야 할 점은 &lt;code&gt;content&lt;/code&gt; 텍스처와 타깃 텍스처의 크기가 같아야 한다는 점입니다. 이 둘은 서로 특징 추출값의 픽셀을 &lt;code&gt;MSE&lt;/code&gt;로 비교하기 때문에 크기가 다르면 안됩니다. 반면 &lt;code&gt;style&lt;/code&gt; 텍스처는 타깃 텍스처와 크기가 달라도 상관없습니다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Gram Matrix&lt;/code&gt; 계산값은 각 레이어의 &lt;code&gt;[채널 수]X[채널 수]&lt;/code&gt;만큼의 값을 서로 비교하기 때문입니다.&lt;/p&gt;
&lt;h3 id=&#34;6-content-특징-추출-모델-만들기&#34;&gt;(6) &lt;code&gt;content&lt;/code&gt; 특징 추출 모델 만들기&lt;/h3&gt;
&lt;p&gt;이제 &lt;code&gt;content&lt;/code&gt;의 특징을 추출하기 위한 모델을 만들어야 하는데, 모델을 정의하는 방식은 다음과 같습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;content_batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; content_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;)
content_batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(content_batch, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)

content_layers&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;block5_conv2&amp;#39;&lt;/span&gt;]

vgg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trainable &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; False
outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [vgg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_layer(name)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;output &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; name &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; content_layers]
model_content &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Model([vgg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;input], outputs)
content_output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model_content(preprocess_input(content_batch &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;content&lt;/code&gt;특징 추출을 위해 선택한 레이어는 &lt;code&gt;block5_conv1&lt;/code&gt; 바로 뒤에 있는 &lt;code&gt;block5_conv2&lt;/code&gt; 레이어입니다. 위에서 &lt;code&gt;style&lt;/code&gt; 특징을 추출하는 모델과 별도의 모델을 만들어서 &lt;code&gt;model_content&lt;/code&gt;에 저장하고, 이 모델을 사용해 &lt;code&gt;content&lt;/code&gt; 텍스처에서 미리 특징을 추출해서 &lt;code&gt;content_output&lt;/code&gt; 변수에 저장합니다. &lt;code&gt;style_outputs&lt;/code&gt;처럼 이 값도 여기서 한 번만 계산해놓으면 바뀌지 않고 계속 사용됩니다.&lt;/p&gt;
&lt;h3 id=&#34;7-타깃-텍스처-업데이트-함수-정의&#34;&gt;(7) 타깃 텍스처 업데이트 함수 정의&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;먼저, 타깃 텍스처에서 &lt;code&gt;gram matrix&lt;/code&gt;을 구하는 함수가 필요합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;MSE&lt;/code&gt;를 구하는 함수가 필요한데, 원본 텍스처의 &lt;code&gt;Gram Matrix&lt;/code&gt; 값과, 타깃 텍스처의 &lt;code&gt;Gram Matrix&lt;/code&gt; 사이의 MSE 함수가 필요합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이 때, &lt;code&gt;MSE&lt;/code&gt; 값이 0.0에서 1.0사이의 컬러 값이어야 하기 때문에 그 이하나 이상으로 값이 넘어가지 않도록 해주는 함수가 필요합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 타깃 텍스처 gram matrix 함수 정의&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;gram_matrix&lt;/span&gt;(input_tensor):
    channels &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(input_tensor&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
    a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(input_tensor, [&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, channels])
    n &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape(a)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
    gram &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;matmul(a, a, transpose_a&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; gram &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(n, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_outputs&lt;/span&gt;(image):
    image_batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(image, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
    output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model(preprocess_input(image_batch &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;))
    outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [gram_matrix(out) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; out &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; output]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; outputs

&lt;span style=&#34;color:#75715e&#34;&gt;# MSE 구하는 함수 (원본 텍스처 gram matrix - 타깃 텍스처 gram matrix)&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_loss&lt;/span&gt;(outputs, style_outputs):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_sum([tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_mean((o&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;s)&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; o,s &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(outputs, style_outputs)])
  
&lt;span style=&#34;color:#75715e&#34;&gt;# 0.0~1.0 사이의 컬러값 정의 함수&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clip_0_1&lt;/span&gt;(image):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clip_by_value(image, clip_value_min&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.0&lt;/span&gt;, clip_value_max&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;8-content-output-loss-함수-정의&#34;&gt;(8) content output, loss 함수 정의&lt;/h3&gt;
&lt;p&gt;이제 &lt;code&gt;style&lt;/code&gt;에서 했던 것처럼 &lt;code&gt;content&lt;/code&gt; 전용의 &lt;code&gt;output&lt;/code&gt;과 &lt;code&gt;loss&lt;/code&gt; 함수를 정의합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_content_output&lt;/span&gt;(image):
  image_batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(image, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
  output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model_content(preprocess_input(image_batch &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;))
  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; output

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_content_loss&lt;/span&gt;(image, content_output):
  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_sum(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_mean(image&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;content_output)&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# 0.0~1.0 사이의 컬러값 정의 함수&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clip_0_1&lt;/span&gt;(image):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clip_by_value(image, clip_value_min&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.0&lt;/span&gt;, clip_value_max&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;get_content_loss&lt;/code&gt;함수에서는 타깃 텍스처와 &lt;code&gt;content&lt;/code&gt; 텍스처의 &lt;code&gt;MSE&lt;/code&gt;를 구합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;9-content-loss-손실-계산식에-추가&#34;&gt;(9) Content loss 손실 계산식에 추가&lt;/h3&gt;
&lt;p&gt;이제, &lt;code&gt;content loss&lt;/code&gt;를 계산식에 추가하고, 모델의 하이퍼파라미터인 &lt;code&gt;Adam Optimizer&lt;/code&gt;의 학습률과 각 &lt;code&gt;loss&lt;/code&gt;의 가중치들을 신경 스타일 전이 과제에 맞게 조정합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;opt &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(learning_rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.001&lt;/span&gt;, beta_1&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.99&lt;/span&gt;, epsilon&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1e-1&lt;/span&gt;)

total_variation_weight &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1e9&lt;/span&gt;
style_weight &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1e-2&lt;/span&gt;
content_weight &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1e4&lt;/span&gt;

&lt;span style=&#34;color:#a6e22e&#34;&gt;@tf.function&lt;/span&gt;()
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;train_step&lt;/span&gt;(image):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;GradientTape() &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tape:
        outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_outputs(image)
        output2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_content_output(image)
        loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; style_weight &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; get_loss(outputs, style_outputs)
        loss &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; content_weight &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; get_content_loss(output2, content_output)
        loss &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; total_variation_weight &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; total_variation_loss(image)

    grad &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tape&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gradient(loss, image)
    opt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply_gradients([(grad, image)])
    image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;assign(clip_0_1(image))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;10-신경-스타일-전이-알고리즘-직접-실행&#34;&gt;(10) 신경 스타일 전이 알고리즘 직접 실행&lt;/h3&gt;
&lt;p&gt;이제 신경 스타일 전이 알고리즘을 직접 실행해보겠습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; IPython.display &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; display
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; time
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; imageio

start &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time()

&lt;span style=&#34;color:#75715e&#34;&gt;# target_image = tf.random.uniform(content_image.shape)&lt;/span&gt;
image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Variable(content_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;))

epochs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;
steps_per_epoch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;

step &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(epochs):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; m &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(steps_per_epoch):
        step &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
        train_step(image)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;.&amp;#34;&lt;/span&gt;, end&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; epochs &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:
        imageio&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imwrite(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;style_{0}_content_{1}_transfer_epoch_{2}.png&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(style_weight, content_weight, n), image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_value()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy())
    display&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clear_output(wait&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;))
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_value())
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Train step: {}&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(step))
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

end &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time()
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Total time: {:.1f}&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(end&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;start))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_03_2/output_27_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Total time: 123.6
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;option-그림-824-원본-소스코드&#34;&gt;Option, 그림 8.24 원본 소스코드&lt;/h2&gt;
&lt;p&gt;그림 8.24(교재 299p)에서는 첫 번째 레이어에서 활성화되는 64개 뉴런의 특징 추출값을 모두 표시했습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(style_path)
style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(style_image, dsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;))
style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; style_image &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;

style_batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; style_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;)
style_batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(style_batch, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
style_output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model(preprocess_input(style_batch &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;))

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;))

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(style_output[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]):
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(style_output[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][:,:,:,c], &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;), cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_03_2/output_29_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;iii-연습-파일&#34;&gt;III. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch8_3_1_Texture_Synthesis.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;vi-reference&#34;&gt;VI. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_3_1_texture_synthesis/&#34;&gt;Tensorflow 2.0 Tutorial ch8.3.1 - 컨볼루션 신경망을 사용한 텍스처 합성&lt;/a&gt; 에서 &lt;code&gt;Gram Matrix&lt;/code&gt;에 대해 다뤘다. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch8.3.1 - 컨볼루션 신경망을 사용한 텍스처 합성</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch8_3_1_texture_synthesis/</link>
      <pubDate>Fri, 01 May 2020 17:20:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch8_3_1_texture_synthesis/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.2 - 다항분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/&#34;&gt;Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/&#34;&gt;Tensorflow 2.0 Tutorial ch6.1-2 - CNN 이론&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_3_fashion_mnist_with_cnn/&#34;&gt;Tensorflow 2.0 Tutorial ch6.3 - Fashion MNIST with CNN 실습&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_4_improve_performance/&#34;&gt;Tensorflow 2.0 Tutorial ch6.4 - 모형의 성능 높이기&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (1)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (2)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_3_sentimentanalysis/&#34;&gt;Tensorflow 2.0 Tutorial ch7.3 - 긍정, 부정 감성 분석&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (1) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (2) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_1_tensorflow_hub/&#34;&gt;Tensorflow 2.0 Tutorial ch8.1 - 텐서플로 허브&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_2_transfer_learning/&#34;&gt;Tensorflow 2.0 Tutorial ch8.2 - 전이 학습과 &amp;amp; Kaggle 대회&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요&#34;&gt;I. 개요&lt;/h2&gt;
&lt;p&gt;2015년, 딥러닝과 예술의 만남으로 큰 화제가 되었던 신경 스타일 전이 논문&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;은 반 고흐의 (별이 빛나는 밤에)라는 그림과 풍경 사진을 합성해서 반 고흐가 그린 것 같은 스타일의 풍경 이미지를 만들었고, &lt;a href=&#34;https://prisma-ai.com/&#34;&gt;프리즈마&lt;/a&gt;등의 앱은 이 알고리즘을 빠르게 탑재해서 인기를 끌었습니다.&lt;/p&gt;
&lt;p&gt;본 포스트에서는 텍스처 합성에 대해 알아본 뒤 2장의 이미지에서 각각 스타일과 내용을 가져와서 합성하는 신경 스타일 전이에 대해 다루도록 합니다.&lt;/p&gt;
&lt;h2 id=&#34;ii-컨볼루션-신경망을-사용한-텍스처-합성&#34;&gt;II. 컨볼루션 신경망을 사용한 텍스처 합성&lt;/h2&gt;
&lt;p&gt;텍스처(Texture)는 넓은 의미로는 단순히 이미지만, 컴퓨터 비전에서 쓰이는 좁은 의미로는 지역적으로는 비교적 다양한 값을 가지면서 전체적으로는 비슷한 모습을 보이는 이미지를 뜻합니다.&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;돌, 나무, 구름, 섬유 등의 텍스처에서는 위 조건에 해당하는 일정한 패턴을 관찰할 수 있으며, 이 패턴은 전체적으로 비슷하면서도 지역적으로는 서로 조금씩 다릅니다.&lt;/p&gt;
&lt;h3 id=&#34;1-텍스처-합성-방법론&#34;&gt;(1) 텍스처 합성 방법론&lt;/h3&gt;
&lt;p&gt;텍스처 합성 방법론은 크게 두가지입니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;첫번째, 픽셀이나 이미지를 잘게 쪼갠 단위인 &lt;code&gt;Patch&lt;/code&gt;(조각)을 재배열하는 방법입니다. Patch Match 알고리즘을 최적화한 버전입니다.&lt;/li&gt;
&lt;li&gt;두번째, 파라미터에 의한 텍스처 모델링입니다. 먼저 원본 텍스처의 공간적인 통계값(Spatial Statistics)을 사람이 정교하게 만든 여러 개의 필터로 구합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;특히, 교재는 필터 부분을 딥러닝이 가장 제일 잘하는 것으로 설명하고 있고, 여기에 관한 그림 및 이론적인 설명으로 297-300페이제 걸쳐서 설명을 하고 있습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;주요 논문은 &lt;a href=&#34;https://papers.nips.cc/paper/5633-texture-synthesis-using-convolutional-neural-networks.pdf&#34;&gt;Texture Synthesis Using Convolutional Neural Networks&lt;/a&gt; 입니다.&lt;/li&gt;
&lt;li&gt;Gram Matrix을 활용합니다.&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;이 부분은 교재를 참고하시기를 바랍니다.&lt;/p&gt;
&lt;h3 id=&#34;2-원본-텍스처-이미지-불러오기&#34;&gt;(2) 원본 텍스처 이미지 불러오기&lt;/h3&gt;
&lt;p&gt;이제 실습 코드로 진행해봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 텐서플로 2 버전 선택&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
    &lt;span style=&#34;color:#75715e&#34;&gt;# %tensorflow_version only exists in Colab.&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;tensorflow_version &lt;span style=&#34;color:#ae81ff&#34;&gt;2.&lt;/span&gt;x
&lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Exception&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;pass&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow_hub &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; hub

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; cv2

style_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;style.jpg&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://bit.ly/2mGfZIq&amp;#39;&lt;/span&gt;)
style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(style_path)
style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(style_image, dsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;))
style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; style_image &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(style_image)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from http://bit.ly/2mGfZIq
344064/337723 [==============================] - 0s 0us/step





&amp;lt;matplotlib.image.AxesImage at 0x7fbf05a4b668&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_03_1/output_6_2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;tf.keras.utils.get_file()&lt;/code&gt; 함수로 파일을 다운로드한 뒤에 &lt;code&gt;OpenCV&lt;/code&gt;로 이미지의 크기를 (224, 224)로 조정합니다. 더 큰 크기로 지정해도 상관없지만 일단은 작은 크기에서 어떻게 동작하는지 확인해보고, 큰 크기의 이미지는 다음 절의 신경 스타일 전이에서 시도합니다.&lt;/p&gt;
&lt;h3 id=&#34;3-타깃-텍스처-만들기&#34;&gt;(3) 타깃 텍스처 만들기&lt;/h3&gt;
&lt;p&gt;그 다음으로는 타깃 텍스처로 사용할 이미지를 만듭니다. 타깃 텍스처는 랜덤 노이즈 이미지에서 시작하며, 랜덤 노이지를 만드는 방법 &lt;code&gt;3.3.1&lt;/code&gt;절의 난수생성에서 배운 걸 응용합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;target_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uniform(style_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(target_image[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,:])

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(target_image)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;tf.Tensor([0.06687331 0.9121063  0.9395486 ], shape=(3,), dtype=float32)





&amp;lt;matplotlib.image.AxesImage at 0x7fbf055b5eb8&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_03_1/output_9_2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;style_image&lt;/code&gt;와 같은 차원을 가지는 랜덤 노이즈를 생성합니다. 컬러 이미지이기 때문에 차원 수는 (224, 224, 3)으로 마지막에 &lt;code&gt;RGB&lt;/code&gt; 차원을 나타내는 3이 붙습니다. 타깃 텍스처의 첫 번째 픽셀(좌측 최상단)의 값을 출력해보면 0~1 사이의 &lt;code&gt;RGB&lt;/code&gt;컬러 값을 확인할 수 있습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras.applications &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; VGG19
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras.applications.vgg19 &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; preprocess_input

vgg &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; VGG19(include_top&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False, weights&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;imagenet&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; layer &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; vgg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers:
  &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(layer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;name)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5
80142336/80134624 [==============================] - 2s 0us/step
input_1
block1_conv1
block1_conv2
block1_pool
block2_conv1
block2_conv2
block2_pool
block3_conv1
block3_conv2
block3_conv3
block3_conv4
block3_pool
block4_conv1
block4_conv2
block4_conv3
block4_conv4
block4_pool
block5_conv1
block5_conv2
block5_conv3
block5_conv4
block5_pool
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;전체 네트워크를 불러올 필요가 없이 때문에 &lt;code&gt;include_top&lt;/code&gt;인수를 &lt;code&gt;False&lt;/code&gt;로 지정해서 마지막의 &lt;code&gt;Dense&lt;/code&gt;레이어를 제외한 나머지 레이어를 불러와 &lt;code&gt;vgg&lt;/code&gt; 변수에 저장합니다. &lt;code&gt;vgg&lt;/code&gt; 변수에 저장된 네트워크에는 특징 추출기의 역할을 하는 컨볼루션 레이어와 풀링 레이어를 포함하고 있습니다. 이 중에서 선택적으로 사용할수도 있지만, &lt;code&gt;Gram Matrix&lt;/code&gt;가 지역적인 구조와 전체적인 구조를 모두 잡아낼 수 있도록 앞쪽과 뒤쪽의 레이어를 모두 사용하는 것이 좋습니다.&lt;/p&gt;
&lt;h3 id=&#34;4-특징-추출-모델-만들기&#34;&gt;(4) 특징 추출 모델 만들기&lt;/h3&gt;
&lt;p&gt;위 내용을 기반으로 특징 추출 모델을 만들어보도록 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;style_layers &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;block1_conv1&amp;#39;&lt;/span&gt;, 
                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;block2_conv1&amp;#39;&lt;/span&gt;, 
                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;block3_conv1&amp;#39;&lt;/span&gt;, 
                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;block4_conv1&amp;#39;&lt;/span&gt;, 
                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;block5_conv1&amp;#39;&lt;/span&gt;]

vgg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trainable &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; False
outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [vgg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_layer(name)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;output &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; name &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; style_layers]
model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Model([vgg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;input], outputs)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;위 코드는 이미지를 입력하면 다섯 개의 레이어에서 출력되는 특징 추출값을 얻을 수 있는 모델입니다.&lt;/li&gt;
&lt;li&gt;이 모델은 &lt;code&gt;model&lt;/code&gt;이라는 변수에 저장합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;5-gram-matrix-함수-정의&#34;&gt;(5) Gram Matrix 함수 정의&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Gram Matrix&lt;/code&gt;를 계산하는 함수를 정의합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;gram_matrix&lt;/span&gt;(input_tensor):
    channels &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(input_tensor&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
    a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(input_tensor, [&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, channels])
    n &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape(a)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
    gram &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;matmul(a, a, transpose_a&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; gram &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(n, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;먼저 입력된 특징 추출값의 형태를 벡터로 변환시킵니다. 예를 들어, 첫 번째 레이어인 &lt;code&gt;block1_conv1&lt;/code&gt;를 통과한 특정 추출값의 차원 수는 (224, 224, 64)입니다.&lt;/li&gt;
&lt;li&gt;이것을 맨 뒤의 차원(채널)인 64만 남기고 나머지를 1차원의 벡터로 만들면 차원 수는 (50176, 64)가 됩니다.&lt;/li&gt;
&lt;li&gt;이렇게 만든 행렬은 자기 자신의 전치행렬과 행렬곱하는 부분은 &lt;code&gt;gram = tf.matmul(a, a, transpose_a = True)&lt;/code&gt;입니다. &lt;code&gt;transpose_a&lt;/code&gt;라는 인수에 &lt;code&gt;True&lt;/code&gt;값을 넣어서 행렬곱을 할 때 전치행렬을 자동으로 만들어서 계산해도 됩니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;transpose_a&lt;/code&gt;가 &lt;code&gt;True&lt;/code&gt;이기 때문에 행렬곱 계산 결과의 차원은 &lt;code&gt;[64,50176]X[50176,64] = [64,64]&lt;/code&gt;가 됩니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;(224, 224, 64)&lt;/code&gt;가 &lt;code&gt;[64, 64]&lt;/code&gt;로 줄어듭니다.&lt;/li&gt;
&lt;li&gt;마지막 &lt;code&gt;return&lt;/code&gt;문에서는 1차원 벡터의 길이인 &lt;code&gt;50,176&lt;/code&gt;으로 &lt;code&gt;Gram Matrix&lt;/code&gt;값을 나눕니다.&lt;/li&gt;
&lt;li&gt;이렇게 나누지 않으면 앞쪽에 오는 레이어일수록 특징 추출값의 이미지가 크기 때문에 &lt;code&gt;Gram Matrix&lt;/code&gt;값도 커져서 큰 영향을 줍니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;6-원본-텍스처에서-gram-matrix-계산&#34;&gt;(6) 원본 텍스처에서 Gram Matrix 계산&lt;/h3&gt;
&lt;p&gt;원본 텍스처에서 &lt;code&gt;Gram Matrix&lt;/code&gt; 계산합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(style_path)
style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(style_image, dsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;))
style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; style_image &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;

style_batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; style_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;)
style_batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(style_batch, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
style_output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model(preprocess_input(style_batch &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;style_output&lt;/code&gt;은 다섯 레이어를 통과한 특징 추출값으로 구성되어 있습니다. 그중 하나를 &lt;code&gt;matplotlib.pyplot&lt;/code&gt;으로 출력합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(style_output[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(style_output[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][:,:,:,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;), cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;(1, 224, 224, 64)





&amp;lt;matplotlib.image.AxesImage at 0x7fbef01cf5f8&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_03_1/output_21_2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;특징 추출값 [1, 224, 224, 64]을 확인할 수 있습니다. 이렇게 처리된 원본 텍스처의 &lt;code&gt;Gram Matrix&lt;/code&gt;값을 계산합니다. 또 값이 어떻게 나오는지 그래프로 분포를 확인해봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;style_outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [gram_matrix(out) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; out &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; style_output]

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;):
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    array &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sorted(style_outputs[c]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tolist())
    array &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; array[::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;bar(range(style_outputs[c]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]), array)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(style_layers[c])
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_03_1/output_23_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Gram Matrix&lt;/code&gt; 값은 레이어마다 다르게 나오고 최대값에서도 차이가 나는 것을 확인할 수 있습니다. 즉, 이 말은 각 레이어에서 계산되는 &lt;code&gt;Gram Matrix&lt;/code&gt;값에 가중치를 곱해주는 방법으로 특정한 레이어가 너무 큰 영향을 끼치지 못하도록 제어를 해야 합니다.&lt;/p&gt;
&lt;p&gt;따라서, 타깃 텍스처를 업데이트 하기 위해 몇 가지 함수를 설정해야 합니다.&lt;/p&gt;
&lt;h3 id=&#34;7-타깃-텍스처-업데이트-함수-정의&#34;&gt;(7) 타깃 텍스처 업데이트 함수 정의&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;먼저, 타깃 텍스처에서 &lt;code&gt;gram matrix&lt;/code&gt;을 구하는 함수가 필요합니다.&lt;/li&gt;
&lt;li&gt;MSE를 구하는 함수가 필요한데, 원본 텍스처의 Gram Matrix 값과, 타깃 텍스처의 Gram Matrix 사이의 &lt;code&gt;MSE&lt;/code&gt; 함수가 필요합니다.&lt;/li&gt;
&lt;li&gt;이 때, MSE 값이 0.0에서 1.0사이의 컬러 값이어야 하기 때문에 그 이하나 이상으로 값이 넘어가지 않도록 해주는 함수가 필요합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 타깃 텍스처 gram matrix 함수 정의&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_outputs&lt;/span&gt;(image):
    image_batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(image, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
    output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model(preprocess_input(image_batch &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;))
    outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [gram_matrix(out) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; out &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; output]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; outputs

&lt;span style=&#34;color:#75715e&#34;&gt;# MSE 구하는 함수 (원본 텍스처 gram matrix - 타깃 텍스처 gram matrix)&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_loss&lt;/span&gt;(outputs, style_outputs):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_sum([tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_mean((o&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;s)&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; o,s &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(outputs, style_outputs)])
  
&lt;span style=&#34;color:#75715e&#34;&gt;# 0.0~1.0 사이의 컬러값 정의 함수&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clip_0_1&lt;/span&gt;(image):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clip_by_value(image, clip_value_min&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.0&lt;/span&gt;, clip_value_max&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;8-이미지-업데이트-함수-정의&#34;&gt;(8) 이미지 업데이트 함수 정의&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;지금까지 배워온 딥러닝과의 차이점&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;tf.keras를 이용해 모델 정의하고 &lt;code&gt;fit()&lt;/code&gt; 함수를 이용해 가중치가 주어진 과제를 잘 수행하도록 하는 것&lt;/li&gt;
&lt;li&gt;그런데, 이번 포스트에서는 학습해야 할 가중치가 존재하지 않음&lt;/li&gt;
&lt;li&gt;존재하는 것은 2개의 이미지와 &lt;code&gt;Gram Matrix&lt;/code&gt;의 차이인 MSE 뿐&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;GradientType&lt;/code&gt;은 이런 상황에 대한 간편한 해결책임. 자동 미분을 통해 입력에 대한 손실을 구한 뒤 다른 변수에 대한 &lt;code&gt;Gradient(기울기)&lt;/code&gt;를 계산함. 여기에서 다른 변수는 입력이 될 수도 있고, 가중치가 될 수도 있음.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;중요한 점은 &lt;code&gt;GradientType&lt;/code&gt;의 계산 과정 안에 묶인 변수에 대한 &lt;code&gt;Gradient&lt;/code&gt;여야 함.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;opt &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(learning_rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, beta_1&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.99&lt;/span&gt;, epsilon&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1e-1&lt;/span&gt;)

&lt;span style=&#34;color:#a6e22e&#34;&gt;@tf.function&lt;/span&gt;()
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;train_step&lt;/span&gt;(image):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;GradientTape() &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tape:
        outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_outputs(image)
        loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_loss(outputs, style_outputs)

    grad &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tape&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gradient(loss, image)
    opt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply_gradients([(grad, image)])
    image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;assign(clip_0_1(image))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;첫 줄에서 최적화 함수(&lt;code&gt;optimizer&lt;/code&gt;)를 정의함. 논문에서는 &lt;code&gt;L-BFGS&lt;/code&gt;라는 최적화 함수를 썼지만, &lt;code&gt;Adam Optimizer&lt;/code&gt;를 사용해도 속도는 더 빠르고 결과물은 비슷하게 나옵니다.&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;tf.function()&lt;/code&gt; 함수는 &lt;code&gt;train_step(image)&lt;/code&gt; 함수를 인수로 받아서 &lt;code&gt;Autograph&lt;/code&gt;라는 강력한 기능을 추가합니다. &lt;code&gt;Autograph&lt;/code&gt;는 파이썬 문법으로 텐서플로의 핵심인 그래프(&lt;code&gt;Graph&lt;/code&gt;)를 컨트롤 할 수 있게 해줍니다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;2.0&lt;/code&gt; 버전을 위해 즉시 실행 모드(&lt;code&gt;Eager Execution&lt;/code&gt;)와 &lt;code&gt;tf.function&lt;/code&gt; 장식자가 나오면서 이런 불편함이 개선됩니다. &lt;code&gt;tf.function&lt;/code&gt;은 해당 장식자를 사용한 함수에서 호출되는 다른 함수도 그래프에 자동으로 포함시킵니다. 그리고 &lt;code&gt;GradientTape&lt;/code&gt;은 계산에 관계되는 모든 변수와 연산을 추적하기 때문에 퍼포먼스에 영향을 주는데 &lt;code&gt;tf.function&lt;/code&gt;장식자를 붙이면 이 연산들을 고성능의 그래프 연산으로 변환하기 때문에 퍼포먼스를 개선할 수 있습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;GradientTape() &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tape:
  outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_outputs(image)
  loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_loss(outputs, style_outputs)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;GradientTape()&lt;/code&gt;는 보통 &lt;code&gt;with&lt;/code&gt;와 함께 사용합니다. &lt;code&gt;tape&lt;/code&gt;라는 이름으로 새로운 &lt;code&gt;GradientTape&lt;/code&gt;의 인스턴스를 생성해서 참조합니다. 앞에서 설명한대로 &lt;code&gt;get_outputs(image)&lt;/code&gt;, &lt;code&gt;get_loss(outputs, style_outputs)&lt;/code&gt; 함수는 &lt;code&gt;tf.function&lt;/code&gt; 장식자를 쓰지 않았지만, 호출한 함수에 장식자가 붙었기 때문에 텐서플로의 그래프에 자동으로 포함됩니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;grad &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tape&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gradient(loss, image)
opt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply_gradients([(grad, image)])
image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;assign(clip_0_1(image))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;tape.gradient(loss, image)&lt;/code&gt;는 &lt;code&gt;with&lt;/code&gt; 구문 안에서 발생한 계산을 추적해서 입력값인 &lt;code&gt;image&lt;/code&gt;에 대한 &lt;code&gt;loss&lt;/code&gt;의 &lt;code&gt;gradient&lt;/code&gt;를 계산합니다.&lt;/li&gt;
&lt;li&gt;이렇게 계산된 &lt;code&gt;gradient&lt;/code&gt;는 변수 &lt;code&gt;grad&lt;/code&gt;에 저장되고 &lt;code&gt;Adam Optimizer&lt;/code&gt;를 통해 &lt;code&gt;image&lt;/code&gt;에 영향을 줍니다. 즉, 입력값인 &lt;code&gt;image&lt;/code&gt;는 이 계산으로 변화가 됩니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;clip_0_1(image)&lt;/code&gt;함수의 계산 결과를 &lt;code&gt;image&lt;/code&gt;에 다시 넣어서 컬러값이 &lt;code&gt;0.0&lt;/code&gt;과 &lt;code&gt;1.0&lt;/code&gt; 사이에 머물게 합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;9-텍스처-합성-알고리즘-실행&#34;&gt;(9) 텍스처 합성 알고리즘 실행&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;이제 앞에서 정의한 &lt;code&gt;train_step(image)&lt;/code&gt; 함수를 반복적으로 실행해서 텍스처를 합성합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; IPython.display &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; display
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; time
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; imageio

start &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time()

image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Variable(target_image)

epochs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;
steps_per_epoch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;

step &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(epochs):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; m &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(steps_per_epoch):
        step &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
        train_step(image)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; epochs &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:
        imageio&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imwrite(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;style_epoch_{0}.png&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(n), image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_value()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy())
    display&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clear_output(wait&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_value())
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Train step: {}&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(step))
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

end &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time()
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Total time: {:.1f}&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(end&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;start))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_03_1/output_32_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Total time: 119.2
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;먼저 첫 줄에서는 새로운 텍스처 출력을 나타내고 이전 이전 텍스처 출력을 지우기 위해 &lt;code&gt;IPython.display&lt;/code&gt;에서 &lt;code&gt;display&lt;/code&gt;를 임포트합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;실행 시간을 추적하기 위해 &lt;code&gt;time&lt;/code&gt;을, 합성된 텍스처 이미지를 저장하기 위해 &lt;code&gt;imageio&lt;/code&gt;를 import 합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Variable(target_image)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;타깃 텍스처에 &lt;code&gt;tf.Variable&lt;/code&gt;을 씌워서 &lt;code&gt;image&lt;/code&gt;라는 변수로 저장합니다. 텐서플로에서 그래프 연산을 하는 &lt;code&gt;tensor&lt;/code&gt;는 &lt;code&gt;tf.Variable&lt;/code&gt;이나 &lt;code&gt;tf.Constant&lt;/code&gt; 등에 저장되어야 합니다. (&lt;code&gt;tf.keras&lt;/code&gt;)에서는 넘파이 &lt;code&gt;array&lt;/code&gt;를 넘겨도 자동으로 이런 변환을 해줬지만 여기서는 직접 해야 합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;중첩 for 문에서는 에포크당 100 step씩 train_step(image)함수를 실행시킵니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;10-variation-loss-함수-정의&#34;&gt;(10) variation loss 함수 정의&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;매끄러운 원본과 달리 자글자글한 노이즈가 보입니다. 이러한 이미지에 생기는 노이즈를 개선하기 위해서 전체 손실에 &lt;code&gt;variation loss&lt;/code&gt;라는 것을 추가해볼 수 있습니다. &lt;code&gt;variation loss&lt;/code&gt;란 어떤 픽셀과 바로 옆에 인접한 픽셀의 차이입니다. 이 차이가 작을수록 이미지는 매끄럽게 보입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;high_pass_x_y&lt;/span&gt;(image):
  x_var &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; image[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:, :] &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; image[:, :&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, :]
  y_var &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; image[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:, :, :] &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; image[:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, :, :]
  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; x_var, y_var

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;total_variation_loss&lt;/span&gt;(image):
  x_deltas, y_deltas &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; high_pass_x_y(image)
  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_mean(x_deltas&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_mean(y_deltas&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;high_pass_x_y(image)&lt;/code&gt; 함수에서는 입력된 &lt;code&gt;image&lt;/code&gt;의 &lt;code&gt;x축 방향&lt;/code&gt;과 &lt;code&gt;y축 방향&lt;/code&gt;의 차이를 구합니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;x_var&lt;/code&gt;는 &lt;code&gt;image(224, 224, 3)&lt;/code&gt;의 &lt;code&gt;Shape&lt;/code&gt;일 때 &lt;code&gt;(224, 223, 3)&lt;/code&gt;이 되고, &lt;code&gt;y_var&lt;/code&gt;는 &lt;code&gt;(223, 224, 3)&lt;/code&gt;으로 각각 x와 y의 방향으로 1픽셀씩 작은 image가 됩니다.&lt;/li&gt;
&lt;li&gt;total_variation_loss(image) 함수에서는 이렇게 구한 x, y축 방향의 차이를 제곱해서 평균을 낸 다음에 합해서 반환합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;왜 &lt;code&gt;variation loss&lt;/code&gt;가 필요한지 원본 텍스처와 타깃 텍스처, 그리고 랜덤 노이즈 텍스처의 &lt;code&gt;variation loss&lt;/code&gt;를 비교합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;target :&amp;#39;&lt;/span&gt;, total_variation_loss(image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_value()))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;noise : &amp;#39;&lt;/span&gt;, total_variation_loss(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uniform(style_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;original : &amp;#39;&lt;/span&gt;, total_variation_loss(style_image))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;target : tf.Tensor(0.101396605, shape=(), dtype=float32)
noise :  tf.Tensor(0.3360309, shape=(), dtype=float32)
original :  tf.Tensor(0.03641251305469578, shape=(), dtype=float64)
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;위 결과값은 타깃 텍스처의 &lt;code&gt;variation loss&lt;/code&gt;는 랜덤 노이즈의 1/3 정도로 작지만, 원본 텍스처보다는 3배 정도 큽니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;11-각-손실의-가중치-추가&#34;&gt;(11) 각 손실의 가중치 추가&lt;/h3&gt;
&lt;p&gt;이 차이가 줄어들게 된다면 타깃 텍스처는 원본 텍스처에 더 가까운 모습을 보일 것이라고 가정하고, &lt;code&gt;variation loss&lt;/code&gt;를 전체 손실 계산식에 추가합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;total_variation_weight &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1e9&lt;/span&gt;
style_weight &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1e-1&lt;/span&gt;

&lt;span style=&#34;color:#a6e22e&#34;&gt;@tf.function&lt;/span&gt;()
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;train_step&lt;/span&gt;(image):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;GradientTape() &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tape:
        outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_outputs(image)
        loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; style_weight &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; get_loss(outputs, style_outputs)
        loss &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; total_variation_weight &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; total_variation_loss(image)

    grad &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tape&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gradient(loss, image)
    opt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply_gradients([(grad, image)])
    image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;assign(clip_0_1(image))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;지금까지 구한 &lt;code&gt;Gram Matrix&lt;/code&gt;는 &lt;code&gt;style loss&lt;/code&gt;라고 부릅니다. 이 &lt;code&gt;style loss&lt;/code&gt;와 새로 추가된 &lt;code&gt;variation loss&lt;/code&gt;에 각각 가중치를 곱해서 전체 손실에 더합니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;variation loss&lt;/code&gt;는 &lt;code&gt;Gram Matrix&lt;/code&gt; 계산값에 비해 작기 때문에 큰 가중치를 곱하고, 반대로 &lt;code&gt;style loss&lt;/code&gt;는 값을 줄여줍니다. 여기에 들어가는 가중치인 &lt;code&gt;total_variation_weight&lt;/code&gt;와 &lt;code&gt;style_weight&lt;/code&gt;는 적절한 값을 찾을 때까지 꾸준한 실험이 필요합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;12-variation-loss를-추가한-텍스처-합성-알고리즘-실행&#34;&gt;(12) variation loss를 추가한 텍스처 합성 알고리즘 실행&lt;/h3&gt;
&lt;p&gt;개선된 결과를 얻을 수 있는지, 결과값의 &lt;code&gt;variation loss&lt;/code&gt;를 출력하면 다음과 같습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;start &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time()

target_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uniform(style_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Variable(target_image)

epochs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;
steps_per_epoch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;

step &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(epochs):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; m &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(steps_per_epoch):
        step &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
        train_step(image)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; epochs &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:
        imageio&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imwrite(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;style_epoch_{0}.png&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(n), image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_value()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy())
    display&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clear_output(wait&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_value())
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Train step: {}&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(step))
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

end &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time()
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Total time: {:.1f}&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(end&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;start))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_03_1/output_43_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Total time: 119.7
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;확실히 좀 더 개선된 결과를 얻을 수 있습니다. 이렇게 결과값의 &lt;code&gt;variation loss&lt;/code&gt;를 출력해보면 다음과 같습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;target :&amp;#39;&lt;/span&gt;, total_variation_loss(image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_value()))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;original : &amp;#39;&lt;/span&gt;, total_variation_loss(style_image))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;target : tf.Tensor(0.030996362, shape=(), dtype=float32)
original :  tf.Tensor(0.03641251305469578, shape=(), dtype=float64)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;타깃 텍스처의 &lt;code&gt;variation loss&lt;/code&gt;가 원본 텍스처보다도 더 작아진 것을 확인할 수 있습니다. 결과 이미지도 &lt;code&gt;style loss&lt;/code&gt;만 사용했을 때 보다 매끄럽게 변한 것 같습니다.&lt;/p&gt;
&lt;h3 id=&#34;13-결론&#34;&gt;(13) 결론&lt;/h3&gt;
&lt;p&gt;지금까지 배운 것은 &lt;code&gt;style loss&lt;/code&gt;와 &lt;code&gt;variation loss&lt;/code&gt;를 이용하여 텍스쳐 합성 방법을 알아보도록 합니다.&lt;/p&gt;
&lt;h2 id=&#34;iii-연습-파일&#34;&gt;III. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch8_3_1_Texture_Synthesis.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;vi-reference&#34;&gt;VI. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Leon A. Gatys, Alexander S. Ecker, Matthias Bethge., (2015). A Neural Algorithm of Artistic Style. &lt;a href=&#34;https://arxiv.org/abs/1508.06576&#34;&gt;https://arxiv.org/abs/1508.06576&lt;/a&gt; &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.textures.com/&#34;&gt;https://www.textures.com/&lt;/a&gt; 에서 텍스처 이미지를 다양하게 확인할 수 있습니다. &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Gram Matrix는 앞에서 본 각 뉴런의 특징 추출값을 1차원의 벡터로 변환한 다음에, 벡터를 쌓아올린 행렬을 그 자신의 전치(&lt;code&gt;transpose&lt;/code&gt;) 행렬과 행렬곱해서 얻는 값입니다. &lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Ivanov, S. (2017). &amp;ldquo;Picking an optimizer for Style Transfer&amp;rdquo;. Retrieved from &lt;a href=&#34;https://blog.slavv.com/picking-an-optimizer-for-style-transfer-86e7b8cba84b&#34;&gt;https://blog.slavv.com/picking-an-optimizer-for-style-transfer-86e7b8cba84b&lt;/a&gt; &lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch8.2 - 전이 학습과 &amp; Kaggle 대회</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch8_2_transfer_learning/</link>
      <pubDate>Wed, 29 Apr 2020 17:20:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch8_2_transfer_learning/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.2 - 다항분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/&#34;&gt;Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/&#34;&gt;Tensorflow 2.0 Tutorial ch6.1-2 - CNN 이론&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_3_fashion_mnist_with_cnn/&#34;&gt;Tensorflow 2.0 Tutorial ch6.3 - Fashion MNIST with CNN 실습&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_4_improve_performance/&#34;&gt;Tensorflow 2.0 Tutorial ch6.4 - 모형의 성능 높이기&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (1)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (2)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_3_sentimentanalysis/&#34;&gt;Tensorflow 2.0 Tutorial ch7.3 - 긍정, 부정 감성 분석&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (1) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (2) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_1_tensorflow_hub/&#34;&gt;Tensorflow 2.0 Tutorial ch8.1 - 텐서플로 허브&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요&#34;&gt;I. 개요&lt;/h2&gt;
&lt;p&gt;전이 학습이란 미리 훈련된 모델을 다른 작업에 사용하기 위해 추가적인 학습을 시키는 것입니다. 이 때 훈련된 모델은 데이터에서 유의미한 특징(feature)을 뽑아내기 위한 특징 추출기(&lt;code&gt;Feature Extractor&lt;/code&gt;)로 쓰이거나, 모델의 일부를 재학습시키기도 합니다.&lt;/p&gt;
&lt;p&gt;이 부분에 대한 구체적인 이론 설명[8.2.1 모델의 일부를 재학습시키기]은 교재를 참고하시기를 바랍니다. 전이학습은 간단하게 말하면 훈련 시킬 레이어와 그렇지 않을 레이어를 구분해야 하고, 이때 &lt;code&gt;freeze&lt;/code&gt;라는 용어를 사용합니다.&lt;/p&gt;
&lt;h3 id=&#34;1-이슈&#34;&gt;(1) 이슈&lt;/h3&gt;
&lt;p&gt;변경된 부분은 크게 2개입니다.&lt;/p&gt;
&lt;p&gt;텐서플로의 버전을 2.1.0으로 다시 설치한 후 진행하는 코드를 첫 부분에 추가했습니다. (기존 코드를 최대한 살리기 위해 ImageDataGenerator를 사용해서 직접 학습을 시키려고 했습니다만 현재(2020.04.08) 텐서플로 2.2.0-rc2 버전에서는 ImageDataGenerator를 사용해서 model.fit()이나 model.fit_generator()를 학습시키려 할 경우 1 epoch 진행 후 무한루프에 걸리는 문제가 있기 때문에 텐서플로를 2.1.0으로 다시 설치했습니다.)
예제 8.16을 예제 8.24, 예제 8.25의 내용을 이용하여 수정했고 예제 8.19의 학습 코드도 일부 수정했습니다. 수정된 부분은 최대한 자세하게 주석을 달았습니다. 독자분들께 불편을 드려 죄송합니다.&lt;/p&gt;
&lt;p&gt;[저자, 김환희]&lt;/p&gt;
&lt;h2 id=&#34;ii-캐글-데이터와-연동&#34;&gt;II. 캐글 데이터와 연동&lt;/h2&gt;
&lt;p&gt;캐글은 2010년에 설립된 예측 모델 및 분석 대회를 위한 플랫폼으로 2017년에 구글에 인수되었습니다. 초기에는 전통적인 머신러닝 기법으로 풀 수 있는 테이블 데이터 위주의 문제들이 많았지만, 딥러닝의 발전으로 이미지, 음성, 자연어, 동영상 등 다양한 데이터에 대한 문제들이 올라옵니다.&lt;/p&gt;
&lt;p&gt;한번 알면 어려운 부분은 아닙니다. 그러나 처음 접하는 분들에게는 늘 항상 어렵기 때문에, 잘 따라오시기를 바랍니다.&lt;/p&gt;
&lt;p&gt;또한, 혹, 접근 이미지가 바뀌면, 댓글로 남겨주시기를 바랍니다. 수정하도록 하겠습니다.&lt;/p&gt;
&lt;h3 id=&#34;1-kaggle-module-설치&#34;&gt;(1) Kaggle Module 설치&lt;/h3&gt;
&lt;p&gt;다음 셀에서 짧은 명령어를 실행합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;!&lt;/span&gt;pip install kaggle
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)
Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.4.5.1)
Requirement already satisfied: six&amp;gt;=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)
Requirement already satisfied: urllib3&amp;lt;1.25,&amp;gt;=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)
Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.38.0)
Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)
Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)
Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)
Requirement already satisfied: chardet&amp;lt;3.1.0,&amp;gt;=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests-&amp;gt;kaggle) (3.0.4)
Requirement already satisfied: idna&amp;lt;2.9,&amp;gt;=2.5 in /usr/local/lib/python3.6/dist-packages (from requests-&amp;gt;kaggle) (2.8)
Requirement already satisfied: text-unidecode&amp;gt;=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify-&amp;gt;kaggle) (1.3)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;설치가 끝나면 API Token을 생성해야 합니다. 캐글이 없으신 분은 &lt;a href=&#34;https://www.kaggle.com/&#34;&gt;캐글 가입&lt;/a&gt;을 하시기를 바랍니다.&lt;/p&gt;
&lt;h3 id=&#34;2-api-연동&#34;&gt;(2) API 연동&lt;/h3&gt;
&lt;p&gt;캐글 가입이 완료가 되면, &lt;code&gt;My Account&lt;/code&gt;를 클릭하시기를 바랍니다. (그림 참조)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_02/kaggle_01.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;클릭 이후에 페이지 중간에 &lt;code&gt;API&lt;/code&gt; 부분에서 &lt;code&gt;Create New API Token&lt;/code&gt;을 생성합니다. 그러면 &lt;code&gt;kaggle.json&lt;/code&gt; 파일이 다운로드 됩니다. 이 파일 에디터에 있는 &lt;code&gt;username&lt;/code&gt;과 &lt;code&gt;key&lt;/code&gt;를 google colab의 한 셀에 붙여 넣기를 합니다. 그리고 아래 코드처럼 작성을 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;environ[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;KAGGLE_USERNAME&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;user_id&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# 독자의 ID&lt;/span&gt;
os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;environ[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;KAGGLE_KEY&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;user_api_token&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# 독자의 캐글 API Token&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;위 코드를 작성합니다.&lt;/p&gt;
&lt;h3 id=&#34;3-dog-breed-identification-대회&#34;&gt;(3) Dog Breed Identification 대회&lt;/h3&gt;
&lt;p&gt;본 대회는 약 2년전에 개최된 대회입니다. 본 포스트에서는 캐글 대회에 제출해서 점수를 확인하는 것까지의 여정을 담았습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;대회 주소: &lt;a href=&#34;https://www.kaggle.com/c/dog-breed-identification&#34;&gt;https://www.kaggle.com/c/dog-breed-identification&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;iii-전이학습-모형-실습-예제&#34;&gt;III. 전이학습 모형 실습 예제&lt;/h2&gt;
&lt;h3 id=&#34;1-tensorflow-설치-버전-확인&#34;&gt;(1) tensorflow 설치 버전 확인&lt;/h3&gt;
&lt;p&gt;이슈에서 제기한 것처럼 반드시 아래 코드를 실행시키셔 2.1.0 버전으로 tensorflow를 설치하시기를 바랍니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;!&lt;/span&gt;pip install tensorflow&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2.1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Collecting tensorflow==2.1.0
[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)
[K     |████████████████████████████████| 421.8MB 35kB/s 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;.
.
.
Successfully installed gast-0.2.2 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0&lt;/p&gt;
&lt;h3 id=&#34;2-데이터-다운로드&#34;&gt;(2) 데이터 다운로드&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;environ[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;KAGGLE_USERNAME&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;j2hoon85&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# 독자의 ID&lt;/span&gt;
os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;environ[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;KAGGLE_KEY&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;10109b99cfbccf2eebbf5754a5b45cb7&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# 독자의 캐글 API Token&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# !kaggle competitions download -c dog-breed-identification&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;Notice 교재에서는 &lt;code&gt;!kaggle competitions download -c dog-breed-identification&lt;/code&gt; 코드가 나와 있지만, 아래 코드로 수정하시기를 바랍니다.&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow_hub &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; hub
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 2020.02.01 현재 kaggle의 Stanford Dog Dataset 파일 구조가 변경되었습니다. &lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# kaggle API를 사용하는 대신에 아래 링크에서 파일을 직접 받아오도록 수정되었습니다.&lt;/span&gt;
tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/labels.csv&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://bit.ly/2GDxsYS&amp;#39;&lt;/span&gt;)
tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/sample_submission.csv&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://bit.ly/2GGnMNd&amp;#39;&lt;/span&gt;)
tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/train.zip&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://bit.ly/31nIyel&amp;#39;&lt;/span&gt;)
tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/test.zip&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://bit.ly/2GHEsnO&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from http://bit.ly/2GDxsYS
483328/482063 [==============================] - 0s 1us/step
Downloading data from http://bit.ly/2GGnMNd
25206784/25200295 [==============================] - 1s 0us/step
Downloading data from http://bit.ly/31nIyel
361357312/361353329 [==============================] - 11s 0us/step
Downloading data from http://bit.ly/2GHEsnO
362848256/362841195 [==============================] - 11s 0us/step





&#39;/content/test.zip&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;다운로드가 완료되면 구글 코랩 좌측 상단에 있는 파일 메뉴를 클릭해서 정상적으로 다운로드를 받았는지 확인해봅니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;labels.csv&lt;/li&gt;
&lt;li&gt;sample_submission.csv&lt;/li&gt;
&lt;li&gt;test.zip&lt;/li&gt;
&lt;li&gt;train.zip&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;위 파일들이 있는지 확인한 뒤, train, test의 압축 데이터를 푼다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;!&lt;/span&gt;unzip train&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zip
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.[0m
  inflating: train/83bcff6b55ee179a7c123fa6103c377a.jpg  
  inflating: train/83be6d622ab74a5e7e08b53eb8fd566a.jpg  
  .
  .
  .
  inflating: train/ffd3f636f7f379c51ba3648a9ff8254f.jpg  
  inflating: train/fff43b07992508bc822f33d8ffd902ae.jpg  
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;3-라벨-데이터-확인&#34;&gt;(3) 라벨 데이터 확인&lt;/h3&gt;
&lt;p&gt;폴더가 있는 경우 먼저 폴더를 만들고 그 안에 압축 파일 안의 파일들을 복사하는 것을 확인할 수 있습니다. 이번에는 정답 라벨을 담고 있는 &lt;code&gt;csv&lt;/code&gt; 파일을 확인합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
label_text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;labels.csv&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(label_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;                                 id             breed
0  000bec180eb18c7604dcecc8fe0dba07       boston_bull
1  001513dfcb2ffafc82cccf4d8bbaba97             dingo
2  001cdf01b096e06d78e9e5112d419397          pekinese
3  00214f311d5d2247d5dfe4fe24b2303d          bluetick
4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;이번에는 &lt;code&gt;info()&lt;/code&gt; 함수를 활용해서 실행하도록 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;label_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;info()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;class &#39;pandas.core.frame.DataFrame&#39;&amp;gt;
RangeIndex: 10222 entries, 0 to 10221
Data columns (total 2 columns):
 #   Column  Non-Null Count  Dtype 
---  ------  --------------  ----- 
 0   id      10222 non-null  object
 1   breed   10222 non-null  object
dtypes: object(2)
memory usage: 159.8+ KB
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;총 10,222장의 사진이 훈련 데이터에 포함되어 있음을 확인할 수 있습니다.&lt;/p&gt;
&lt;p&gt;이번에는 &lt;code&gt;nunique()&lt;/code&gt; 함수를 활용하여 해당 값의 겹치지 않는 숫자를 구한다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;label_text[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;breed&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nunique()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;120
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;4-이미지-확인-시각화&#34;&gt;(4) 이미지 확인 시각화&lt;/h3&gt;
&lt;p&gt;실제로 어떤 사진들로 구성이 되어 있는지 이미지와 라벨을 함께 출력해서 확인합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; PIL.Image &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; Image
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;):
  image_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; label_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[c, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;id&amp;#39;&lt;/span&gt;]
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/train/&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; image_id &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.jpg&amp;#39;&lt;/span&gt;))
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(str(c) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;, &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; label_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[c, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;breed&amp;#39;&lt;/span&gt;])
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_02/output_27_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;각 견종은 다양한 각도에서 찍힌 것을 확인할 수 있습니다.&lt;/p&gt;
&lt;h3 id=&#34;5-가중치-초기화-모델&#34;&gt;(5) 가중치 초기화 모델&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;이 문제가 얼마나 어려운지 확인하기 위해 전이학습 전 먼저 &lt;code&gt;MobileNet V2&lt;/code&gt;의 모든 레이어의 가중치를 초기화한 상태에서 학습시킵니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;어떤 뜻이냐면, 레이어의 구조는 같지만, &lt;code&gt;ImageNet&lt;/code&gt;의 데이터로 미리 훈련된 이미지에 대한 지식은 전혀 없는 상태에서 학습시켜봅니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;텐서플로 허브를 이용하는 방법 외에 &lt;code&gt;tf.keras&lt;/code&gt;에서도 &lt;code&gt;MobileNet V2&lt;/code&gt;를 불러올 수 있습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras.applications &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; MobileNetV2
mobilev2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; MobileNetV2()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5
14540800/14536120 [==============================] - 1s 0us/step
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; layer &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; mobilev2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers[:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]:
    layer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trainable &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; True
    
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; layer &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; mobilev2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers[:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]: 
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;kernel&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; layer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__dict__:
        kernel_shape &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(layer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_weights())&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape
        &lt;span style=&#34;color:#75715e&#34;&gt;# weight를 평균이 0, 표준편차가 1인 random 변수로 초기화&lt;/span&gt;
        layer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_weights(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;normal(kernel_shape, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;위 코드는 MobileNetV2의 가중치를 모두 초기화한 것입니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;첫번째 for 문에서는 각 레이어의 훈련 가능 여부를 모두 True로 바꿉니다. 다만 마지막 레이어인 소프트맥스 &lt;code&gt;Dense&lt;/code&gt;층은 사용하지 않을 것이기 때문에 &lt;code&gt;Mobilev2.layers[:-1]&lt;/code&gt;명령으로 제외합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;두번째 for 문에서는 각 레이어에 &lt;code&gt;kernel&lt;/code&gt;이 있는지를 확인합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;3장에서 뉴런은 가중치 &lt;code&gt;w&lt;/code&gt;와 편향 &lt;code&gt;b&lt;/code&gt;가 있다고 설명합니다. 이 때의 &lt;code&gt;kernel&lt;/code&gt;은 바로 가중치 &lt;code&gt;w&lt;/code&gt;에 해당하고, &lt;code&gt;bias&lt;/code&gt;는 편향 &lt;code&gt;b&lt;/code&gt;를 의미합니다. &lt;code&gt;bias&lt;/code&gt;는 &lt;code&gt;MobileNet V2&lt;/code&gt;에 존재하지 않기 때문에 &lt;code&gt;kernel&lt;/code&gt;이 있는지만 검사해서 있을 경우 그 값을 모두 &lt;code&gt;random&lt;/code&gt;변수로 초기화합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;6-훈련데이터-메모리-로드&#34;&gt;(6) 훈련데이터 메모리 로드&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;초기화가 끝나면 이제 실제로 학습시킵니다. 마찬가지로 여기에 주의점이 있습니다. 용량문제로 인해 4.8일자로 소스코드가 변경되었습니다.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;따라서, 아래 코드로 작성하실 것을 권유 드립니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# # 8.16 train 데이터를 메모리에 로드&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# import cv2&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# train_X = []&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# for i in range(len(label_text)):&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#     img = cv2.imread(&amp;#39;/content/train/&amp;#39; + label_text[&amp;#39;id&amp;#39;][i] + &amp;#39;.jpg&amp;#39;)&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#     img = cv2.resize(img, dsize=(224, 224))&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#     img = img / 255.0&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#     train_X.append(img)&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# train_X = np.array(train_X)&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# print(train_X.shape)&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# print(train_X.size * train_X.itemsize, &amp;#39; bytes&amp;#39;)&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# 2020.04.08 수정된 부분입니다.&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 예제 8.16은 고용량 RAM 모드를 지원하지 않는 무료 버전의 경우 OOM(Out Of Memory) 문제를 일으키기 때문에 주석처리합니다.&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 대신에 예제 8.24와 8.25를 이용해서 ImageDataGenerator로 학습을 시킵니다.&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# 8.24 ImageDataGenerator가 처리할 수 있는 하위 디렉토리 구조로 데이터 복사&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; shutil

os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mkdir(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/train_sub&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(len(label_text)):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exists(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/train_sub/&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; label_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[i][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;breed&amp;#39;&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; False:
        os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mkdir(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/train_sub/&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; label_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[i][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;breed&amp;#39;&lt;/span&gt;])
    shutil&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;copy(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/train/&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; label_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[i][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;id&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.jpg&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/train_sub/&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; label_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[i][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;breed&amp;#39;&lt;/span&gt;])

&lt;span style=&#34;color:#75715e&#34;&gt;# 8.25 ImageDataGenerator를 이용한 train/validation 데이터 분리, Image Augmentation&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.python.keras.preprocessing.image &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; ImageDataGenerator
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; keras.applications.inception_resnet_v2 &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; preprocess_input

image_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# 이미지 사이즈가 299에서 224로 바뀌었습니다.&lt;/span&gt;
batch_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;

train_datagen &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ImageDataGenerator(rescale&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;255.&lt;/span&gt;, horizontal_flip&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, shear_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, zoom_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, width_shift_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, height_shift_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;)
valid_datagen &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ImageDataGenerator(rescale&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;255.&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;)

train_generator &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_datagen&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flow_from_directory(directory&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/content/train_sub/&amp;#34;&lt;/span&gt;, subset&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;training&amp;#34;&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;batch_size, seed&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;42&lt;/span&gt;, shuffle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, class_mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;categorical&amp;#34;&lt;/span&gt;, target_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(image_size, image_size))
valid_generator &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; valid_datagen&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flow_from_directory(directory&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/content/train_sub/&amp;#34;&lt;/span&gt;, subset&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;validation&amp;#34;&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, seed&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;42&lt;/span&gt;, shuffle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, class_mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;categorical&amp;#34;&lt;/span&gt;, target_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(image_size, image_size))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Using TensorFlow backend.


Found 7718 images belonging to 120 classes.
Found 2504 images belonging to 120 classes.
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;6-라벨-데이터-작성&#34;&gt;(6) 라벨 데이터 작성&lt;/h3&gt;
&lt;p&gt;이제 Y에 해당하는 라벨 데이터를 작성합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;unique_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; label_text[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;breed&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unique()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tolist()
train_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [unique_Y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;index(breed) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; breed &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; label_text[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;breed&amp;#39;&lt;/span&gt;]]
train_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(train_Y)

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_Y[:&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;])
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_Y[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;:])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[0 1 2 3 4 5 5 6 7 8]
[34 87 91 63 48  6 93 63 77 92]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;여기서 라벨 데이터는 &lt;code&gt;boston_bull&lt;/code&gt;, &lt;code&gt;dingo&lt;/code&gt;와 같은 텍스트로 되어 있기 때문에 먼저 숫자로 바꾸는 과정이 필요합니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;unique()&lt;/code&gt; 함수를 사용해 &lt;code&gt;label_text[&#39;breed&#39;]&lt;/code&gt;를 구성하는 겹치지 않는 유일한 원소들을 구합니다. 그리고 &lt;code&gt;tolist()&lt;/code&gt; 활용해 array에서 리스트로 변환합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;train_Y의 처음 값 10개와 마지막 값 10개를 확인합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;7-가중치-초기화-시킨-학습-모델-정의&#34;&gt;(7) 가중치 초기화 시킨 학습 모델 정의&lt;/h3&gt;
&lt;p&gt;이제 전이 학습 모델을 정의합니다. 이때 &lt;code&gt;loss&lt;/code&gt; &lt;code&gt;categorical_crossentropy&lt;/code&gt;로 바꿔주시기를 바랍니다. (교재와 다릅니다!)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mobilev2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;output
predictions &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;120&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;)(x)
model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Model(inputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;mobilev2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;input, outputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;predictions)

&lt;span style=&#34;color:#75715e&#34;&gt;# model.compile(optimizer=&amp;#39;sgd&amp;#39;, loss=&amp;#39;sparse_categorical_crossentropy&amp;#39;, metrics=[&amp;#39;accuracy&amp;#39;])&lt;/span&gt;
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sgd&amp;#39;&lt;/span&gt;, loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;categorical_crossentropy&amp;#39;&lt;/span&gt;, metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;]) &lt;span style=&#34;color:#75715e&#34;&gt;# 라벨이 원-핫 인코딩을 사용하기 때문에 sparse가 아닌 categorical_crossentropy를 사용합니다.&lt;/span&gt;
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;model&amp;quot;
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
.
.
.
global_average_pooling2d (Globa (None, 1280)         0           out_relu[0][0]                   
__________________________________________________________________________________________________
dense (Dense)                   (None, 120)          153720      global_average_pooling2d[0][0]   
==================================================================================================
Total params: 2,411,704
Trainable params: 2,377,592
Non-trainable params: 34,112
__________________________________________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;첫 번째 줄에서는 &lt;code&gt;MobileNet V2&lt;/code&gt;에서 마지막 &lt;code&gt;Dense&lt;/code&gt;레이어를 제외하기 위해 두 번째 레이어를 지정해서 그 레이어의 &lt;code&gt;output&lt;/code&gt;을 x라는 변수에 저장합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;그리고, 120개의 뉴런을 가진 &lt;code&gt;Dense&lt;/code&gt;레이어를 새롭게 만듭니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;predictions &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;120&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;)(x)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;보통 모델을 정의할 때, 지금까지는 &lt;code&gt;tf.keras.Sequential&lt;/code&gt; 모델만 사용했습니다. 그리고, 각 레이어는 모형의 안에 존재 했는데, 이번에는 조금 다릅니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;레이어를 함수처럼 사용하는 구문을 함수형(&lt;code&gt;Functional&lt;/code&gt;) API라고 합니다.&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; 자세한 설명은 교재 또는 공식 문서를 참조하시기를 바랍니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;8-정의된-모형-학습-가중치-초기화&#34;&gt;(8) 정의된 모형 학습 (가중치 초기화)&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;model.fit&lt;/code&gt;을 활용해서 학습을 진행합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# history = model.fit(train_X, train_Y, epochs=10, validation_split=0.25, batch_size=32)&lt;/span&gt;
steps_per_epoch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(&lt;span style=&#34;color:#ae81ff&#34;&gt;7718&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;) &lt;span style=&#34;color:#75715e&#34;&gt;# generator를 사용하기 때문에 1epoch 당 학습할 step수를 정합니다. batch_size인 32로 train_data의 크기를 나눠주면 됩니다.&lt;/span&gt;
history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit_generator(train_generator, validation_data&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;valid_generator, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, steps_per_epoch&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;steps_per_epoch) &lt;span style=&#34;color:#75715e&#34;&gt;# model.fit_generator()를 사용합니다.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  [&#39;...&#39;]
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  [&#39;...&#39;]
Train for 241 steps, validate for 2504 steps
Epoch 1/10
241/241 [==============================] - 124s 516ms/step - loss: 4.8789 - accuracy: 0.0101 - val_loss: 9.5161 - val_accuracy: 0.0096
Epoch 2/10
241/241 [==============================] - 124s 514ms/step - loss: 4.8576 - accuracy: 0.0100 - val_loss: 8.6696 - val_accuracy: 0.0104
Epoch 3/10
241/241 [==============================] - 124s 516ms/step - loss: 4.8677 - accuracy: 0.0107 - val_loss: 9.1874 - val_accuracy: 0.0096
Epoch 4/10
241/241 [==============================] - 124s 513ms/step - loss: 4.8604 - accuracy: 0.0108 - val_loss: 8.2864 - val_accuracy: 0.0088
Epoch 5/10
241/241 [==============================] - 124s 513ms/step - loss: 4.8434 - accuracy: 0.0101 - val_loss: 8.3031 - val_accuracy: 0.0080
Epoch 6/10
241/241 [==============================] - 124s 514ms/step - loss: 4.8401 - accuracy: 0.0133 - val_loss: 7.9722 - val_accuracy: 0.0064
Epoch 7/10
241/241 [==============================] - 124s 514ms/step - loss: 4.8345 - accuracy: 0.0130 - val_loss: 7.2442 - val_accuracy: 0.0080
Epoch 8/10
241/241 [==============================] - 124s 516ms/step - loss: 4.8256 - accuracy: 0.0129 - val_loss: 6.9645 - val_accuracy: 0.0120
Epoch 9/10
241/241 [==============================] - 125s 518ms/step - loss: 4.8099 - accuracy: 0.0139 - val_loss: 7.0742 - val_accuracy: 0.0076
Epoch 10/10
241/241 [==============================] - 125s 517ms/step - loss: 4.8077 - accuracy: 0.0147 - val_loss: 6.5409 - val_accuracy: 0.0080
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;9-모형-결과-학습-시각화&#34;&gt;(9) 모형 결과 학습 시각화&lt;/h3&gt;
&lt;p&gt;모형 학습에 대한 결과를 시각화 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;k--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylim(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_02/output_44_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;모형의 학습 결과는 일단, 결론적으로 학습이 잘 되고 있다고 말하기는 어렵습니다.&lt;/p&gt;
&lt;p&gt;다시 위 모형은 사전에 학습된 모형의 가중치를 제거한 모형을 학습 시킨 결과물입니다. 개념을 돕고자 이렇게 학습시키는 것이고, &lt;code&gt;실무에서는 이렇게 할 이유가 없습니다!&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&#34;10-전이-학습-모형-정의&#34;&gt;(10) 전이 학습 모형 정의&lt;/h3&gt;
&lt;p&gt;이번에는 전이 학습을 시도합니다. 일부 레이어의 가중치를 고정시킨 상태로 학습시킵니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras.applications &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; MobileNetV2
mobilev2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; MobileNetV2()

x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mobilev2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;output
predictions &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;120&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;)(x)
model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Model(inputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;mobilev2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;input, outputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;predictions)

&lt;span style=&#34;color:#75715e&#34;&gt;# 뒤에서 20개까지의 레이어는 훈련 가능, 나머지는 가중치 고정&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; layer &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers[:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;]:
    layer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trainable &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; False
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; layer &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;:]:
    layer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trainable &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; True

&lt;span style=&#34;color:#75715e&#34;&gt;# model.compile(optimizer=&amp;#39;sgd&amp;#39;, loss=&amp;#39;sparse_categorical_crossentropy&amp;#39;, metrics=[&amp;#39;accuracy&amp;#39;])&lt;/span&gt;
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sgd&amp;#39;&lt;/span&gt;, loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;categorical_crossentropy&amp;#39;&lt;/span&gt;, metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;]) &lt;span style=&#34;color:#75715e&#34;&gt;# 라벨이 원-핫 인코딩을 사용하기 때문에 sparse가 아닌 categorical_crossentropy를 사용합니다.&lt;/span&gt;
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;model_4&amp;quot;
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
.
.
__________________________________________________________________________________________________
global_average_pooling2d_4 (Glo (None, 1280)         0           out_relu[0][0]                   
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 120)          153720      global_average_pooling2d_4[0][0] 
==================================================================================================
Total params: 2,411,704
Trainable params: 1,204,280
Non-trainable params: 1,207,424
__________________________________________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;함수형 &lt;code&gt;API&lt;/code&gt;를 이용해 모델을 정의하는 과정은 그전과 비슷합니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;model.summary()&lt;/code&gt;의 출력 결과에서 훈련 가능한 가중치의 수와 고정된 값의 가중치가 반반 정도로 비슷해진 것을 확인할 수 있다.&lt;/li&gt;
&lt;li&gt;뒤에서 20개까지의 레이어를 훈련 가능하게 하고, 나머지 레이어의 가중치는 고정시키는 작업을 합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;11-모형-학습-전이-학습-및-결과-시각화&#34;&gt;(11) 모형 학습 (전이 학습) 및 결과 시각화&lt;/h3&gt;
&lt;p&gt;이제 학습을 시키고, 시각화를 진행합니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;모형 학습입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;steps_per_epoch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(&lt;span style=&#34;color:#ae81ff&#34;&gt;7718&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;) &lt;span style=&#34;color:#75715e&#34;&gt;# generator를 사용하기 때문에 1epoch 당 학습할 step수를 정합니다. batch_size인 32로 train_data의 크기를 나눠주면 됩니다.&lt;/span&gt;
history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit_generator(train_generator, validation_data&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;valid_generator, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, steps_per_epoch&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;steps_per_epoch) &lt;span style=&#34;color:#75715e&#34;&gt;# model.fit_generator()를 사용합니다.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  [&#39;...&#39;]
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  [&#39;...&#39;]
Train for 241 steps, validate for 2504 steps
Epoch 1/10
241/241 [==============================] - 170s 703ms/step - loss: 3.4284 - accuracy: 0.2918 - val_loss: 1.9956 - val_accuracy: 0.4772
Epoch 2/10
241/241 [==============================] - 167s 695ms/step - loss: 1.6856 - accuracy: 0.6227 - val_loss: 1.4928 - val_accuracy: 0.5843
Epoch 3/10
241/241 [==============================] - 166s 690ms/step - loss: 1.2359 - accuracy: 0.7022 - val_loss: 1.3797 - val_accuracy: 0.6082
Epoch 4/10
241/241 [==============================] - 166s 688ms/step - loss: 1.0110 - accuracy: 0.7482 - val_loss: 1.2314 - val_accuracy: 0.6522
Epoch 5/10
241/241 [==============================] - 166s 690ms/step - loss: 0.8846 - accuracy: 0.7791 - val_loss: 1.1955 - val_accuracy: 0.6526
Epoch 6/10
241/241 [==============================] - 166s 689ms/step - loss: 0.7828 - accuracy: 0.8078 - val_loss: 1.1607 - val_accuracy: 0.6697
Epoch 7/10
241/241 [==============================] - 166s 690ms/step - loss: 0.7045 - accuracy: 0.8246 - val_loss: 1.1379 - val_accuracy: 0.6733
Epoch 8/10
241/241 [==============================] - 166s 690ms/step - loss: 0.6532 - accuracy: 0.8380 - val_loss: 1.1241 - val_accuracy: 0.6865
Epoch 9/10
241/241 [==============================] - 166s 689ms/step - loss: 0.5957 - accuracy: 0.8557 - val_loss: 1.1469 - val_accuracy: 0.6737
Epoch 10/10
241/241 [==============================] - 166s 690ms/step - loss: 0.5488 - accuracy: 0.8631 - val_loss: 1.1132 - val_accuracy: 0.6809
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;이번엔 시각화입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;k--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylim(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_02/output_53_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;같은 네트워크 구조를 사용했지만, &lt;code&gt;val_accuray&lt;/code&gt;는 &lt;code&gt;1%&lt;/code&gt; 정도에 머물던 가중치 초기화 학습 모델에 비해 전혀 다른 결과(&lt;code&gt;86.3%&lt;/code&gt;)가 나온 것을 확인할 수 있습니다. &lt;code&gt;val_loss&lt;/code&gt;는 감소하는 추세이고, &lt;code&gt;val_accuracy&lt;/code&gt;는 증가 추세여서 학습을 추가적으로 해도 네트워크의 성능이 보다 향상 될 것 같습니다. (다만, 시간은 많이 소요 됩니다!)&lt;/p&gt;
&lt;h2 id=&#34;iii-특징-추출기&#34;&gt;III. 특징 추출기&lt;/h2&gt;
&lt;p&gt;미리 훈련된 모델에서 데이터의 특징만 추출하고, 그 특징을 작은 네트워크에 통과시켜서 정답을 예측하는 방법도 있습니다. 자세한 설명은 교재 (p. 270)을 참조하시기를 바랍니다.&lt;/p&gt;
&lt;h3 id=&#34;1-특징-추출기-불러오기&#34;&gt;(1) 특징 추출기 불러오기&lt;/h3&gt;
&lt;p&gt;텐서플로 허브에서 &lt;code&gt;Inception V3&lt;/code&gt;를 불러옵니다. &lt;code&gt;Inception&lt;/code&gt;은 2014년에 구글이 &lt;code&gt;ImageNet&lt;/code&gt; 대회를 위해 &lt;code&gt;GoogleNet&lt;/code&gt;이라는 이름으로 발표한 컨볼루션 신경망입니다. V3는 세 번째로 개선된 버전입니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow_hub &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; hub

inception_url &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4&amp;#39;&lt;/span&gt;
feature_model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
    hub&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;KerasLayer(inception_url, output_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2048&lt;/span&gt;,), trainable&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)
])
feature_model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;build([None, &lt;span style=&#34;color:#ae81ff&#34;&gt;299&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;299&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;])
feature_model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
keras_layer (KerasLayer)     multiple                  21802784  
=================================================================
Total params: 21,802,784
Trainable params: 0
Non-trainable params: 21,802,784
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;feature_model.build([None, 299, 299, 3])&lt;/code&gt; 함수는 입력 데이터의 차원을 정의해서 넣습니다. 첫번째 차원은 배치 차원이기 때문에 입력이 몇개가 들어와도 상관없습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-imagedatagenerator-파일-복사&#34;&gt;(2) ImageDataGenerator 파일 복사&lt;/h3&gt;
&lt;p&gt;ImageDataGenerator는 라벨이 있는 데이터를 처리할 때 각 라벨의 이름을 하위 디렉터리로 가지고 있는 디렉토리를 받아서 그 데이터를 처리합니다. 반면에 캐글에서 내려받은 데이터들은 하위 디렉터리의 구분 없이 &lt;code&gt;train&lt;/code&gt;폴더에 모든 이미지 파일이 저장되어 있습니다. 따라서 ImageDataGenerator가 처리할 수 있는 방식으로 데이터를 복사합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; shutil

os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mkdir(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/train_sub&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(len(label_text)):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exists(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/train_sub/&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; label_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[i][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;breed&amp;#39;&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; False:
        os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mkdir(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/train_sub/&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; label_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[i][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;breed&amp;#39;&lt;/span&gt;])
    shutil&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;copy(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/train/&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; label_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[i][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;id&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.jpg&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/train_sub/&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; label_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[i][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;breed&amp;#39;&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;3-훈련-및-검증-데이터-분리-그리고-이미지-보강&#34;&gt;(3) 훈련 및 검증 데이터 분리, 그리고 이미지 보강&lt;/h3&gt;
&lt;p&gt;먼저 훈련 및 검증 데이터로 분리하는 소스코드를 작성합니다.
_datagen 함수 안에 있는 인수에 대한 설명은 교재 274페이지를 참고합나디.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.python.keras.preprocessing.image &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; ImageDataGenerator
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; keras.applications.inception_resnet_v2 &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; preprocess_input

image_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;299&lt;/span&gt;
batch_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;

train_datagen &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ImageDataGenerator(rescale&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;255.&lt;/span&gt;, horizontal_flip&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, shear_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, zoom_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, width_shift_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, height_shift_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;)
valid_datagen &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ImageDataGenerator(rescale&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;255.&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;)

train_generator &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_datagen&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flow_from_directory(directory&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/content/train_sub/&amp;#34;&lt;/span&gt;, subset&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;training&amp;#34;&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;batch_size, seed&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;42&lt;/span&gt;, shuffle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, class_mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;categorical&amp;#34;&lt;/span&gt;, target_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(image_size, image_size))
valid_generator &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; valid_datagen&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flow_from_directory(directory&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/content/train_sub/&amp;#34;&lt;/span&gt;, subset&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;validation&amp;#34;&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, seed&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;42&lt;/span&gt;, shuffle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, class_mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;categorical&amp;#34;&lt;/span&gt;, target_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(image_size, image_size))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Found 7718 images belonging to 120 classes.
Found 2504 images belonging to 120 classes.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;이번에는 훈련 데이터를 특징 벡터로 변환합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;batch_step &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;7718&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt; batch_size
train_features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
train_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; idx &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(batch_step):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; idx &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(idx)
    x, y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_generator&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next()
    train_Y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;extend(y)
    
    feature &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; feature_model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(x)
    train_features&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;extend(feature)

train_features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(train_features)
train_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(train_Y)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_features&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_Y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;0
100
200
300
400
500
600
700
(23084, 2048)
(23084, 120)
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;첫번째 코드가 조금 중요한데, &lt;code&gt;batch_step&lt;/code&gt;은 부족한 RAM에 비해 훈련시 필요한 메모리 부족을 해소하기 위해 단계별로 진행핟나는 뜻입니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;batch_size로 나눠서 &lt;code&gt;training&lt;/code&gt; 부분 집합을 3번 정도 반복해서 특징 벡터를 뽑아냅니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;next()&lt;/code&gt; 함수를 사용하면 다음에 올 값을 반환받을 수 있습니다. 훈련 데이터는 이미지의 분류에 해당하는 &lt;code&gt;y&lt;/code&gt;값이 있기 때문에 식의 좌변에서 &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt;를 함께 받습ㄴ다. &lt;code&gt;y&lt;/code&gt;값은 바로 &lt;code&gt;train_Y&lt;/code&gt;에 저장해서 추후 활용하게 됩니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;x&lt;/code&gt;값은 이미지 데이터에 해당하는 부분입니다. 이미 학습이 완료된 특징 추출기를 사용하기 때문에 &lt;code&gt;predict()&lt;/code&gt;로 특징 벡터를 추출합니다. 특징 벡터는 &lt;code&gt;feature&lt;/code&gt;라는 변수에 저장한 뒤 추후에 사용할 수 있도록 &lt;code&gt;train_features&lt;/code&gt;에 저장합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;최종 출력되는 &lt;code&gt;Shape&lt;/code&gt;는 train_feature가 (23084, 2048)이고, train_Y가 (23084, 120)입니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;즉, 특징 벡터는 2,048차원의 벡터임을 확인할 수 있습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;마찬가지로 검증 데이터에도 적용하도록 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;valid_features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
valid_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; idx &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(valid_generator&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;n):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; idx &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(idx)
    x, y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; valid_generator&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next()
    valid_Y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;extend(y)
    
    feature &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; feature_model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(x)
    valid_features&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;extend(feature)

valid_features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(valid_features)
valid_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(valid_Y)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(valid_features&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(valid_Y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
(2504, 2048)
(2504, 120)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;4-작은-시퀀셜-모델-정의&#34;&gt;(4) 작은 시퀀셜 모델 정의&lt;/h3&gt;
&lt;p&gt;이제 분류 모형을 위한 &lt;code&gt;Sequential&lt;/code&gt; 모형을 정의합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2048&lt;/span&gt;,)),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;120&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;)
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;RMSprop(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.0001&lt;/span&gt;), loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;categorical_crossentropy&amp;#39;&lt;/span&gt;, metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential_1&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_5 (Dense)              (None, 256)               524544    
_________________________________________________________________
dropout (Dropout)            (None, 256)               0         
_________________________________________________________________
dense_6 (Dense)              (None, 120)               30840     
=================================================================
Total params: 555,384
Trainable params: 555,384
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;input_shape=(2048,)&lt;/code&gt;을 지정해서 특징 벡터를 받을 수 있도록 합니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Dense&lt;/code&gt; 레이어는 분류를 위해 &lt;code&gt;softmax&lt;/code&gt; 활성화 함수를 지정하고 뉴런의 수는 견종의 수와 같은 &lt;code&gt;120&lt;/code&gt;으로 지정합니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;categorical_crossentropy&lt;/code&gt;가 사용된 이유는 &lt;code&gt;train_Y&lt;/code&gt;의 마지막 차원이 1이 아닌 원-핫 벡터인 120이기 때문입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;정답의 인덱스만 기록된 희소 행렬(sparse matrix)을 Y로 사용할 때는 &lt;code&gt;sparse_categorical_crossentropy&lt;/code&gt;를 사용하고, &lt;code&gt;one-hot&lt;/code&gt; 벡터를 사용할 때는 &lt;code&gt;sparse&lt;/code&gt;가 없는 버전을 사용합니다.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;5-모형-학습-및-시각화&#34;&gt;(5) 모형 학습 및 시각화&lt;/h3&gt;
&lt;p&gt;모형을 학습시키고 시각화로 확인합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_features, train_Y, validation_data&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(valid_features, valid_Y), epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;)

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;k--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylim(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Train on 23084 samples, validate on 2504 samples
Epoch 1/10
23084/23084 [==============================] - 3s 123us/sample - loss: 2.8557 - accuracy: 0.4517 - val_loss: 0.9163 - val_accuracy: 0.8550
Epoch 2/10
23084/23084 [==============================] - 2s 105us/sample - loss: 0.9270 - accuracy: 0.7808 - val_loss: 0.4353 - val_accuracy: 0.8890
Epoch 3/10
23084/23084 [==============================] - 2s 105us/sample - loss: 0.6147 - accuracy: 0.8295 - val_loss: 0.3560 - val_accuracy: 0.8946
Epoch 4/10
23084/23084 [==============================] - 2s 105us/sample - loss: 0.5079 - accuracy: 0.8518 - val_loss: 0.3306 - val_accuracy: 0.8950
Epoch 5/10
23084/23084 [==============================] - 2s 104us/sample - loss: 0.4466 - accuracy: 0.8628 - val_loss: 0.3208 - val_accuracy: 0.8978
Epoch 6/10
23084/23084 [==============================] - 2s 105us/sample - loss: 0.4064 - accuracy: 0.8734 - val_loss: 0.3197 - val_accuracy: 0.8962
Epoch 7/10
23084/23084 [==============================] - 2s 105us/sample - loss: 0.3707 - accuracy: 0.8845 - val_loss: 0.3099 - val_accuracy: 0.9014
Epoch 8/10
23084/23084 [==============================] - 2s 105us/sample - loss: 0.3445 - accuracy: 0.8907 - val_loss: 0.3067 - val_accuracy: 0.9006
Epoch 9/10
23084/23084 [==============================] - 2s 106us/sample - loss: 0.3172 - accuracy: 0.9001 - val_loss: 0.3080 - val_accuracy: 0.8974
Epoch 10/10
23084/23084 [==============================] - 2s 106us/sample - loss: 0.2999 - accuracy: 0.9042 - val_loss: 0.3048 - val_accuracy: 0.8994
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_02/output_71_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;각 에포크당 3초가 걸릴 정도로 학습 속도가 매우 빨라진 것을 확인했습니다.&lt;/p&gt;
&lt;h3 id=&#34;6-학습-모형-테스트&#34;&gt;(6) 학습 모형 테스트&lt;/h3&gt;
&lt;p&gt;모델이 예측을 얼마나 잘하는지 알아보기 위해 검증 데이터의 이미지에 대한 분류를 시각화합니다.&lt;/p&gt;
&lt;p&gt;그 전에 먼저 라벨의 이름을 따로 저장하는데, &lt;code&gt;ImageDataGenerator&lt;/code&gt;에서 라벨을 인덱스로 저장할 때 알파벳 순으로 정렬된 순서로 저장하기 때문에 여기서도 마찬가지로 저장합니다.&lt;/p&gt;
&lt;p&gt;그리고 알파벳순 1~5까지를 순서대로 출력해서 확인합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;unique_sorted_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sorted(unique_Y)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(unique_sorted_Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[&#39;affenpinscher&#39;, &#39;afghan_hound&#39;, &#39;african_hunting_dog&#39;, &#39;airedale&#39;, &#39;american_staffordshire_terrier&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;이제 검증 데이터를 시각화합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; cv2
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; random
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;))
  
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;):
    image_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;choice(valid_generator&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;filepaths)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# 이미지 표시&lt;/span&gt;
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(image_path))
    real_y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; image_path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;]
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(real_y)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)
    idx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; unique_sorted_Y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;index(real_y)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# 예측값 표시&lt;/span&gt;
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(image_path)
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(img, dsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;299&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;299&lt;/span&gt;))
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; img &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(img, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# Inception V3를 이용한 특징 벡터 추출&lt;/span&gt;
    feature_vector &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; feature_model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(img)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# Sequential 모델을 이용한 예측&lt;/span&gt;
    prediction &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(feature_vector)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# 가장 높은 확률의 예측값 5개를 뽑음&lt;/span&gt;
    top_5_predict &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; prediction&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argsort()[::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][:&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;]
    labels &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [unique_sorted_Y[index] &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; index &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; top_5_predict]
    color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; idx &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; top_5_predict:
        color[top_5_predict&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tolist()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;index(idx)] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;green&amp;#39;&lt;/span&gt;
    color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; color[::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;barh(range(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;), prediction[top_5_predict][::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;color)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;yticks(range(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;), labels[::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_02/output_76_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Top-1으로 3개를 다 맞춘것으로 확인됩니다. 그러나 계속 실행하면 중간중간 잘 맞지 않는 부분도 있으나, 상위 5개에는 꼭 있음을 확인할 수 있습니다.&lt;/p&gt;
&lt;h2 id=&#34;iv-submission&#34;&gt;IV. Submission&lt;/h2&gt;
&lt;p&gt;예측 결과를 캐글에 올리도록 하는 소스코드를 구현합니다. 이미지와 관련된 캐글 대회에 나가더라도, 본 소스코드는 잘 숙지하셔서 응용하시기를 바랍니다.&lt;/p&gt;
&lt;h3 id=&#34;1-테스트-데이터-압축-풀기&#34;&gt;(1) 테스트 데이터 압축 풀기&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;!&lt;/span&gt;unzip test&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zip
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.[0m
  inflating: test/82e41a906dbd9ec362a3d49cf6bbe645.jpg  
  .
  .
  .
  inflating: test/fffbff22c1f51e3dc80c4bf04089545b.jpg  
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;2-submission-파일-확인&#34;&gt;(2) submission 파일 확인&lt;/h3&gt;
&lt;p&gt;submission 파일을 확인합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
submission &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sample_submission.csv&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(submission&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head())
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;()
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(submission&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;info())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;                                 id  ...  yorkshire_terrier
0  000621fb3cbb32d8935728e48679680e  ...           0.008333
1  00102ee9d8eb90812350685311fe5890  ...           0.008333
2  0012a730dfa437f5f3613fb75efcd4ce  ...           0.008333
3  001510bc8570bbeee98c8d80c8a95ec1  ...           0.008333
4  001a5f3114548acdefa3d4da05474c2e  ...           0.008333

[5 rows x 121 columns]

&amp;lt;class &#39;pandas.core.frame.DataFrame&#39;&amp;gt;
RangeIndex: 10357 entries, 0 to 10356
Columns: 121 entries, id to yorkshire_terrier
dtypes: float64(120), object(1)
memory usage: 9.6+ MB
None
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;데이터 프레임의 첫열은 label.csv와 같은 id입니다. 나머지 열은 120개의 견종의 이름이 있고, 각 id에 대한 각 견종의 예측 값은 랜덤한 선택을 했을 때의 값 0.008333으로 채워져 있습니다. 이 대로 캐글에 제출해도 &lt;code&gt;Multiclass Logloss&lt;/code&gt;로 산정되며 4.78749의 점수를 얻게 됩니다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_02/kaggle_03.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;3-테스트-데이터-정제&#34;&gt;(3) 테스트 데이터 정제&lt;/h3&gt;
&lt;p&gt;테스트 데이터도 훈련 데이터와 마찬가지로 ImageDataGenerator를 사용하도록 합니다. 이 때 &lt;code&gt;ImageDataGenerator&lt;/code&gt;가 &lt;code&gt;flow_from_directory()&lt;/code&gt; 함수로 이미지를 읽어 들이기 위해 하위 디렉토리가 꼭 필요합니다.&lt;/p&gt;
&lt;p&gt;현재 테스트 데이터는 각 사진이 어떤 범주에 속하는지 알 수 없기 때문에 &lt;code&gt;unknown&lt;/code&gt;이라는 폴더를 만들고 모든 데이터를 이곳에 복사하도록 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 8.34 ImageDataGenerator가 처리할 수 있는 하위 디렉토리 구조로 데이터 복사&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; shutil

os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mkdir(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/test_sub/&amp;#39;&lt;/span&gt;)
os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mkdir(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/test_sub/unknown/&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(len(submission)):
    shutil&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;copy(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/test/&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; submission&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[i][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;id&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.jpg&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/test_sub/unknown/&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;test_sub&lt;/code&gt; 폴더 하위에 &lt;code&gt;unknown&lt;/code&gt;이라는 폴더가 생기고 모든 파일이 이 안에 들어있음을 확인합니다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_02/kaggle_04.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;이제 테스트 데이터를 불러오는 &lt;code&gt;ImageDataGenerator&lt;/code&gt;를 정의합니다. 이미지 보강 등은 진행할 필요가 없기 때문에 보다 간소화됩니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.python.keras.preprocessing.image &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; ImageDataGenerator

test_datagen&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ImageDataGenerator(rescale&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;255.&lt;/span&gt;)
test_generator&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;test_datagen&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flow_from_directory(directory&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/content/test_sub/&amp;#34;&lt;/span&gt;,batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,seed&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;42&lt;/span&gt;,shuffle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False,target_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;299&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;299&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Found 10357 images belonging to 1 classes.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;위와 같이 정상적으로 &lt;code&gt;ImageDataGenerator&lt;/code&gt;가 만들어지면 이를 이용해서 벡터를 추출합니다.&lt;/p&gt;
&lt;h3 id=&#34;4-테스트-데이터의-벡터-변환&#34;&gt;(4) 테스트 데이터의 벡터 변환&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;test_features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; idx &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(test_generator&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;n):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; idx &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(idx)
        
    x, _ &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_generator&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next()
    feature &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; feature_model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(x)
    test_features&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;extend(feature)

test_features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(test_features)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(test_features&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;0
100
200
.
.
.
10100
10200
10300
(10357, 2048)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;각 이미지 데이터는 120의 길이를 가진 벡터로 변환이 되었습니다. 이렇게 생성된 벡터로 데스트 데이터의 정답을 예측합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;test_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(test_features, verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;10357/10357 [==============================] - 0s 41us/sample
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;model.predict()&lt;/code&gt; 함수는 &lt;code&gt;verbose&lt;/code&gt; 인수의 값이 0으로 설정되어 있기 때문에 진행 과정을 보기 위해서는 &lt;code&gt;verbose=1&lt;/code&gt;로 지정해야 합니다.&lt;/p&gt;
&lt;h3 id=&#34;5-테스트-데이터-분류-라벨-확인&#34;&gt;(5) 테스트 데이터 분류 라벨 확인&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; random
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; cv2
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;))
  
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;):
    image_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;choice(test_generator&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;filepaths)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# 이미지 표시&lt;/span&gt;
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(image_path))
    real_y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; image_path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;]
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(real_y)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# 예측값 표시&lt;/span&gt;
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(image_path)
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(img, dsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;299&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;299&lt;/span&gt;))
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; img &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(img, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# Inception V3를 이용한 특징 벡터 추출&lt;/span&gt;
    feature_vector &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; feature_model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(img)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# Sequential 모델을 이용한 예측&lt;/span&gt;
    prediction &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(feature_vector)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# 가장 높은 확률의 예측값 5개를 뽑음&lt;/span&gt;
    top_5_predict &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; prediction&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argsort()[::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][:&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;]
    labels &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [unique_sorted_Y[index] &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; index &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; top_5_predict]
    color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;barh(range(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;), prediction[top_5_predict][::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;color)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;yticks(range(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;), labels[::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_02/output_95_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;저난적으로 모형은 꽤 학신을 가지고 테스트 데이터에 대해 답을 예측하고 있습니다.&lt;/p&gt;
&lt;h3 id=&#34;6-submission-준비-및-파일-내보내기&#34;&gt;(6) Submission 준비 및 파일 내보내기&lt;/h3&gt;
&lt;p&gt;submission의 준비작업은 아래와 같이 코드를 작성하고 실제로 예측값이 잘 저장됐는지 확인하기 위해 데이터의 일부를 출력합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(len(test_Y)):
  &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;letter I &amp;#39;re on time &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%d&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; (i))
  &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(len(test_Y[i])):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;letter J&amp;#39;re on time &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%d&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; (j))
    breed_column &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; unique_sorted_Y[j]
    submission&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[i, breed_column] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_Y[i, j]

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(submission&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;iloc[:&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, :&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.[0m
We&#39;re on time 0
We&#39;re on time 1
.
.
.
We&#39;re on time 10317
We&#39;re on time 0
We&#39;re on time 1
.
.
                                 id  ...      airedale
0  000621fb3cbb32d8935728e48679680e  ...  6.192151e-07
1  00102ee9d8eb90812350685311fe5890  ...  2.064632e-07
2  0012a730dfa437f5f3613fb75efcd4ce  ...  3.297540e-06
3  001510bc8570bbeee98c8d80c8a95ec1  ...  1.829849e-07
4  001a5f3114548acdefa3d4da05474c2e  ...  6.606462e-07

[5 rows x 5 columns]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Submission 파일을 만드는데 생각보다 많은 시간이 소요됩니다. 인내심을 가지고 조금 기다리셔야 합니다. (약 28MB 용량의 파일)&lt;/p&gt;
&lt;p&gt;이제 csv파일로 저장합니다. 버전 관리를 할 수 있는 이름으로 파일을 저장 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;submission&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dogbreed_submission_inceptionV3_epoch10_299_20200429.csv&amp;#39;&lt;/span&gt;, index&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;위 코드를 실행하면 왼쪽 파일, 가상 환경에 저장되기 때문에 꼭 확인해서 다운로드 받기를 바랍니다. Colab에서는 연결이 끊기면 파일이 사라집니다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_02/kaggle_05.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;7-파일-업로드-및-점수-확인&#34;&gt;(7) 파일 업로드 및 점수 확인&lt;/h3&gt;
&lt;p&gt;submission 파일 싸이트로 돌아가서 다운로드 받은 파일을 업로드 하고 결과를 확인합니다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Score&lt;/code&gt;가 아래 그림에서 확인하는 것처럼 &lt;code&gt;0.32208&lt;/code&gt;인 것을 확인할 수 있습니다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_02/kaggle_06.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;참고로 위 대회는 2년전에 이미 마감되었기 때문에, 랭킹에 반영되지 않습니다. 그러나, 아래 그림을 통해서 현재 만든 모형의 결과가 어느정도 순위인지 확인은 할 수 있습니다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_02/kaggle_07.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;대략적으로 510위 정도에 해당하는 모형이라고 할 수 있습니다. 이 순위는 상위 약 40%에 해당한다고 할 수 있습니다.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;사실 이제 시작입니다. 모형을 반복해서 만들어서 성능을 끌어 올리는 것은 모든 머신러닝/딥러닝 개발자의 숙명이자 과제입니다.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;iii-연습-파일&#34;&gt;III. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch8_2_transfer_learning.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;vi-reference&#34;&gt;VI. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
&lt;p&gt;Karpathy, A. (2015). The Unreasonable Effectiveness of Recurrent Neural Networks. Retrieved April 26, 2020, from &lt;a href=&#34;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&#34;&gt;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&lt;/a&gt;&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;2020년 4월 8일에 &lt;a href=&#34;https://github.com/wikibook/tf2/blob/master/Chapter8_20200408%EC%88%98%EC%A0%95.ipynb&#34;&gt;수정본&lt;/a&gt;이 있습니다. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;텐서플로 홈페이지 &lt;a href=&#34;https://www.tensorflow.org/guide/keras/overview?hl=ko#%ED%95%A8%EC%88%98%ED%98%95_api&#34;&gt;함수형 API&lt;/a&gt;에 관한 문서를 살펴보시기를 바랍니다. &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
  </channel>
</rss>