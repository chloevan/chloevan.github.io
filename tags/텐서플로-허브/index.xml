<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>텐서플로 허브 on Data Science | ChloEvan</title>
    <link>https://chloevan.github.io/tags/%ED%85%90%EC%84%9C%ED%94%8C%EB%A1%9C-%ED%97%88%EB%B8%8C/</link>
    <description>Recent content in 텐서플로 허브 on Data Science | ChloEvan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 28 Apr 2020 17:20:30 +0900</lastBuildDate>
    
        <atom:link href="https://chloevan.github.io/tags/%ED%85%90%EC%84%9C%ED%94%8C%EB%A1%9C-%ED%97%88%EB%B8%8C/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch8.1 - 텐서플로 허브</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch8_1_tensorflow_hub/</link>
      <pubDate>Tue, 28 Apr 2020 17:20:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch8_1_tensorflow_hub/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.2 - 다항분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/&#34;&gt;Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/&#34;&gt;Tensorflow 2.0 Tutorial ch6.1-2 - CNN 이론&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_3_fashion_mnist_with_cnn/&#34;&gt;Tensorflow 2.0 Tutorial ch6.3 - Fashion MNIST with CNN 실습&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_4_improve_performance/&#34;&gt;Tensorflow 2.0 Tutorial ch6.4 - 모형의 성능 높이기&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (1)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (2)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_3_sentimentanalysis/&#34;&gt;Tensorflow 2.0 Tutorial ch7.3 - 긍정, 부정 감성 분석&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (1) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (2) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요&#34;&gt;I. 개요&lt;/h2&gt;
&lt;p&gt;딥러닝은 일반적인 개발과 다르게 사실 시간과의 싸움입니다. 코딩의 양에 비해, 결과물이 바로 나오지 않기 때문에 저녁에 모형을 돌리고 아침에 와서 확인하는 경우가 예사입니다.&lt;/p&gt;
&lt;p&gt;특히, 딥러닝의 경우, 기본적으로 좋은 성능을 보이려면 네트워크는 수십 및 또는 수백개의 레이어를 쌓은 경우가 대부분이고, 당연히 늘어난 레이어의 수만큼 네트워크를 훈련시키는 데 필요한 훈련 시간도 증가하게 됩니다.&lt;/p&gt;
&lt;p&gt;다행히, 딥러닝은 아직까지는 범용적으로 사용하는 상용단계라기보다는 연구, 실험, 그리고 이제서야 적용 단계에 있는 기술이기 때문에, 다른 IT기술보다는 개방적인 연구 환경을 갖추고 있습니다.&lt;/p&gt;
&lt;p&gt;이렇게 연구자들이 자신이 만든 사전 훈련된 모델(&lt;code&gt;pre-trained model&lt;/code&gt;)을 인터넷에 올려놓아 다른 사람들이 쉽게 내려받을 수 있도록 합니다.&lt;/p&gt;
&lt;p&gt;이렇게 내려받은 모델을 그대로 사용할 수도 있고, 전이 학습(&lt;code&gt;Transfer Learning&lt;/code&gt;)이나 신경 스타일 전이(&lt;code&gt;Neural Style Transfer&lt;/code&gt;)처럼 다른 과제를 위해 재가공해서 사용합니다.&lt;/p&gt;
&lt;h2 id=&#34;ii-텐서플로-허브-소개&#34;&gt;II. 텐서플로 허브 소개&lt;/h2&gt;
&lt;p&gt;텐서플로에서 제공하는 텐서플로 허브는 재사용 가능한 모델을 쉽게 이용할 수 있도록 하는 라이브러리입니다.&lt;/p&gt;
&lt;p&gt;텐서플로허브 홈페이지에서 확인해봅니다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_01/tensorflow_hub.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;텐서플로 허브에서 사전 훈련된 &lt;code&gt;MobileNet&lt;/code&gt; 모델을 불러와서 학습하는 것을 시도합니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;참고로, 텐서플로 2.0을 사용하시는 분들은 굳이 별도로 텐서플로 허브를 설치할 필요가 없지만, 1.x 버전을 사용하신다면 별도로 아래와 같이 설치하시기를 바랍니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-terminal&#34; data-lang=&#34;terminal&#34;&gt;!pip install tensorflow-hub
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;1-mobilenet-불러오기&#34;&gt;(1) MobileNet 불러오기&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;MobileNet&lt;/code&gt;은 계산 부담이 큰 컨볼루션 신경망을 연산 성능이 제한된 모바일 환경에서도 작동 가능하도록 네트워크 구조를 경량화한 것입니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 텐서플로 2 버전 선택&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
    &lt;span style=&#34;color:#75715e&#34;&gt;# %tensorflow_version only exists in Colab.&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;tensorflow_version &lt;span style=&#34;color:#ae81ff&#34;&gt;2.&lt;/span&gt;x
&lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Exception&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;pass&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow_hub &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; hub
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;mobile_net_url &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4&amp;#39;&lt;/span&gt;
model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
  hub&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;KerasLayer(handle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;mobile_net_url, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), trainable&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)
])
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
keras_layer (KerasLayer)     (None, 1001)              3540265   
=================================================================
Total params: 3,540,265
Trainable params: 0
Non-trainable params: 3,540,265
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;MobileNet&lt;/code&gt;은 &lt;code&gt;ImageNet&lt;/code&gt;에 존재하는 1,000 종류의 이미지를 분류할 수 있으며, 이 가운데 어떤 것에도 속하지 않는다고 판단될 때는 &lt;code&gt;background&lt;/code&gt;에 해당하는 인덱스 0을 반환합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras.applications &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; MobileNetV2

mobilev2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; MobileNetV2()
tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot_model(mobilev2)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_01/output_8_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;MobileNetV2&lt;/code&gt;의 구조는 이와 같이 도식화 되어 있습니다. 도식화에 대한 구체적인 설명은 교재 243페이를 확인하시기를 바랍니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;MobileNet&lt;/code&gt;의 성능을 평가하기 위해 이미지를 학습시켰을 때 얼마나 적합한 라벨로 분류하는지 알아봅니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-imagenet-불러오기&#34;&gt;(2) ImageNet 불러오기&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;ImageNet&lt;/code&gt;의 데이터 중 일부만 모아놓은 &lt;code&gt;ImageNetV2&lt;/code&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;를 사용합니다. &lt;code&gt;ImageNetV2&lt;/code&gt;는 &lt;a href=&#34;https://www.mturk.com/&#34;&gt;아마존 메커니컬 터크&lt;/a&gt;&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;를 이용해 다수의 참가자에게서 클래스 예측값을 받아서 선별한 데이터입니다.&lt;/p&gt;
&lt;p&gt;여기서는 각 클래스에서 가장 많은 선택을 받은 이미지 10장씩을 모아높은 10,000장의 이미지가 포함된 &lt;code&gt;TopImages&lt;/code&gt;데이터를 사용합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pathlib

content_data_url &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/sample_data&amp;#39;&lt;/span&gt;
data_root_orig &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;imagenetV2&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;https://s3-us-west-2.amazonaws.com/imagenetv2public/imagenetv2-topimages.tar.gz&amp;#39;&lt;/span&gt;, cache_dir&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;content_data_url, extract&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
data_root &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pathlib&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Path(content_data_url &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/datasets/imagenetv2-topimages&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(data_root)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;/content/sample_data/datasets/imagenetv2-topimages
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;tf.keras.utils.get_file()&lt;/code&gt; 함수로 &lt;code&gt;ImageNetV2&lt;/code&gt; 데이터를 불러올 수 있습니다. 함수의 인수 중 &lt;code&gt;extract=True&lt;/code&gt;로 지정했기 때문에, &lt;code&gt;tar.gz&lt;/code&gt; 형식의 압축 파일이 자동으로 해제됭 구글 코랩 가상 머신에 저장됩니다.&lt;/p&gt;
&lt;p&gt;디렉터리의 경로를 출력해서, 예제 데이터를 확인해 봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; idx, item &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(data_root&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;iterdir()):
  &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(item)
  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; idx &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;break&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;/content/sample_data/datasets/imagenetv2-topimages/462
/content/sample_data/datasets/imagenetv2-topimages/630
/content/sample_data/datasets/imagenetv2-topimages/687
/content/sample_data/datasets/imagenetv2-topimages/858
/content/sample_data/datasets/imagenetv2-topimages/172
/content/sample_data/datasets/imagenetv2-topimages/856
/content/sample_data/datasets/imagenetv2-topimages/407
/content/sample_data/datasets/imagenetv2-topimages/300
/content/sample_data/datasets/imagenetv2-topimages/374
/content/sample_data/datasets/imagenetv2-topimages/0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;하위 디렉토리는 0~999까지 총 1,000개입니다.&lt;/p&gt;
&lt;h3 id=&#34;3-라벨-텍스트-불러오기&#34;&gt;(3) 라벨 텍스트 불러오기&lt;/h3&gt;
&lt;p&gt;라벨에 대한 숫자가 어떤 데이터를 뜻하는지에 대한 정보인 라벨 텍스트는 따로 불러와야 합니다. &lt;code&gt;MobileNet&lt;/code&gt;에서 사용된 라벨은 &lt;code&gt;tf.keras.utils.get_file()&lt;/code&gt;함수로 불러옵니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;label_file &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;label&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt&amp;#39;&lt;/span&gt;)
label_text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; None
&lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; open(label_file, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r&amp;#39;&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; f:
    label_text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; f&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)[:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(len(label_text))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(label_text[:&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;])
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(label_text[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;:])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt
16384/10484 [==============================================] - 0s 0us/step
1001
[&#39;background&#39;, &#39;tench&#39;, &#39;goldfish&#39;, &#39;great white shark&#39;, &#39;tiger shark&#39;, &#39;hammerhead&#39;, &#39;electric ray&#39;, &#39;stingray&#39;, &#39;cock&#39;, &#39;hen&#39;]
[&#39;buckeye&#39;, &#39;coral fungus&#39;, &#39;agaric&#39;, &#39;gyromitra&#39;, &#39;stinkhorn&#39;, &#39;earthstar&#39;, &#39;hen-of-the-woods&#39;, &#39;bolete&#39;, &#39;ear&#39;, &#39;toilet tissue&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;4-이미지-확인-시각화&#34;&gt;(4) 이미지 확인 시각화&lt;/h3&gt;
&lt;p&gt;그럼, 이제 이미지를 확인해봅니다. &lt;code&gt;matplotlib.pyplot&lt;/code&gt;을 이용해서 이미지를 출력합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;all_image_paths &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; list(data_root&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;glob(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;*/*&amp;#39;&lt;/span&gt;))
all_image_paths &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [str(path) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; path &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; all_image_paths]

&lt;span style=&#34;color:#75715e&#34;&gt;# 이미지를 랜덤하게 섞습니다. &lt;/span&gt;
random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shuffle(all_image_paths)
image_count &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; len(all_image_paths)

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;image_count:&amp;#39;&lt;/span&gt;, image_count)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;image_count: 10000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;이미지의 개수가 10,000인 것을 확인합ㄴ디ㅏ.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; PIL.Image &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; Image
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; random

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;):
  image_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;choice(all_image_paths)
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(image_path))
  idx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(image_path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(str(idx) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;, &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; label_text[idx])
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_01/output_20_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;10,000장의 이미지 중 랜덤하게 뽑은 9장의 이미지이기 때문에 독자와는 조금 다를 수 있습니다. 전반적으로 사진들이 잘 분류가 되고 있음을 확인할 수 있습니다.&lt;/p&gt;
&lt;p&gt;위 코드에서 한가지 유의할 점은 라벨 텍스트는 &lt;code&gt;background&lt;/code&gt;가 포함되어 있어서, 총 1,001개의 텍스트가 있지만, 실제 데이터의 라벨은 0에서 999까지의, 1000개라는 점입니다. 이러한 차이를 무마하기 위해서, 코드 &lt;code&gt;idx = int(image_path.split(&#39;/&#39;)[-2]) + 1&lt;/code&gt;에서 파일 경로의 라벨 디렉토리에 해당하는 부분을 정수로 변환한 다음 1을 더해 첫번째부터 1,000번째까지의 라벨 텍스트와 동일한 값을 가리킵니다.&lt;/p&gt;
&lt;h3 id=&#34;5-모형-성능-테스트&#34;&gt;(5) 모형 성능 테스트&lt;/h3&gt;
&lt;p&gt;이제 이 이미지들을 &lt;code&gt;MobileNet&lt;/code&gt;이 얼마나 잘 분류하는지 확인해봅니다. 전통적으로 &lt;code&gt;ImageNet&lt;/code&gt; 대회에서는 예측하는 값 중 상위 5개 이내에 데이터의 실제 분류가 포함되어 있으면 정답으로 인정하는 &lt;code&gt;Top-5&lt;/code&gt; 정확도를 분류 정확도로 측정합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; cv2

top_1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
top_5 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; image_path &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; all_image_paths:
  img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(image_path)
  img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(img, dsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;))
  img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; img &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
  img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(img, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
  top_5_predict &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(img)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argsort()[::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][:&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;]
  idx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(image_path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;])&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; idx &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; top_5_predict:
    top_5 &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; top_5_predict[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; idx:
      top_1 &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Top-5 correctness:&amp;#39;&lt;/span&gt;, top_5 &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; len(all_image_paths) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;%&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Top-5 correctness:&amp;#39;&lt;/span&gt;, top_1 &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; len(all_image_paths) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;%&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Top-5 correctness: 83.84 %
Top-5 correctness: 59.45 %
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Top-5 정확도는 83.84%, Top-1 정확도는 59.45%가 나옵니다. 논문에서는 정확도를 높이기 위해 이미지에 여러 가지 전처리 기법을 사용하지만 여기서는 특별한 방법을 사용하지 않았기 때문에 정확도가 약간 낮게 나옵니다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;cv2&lt;/code&gt; 모듈은 &lt;code&gt;OpenCV(Open Source Computer Vision)&lt;/code&gt; 라이브러리입니다. 이미지를 메모리에 불러오고 크기를 조정하는 등의 작업을 편하게 해줍니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;top_5_predict &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(img)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argsort()[::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][:&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;여기에서 &lt;code&gt;argsort()&lt;/code&gt;는 인덱스를 정렬합니다. 그런데, 우리가 원하는 것은 예측확률이 높은 순서이기 때문에 &lt;code&gt;array[::-1]&lt;/code&gt;로 반전시키비다. 그 다음에 앞에서부터 5번째까지의 값을 &lt;code&gt;array[:5]&lt;/code&gt;로 잘라서 &lt;code&gt;top_5_predict&lt;/code&gt;에 저장합니다.&lt;/p&gt;
&lt;p&gt;소스코드를 보면 더 쉽게 이해가 갈 것입니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;99&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;])
arg &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argsort(a)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(arg)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sort(a))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(a[arg])
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(a[arg][::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(a[arg][::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][:&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[2 4 1 3 0]
[ 5 20 32 64 99]
[ 5 20 32 64 99]
[99 64 32 20  5]
[99 64]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;참고로 교재에서는 &lt;code&gt;print(a[arg][::-1])&lt;/code&gt; 와 &lt;code&gt;print(a[arg][::-1][:2])&lt;/code&gt;의 소스코드는 독자들의 이해를 더 구하기 위해 추가하였습니다.&lt;/p&gt;
&lt;h3 id=&#34;6-분류-라벨-확인&#34;&gt;(6) 분류 라벨 확인&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;MobileNet&lt;/code&gt;이 분류하는 라벨을 실제로 확인하고 &lt;code&gt;Top-5&lt;/code&gt;예측을 표시합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;))

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;softmax&lt;/span&gt;(x):
    e_x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(x &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;max(x))
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; e_x &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; e_x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
  
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;):
    image_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;choice(all_image_paths)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# 이미지 표시&lt;/span&gt;
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(image_path))
    idx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(image_path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(str(idx) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;, &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; label_text[idx])
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# 예측값 표시&lt;/span&gt;
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(image_path)
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(img, dsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;))
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; img &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(img, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# MobileNet을 이용한 예측&lt;/span&gt;
    logits &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(img)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
    prediction &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; softmax(logits)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# 가장 높은 확률의 예측값 5개를 뽑음&lt;/span&gt;
    top_5_predict &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; prediction&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argsort()[::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][:&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;]
    labels &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [label_text[index] &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; index &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; top_5_predict]
    color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; idx &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; top_5_predict:
        color[top_5_predict&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tolist()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;index(idx)] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;green&amp;#39;&lt;/span&gt;
    color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; color[::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;barh(range(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;), prediction[top_5_predict][::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;color)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;yticks(range(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;), labels[::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_01/output_28_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;랜덤하게 뽑은 세 개의 이미지 중 3개는 모두 &lt;code&gt;Top-1&lt;/code&gt; 예측을 맞췄습니다. 이렇게 별도의 훈련 과정 없이 미리 훈련된 모델을 텐서플로 허브에서 불러오는 것으로 네트워크를 그대로 사용할 수 있습니다.&lt;/p&gt;
&lt;h2 id=&#34;iii-연습-파일&#34;&gt;III. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch8_1_tensorflow_hub.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;vi-reference&#34;&gt;VI. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
&lt;p&gt;Karpathy, A. (2015). The Unreasonable Effectiveness of Recurrent Neural Networks. Retrieved April 26, 2020, from &lt;a href=&#34;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&#34;&gt;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&lt;/a&gt;&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/modestyachts/imageNetV2&#34;&gt;https://github.com/modestyachts/imageNetV2&lt;/a&gt; &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;사람의 수작업이 필요한 이미지 라벨링 등을 위해 비교적 저렴한 가격으로 서비스 구매자와 제공자를 연결해주는 작업 플랫폼 &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
  </channel>
</rss>