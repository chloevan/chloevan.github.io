<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>분류 on Data Science | ChloEvan</title>
    <link>https://chloevan.github.io/tags/%EB%B6%84%EB%A5%98/</link>
    <description>Recent content in 분류 on Data Science | ChloEvan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 20 Apr 2020 17:08:30 +0900</lastBuildDate>
    
        <atom:link href="https://chloevan.github.io/tags/%EB%B6%84%EB%A5%98/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/</link>
      <pubDate>Mon, 20 Apr 2020 17:08:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.2 - 다항분류&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요1&#34;&gt;I. 개요&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;MNIST&lt;/code&gt;는 머신러닝의 고전적인 문제로 손으로 쓴 숫자 글씨를 모아놓은 데이터 세트이며, &lt;code&gt;Fashion MNIST&lt;/code&gt;는 손글씨가 아닌 옷과 신발, 가방의 이미지 등을 모아 놓는다. 그레이스케일 이미지&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;라는 점과 범주의 수가 10개라는 점, 각 이미지의 크기가 28X28 픽셀이라는 점은 &lt;code&gt;MNIST&lt;/code&gt;와 동일하지만 좀 더 어려운 문제로 평가됩니다.&lt;/p&gt;
&lt;p&gt;라벨의 정의는 아래와 같습니다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;라벨&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;범주&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;티셔츠/상의&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;바지&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;스웨터&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;드레스&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;코트&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;샌들&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;셔츠&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;운동화&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;가방&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;부츠&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;ii-데이터-불러오기&#34;&gt;II. 데이터 불러오기&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Fashion MNIST&lt;/code&gt; 데이터세트는 &lt;code&gt;tf.keras&lt;/code&gt;에 기본으로 탑재가 되어 있기 때문에 간단하게 불러올 수 있다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 텐서플로 2 버전 선택&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
    &lt;span style=&#34;color:#75715e&#34;&gt;# %tensorflow_version only exists in Colab.&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;tensorflow_version &lt;span style=&#34;color:#ae81ff&#34;&gt;2.&lt;/span&gt;x
&lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Exception&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;pass&lt;/span&gt;

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tabulate &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tabulate

fashion_mnist &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;datasets&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fashion_mnist
(train_X, train_Y), (test_X, test_Y) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; fashion_mnist&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load_data()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz
32768/29515 [=================================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz
26427392/26421880 [==============================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz
8192/5148 [===============================================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz
4423680/4422102 [==============================] - 0s 0us/step
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(len(train_X), len(test_X))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;60000 10000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;훈련 데이터는 60,000장, 테스트 데이터는 10,000장의 패션 이미지를 포함하고 있습니다. 데이터세트를 불러온 후에는 이 데이터가 어떻게 생겼는지 확인해봐야 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(train_X[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;colorbar()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_05_03/output_6_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;9
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;imshow()&lt;/code&gt; 이미지를 그래프의 형태로 표시 할 수 있고, &lt;code&gt;colorbar()&lt;/code&gt; 함수는 그래프 옆에 색상의 값 정보를 (bar) 형태로 표시할 수 있습니다. 데이터의 이미지가 0에서 255까지의 값을 가지는 28X28 픽셀 크기의 2차원 이미지라는 것을 확인할 수 있습니다.&lt;/p&gt;
&lt;h2 id=&#34;iii-데이터-정규화&#34;&gt;III. 데이터 정규화&lt;/h2&gt;
&lt;p&gt;데이터를 정규화를 진행합니다. 여기에서는 최대값과 최소값을 이미 알고 있기 때문에 이미지의 각 픽셀값을 255로 나누기만 하면 0.0~1.0사이의 값으로 정규화됩니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_X &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_X[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[[0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.00392157 0.         0.         0.05098039 0.28627451 0.
  0.         0.00392157 0.01568627 0.         0.         0.
  0.         0.00392157 0.00392157 0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.01176471 0.         0.14117647 0.53333333 0.49803922 0.24313725
  0.21176471 0.         0.         0.         0.00392157 0.01176471
  0.01568627 0.         0.         0.01176471]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.02352941 0.         0.4        0.8        0.69019608 0.5254902
  0.56470588 0.48235294 0.09019608 0.         0.         0.
  0.         0.04705882 0.03921569 0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.60784314 0.9254902  0.81176471 0.69803922
  0.41960784 0.61176471 0.63137255 0.42745098 0.25098039 0.09019608
  0.30196078 0.50980392 0.28235294 0.05882353]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.00392157
  0.         0.27058824 0.81176471 0.8745098  0.85490196 0.84705882
  0.84705882 0.63921569 0.49803922 0.4745098  0.47843137 0.57254902
  0.55294118 0.34509804 0.6745098  0.25882353]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.00392157 0.00392157 0.00392157
  0.         0.78431373 0.90980392 0.90980392 0.91372549 0.89803922
  0.8745098  0.8745098  0.84313725 0.83529412 0.64313725 0.49803922
  0.48235294 0.76862745 0.89803922 0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.71764706 0.88235294 0.84705882 0.8745098  0.89411765
  0.92156863 0.89019608 0.87843137 0.87058824 0.87843137 0.86666667
  0.8745098  0.96078431 0.67843137 0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.75686275 0.89411765 0.85490196 0.83529412 0.77647059
  0.70588235 0.83137255 0.82352941 0.82745098 0.83529412 0.8745098
  0.8627451  0.95294118 0.79215686 0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.00392157 0.01176471 0.
  0.04705882 0.85882353 0.8627451  0.83137255 0.85490196 0.75294118
  0.6627451  0.89019608 0.81568627 0.85490196 0.87843137 0.83137255
  0.88627451 0.77254902 0.81960784 0.20392157]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.02352941 0.
  0.38823529 0.95686275 0.87058824 0.8627451  0.85490196 0.79607843
  0.77647059 0.86666667 0.84313725 0.83529412 0.87058824 0.8627451
  0.96078431 0.46666667 0.65490196 0.21960784]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.01568627 0.         0.
  0.21568627 0.9254902  0.89411765 0.90196078 0.89411765 0.94117647
  0.90980392 0.83529412 0.85490196 0.8745098  0.91764706 0.85098039
  0.85098039 0.81960784 0.36078431 0.        ]
 [0.         0.         0.00392157 0.01568627 0.02352941 0.02745098
  0.00784314 0.         0.         0.         0.         0.
  0.92941176 0.88627451 0.85098039 0.8745098  0.87058824 0.85882353
  0.87058824 0.86666667 0.84705882 0.8745098  0.89803922 0.84313725
  0.85490196 1.         0.30196078 0.        ]
 [0.         0.01176471 0.         0.         0.         0.
  0.         0.         0.         0.24313725 0.56862745 0.8
  0.89411765 0.81176471 0.83529412 0.86666667 0.85490196 0.81568627
  0.82745098 0.85490196 0.87843137 0.8745098  0.85882353 0.84313725
  0.87843137 0.95686275 0.62352941 0.        ]
 [0.         0.         0.         0.         0.07058824 0.17254902
  0.32156863 0.41960784 0.74117647 0.89411765 0.8627451  0.87058824
  0.85098039 0.88627451 0.78431373 0.80392157 0.82745098 0.90196078
  0.87843137 0.91764706 0.69019608 0.7372549  0.98039216 0.97254902
  0.91372549 0.93333333 0.84313725 0.        ]
 [0.         0.22352941 0.73333333 0.81568627 0.87843137 0.86666667
  0.87843137 0.81568627 0.8        0.83921569 0.81568627 0.81960784
  0.78431373 0.62352941 0.96078431 0.75686275 0.80784314 0.8745098
  1.         1.         0.86666667 0.91764706 0.86666667 0.82745098
  0.8627451  0.90980392 0.96470588 0.        ]
 [0.01176471 0.79215686 0.89411765 0.87843137 0.86666667 0.82745098
  0.82745098 0.83921569 0.80392157 0.80392157 0.80392157 0.8627451
  0.94117647 0.31372549 0.58823529 1.         0.89803922 0.86666667
  0.7372549  0.60392157 0.74901961 0.82352941 0.8        0.81960784
  0.87058824 0.89411765 0.88235294 0.        ]
 [0.38431373 0.91372549 0.77647059 0.82352941 0.87058824 0.89803922
  0.89803922 0.91764706 0.97647059 0.8627451  0.76078431 0.84313725
  0.85098039 0.94509804 0.25490196 0.28627451 0.41568627 0.45882353
  0.65882353 0.85882353 0.86666667 0.84313725 0.85098039 0.8745098
  0.8745098  0.87843137 0.89803922 0.11372549]
 [0.29411765 0.8        0.83137255 0.8        0.75686275 0.80392157
  0.82745098 0.88235294 0.84705882 0.7254902  0.77254902 0.80784314
  0.77647059 0.83529412 0.94117647 0.76470588 0.89019608 0.96078431
  0.9372549  0.8745098  0.85490196 0.83137255 0.81960784 0.87058824
  0.8627451  0.86666667 0.90196078 0.2627451 ]
 [0.18823529 0.79607843 0.71764706 0.76078431 0.83529412 0.77254902
  0.7254902  0.74509804 0.76078431 0.75294118 0.79215686 0.83921569
  0.85882353 0.86666667 0.8627451  0.9254902  0.88235294 0.84705882
  0.78039216 0.80784314 0.72941176 0.70980392 0.69411765 0.6745098
  0.70980392 0.80392157 0.80784314 0.45098039]
 [0.         0.47843137 0.85882353 0.75686275 0.70196078 0.67058824
  0.71764706 0.76862745 0.8        0.82352941 0.83529412 0.81176471
  0.82745098 0.82352941 0.78431373 0.76862745 0.76078431 0.74901961
  0.76470588 0.74901961 0.77647059 0.75294118 0.69019608 0.61176471
  0.65490196 0.69411765 0.82352941 0.36078431]
 [0.         0.         0.29019608 0.74117647 0.83137255 0.74901961
  0.68627451 0.6745098  0.68627451 0.70980392 0.7254902  0.7372549
  0.74117647 0.7372549  0.75686275 0.77647059 0.8        0.81960784
  0.82352941 0.82352941 0.82745098 0.7372549  0.7372549  0.76078431
  0.75294118 0.84705882 0.66666667 0.        ]
 [0.00784314 0.         0.         0.         0.25882353 0.78431373
  0.87058824 0.92941176 0.9372549  0.94901961 0.96470588 0.95294118
  0.95686275 0.86666667 0.8627451  0.75686275 0.74901961 0.70196078
  0.71372549 0.71372549 0.70980392 0.69019608 0.65098039 0.65882353
  0.38823529 0.22745098 0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.15686275 0.23921569 0.17254902 0.28235294 0.16078431
  0.1372549  0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;모든 데이터가 0에서 1사이의 값을 갖기 때문에 데이터 &lt;code&gt;정규화&lt;/code&gt;가 잘 된 것을 알 수 있습니다. 이 다음에 진행해야 하는 것은 &lt;code&gt;train_Y&lt;/code&gt;와 &lt;code&gt;test_Y&lt;/code&gt;에 원-핫 인코딩으로 바꾸는 부분입니다. &lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;(이전 강의 참조)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;to_categorical&lt;/code&gt; 함수를 이용해 정답 행렬을 원-핫 인코딩으로 바꾸면 아래와 같습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_categorical(train_Y, num_classes&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;)
test_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_categorical(test_Y, num_classes&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;이 때 9는 [0,0,0,0,0,0,0,0,0,1]로 바뀔 것입니다. 만약에 분류해야 하는 것이 &lt;code&gt;100&lt;/code&gt;이라면 어떻게 해야 할까요? 이러한 비효율성을 제거해줄 때 희소 행렬이라는 원리를 이용합니다. 행렬이 클 경우 수 많은 0을 위한 메모리를 모두 확보하는 것 자체가 매우 시스템적으로 낭비이기 때문입니다. 이렇게 이미지 분류의 경우에는 원-핫 인코딩보다는 희소행렬 원리를 이용해서 작성하는 경우가 많으니 참고하기를 바랍니다.&lt;/p&gt;
&lt;h2 id=&#34;iv-딥러닝-모형&#34;&gt;IV. 딥러닝 모형&lt;/h2&gt;
&lt;p&gt;이제 모형을 생성합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Flatten(input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;)), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;relu&amp;#34;&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;softmax&amp;#34;&lt;/span&gt;)
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(), 
              loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sparse_categorical_crossentropy&amp;#39;&lt;/span&gt;, 
              metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten (Flatten)            (None, 784)               0         
_________________________________________________________________
dense (Dense)                (None, 128)               100480    
_________________________________________________________________
dense_1 (Dense)              (None, 10)                1290      
=================================================================
Total params: 101,770
Trainable params: 101,770
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;여기에서 주의해서 봐야하는 것은 &lt;code&gt;loss&lt;/code&gt;에 &lt;code&gt;sparse_categorical_crossentropy&lt;/code&gt;로 기재하면 별도의 데이터 전처리 없이 희소 행렬을 나타내는 데이터를 정답 행렬로 사용할 수 있습니다.&lt;/li&gt;
&lt;li&gt;또한, &lt;code&gt;Dense&lt;/code&gt;대신에 &lt;code&gt;Flatten&lt;/code&gt;이 사용되었는데, 이는 다차원 데이터를 1차원으로 정렬하는 역할을 합니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Adam()&lt;/code&gt;의 기본값은 0,001로 매우 작습니다.&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_X, train_Y, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/25
1407/1407 [==============================] - 4s 3ms/step - loss: 0.5262 - accuracy: 0.8160 - val_loss: 0.4230 - val_accuracy: 0.8477
Epoch 2/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.3936 - accuracy: 0.8608 - val_loss: 0.3669 - val_accuracy: 0.8703
Epoch 3/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.3509 - accuracy: 0.8733 - val_loss: 0.3639 - val_accuracy: 0.8670
Epoch 4/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.3262 - accuracy: 0.8818 - val_loss: 0.3671 - val_accuracy: 0.8691
Epoch 5/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.3081 - accuracy: 0.8868 - val_loss: 0.3514 - val_accuracy: 0.8727
Epoch 6/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.2907 - accuracy: 0.8921 - val_loss: 0.3476 - val_accuracy: 0.8807
Epoch 7/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.2789 - accuracy: 0.8980 - val_loss: 0.3285 - val_accuracy: 0.8827
Epoch 8/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.2637 - accuracy: 0.9017 - val_loss: 0.3161 - val_accuracy: 0.8869
Epoch 9/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.2552 - accuracy: 0.9060 - val_loss: 0.3268 - val_accuracy: 0.8851
Epoch 10/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.2474 - accuracy: 0.9093 - val_loss: 0.3391 - val_accuracy: 0.8808
Epoch 11/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.2375 - accuracy: 0.9106 - val_loss: 0.3299 - val_accuracy: 0.8833
Epoch 12/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.2310 - accuracy: 0.9146 - val_loss: 0.3291 - val_accuracy: 0.8833
Epoch 13/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.2203 - accuracy: 0.9174 - val_loss: 0.3204 - val_accuracy: 0.8880
Epoch 14/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.2149 - accuracy: 0.9196 - val_loss: 0.3294 - val_accuracy: 0.8883
Epoch 15/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.2075 - accuracy: 0.9214 - val_loss: 0.3354 - val_accuracy: 0.8821
Epoch 16/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.2025 - accuracy: 0.9251 - val_loss: 0.3220 - val_accuracy: 0.8922
Epoch 17/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.1949 - accuracy: 0.9264 - val_loss: 0.3148 - val_accuracy: 0.8927
Epoch 18/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.1918 - accuracy: 0.9291 - val_loss: 0.3359 - val_accuracy: 0.8899
Epoch 19/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.1844 - accuracy: 0.9319 - val_loss: 0.3367 - val_accuracy: 0.8891
Epoch 20/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.1809 - accuracy: 0.9321 - val_loss: 0.3369 - val_accuracy: 0.8893
Epoch 21/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.1766 - accuracy: 0.9352 - val_loss: 0.3314 - val_accuracy: 0.8933
Epoch 22/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.1712 - accuracy: 0.9353 - val_loss: 0.3511 - val_accuracy: 0.8892
Epoch 23/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.1672 - accuracy: 0.9371 - val_loss: 0.3677 - val_accuracy: 0.8866
Epoch 24/25
1407/1407 [==============================] - 4s 3ms/step - loss: 0.1621 - accuracy: 0.9388 - val_loss: 0.3814 - val_accuracy: 0.8858
Epoch 25/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.1574 - accuracy: 0.9413 - val_loss: 0.3483 - val_accuracy: 0.8935
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;v-모형-결과-확인&#34;&gt;V. 모형 결과 확인&lt;/h2&gt;
&lt;p&gt;학습 출력 결과를 보면 훈련 데이터의 정확도는 점점 증가하고, 검증 데이터의 정확도는 일정한 수준으로 유지됩니다. 전체 학습 과정을 조망하기 위해 &lt;code&gt;history&lt;/code&gt; 변수에 저장된 학습 결과를 시각화 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylim(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_05_03/output_15_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;검증 데이터의 손실이 감소하다가 시간이 지날수록 서서히 증가하는 과적합 현상을 확인할 수 있는데, 이를 막기 위해서는 &lt;code&gt;tf.keras.callbacks.EarlyStopping&lt;/code&gt;을 사용합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(test_X, test_Y)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;313/313 [==============================] - 0s 1ms/step - loss: 0.3830 - accuracy: 0.8877





[0.3830251693725586, 0.8877000212669373]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;테스트 데이터에 대한 평가 정확도는 88.5%가 나왔습니다. 괜찮은 수치 같지만, 네트워크 구조 변경과 다른 학습 기법을 사용해서 정확도를 90%이상으로 끌어 올려야 합니다. 이를 컨볼루션 신경망(&lt;code&gt;CNN&lt;/code&gt;)에서 그 방법을 확인합니다.&lt;/p&gt;
&lt;h2 id=&#34;vi-연습-파일&#34;&gt;VI. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch5_3_Fashion_MNIST.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;vii-reference&#34;&gt;VII. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;책의 교재에도 각주로 설명이 되어 있지만, 텐서플로 홈페이지의 &lt;code&gt;첫 번째 신경망 훈련하기: 기초적인 분류 문제&lt;/code&gt; 페이지의 일부 내용을 참고하였다. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;컬러 이미지를 밝기 정보만 남긴 회색조로 변환한 이미지를 뜻함. &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;이렇게 기본값을 작게 해놓은 이유는 이 때의 값이 가장 좋았다는 &lt;a href=&#34;https://arxiv.org/pdf/1412.6980.pdf&#34;&gt;논문&lt;/a&gt;에 근거합니다. 물론 이를 이해하려면 수식을 전체 이해해야 하며, 추가적으로 성능 비교를 하려면 더 크거나 작은 값을 시도해야 합니다. &lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch5.2 - 다항분류</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/</link>
      <pubDate>Sun, 19 Apr 2020 14:08:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-다항분류&#34;&gt;I. 다항분류&lt;/h2&gt;
&lt;p&gt;지난 시간에 이항 분류에 대해 배웠다면 이번 시간에는 다항 분류에 대해서 배우는 시간을 갖도록 합니다. 다항 분류는 범주의 수가 2개를 초과하는 경우를 말합니다. 와인 데이터의 품질은 0에서 10까지의 숫자로 구분이 되어 있기 때문에, 품질을 종속변수로 생각하고 분류 할 수 있습니다.&lt;/p&gt;
&lt;p&gt;와인의 색깔이 아닌 와인의 품질에 대해 예측해보도록 합니다.&lt;/p&gt;
&lt;h2 id=&#34;ii-데이터-준비&#34;&gt;II. 데이터 준비&lt;/h2&gt;
&lt;p&gt;지난 시간에 배운 내용을 복습하면서 다시한번 소스코드를 작성합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 텐서플로 2 버전 선택&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
    &lt;span style=&#34;color:#75715e&#34;&gt;# %tensorflow_version only exists in Colab.&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;tensorflow_version &lt;span style=&#34;color:#ae81ff&#34;&gt;2.&lt;/span&gt;x
&lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Exception&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;pass&lt;/span&gt;

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tabulate &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tabulate


red &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv&amp;#39;&lt;/span&gt;, sep&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;;&amp;#39;&lt;/span&gt;)
white &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv&amp;#39;&lt;/span&gt;, sep&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;;&amp;#39;&lt;/span&gt;)

red[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;type&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
white[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;type&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
wine &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;concat([red, white])
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(wine&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;describe())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;       fixed acidity  volatile acidity  ...      quality         type
count    6497.000000       6497.000000  ...  6497.000000  6497.000000
mean        7.215307          0.339666  ...     5.818378     0.753886
std         1.296434          0.164636  ...     0.873255     0.430779
min         3.800000          0.080000  ...     3.000000     0.000000
25%         6.400000          0.230000  ...     5.000000     1.000000
50%         7.000000          0.290000  ...     6.000000     1.000000
75%         7.700000          0.400000  ...     6.000000     1.000000
max        15.900000          1.580000  ...     9.000000     1.000000

[8 rows x 13 columns]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;데이터셋이 준비가 되었다면, 품질 데이터가 어떤 비율로 구성이 되어 있는지 알아보도록 합니다.&lt;/p&gt;
&lt;h2 id=&#34;iii-종속변수-선정-및-재범주화&#34;&gt;III. 종속변수 선정 및 재범주화&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(wine[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;quality&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;describe())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;count    6497.000000
mean        5.818378
std         0.873255
min         3.000000
25%         5.000000
50%         6.000000
75%         6.000000
max         9.000000
Name: quality, dtype: float64
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;위 데이터 통계를 통해서 보면, 최소값은 3이고, 최대값은 9인 것으로 확인할 수 있습니다. &lt;code&gt;value_counts()&lt;/code&gt;에서는 각 분류의 개수를 확인해보면 각 항목의 수가 균일하지 않고 꽤 차이가 나는 것을 볼 수 있습니다. 좀 더 정확한 정보를 알기 위해 히스토그램 시각화를 진행합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;hist(wine[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;quality&amp;#39;&lt;/span&gt;], bins&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;, rwidth&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_05_02/output_6_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;데이터의 양이 작은 대신 범주의 수가 많은 것을 확인할 수 있습니다. 실제 값의 개수를 확인해도 마찬가지입니다.&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;count &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; wine[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;quality&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;value_counts()
ratio &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; wine[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;quality&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;value_counts(normalize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)

frame &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; { &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Count&amp;#39;&lt;/span&gt;: count, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Ratio&amp;#39;&lt;/span&gt;: ratio } 

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(tabulate(frame, headers&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;keys&amp;#39;&lt;/span&gt;, tablefmt&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;psql&amp;#39;&lt;/span&gt;))

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;+---------+-------------+
|   Count |       Ratio |
|---------+-------------|
|    2836 | 0.436509    |
|    2138 | 0.329075    |
|    1079 | 0.166077    |
|     216 | 0.0332461   |
|     193 | 0.029706    |
|      30 | 0.00461752  |
|       5 | 0.000769586 |
+---------+-------------+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;이 때 어떻게 재범주화 할 것인지가 중요한 요소가 됩니다. 여기서가 분석가와 현업사이에서의 커뮤니케이션이 발생하는 주요 지점이 됩니다. 이 부분에서 도메인 지식이 수반되는 지점이니 꼭 현업과 상의하면서 재범주화를 진행합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;wine&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[wine[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;quality&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;new_quality&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
wine&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[wine[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;quality&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;new_quality&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
wine&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[wine[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;quality&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;new_quality&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;

count &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; wine[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;new_quality&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;value_counts()
ratio &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; wine[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;new_quality&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;value_counts(normalize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)

frame &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; { &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Count&amp;#39;&lt;/span&gt;: count, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Ratio&amp;#39;&lt;/span&gt;: ratio } 
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(tabulate(frame, headers&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;keys&amp;#39;&lt;/span&gt;, tablefmt&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;psql&amp;#39;&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;+---------+----------+
|   Count |    Ratio |
|---------+----------|
|    2836 | 0.436509 |
|    2384 | 0.366939 |
|    1277 | 0.196552 |
+---------+----------+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;위 소스코드에서 &lt;code&gt;.loc&lt;/code&gt;는 특정한 데이터의 인덱스를 골라내는 역할을 합니다. 본 교재(p. 125~126)에서는 간단한 예제로 설명이 되어 있습니다만, 이 부분은 강사가 향후 준비하는 자료로 대체하도록 합니다. &lt;code&gt;.loc외에&lt;/code&gt; &lt;code&gt;.iloc&lt;/code&gt;등 기본 문법 등이 같이 소개가 되면 더 좋을 듯 합니다.&lt;/p&gt;
&lt;p&gt;정리가 되는대로 자료 링크를 걸어두도록 합니다.&lt;/p&gt;
&lt;h2 id=&#34;iv-데이터-정규화-및-데이터-분리&#34;&gt;IV. 데이터 정규화 및 데이터 분리&lt;/h2&gt;
&lt;p&gt;코드부터 작성한 뒤, 설명을 진행하도록 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;del&lt;/span&gt; wine[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;quality&amp;#39;&lt;/span&gt;]
wine_norm &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (wine &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; wine&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;min()) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; (wine&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;max() &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; wine&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;min())
wine_shuffle &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; wine_norm&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(frac&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
wine_np &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; wine_shuffle&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_numpy()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;우선 &lt;code&gt;new_quality&lt;/code&gt; 변수가 만들어졌기 때문에 기존의 &lt;code&gt;quality&lt;/code&gt; 변수를 삭제하였습니다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;min()&lt;/code&gt;, &lt;code&gt;max()&lt;/code&gt; 함수를 통해서 데이터 정규화를 진행합니다.&lt;/p&gt;
&lt;p&gt;판다스의 &lt;code&gt;sample()&lt;/code&gt; 함수는 전체 데이터프레임에서 &lt;code&gt;frac&lt;/code&gt;인수로 지정된 비율만큼의 행을 랜덤하게 뽑아서 새로운 데이터프레임을 만듭니다.
&lt;code&gt;frac=1&lt;/code&gt;로 지정됐기 때문에 &lt;code&gt;100%&lt;/code&gt;, 즉 모든 데이터를 뽑아서 섞는 것과 동일한 효과를 가집니다.&lt;/p&gt;
&lt;p&gt;*Tip: 입문자들이 처음 딥러닝 소스코드 작성하는 것을 어려워 하는 부분이 엑셀데이터와 같은 데이터프레임을 딥러닝의 Input 객체로 변환하는가인데, 위 소스코드는 굉장히 유용하며, 만약 반복적인 작업이 이루어지면 사용자 정의 함수를 사용하여 작성하여 사용하는 것도 도움이 된다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train_idx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(len(wine_np) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;)
train_X, train_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; wine_np[:train_idx, :&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], wine_np[:train_idx, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
test_X, test_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; wine_np[train_idx:, :&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], wine_np[train_idx:, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]

train_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_categorical(train_Y, num_classes&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
test_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_categorical(test_Y, num_classes&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;그리고, 훈련 데이터와 테스트 데이터를 분리한 뒤 모형 학습을 진행하도록 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;48&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;relu&amp;#34;&lt;/span&gt;, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, )), 
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;24&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;relu&amp;#34;&lt;/span&gt;), 
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;relu&amp;#34;&lt;/span&gt;), 
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;softmax&amp;#34;&lt;/span&gt;)
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(lr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.07&lt;/span&gt;), loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;categorical_crossentropy&amp;#39;&lt;/span&gt;, metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])
history&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_X, train_Y, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/25
122/122 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.8070 - val_loss: 0.4394 - val_accuracy: 0.7869
Epoch 2/25
122/122 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8101 - val_loss: 0.4491 - val_accuracy: 0.7869
Epoch 3/25
122/122 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.8134 - val_loss: 0.4175 - val_accuracy: 0.7869
Epoch 4/25
122/122 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8150 - val_loss: 0.4437 - val_accuracy: 0.7869
Epoch 5/25
122/122 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8047 - val_loss: 0.4189 - val_accuracy: 0.7869
Epoch 6/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.8134 - val_loss: 0.4269 - val_accuracy: 0.8123
Epoch 7/25
122/122 [==============================] - 0s 2ms/step - loss: 0.4039 - accuracy: 0.8152 - val_loss: 0.4094 - val_accuracy: 0.7946
Epoch 8/25
122/122 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8073 - val_loss: 0.4250 - val_accuracy: 0.7869
Epoch 9/25
122/122 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8068 - val_loss: 0.4353 - val_accuracy: 0.7869
Epoch 10/25
122/122 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.8132 - val_loss: 0.4061 - val_accuracy: 0.7869
Epoch 11/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8073 - val_loss: 0.4166 - val_accuracy: 0.7869
Epoch 12/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.8181 - val_loss: 0.4064 - val_accuracy: 0.8046
Epoch 13/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.8132 - val_loss: 0.3985 - val_accuracy: 0.8123
Epoch 14/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3976 - accuracy: 0.8163 - val_loss: 0.3994 - val_accuracy: 0.8108
Epoch 15/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8163 - val_loss: 0.4174 - val_accuracy: 0.8008
Epoch 16/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3993 - accuracy: 0.8134 - val_loss: 0.4261 - val_accuracy: 0.7869
Epoch 17/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8191 - val_loss: 0.4289 - val_accuracy: 0.8023
Epoch 18/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8222 - val_loss: 0.4129 - val_accuracy: 0.7877
Epoch 19/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8199 - val_loss: 0.4028 - val_accuracy: 0.8077
Epoch 20/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3972 - accuracy: 0.8075 - val_loss: 0.4200 - val_accuracy: 0.7869
Epoch 21/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8155 - val_loss: 0.4135 - val_accuracy: 0.8054
Epoch 22/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8150 - val_loss: 0.4130 - val_accuracy: 0.8115
Epoch 23/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3935 - accuracy: 0.8132 - val_loss: 0.4040 - val_accuracy: 0.8085
Epoch 24/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8124 - val_loss: 0.3962 - val_accuracy: 0.8123
Epoch 25/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.8029 - val_loss: 0.4029 - val_accuracy: 0.7869
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;모델 정의에서 마지막 레이어의 뉴런 수가 &lt;code&gt;2&lt;/code&gt;가 아닌 &lt;code&gt;3&lt;/code&gt;이 된 것 외에는 동일한 구조의 네트워크를 사용하였습니다. 검증 데이터에 대해 약 &lt;code&gt;79%&lt;/code&gt; 정도의 분류 성적을 거두고 있습니다.&lt;/p&gt;
&lt;p&gt;늘 강조하듯이, 모형을 학습한 뒤에는 항상 모형 결과를 시각화해야 합니다. 그래야, 학습이 잘 되고 있는지, 아니면 &lt;code&gt;오버피팅(Overfitting)&lt;/code&gt; 되고 있는지 확인해야 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylim(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_05_02/output_18_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;val_loss&lt;/code&gt;가 중간에 튀기도 하고, 전반적으로 &lt;code&gt;loss&lt;/code&gt;보다 큰 값인 것을 확인할 수 있습니다. 학습을 계속하면 &lt;code&gt;loss&lt;/code&gt;는 꾸준히 작아지지만 네트워크가 훈련 데이터에 과적합되기 때문에 &lt;code&gt;val_loss&lt;/code&gt;는 증가하기 시작합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(test_X, test_Y)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;41/41 [==============================] - 0s 1ms/step - loss: 0.4058 - accuracy: 0.7985





[0.40582624077796936, 0.7984615564346313]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;데스트 데이터의 정확도는 약 79.8% 정도로 검증 데이터의 정확도와 크게 차이가 없는 것으로 나온다. 이런 경우 해결방법은 네트워크의 구성도의 크기를 키우거나 학습률을 조정해보는 등 다양한 방면으로 노력해야 한다.&lt;/p&gt;
&lt;h2 id=&#34;v-결론&#34;&gt;V. 결론&lt;/h2&gt;
&lt;p&gt;지금까지는 주로 데이터프레임에 기반하여 연습을 진행하였다. 딥러닝을 하는 목적은 사실 이러한 데이터프레임보다는 이미지 분류, 텍스트 분류와 같은 비정형 데이터 분류를 위한 것에 더 많이 사용된다. 이제 앞으로는 이러한 비정형 데이터를 다루는 방법, 학습하는 방법에 대해 공부가 될 예정이다.&lt;/p&gt;
&lt;h2 id=&#34;vi-연습-파일&#34;&gt;VI. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch5_2_multi_classification.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;vii-reference&#34;&gt;VII. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;강사가 직접 작성한 코드입니다. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch5.1 - 분류</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/</link>
      <pubDate>Sat, 18 Apr 2020 11:08:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-분류의-개요&#34;&gt;I. 분류의 개요&lt;/h2&gt;
&lt;p&gt;분류는 크게 2가지로 구분됩니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;분류 문제에 명확한 정답이 있는 경우 Vs. 분류 문제에 명확한 정답이 없는 경우.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;보통 이러한 경우 지도학습 Vs. 비지도학습이라고 얘기를 하는데, 난이도로 따지면 비지도학습이 조금 더 어렵습니다. 예를 들면, 개인정보가 가려진 신용카드 사용 정보로 비슷한 유형의 구매자 군집을 분류하는 문제도 분류 문제의 일종입니다. 이 부분에 대한 설명이 오토인코더(AutoEncoder)라 불리우는 9장에서 조금더 다루도록합니다.
이번장에서는 지도학습(Supervised Learning)에 해당하는 분류 문제만 다룹니다.&lt;/p&gt;
&lt;p&gt;그 외에 조금 더 구체적인 이론적 개념이 필요하신 분들은 NVIDIA의 글을 한번 읽어보시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blogs.nvidia.co.kr/2018/09/03/supervised-unsupervised-learning/&#34;&gt;딥러닝 지도학습, 자율학습, 지도/자율 학습, 강화학습의 차이점은 무엇일까?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ii-이항분류&#34;&gt;II. 이항분류&lt;/h2&gt;
&lt;p&gt;와인 데이터세트로 이항분류를 진행합니다. 와인은 크게 레드 와인과 화이트 와인의 두 종류로 나눌 수 있습니다. 색깔 없이 단순히, 당도, 산도, 알코올 도수 등으로 분류하는 것은 쉽지 않습니다. 이번에는 데이터 정제 과정을 거쳐야 하기 때문에 주의깊게 살펴보시기를 바랍니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 텐서플로 2 버전 선택&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
    &lt;span style=&#34;color:#75715e&#34;&gt;# %tensorflow_version only exists in Colab.&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;tensorflow_version &lt;span style=&#34;color:#ae81ff&#34;&gt;2.&lt;/span&gt;x
&lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Exception&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;pass&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
red &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv&amp;#39;&lt;/span&gt;, sep&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;;&amp;#39;&lt;/span&gt;)
white &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv&amp;#39;&lt;/span&gt;, sep&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;;&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(red&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head())
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(white&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;   fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality
0            7.4              0.70         0.00  ...       0.56      9.4        5
1            7.8              0.88         0.00  ...       0.68      9.8        5
2            7.8              0.76         0.04  ...       0.65      9.8        5
3           11.2              0.28         0.56  ...       0.58      9.8        6
4            7.4              0.70         0.00  ...       0.56      9.4        5

[5 rows x 12 columns]
   fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality
0            7.0              0.27         0.36  ...       0.45      8.8        6
1            6.3              0.30         0.34  ...       0.49      9.5        6
2            8.1              0.28         0.40  ...       0.44     10.1        6
3            7.2              0.23         0.32  ...       0.40      9.9        6
4            7.2              0.23         0.32  ...       0.40      9.9        6

[5 rows x 12 columns]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;판다스 데이터프레임에 관한 설명은 강사가 작성해 놓은 자료를 참조하셔서 공부하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/pandas/pandas_dataframe/&#34;&gt;Pandas Dataframe&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;데이터프레임은 여러 개의 행으로 구성되어 있으며, &lt;code&gt;head()&lt;/code&gt;는 이 가운데 일부를 출력해서 보여줍니다. 각 데이터에 대한 속성은 영어로도 정리가 되어 있지만, 한글 독자분들은 교재 (108 p.)를 참고하시기를 바랍니다.&lt;/p&gt;
&lt;p&gt;원서의 정리는 다음 자료에서 확인합니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://archive.ics.uci.edu/ml/datasets/Wine+Quality&#34;&gt;Wine Quality Data Set&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;1-데이터-합치기&#34;&gt;(1) 데이터 합치기&lt;/h3&gt;
&lt;p&gt;와인 분류문제에서는 12개 속성으로 와인의 종류(레드/화이트)를 분류해야 합니다. 현재는 &lt;code&gt;red&lt;/code&gt;와 &lt;code&gt;white&lt;/code&gt;의 두 데이터프레임으로 데이터가 분리되어 있기 때문에 텐서플로에서 이 데이터를 사용하기 위해 두 데이터프레임을 하나로 합쳐야 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;red[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;type&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
white[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;type&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(red&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(white&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;))

wine &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;concat([red, white])
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(wine&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;describe())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;   fixed acidity  volatile acidity  citric acid  ...  alcohol  quality  type
0            7.4              0.70          0.0  ...      9.4        5     0
1            7.8              0.88          0.0  ...      9.8        5     0

[2 rows x 13 columns]
   fixed acidity  volatile acidity  citric acid  ...  alcohol  quality  type
0            7.0              0.27         0.36  ...      8.8        6     1
1            6.3              0.30         0.34  ...      9.5        6     1

[2 rows x 13 columns]
       fixed acidity  volatile acidity  ...      quality         type
count    6497.000000       6497.000000  ...  6497.000000  6497.000000
mean        7.215307          0.339666  ...     5.818378     0.753886
std         1.296434          0.164636  ...     0.873255     0.430779
min         3.800000          0.080000  ...     3.000000     0.000000
25%         6.400000          0.230000  ...     5.000000     1.000000
50%         7.000000          0.290000  ...     6.000000     1.000000
75%         7.700000          0.400000  ...     6.000000     1.000000
max        15.900000          1.580000  ...     9.000000     1.000000

[8 rows x 13 columns]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;각 코드에 대한 설명은 다음과 같습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;먼저 데이터프레임에 새로운 속성을 추가하는 방법은 단순히 &lt;code&gt;red[&#39;type&#39;] = 0&lt;/code&gt; 처럼 데이터프레임이 파이썬의 사전(&lt;code&gt;dictionary&lt;/code&gt;) 타입인 것처럼 속성명과 값을 지정합니다. 레드 와인은 0, 화이트 와인은 1로 지정했습니다. 이 부분이 이항분류의 종속변수가 될 것입니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pd.concat()&lt;/code&gt; 데이터 프레임을 단순히 위아래로 연결하는 새로운 데이터프레임을 만들어 냅니다.&lt;/li&gt;
&lt;li&gt;데이터가 잘 입력되었는지 가설을 확인하기 위해 간단한 그래프를 그려봅니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;hist(wine[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;type&amp;#39;&lt;/span&gt;])
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xticks([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(wine[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;type&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;value_counts())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_05_01/output_7_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1    4898
0    1599
Name: type, dtype: int64
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;위 그래프를 토대로 확인해보면 레드 와인보다 화이트 와인이 더 많다는 것을 알 수 있습니다. 정확한 수치로 표현하기 위해 &lt;code&gt;value_counts()&lt;/code&gt;함수를 사용했습니다.&lt;/p&gt;
&lt;h3 id=&#34;2-데이터-정규화&#34;&gt;(2) 데이터 정규화&lt;/h3&gt;
&lt;p&gt;데이터 정규화는 수치형 값에 적용하는 것이지, 문자열에 적용하는 건 아닙니다. 문제는 외부에서 불러오는 데이터의 경우 어떤 값으로 구성되어 있는지 알기 어려운데, 이 때 데이터의 파악을 도와주는 것이 판다스의 &lt;code&gt;info()&lt;/code&gt; 입니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(wine&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;info())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;class &#39;pandas.core.frame.DataFrame&#39;&amp;gt;
Int64Index: 6497 entries, 0 to 4897
Data columns (total 13 columns):
 #   Column                Non-Null Count  Dtype  
---  ------                --------------  -----  
 0   fixed acidity         6497 non-null   float64
 1   volatile acidity      6497 non-null   float64
 2   citric acid           6497 non-null   float64
 3   residual sugar        6497 non-null   float64
 4   chlorides             6497 non-null   float64
 5   free sulfur dioxide   6497 non-null   float64
 6   total sulfur dioxide  6497 non-null   float64
 7   density               6497 non-null   float64
 8   pH                    6497 non-null   float64
 9   sulphates             6497 non-null   float64
 10  alcohol               6497 non-null   float64
 11  quality               6497 non-null   int64  
 12  type                  6497 non-null   int64  
dtypes: float64(11), int64(2)
memory usage: 710.6 KB
None
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;다행히 모든 데이터가 &lt;code&gt;float64&lt;/code&gt; &amp;amp; &lt;code&gt;int64&lt;/code&gt;인 것을 확인할 수 있습니다. 데이터 정규화는 다음의 한줄 코드로 실현이 가능합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;wine_norm &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (wine &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; wine&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;min()) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; (wine&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;max() &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; wine&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;min())
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(wine_norm&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head())
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(wine_norm&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;describe())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;   fixed acidity  volatile acidity  citric acid  ...   alcohol   quality  type
0       0.297521          0.413333     0.000000  ...  0.202899  0.333333   0.0
1       0.330579          0.533333     0.000000  ...  0.260870  0.333333   0.0
2       0.330579          0.453333     0.024096  ...  0.260870  0.333333   0.0
3       0.611570          0.133333     0.337349  ...  0.260870  0.500000   0.0
4       0.297521          0.413333     0.000000  ...  0.202899  0.333333   0.0

[5 rows x 13 columns]
       fixed acidity  volatile acidity  ...      quality         type
count    6497.000000       6497.000000  ...  6497.000000  6497.000000
mean        0.282257          0.173111  ...     0.469730     0.753886
std         0.107143          0.109758  ...     0.145543     0.430779
min         0.000000          0.000000  ...     0.000000     0.000000
25%         0.214876          0.100000  ...     0.333333     1.000000
50%         0.264463          0.140000  ...     0.500000     1.000000
75%         0.322314          0.213333  ...     0.500000     1.000000
max         1.000000          1.000000  ...     1.000000     1.000000

[8 rows x 13 columns]
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;pandas&lt;/code&gt;에서는 &lt;code&gt;max()&lt;/code&gt;, &lt;code&gt;min()&lt;/code&gt;함수를 이용해 각 속성의 최대값과 최소값을 얻을 수 있고, 이 값들을 이용해 모든 속성과 모든 행에 대한 계산이 가능합니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;describe()&lt;/code&gt;함수에서 볼 수 있는 속성들이 0~1사이로 값이 모아진 것을 확인할 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3-데이터-변환-dataframe에서-array&#34;&gt;(3) 데이터 변환 (DataFrame에서 Array)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;이렇게 정규화된 데이터를 &lt;code&gt;NumPy Array&lt;/code&gt;로 변환합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
wine_shuffle &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; wine_norm&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(frac&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(wine_shuffle&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head())
wine_np &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; wine_shuffle&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_numpy()
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(wine_np[:&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;      fixed acidity  volatile acidity  citric acid  ...   alcohol   quality  type
3006       0.198347          0.053333     0.192771  ...  0.434783  0.500000   1.0
3757       0.223140          0.120000     0.204819  ...  0.391304  0.333333   1.0
3052       0.148760          0.080000     0.397590  ...  0.347826  0.666667   1.0
1270       0.099174          0.200000     0.006024  ...  0.869565  0.500000   0.0
1087       0.338843          0.073333     0.253012  ...  0.463768  0.500000   0.0

[5 rows x 13 columns]
[[0.19834711 0.05333333 0.19277108 0.00766871 0.0448505  0.25347222
  0.41013825 0.07422402 0.3875969  0.10674157 0.43478261 0.5
  1.        ]
 [0.2231405  0.12       0.20481928 0.01226994 0.05149502 0.08333333
  0.41013825 0.09735878 0.44186047 0.13483146 0.39130435 0.33333333
  1.        ]
 [0.14876033 0.08       0.39759036 0.14723926 0.05647841 0.26736111
  0.38940092 0.14247156 0.20155039 0.11797753 0.34782609 0.66666667
  1.        ]
 [0.09917355 0.2        0.0060241  0.01533742 0.06478405 0.08680556
  0.12442396 0.07191055 0.75968992 0.29775281 0.86956522 0.5
  0.        ]
 [0.33884298 0.07333333 0.25301205 0.01533742 0.07973422 0.05902778
  0.05529954 0.13283208 0.44186047 0.26404494 0.46376812 0.5
  0.        ]]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;판다스의 &lt;code&gt;sample()&lt;/code&gt; 함수는 전체 데이터프레임에서 &lt;code&gt;frac&lt;/code&gt;인수로 지정된 비율만큼의 행을 랜덤하게 뽑아서 새로운 데이터프레임을 만듭니다.
&lt;code&gt;frac=1&lt;/code&gt;로 지정됐기 때문에 &lt;code&gt;100%&lt;/code&gt;, 즉 모든 데이터를 뽑아서 섞는 것과 동일한 효과를 가집니다.&lt;/p&gt;
&lt;p&gt;*Tip: 입문자들이 처음 딥러닝 소스코드 작성하는 것을 어려워 하는 부분이 엑셀데이터와 같은 데이터프레임을 딥러닝의 Input 객체로 변환하는가인데, 위 소스코드는 굉장히 유용하며, 만약 반복적인 작업이 이루어지면 사용자 정의 함수를 사용하여 작성하여 사용하는 것도 도움이 된다.&lt;/p&gt;
&lt;h3 id=&#34;4-훈련-데이터와-테스트-데이터-분리&#34;&gt;(4) 훈련 데이터와 테스트 데이터 분리&lt;/h3&gt;
&lt;p&gt;훈련 데이터와 테스트 데이터로 나누어 진행합니다. 검증데이터는 훈련데이터서 일부를 떼서 자동으로 만들 예정이기 때문에, 여기에서는 훈련 데이터와 테스트 데이터로만 나누어 진행합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
train_idx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(len(wine_np) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;)
train_X, train_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; wine_np[:train_idx, :&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], wine_np[:train_idx, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
test_X, test_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; wine_np[train_idx:, :&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], wine_np[train_idx:, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_X[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(test_X[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(test_Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
train_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_categorical(train_Y, num_classes&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
test_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_categorical(test_Y, num_classes&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(test_Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[0.19834711 0.05333333 0.19277108 0.00766871 0.0448505  0.25347222
 0.41013825 0.07422402 0.3875969  0.10674157 0.43478261 0.5       ]
1.0
[0.84297521 0.22       0.37951807 0.04907975 0.13289037 0.01736111
 0.09447005 0.27549643 0.2248062  0.33146067 0.4057971  0.5       ]
0.0
[0. 1.]
[1. 0.]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;위 소스코드에 대한 설명은 아래와 같습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;먼저 80%에 해당하는 데이터를 훈련 데이터와 검증 데이터로 만들기 위해 wine_np의 수의 80%에 해당하는 인덱스를 &lt;code&gt;int&lt;/code&gt;값으로 저장합니다.&lt;/li&gt;
&lt;li&gt;그 다음 이 인덱스를 이용해 &lt;code&gt;wine_np&lt;/code&gt;를 분리합니다. NumPy Array에서는 2차원 이상의 인덱스에 접근할 때 쉼표(,)를 사용하기 때문에 쉼표를 이용해 &lt;code&gt;X&lt;/code&gt;와 &lt;code&gt;Y&lt;/code&gt;도 구분합니다. 12개의 기존 속성은 &lt;code&gt;X&lt;/code&gt;가 되고 새롭게 추가한 &lt;code&gt;type&lt;/code&gt;은 &lt;code&gt;Y&lt;/code&gt;가 됩니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;to_categorical&lt;/code&gt; 분류 문제에서 자주 쓰이는 함수로 정답 행렬을 &lt;code&gt;원-핫 인코딩(One-Hot Encoding)&lt;/code&gt; 방식으로 바꿉니다. 이 함수의 두번째 인수인 &lt;code&gt;num_classes&lt;/code&gt;는 정답 클래스의 개수입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;iii-딥러닝-학습&#34;&gt;III. 딥러닝 학습&lt;/h2&gt;
&lt;p&gt;시퀀셜 모델을 통해서 모형을 학습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 5.8 와인 데이터셋 분류 모델 생성&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;48&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;,)),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;24&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;)
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(lr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.07&lt;/span&gt;), loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;categorical_crossentropy&amp;#39;&lt;/span&gt;, metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential_8&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_32 (Dense)             (None, 48)                624       
_________________________________________________________________
dense_33 (Dense)             (None, 24)                1176      
_________________________________________________________________
dense_34 (Dense)             (None, 12)                300       
_________________________________________________________________
dense_35 (Dense)             (None, 2)                 26        
=================================================================
Total params: 2,126
Trainable params: 2,126
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;회귀모형과 다르게 분류 모델이기 때문에 소프트맥스(&lt;code&gt;softmax&lt;/code&gt;)를 사용했습니다. 소프트맥스의 역할은 큰 값을 강조하고 작은 값은 약화하는 효과를 갖습니다. (자세한 내용은 교재 117페이지 참고)&lt;/p&gt;
&lt;p&gt;우선, [2,1,0]이라는 값이 있습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;max로 변환 시, [2,0,0]이 됩니다.&lt;/li&gt;
&lt;li&gt;softmax로 변환하면 [0.67, 0.24, 0.09]의 확률값이 됩니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$e$를 밑으로 하는 지수함수를 취하기 때문에 위의 효과가 발생하며, 0이나 음수에도 적용 가능합니다. &lt;code&gt;softmax&lt;/code&gt;가 중요한 이유는 분류 문제나 언어 &lt;code&gt;RNN&lt;/code&gt;에서의 다음 토큰 예측, 강화학습에서 에이전트의 행동 확률을 구하는 결과값으로 확률이 필요한 다양한 분야에서 쓰입니다.&lt;/p&gt;
&lt;p&gt;여기에서는 예측값이 레드 와인일 확률과 화이트 와인일 확률을 구하는데 사용되며, [0.97, 0.03]처럼 합이 &lt;code&gt;1.0&lt;/code&gt;인 확률값이 될 것입니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; math
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.01&lt;/span&gt;)
e_x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; math&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;e &lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt; x

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axhline(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axvline(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(x, x, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;y=x&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(x, e_x, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g.&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;y=e^x&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;X&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Y&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_05_01/output_19_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;마지막 레이어에서 한 가지 더 주목할 점은 뉴런의 개수가 2로 설정되어 있다는 점입니다. 이는 종속변수의 클래스 숫자와 동일합니다.&lt;/p&gt;
&lt;p&gt;손실함수 &lt;code&gt;loss&lt;/code&gt;에는 &lt;code&gt;sparse_categorical_crossentropy&lt;/code&gt;라는 값이 들어가 있습니다. 이에 관한 구체적인 설명은 118~119 페이지에 있으니 참고바랍니다. 엔트로피와 정보이론에 관한 설명은 다음 자료를 참고하십시요.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.naver.com/gyrbsdl18/221013188633&#34;&gt;Cross Entropy 란 무엇인가 (information theory)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;이제 분류 네트워크를 학습시켜 봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_X, train_Y, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/25
122/122 [==============================] - 0s 3ms/step - loss: 0.2900 - accuracy: 0.8673 - val_loss: 0.1034 - val_accuracy: 0.9762
Epoch 2/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0825 - accuracy: 0.9800 - val_loss: 0.0609 - val_accuracy: 0.9823
Epoch 3/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.9833 - val_loss: 0.0786 - val_accuracy: 0.9754
Epoch 4/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0566 - accuracy: 0.9867 - val_loss: 0.0336 - val_accuracy: 0.9931
Epoch 5/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0493 - accuracy: 0.9885 - val_loss: 0.0334 - val_accuracy: 0.9877
Epoch 6/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 0.9908 - val_loss: 0.0365 - val_accuracy: 0.9931
Epoch 7/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0416 - accuracy: 0.9892 - val_loss: 0.0277 - val_accuracy: 0.9946
Epoch 8/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0479 - accuracy: 0.9864 - val_loss: 0.0237 - val_accuracy: 0.9931
Epoch 9/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0445 - accuracy: 0.9874 - val_loss: 0.0319 - val_accuracy: 0.9915
Epoch 10/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.9867 - val_loss: 0.0392 - val_accuracy: 0.9915
Epoch 11/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0422 - accuracy: 0.9879 - val_loss: 0.0330 - val_accuracy: 0.9869
Epoch 12/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 0.9918 - val_loss: 0.0274 - val_accuracy: 0.9946
Epoch 13/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 0.9885 - val_loss: 0.0203 - val_accuracy: 0.9969
Epoch 14/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.9900 - val_loss: 0.0238 - val_accuracy: 0.9946
Epoch 15/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0416 - accuracy: 0.9902 - val_loss: 0.0250 - val_accuracy: 0.9908
Epoch 16/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.9915 - val_loss: 0.0394 - val_accuracy: 0.9854
Epoch 17/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0435 - accuracy: 0.9900 - val_loss: 0.0321 - val_accuracy: 0.9908
Epoch 18/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.9905 - val_loss: 0.0282 - val_accuracy: 0.9938
Epoch 19/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0460 - accuracy: 0.9887 - val_loss: 0.0374 - val_accuracy: 0.9900
Epoch 20/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9920 - val_loss: 0.0251 - val_accuracy: 0.9946
Epoch 21/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.9913 - val_loss: 0.0251 - val_accuracy: 0.9938
Epoch 22/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 0.9867 - val_loss: 0.0432 - val_accuracy: 0.9846
Epoch 23/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.9887 - val_loss: 0.0324 - val_accuracy: 0.9938
Epoch 24/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 0.9900 - val_loss: 0.0239 - val_accuracy: 0.9946
Epoch 25/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9926 - val_loss: 0.0193 - val_accuracy: 0.9962
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;학습 과정에서의 training 데이터의 정확도와 검증 데이터의 정확도가 각각 accuracy와 val_accuracy라는 이름으로 표시됩니다.&lt;/p&gt;
&lt;p&gt;분류 모델의 학습 결과를 시각화해보면 정확도가 100%에 가까운 매우 좋은 결과를 유지하고 있음을 확인할 수 있습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;k--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylim(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_05_01/output_23_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;iv-딥러닝-모형-평가&#34;&gt;IV. 딥러닝 모형 평가&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;model.evaluate()&lt;/code&gt; 함수를 통해서 모델의 성능을 평가할 수 있습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(test_X, test_Y)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;41/41 [==============================] - 0s 1ms/step - loss: 0.0447 - accuracy: 0.9915





[0.044681474566459656, 0.9915384650230408]
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;v-연습-파일&#34;&gt;V. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch5_1_binary_classification.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;vi-reference&#34;&gt;VI. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>