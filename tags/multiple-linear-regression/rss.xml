<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Multiple Linear Regression on Data Science | ChloEvan</title>
    <link>https://chloevan.github.io/tags/multiple-linear-regression/</link>
    <description>Recent content in Multiple Linear Regression on Data Science | ChloEvan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 15 Apr 2020 13:40:30 +0900</lastBuildDate>
    
        <atom:link href="https://chloevan.github.io/tags/multiple-linear-regression/rss.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch4.2 - 다항 회귀</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/</link>
      <pubDate>Wed, 15 Apr 2020 13:40:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-기본개념&#34;&gt;I. 기본개념&lt;/h2&gt;
&lt;p&gt;비선형 회귀(Nonlinear Regression)는 선형 회귀로는 표현할 수 없는 데이터의 경향성을 설명하기 위한 회귀입니다. 이 가운데 $x^2$, $x^3$ 등의 다항식을 이용한 회귀를 다항회귀(Polynomial Regression)라고 합니다.&lt;/p&gt;
&lt;p&gt;즉, 회귀선이 직선 대신 2차 함수, 3차 함수 등의 곡선이 됩니다.&lt;/p&gt;
&lt;p&gt;2차 함수 이상의 그래프를 그려도 데이터의 경향성이 잘 나타나는지 확인합니다. 텐서플로를 이용해서 소스코드를 작업합니다.&lt;/p&gt;
&lt;h2 id=&#34;ii-2차함수-소스코드-및-손실량&#34;&gt;II. 2차함수 소스코드 및 손실량&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np

&lt;span style=&#34;color:#75715e&#34;&gt;# 모듈을 가져옵니다. &lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; random
X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.78&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1.26&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.03&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1.11&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.24&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.24&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.47&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.77&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.37&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.85&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.41&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.27&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.02&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.76&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2.66&lt;/span&gt;]
Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;12.27&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;14.44&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;11.87&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;18.75&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;17.52&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;16.37&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;19.78&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;19.51&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;12.65&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;14.74&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10.72&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;21.94&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;12.83&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;15.51&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;17.14&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;14.42&lt;/span&gt;]

&lt;span style=&#34;color:#75715e&#34;&gt;# a와 b, c를 랜덤한 값으로 초기화합니다.&lt;/span&gt;
a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Variable(random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random())
b &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Variable(random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random())
c &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Variable(random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random())

&lt;span style=&#34;color:#75715e&#34;&gt;# 잔차의 제곱의 평균을 반환하는 함수입니다. &lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;compute_loss&lt;/span&gt;(): 
  &lt;span style=&#34;color:#75715e&#34;&gt;# 책의 본문(p, 83)은 아래처럼 되어 있지만, 에러가 날 것이다. &lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;# y_pred = a*X**2 + b*X + c&lt;/span&gt;
  y_pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; a &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; X &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; X &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; X &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; c 
  loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_mean((Y &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; y_pred) &lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; loss

optimizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(lr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.07&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;): 
  &lt;span style=&#34;color:#75715e&#34;&gt;# 잔차의 제곱의 평균을 최소화합니다. &lt;/span&gt;
  optimizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;minimize(compute_loss, var_list&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[a, b, c])

  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;99&lt;/span&gt;: 
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(i, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;a:&amp;#39;&lt;/span&gt;, a&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy(), &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b:&amp;#39;&lt;/span&gt;, b&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy(), &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;c:&amp;#39;&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy(), &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss:&amp;#39;&lt;/span&gt;, compute_loss()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy())

line_x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(min(X), max(X), &lt;span style=&#34;color:#ae81ff&#34;&gt;0.01&lt;/span&gt;)
line_y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; a &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; line_x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; line_x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; line_x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; c

&lt;span style=&#34;color:#75715e&#34;&gt;# 그래프를 그립니다.&lt;/span&gt;
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(line_x,line_y,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r-&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(X,Y,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bo&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Population Growth Rate (%)&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Elderly Population Rate (%)&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;99 a: 3.840222 b: -5.386301 c: 6.4142933 loss: 69.31381
199 a: 2.823892 b: -4.6838207 c: 10.26055 loss: 31.852983
299 a: 1.3373799 b: -2.4428246 c: 12.872813 loss: 16.335335
399 a: 0.36516348 b: -0.95042753 c: 14.520345 loss: 11.102524
499 a: -0.16323428 b: -0.13958982 c: 15.417201 loss: 9.763081
599 a: -0.41179818 b: 0.24179395 c: 15.83927 loss: 9.500618
699 a: -0.5134157 b: 0.39770818 c: 16.01183 loss: 9.461109
799 a: -0.5495791 b: 0.4531944 c: 16.07324 loss: 9.456543
899 a: -0.56077087 b: 0.47036672 c: 16.092247 loss: 9.45614
999 a: -0.5637749 b: 0.47497624 c: 16.097347 loss: 9.456112
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_04_02/output_2_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;달라진 소스코드는 a와 b를 각각 2차항과 1차항의 계수로 바꿨다는 것입니다. &lt;code&gt;X&lt;/code&gt;를 추가하였는데,
기존 &lt;code&gt;a * X + b&lt;/code&gt; 코드를 새로운 코드 &lt;code&gt;a * X * X + b * X + c &lt;/code&gt;로 바꾼 것이 중요합니다. 그러나 결과는 직선 회귀선보다 손실이 소량 감소한 것을 확인 할 수 있습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/#iii-%ED%85%90%EC%84%9C%ED%94%8C%EB%A1%9C%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%ED%9A%8C%EA%B7%80%EC%84%A0-%EA%B5%AC%ED%95%98%EA%B8%B0&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;와 비교해서 확인해봅니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;iii-3차함수-소스코드-및-손실량&#34;&gt;III. 3차함수 소스코드 및 손실량&lt;/h3&gt;
&lt;p&gt;그렇다면, 3차함수($ax^3+bx^2+cx+d$)의 경우는 어떨까요? 기존코드를 최대한 활용해서 손실량을 확인해봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np

&lt;span style=&#34;color:#75715e&#34;&gt;# 모듈을 가져옵니다. &lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; random
X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.78&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1.26&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.03&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1.11&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.24&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.24&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.47&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.77&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.37&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.85&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.41&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.27&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.02&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.76&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2.66&lt;/span&gt;]
Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;12.27&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;14.44&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;11.87&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;18.75&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;17.52&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;16.37&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;19.78&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;19.51&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;12.65&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;14.74&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10.72&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;21.94&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;12.83&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;15.51&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;17.14&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;14.42&lt;/span&gt;]

&lt;span style=&#34;color:#75715e&#34;&gt;# a와 b, c를 랜덤한 값으로 초기화합니다.&lt;/span&gt;
a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Variable(random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random())
b &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Variable(random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random())
c &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Variable(random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random())
d &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Variable(random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random())

&lt;span style=&#34;color:#75715e&#34;&gt;# 잔차의 제곱의 평균을 반환하는 함수입니다. &lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;compute_loss&lt;/span&gt;(): 
  &lt;span style=&#34;color:#75715e&#34;&gt;# 책의 본문(p, 83)은 아래처럼 되어 있지만, 에러가 날 것이다. &lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;# y_pred = a*X**2 + b*X + c&lt;/span&gt;
  y_pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; a &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; X &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; X &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; X &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; X &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; X &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; X &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; d
  loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_mean((Y &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; y_pred) &lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; loss

optimizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(lr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.07&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;): 
  &lt;span style=&#34;color:#75715e&#34;&gt;# 잔차의 제곱의 평균을 최소화합니다. &lt;/span&gt;
  optimizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;minimize(compute_loss, var_list&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[a, b, c])

  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;99&lt;/span&gt;: 
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(i, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;a:&amp;#39;&lt;/span&gt;, a&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy(), &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b:&amp;#39;&lt;/span&gt;, b&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy(), &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;c:&amp;#39;&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy(), &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;d:&amp;#39;&lt;/span&gt;, d&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy(),&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss:&amp;#39;&lt;/span&gt;, compute_loss()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy())

line_x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(min(X), max(X), &lt;span style=&#34;color:#ae81ff&#34;&gt;0.01&lt;/span&gt;)
line_y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; a &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; line_x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; line_x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; line_x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; line_x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; line_x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; line_x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; d

&lt;span style=&#34;color:#75715e&#34;&gt;# 그래프를 그립니다.&lt;/span&gt;
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(line_x,line_y,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r-&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(X,Y,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bo&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Population Growth Rate (%)&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Elderly Population Rate (%)&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;99 a: -1.0329757 b: 6.6740055 c: -4.583161 d: 0.52839094 loss: 160.23645
199 a: -2.6273808 b: 11.315129 c: -5.680506 d: 0.52839094 loss: 138.63791
299 a: -3.9567773 b: 14.502094 c: -4.9157133 d: 0.52839094 loss: 130.275
399 a: -4.8310013 b: 16.512175 c: -4.2031274 d: 0.52839094 loss: 127.39865
499 a: -5.3181896 b: 17.629168 c: -3.7981315 d: 0.52839094 loss: 126.6281
599 a: -5.554209 b: 18.170454 c: -3.6022978 d: 0.52839094 loss: 126.46801
699 a: -5.6541195 b: 18.399607 c: -3.5194376 d: 0.52839094 loss: 126.4422
799 a: -5.6911244 b: 18.484484 c: -3.4887505 d: 0.52839094 loss: 126.43897
899 a: -5.703112 b: 18.511978 c: -3.478811 d: 0.52839094 loss: 126.43866
999 a: -5.7064986 b: 18.519741 c: -3.4760025 d: 0.52839094 loss: 126.43864
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_04_02/output_4_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;3차 함수가 그려졌지만, 데이터의 경향성을 잘 설명한다보 보기 어렵고, 손실도 매우 커졌음을 확인할 수 있습니다.&lt;/p&gt;
&lt;p&gt;1차 함수부터 3차 함수까지 소스코드를 작업한 가장 큰 이유는 &lt;strong&gt;어느 것이 가장 적절한 회귀식인지 즉시 알기는 어렵기 때문에 식을 계속 바꿔가며 최적의 회귀식을 찾기 위해 노력해야 한다는 점입니다.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;딥러닝을 활용한 회귀는 어떻게 될까요? 또한 무엇을 고려해야 할까요?&lt;/p&gt;
&lt;p&gt;다음장에서 조금 더 구체적으로 배우도록 합니다.&lt;/p&gt;
&lt;h2 id=&#34;vi-연습-파일&#34;&gt;VI. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch4_2_multiple_linear_regression.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v-reference&#34;&gt;V. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>