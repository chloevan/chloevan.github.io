<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Binary Classification on Data Science | ChloEvan</title>
    <link>https://chloevan.github.io/tags/binary-classification/</link>
    <description>Recent content in Binary Classification on Data Science | ChloEvan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 01 May 2020 17:20:30 +0900</lastBuildDate>
    
        <atom:link href="https://chloevan.github.io/tags/binary-classification/rss.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch8.3.1 - 컨볼루션 신경망을 사용한 텍스처 합성</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch8_3_1_texture_synthesis/</link>
      <pubDate>Fri, 01 May 2020 17:20:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch8_3_1_texture_synthesis/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.2 - 다항분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/&#34;&gt;Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/&#34;&gt;Tensorflow 2.0 Tutorial ch6.1-2 - CNN 이론&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_3_fashion_mnist_with_cnn/&#34;&gt;Tensorflow 2.0 Tutorial ch6.3 - Fashion MNIST with CNN 실습&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_4_improve_performance/&#34;&gt;Tensorflow 2.0 Tutorial ch6.4 - 모형의 성능 높이기&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (1)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (2)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_3_sentimentanalysis/&#34;&gt;Tensorflow 2.0 Tutorial ch7.3 - 긍정, 부정 감성 분석&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (1) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (2) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_1_tensorflow_hub/&#34;&gt;Tensorflow 2.0 Tutorial ch8.1 - 텐서플로 허브&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_2_transfer_learning/&#34;&gt;Tensorflow 2.0 Tutorial ch8.2 - 전이 학습과 &amp;amp; Kaggle 대회&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요&#34;&gt;I. 개요&lt;/h2&gt;
&lt;p&gt;2015년, 딥러닝과 예술의 만남으로 큰 화제가 되었던 신경 스타일 전이 논문&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;은 반 고흐의 (별이 빛나는 밤에)라는 그림과 풍경 사진을 합성해서 반 고흐가 그린 것 같은 스타일의 풍경 이미지를 만들었고, &lt;a href=&#34;https://prisma-ai.com/&#34;&gt;프리즈마&lt;/a&gt;등의 앱은 이 알고리즘을 빠르게 탑재해서 인기를 끌었습니다.&lt;/p&gt;
&lt;p&gt;본 포스트에서는 텍스처 합성에 대해 알아본 뒤 2장의 이미지에서 각각 스타일과 내용을 가져와서 합성하는 신경 스타일 전이에 대해 다루도록 합니다.&lt;/p&gt;
&lt;h2 id=&#34;ii-컨볼루션-신경망을-사용한-텍스처-합성&#34;&gt;II. 컨볼루션 신경망을 사용한 텍스처 합성&lt;/h2&gt;
&lt;p&gt;텍스처(Texture)는 넓은 의미로는 단순히 이미지만, 컴퓨터 비전에서 쓰이는 좁은 의미로는 지역적으로는 비교적 다양한 값을 가지면서 전체적으로는 비슷한 모습을 보이는 이미지를 뜻합니다.&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;돌, 나무, 구름, 섬유 등의 텍스처에서는 위 조건에 해당하는 일정한 패턴을 관찰할 수 있으며, 이 패턴은 전체적으로 비슷하면서도 지역적으로는 서로 조금씩 다릅니다.&lt;/p&gt;
&lt;h3 id=&#34;1-텍스처-합성-방법론&#34;&gt;(1) 텍스처 합성 방법론&lt;/h3&gt;
&lt;p&gt;텍스처 합성 방법론은 크게 두가지입니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;첫번째, 픽셀이나 이미지를 잘게 쪼갠 단위인 &lt;code&gt;Patch&lt;/code&gt;(조각)을 재배열하는 방법입니다. Patch Match 알고리즘을 최적화한 버전입니다.&lt;/li&gt;
&lt;li&gt;두번째, 파라미터에 의한 텍스처 모델링입니다. 먼저 원본 텍스처의 공간적인 통계값(Spatial Statistics)을 사람이 정교하게 만든 여러 개의 필터로 구합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;특히, 교재는 필터 부분을 딥러닝이 가장 제일 잘하는 것으로 설명하고 있고, 여기에 관한 그림 및 이론적인 설명으로 297-300페이제 걸쳐서 설명을 하고 있습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;주요 논문은 &lt;a href=&#34;https://papers.nips.cc/paper/5633-texture-synthesis-using-convolutional-neural-networks.pdf&#34;&gt;Texture Synthesis Using Convolutional Neural Networks&lt;/a&gt; 입니다.&lt;/li&gt;
&lt;li&gt;Gram Matrix을 활용합니다.&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;이 부분은 교재를 참고하시기를 바랍니다.&lt;/p&gt;
&lt;h3 id=&#34;2-원본-텍스처-이미지-불러오기&#34;&gt;(2) 원본 텍스처 이미지 불러오기&lt;/h3&gt;
&lt;p&gt;이제 실습 코드로 진행해봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 텐서플로 2 버전 선택&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
    &lt;span style=&#34;color:#75715e&#34;&gt;# %tensorflow_version only exists in Colab.&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;tensorflow_version &lt;span style=&#34;color:#ae81ff&#34;&gt;2.&lt;/span&gt;x
&lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Exception&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;pass&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow_hub &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; hub

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; cv2

style_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;style.jpg&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://bit.ly/2mGfZIq&amp;#39;&lt;/span&gt;)
style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(style_path)
style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(style_image, dsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;))
style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; style_image &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(style_image)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from http://bit.ly/2mGfZIq
344064/337723 [==============================] - 0s 0us/step





&amp;lt;matplotlib.image.AxesImage at 0x7fbf05a4b668&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_03_1/output_6_2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;tf.keras.utils.get_file()&lt;/code&gt; 함수로 파일을 다운로드한 뒤에 &lt;code&gt;OpenCV&lt;/code&gt;로 이미지의 크기를 (224, 224)로 조정합니다. 더 큰 크기로 지정해도 상관없지만 일단은 작은 크기에서 어떻게 동작하는지 확인해보고, 큰 크기의 이미지는 다음 절의 신경 스타일 전이에서 시도합니다.&lt;/p&gt;
&lt;h3 id=&#34;3-타깃-텍스처-만들기&#34;&gt;(3) 타깃 텍스처 만들기&lt;/h3&gt;
&lt;p&gt;그 다음으로는 타깃 텍스처로 사용할 이미지를 만듭니다. 타깃 텍스처는 랜덤 노이즈 이미지에서 시작하며, 랜덤 노이지를 만드는 방법 &lt;code&gt;3.3.1&lt;/code&gt;절의 난수생성에서 배운 걸 응용합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;target_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uniform(style_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(target_image[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,:])

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(target_image)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;tf.Tensor([0.06687331 0.9121063  0.9395486 ], shape=(3,), dtype=float32)





&amp;lt;matplotlib.image.AxesImage at 0x7fbf055b5eb8&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_03_1/output_9_2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;style_image&lt;/code&gt;와 같은 차원을 가지는 랜덤 노이즈를 생성합니다. 컬러 이미지이기 때문에 차원 수는 (224, 224, 3)으로 마지막에 &lt;code&gt;RGB&lt;/code&gt; 차원을 나타내는 3이 붙습니다. 타깃 텍스처의 첫 번째 픽셀(좌측 최상단)의 값을 출력해보면 0~1 사이의 &lt;code&gt;RGB&lt;/code&gt;컬러 값을 확인할 수 있습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras.applications &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; VGG19
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras.applications.vgg19 &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; preprocess_input

vgg &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; VGG19(include_top&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False, weights&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;imagenet&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; layer &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; vgg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers:
  &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(layer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;name)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5
80142336/80134624 [==============================] - 2s 0us/step
input_1
block1_conv1
block1_conv2
block1_pool
block2_conv1
block2_conv2
block2_pool
block3_conv1
block3_conv2
block3_conv3
block3_conv4
block3_pool
block4_conv1
block4_conv2
block4_conv3
block4_conv4
block4_pool
block5_conv1
block5_conv2
block5_conv3
block5_conv4
block5_pool
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;전체 네트워크를 불러올 필요가 없이 때문에 &lt;code&gt;include_top&lt;/code&gt;인수를 &lt;code&gt;False&lt;/code&gt;로 지정해서 마지막의 &lt;code&gt;Dense&lt;/code&gt;레이어를 제외한 나머지 레이어를 불러와 &lt;code&gt;vgg&lt;/code&gt; 변수에 저장합니다. &lt;code&gt;vgg&lt;/code&gt; 변수에 저장된 네트워크에는 특징 추출기의 역할을 하는 컨볼루션 레이어와 풀링 레이어를 포함하고 있습니다. 이 중에서 선택적으로 사용할수도 있지만, &lt;code&gt;Gram Matrix&lt;/code&gt;가 지역적인 구조와 전체적인 구조를 모두 잡아낼 수 있도록 앞쪽과 뒤쪽의 레이어를 모두 사용하는 것이 좋습니다.&lt;/p&gt;
&lt;h3 id=&#34;4-특징-추출-모델-만들기&#34;&gt;(4) 특징 추출 모델 만들기&lt;/h3&gt;
&lt;p&gt;위 내용을 기반으로 특징 추출 모델을 만들어보도록 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;style_layers &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;block1_conv1&amp;#39;&lt;/span&gt;, 
                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;block2_conv1&amp;#39;&lt;/span&gt;, 
                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;block3_conv1&amp;#39;&lt;/span&gt;, 
                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;block4_conv1&amp;#39;&lt;/span&gt;, 
                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;block5_conv1&amp;#39;&lt;/span&gt;]

vgg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trainable &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; False
outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [vgg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_layer(name)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;output &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; name &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; style_layers]
model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Model([vgg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;input], outputs)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;위 코드는 이미지를 입력하면 다섯 개의 레이어에서 출력되는 특징 추출값을 얻을 수 있는 모델입니다.&lt;/li&gt;
&lt;li&gt;이 모델은 &lt;code&gt;model&lt;/code&gt;이라는 변수에 저장합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;5-gram-matrix-함수-정의&#34;&gt;(5) Gram Matrix 함수 정의&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Gram Matrix&lt;/code&gt;를 계산하는 함수를 정의합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;gram_matrix&lt;/span&gt;(input_tensor):
    channels &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(input_tensor&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
    a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(input_tensor, [&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, channels])
    n &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape(a)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
    gram &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;matmul(a, a, transpose_a&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; gram &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(n, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;먼저 입력된 특징 추출값의 형태를 벡터로 변환시킵니다. 예를 들어, 첫 번째 레이어인 &lt;code&gt;block1_conv1&lt;/code&gt;를 통과한 특정 추출값의 차원 수는 (224, 224, 64)입니다.&lt;/li&gt;
&lt;li&gt;이것을 맨 뒤의 차원(채널)인 64만 남기고 나머지를 1차원의 벡터로 만들면 차원 수는 (50176, 64)가 됩니다.&lt;/li&gt;
&lt;li&gt;이렇게 만든 행렬은 자기 자신의 전치행렬과 행렬곱하는 부분은 &lt;code&gt;gram = tf.matmul(a, a, transpose_a = True)&lt;/code&gt;입니다. &lt;code&gt;transpose_a&lt;/code&gt;라는 인수에 &lt;code&gt;True&lt;/code&gt;값을 넣어서 행렬곱을 할 때 전치행렬을 자동으로 만들어서 계산해도 됩니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;transpose_a&lt;/code&gt;가 &lt;code&gt;True&lt;/code&gt;이기 때문에 행렬곱 계산 결과의 차원은 &lt;code&gt;[64,50176]X[50176,64] = [64,64]&lt;/code&gt;가 됩니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;(224, 224, 64)&lt;/code&gt;가 &lt;code&gt;[64, 64]&lt;/code&gt;로 줄어듭니다.&lt;/li&gt;
&lt;li&gt;마지막 &lt;code&gt;return&lt;/code&gt;문에서는 1차원 벡터의 길이인 &lt;code&gt;50,176&lt;/code&gt;으로 &lt;code&gt;Gram Matrix&lt;/code&gt;값을 나눕니다.&lt;/li&gt;
&lt;li&gt;이렇게 나누지 않으면 앞쪽에 오는 레이어일수록 특징 추출값의 이미지가 크기 때문에 &lt;code&gt;Gram Matrix&lt;/code&gt;값도 커져서 큰 영향을 줍니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;6-원본-텍스처에서-gram-matrix-계산&#34;&gt;(6) 원본 텍스처에서 Gram Matrix 계산&lt;/h3&gt;
&lt;p&gt;원본 텍스처에서 &lt;code&gt;Gram Matrix&lt;/code&gt; 계산합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(style_path)
style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(style_image, dsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;))
style_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; style_image &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;

style_batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; style_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;)
style_batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(style_batch, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
style_output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model(preprocess_input(style_batch &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;style_output&lt;/code&gt;은 다섯 레이어를 통과한 특징 추출값으로 구성되어 있습니다. 그중 하나를 &lt;code&gt;matplotlib.pyplot&lt;/code&gt;으로 출력합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(style_output[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(style_output[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][:,:,:,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;), cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;(1, 224, 224, 64)





&amp;lt;matplotlib.image.AxesImage at 0x7fbef01cf5f8&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_03_1/output_21_2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;특징 추출값 [1, 224, 224, 64]을 확인할 수 있습니다. 이렇게 처리된 원본 텍스처의 &lt;code&gt;Gram Matrix&lt;/code&gt;값을 계산합니다. 또 값이 어떻게 나오는지 그래프로 분포를 확인해봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;style_outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [gram_matrix(out) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; out &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; style_output]

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;):
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    array &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sorted(style_outputs[c]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tolist())
    array &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; array[::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;bar(range(style_outputs[c]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]), array)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(style_layers[c])
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_03_1/output_23_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Gram Matrix&lt;/code&gt; 값은 레이어마다 다르게 나오고 최대값에서도 차이가 나는 것을 확인할 수 있습니다. 즉, 이 말은 각 레이어에서 계산되는 &lt;code&gt;Gram Matrix&lt;/code&gt;값에 가중치를 곱해주는 방법으로 특정한 레이어가 너무 큰 영향을 끼치지 못하도록 제어를 해야 합니다.&lt;/p&gt;
&lt;p&gt;따라서, 타깃 텍스처를 업데이트 하기 위해 몇 가지 함수를 설정해야 합니다.&lt;/p&gt;
&lt;h3 id=&#34;7-타깃-텍스처-업데이트-함수-정의&#34;&gt;(7) 타깃 텍스처 업데이트 함수 정의&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;먼저, 타깃 텍스처에서 &lt;code&gt;gram matrix&lt;/code&gt;을 구하는 함수가 필요합니다.&lt;/li&gt;
&lt;li&gt;MSE를 구하는 함수가 필요한데, 원본 텍스처의 Gram Matrix 값과, 타깃 텍스처의 Gram Matrix 사이의 &lt;code&gt;MSE&lt;/code&gt; 함수가 필요합니다.&lt;/li&gt;
&lt;li&gt;이 때, MSE 값이 0.0에서 1.0사이의 컬러 값이어야 하기 때문에 그 이하나 이상으로 값이 넘어가지 않도록 해주는 함수가 필요합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 타깃 텍스처 gram matrix 함수 정의&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_outputs&lt;/span&gt;(image):
    image_batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(image, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
    output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model(preprocess_input(image_batch &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;))
    outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [gram_matrix(out) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; out &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; output]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; outputs

&lt;span style=&#34;color:#75715e&#34;&gt;# MSE 구하는 함수 (원본 텍스처 gram matrix - 타깃 텍스처 gram matrix)&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_loss&lt;/span&gt;(outputs, style_outputs):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_sum([tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_mean((o&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;s)&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; o,s &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(outputs, style_outputs)])
  
&lt;span style=&#34;color:#75715e&#34;&gt;# 0.0~1.0 사이의 컬러값 정의 함수&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clip_0_1&lt;/span&gt;(image):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clip_by_value(image, clip_value_min&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.0&lt;/span&gt;, clip_value_max&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;8-이미지-업데이트-함수-정의&#34;&gt;(8) 이미지 업데이트 함수 정의&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;지금까지 배워온 딥러닝과의 차이점&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;tf.keras를 이용해 모델 정의하고 &lt;code&gt;fit()&lt;/code&gt; 함수를 이용해 가중치가 주어진 과제를 잘 수행하도록 하는 것&lt;/li&gt;
&lt;li&gt;그런데, 이번 포스트에서는 학습해야 할 가중치가 존재하지 않음&lt;/li&gt;
&lt;li&gt;존재하는 것은 2개의 이미지와 &lt;code&gt;Gram Matrix&lt;/code&gt;의 차이인 MSE 뿐&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;GradientType&lt;/code&gt;은 이런 상황에 대한 간편한 해결책임. 자동 미분을 통해 입력에 대한 손실을 구한 뒤 다른 변수에 대한 &lt;code&gt;Gradient(기울기)&lt;/code&gt;를 계산함. 여기에서 다른 변수는 입력이 될 수도 있고, 가중치가 될 수도 있음.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;중요한 점은 &lt;code&gt;GradientType&lt;/code&gt;의 계산 과정 안에 묶인 변수에 대한 &lt;code&gt;Gradient&lt;/code&gt;여야 함.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;opt &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(learning_rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, beta_1&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.99&lt;/span&gt;, epsilon&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1e-1&lt;/span&gt;)

&lt;span style=&#34;color:#a6e22e&#34;&gt;@tf.function&lt;/span&gt;()
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;train_step&lt;/span&gt;(image):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;GradientTape() &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tape:
        outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_outputs(image)
        loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_loss(outputs, style_outputs)

    grad &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tape&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gradient(loss, image)
    opt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply_gradients([(grad, image)])
    image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;assign(clip_0_1(image))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;첫 줄에서 최적화 함수(&lt;code&gt;optimizer&lt;/code&gt;)를 정의함. 논문에서는 &lt;code&gt;L-BFGS&lt;/code&gt;라는 최적화 함수를 썼지만, &lt;code&gt;Adam Optimizer&lt;/code&gt;를 사용해도 속도는 더 빠르고 결과물은 비슷하게 나옵니다.&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;tf.function()&lt;/code&gt; 함수는 &lt;code&gt;train_step(image)&lt;/code&gt; 함수를 인수로 받아서 &lt;code&gt;Autograph&lt;/code&gt;라는 강력한 기능을 추가합니다. &lt;code&gt;Autograph&lt;/code&gt;는 파이썬 문법으로 텐서플로의 핵심인 그래프(&lt;code&gt;Graph&lt;/code&gt;)를 컨트롤 할 수 있게 해줍니다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;2.0&lt;/code&gt; 버전을 위해 즉시 실행 모드(&lt;code&gt;Eager Execution&lt;/code&gt;)와 &lt;code&gt;tf.function&lt;/code&gt; 장식자가 나오면서 이런 불편함이 개선됩니다. &lt;code&gt;tf.function&lt;/code&gt;은 해당 장식자를 사용한 함수에서 호출되는 다른 함수도 그래프에 자동으로 포함시킵니다. 그리고 &lt;code&gt;GradientTape&lt;/code&gt;은 계산에 관계되는 모든 변수와 연산을 추적하기 때문에 퍼포먼스에 영향을 주는데 &lt;code&gt;tf.function&lt;/code&gt;장식자를 붙이면 이 연산들을 고성능의 그래프 연산으로 변환하기 때문에 퍼포먼스를 개선할 수 있습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;GradientTape() &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tape:
  outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_outputs(image)
  loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_loss(outputs, style_outputs)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;GradientTape()&lt;/code&gt;는 보통 &lt;code&gt;with&lt;/code&gt;와 함께 사용합니다. &lt;code&gt;tape&lt;/code&gt;라는 이름으로 새로운 &lt;code&gt;GradientTape&lt;/code&gt;의 인스턴스를 생성해서 참조합니다. 앞에서 설명한대로 &lt;code&gt;get_outputs(image)&lt;/code&gt;, &lt;code&gt;get_loss(outputs, style_outputs)&lt;/code&gt; 함수는 &lt;code&gt;tf.function&lt;/code&gt; 장식자를 쓰지 않았지만, 호출한 함수에 장식자가 붙었기 때문에 텐서플로의 그래프에 자동으로 포함됩니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;grad &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tape&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gradient(loss, image)
opt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply_gradients([(grad, image)])
image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;assign(clip_0_1(image))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;tape.gradient(loss, image)&lt;/code&gt;는 &lt;code&gt;with&lt;/code&gt; 구문 안에서 발생한 계산을 추적해서 입력값인 &lt;code&gt;image&lt;/code&gt;에 대한 &lt;code&gt;loss&lt;/code&gt;의 &lt;code&gt;gradient&lt;/code&gt;를 계산합니다.&lt;/li&gt;
&lt;li&gt;이렇게 계산된 &lt;code&gt;gradient&lt;/code&gt;는 변수 &lt;code&gt;grad&lt;/code&gt;에 저장되고 &lt;code&gt;Adam Optimizer&lt;/code&gt;를 통해 &lt;code&gt;image&lt;/code&gt;에 영향을 줍니다. 즉, 입력값인 &lt;code&gt;image&lt;/code&gt;는 이 계산으로 변화가 됩니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;clip_0_1(image)&lt;/code&gt;함수의 계산 결과를 &lt;code&gt;image&lt;/code&gt;에 다시 넣어서 컬러값이 &lt;code&gt;0.0&lt;/code&gt;과 &lt;code&gt;1.0&lt;/code&gt; 사이에 머물게 합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;9-텍스처-합성-알고리즘-실행&#34;&gt;(9) 텍스처 합성 알고리즘 실행&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;이제 앞에서 정의한 &lt;code&gt;train_step(image)&lt;/code&gt; 함수를 반복적으로 실행해서 텍스처를 합성합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; IPython.display &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; display
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; time
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; imageio

start &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time()

image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Variable(target_image)

epochs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;
steps_per_epoch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;

step &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(epochs):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; m &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(steps_per_epoch):
        step &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
        train_step(image)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; epochs &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:
        imageio&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imwrite(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;style_epoch_{0}.png&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(n), image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_value()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy())
    display&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clear_output(wait&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_value())
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Train step: {}&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(step))
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

end &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time()
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Total time: {:.1f}&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(end&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;start))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_03_1/output_32_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Total time: 119.2
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;먼저 첫 줄에서는 새로운 텍스처 출력을 나타내고 이전 이전 텍스처 출력을 지우기 위해 &lt;code&gt;IPython.display&lt;/code&gt;에서 &lt;code&gt;display&lt;/code&gt;를 임포트합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;실행 시간을 추적하기 위해 &lt;code&gt;time&lt;/code&gt;을, 합성된 텍스처 이미지를 저장하기 위해 &lt;code&gt;imageio&lt;/code&gt;를 import 합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Variable(target_image)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;타깃 텍스처에 &lt;code&gt;tf.Variable&lt;/code&gt;을 씌워서 &lt;code&gt;image&lt;/code&gt;라는 변수로 저장합니다. 텐서플로에서 그래프 연산을 하는 &lt;code&gt;tensor&lt;/code&gt;는 &lt;code&gt;tf.Variable&lt;/code&gt;이나 &lt;code&gt;tf.Constant&lt;/code&gt; 등에 저장되어야 합니다. (&lt;code&gt;tf.keras&lt;/code&gt;)에서는 넘파이 &lt;code&gt;array&lt;/code&gt;를 넘겨도 자동으로 이런 변환을 해줬지만 여기서는 직접 해야 합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;중첩 for 문에서는 에포크당 100 step씩 train_step(image)함수를 실행시킵니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;10-variation-loss-함수-정의&#34;&gt;(10) variation loss 함수 정의&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;매끄러운 원본과 달리 자글자글한 노이즈가 보입니다. 이러한 이미지에 생기는 노이즈를 개선하기 위해서 전체 손실에 &lt;code&gt;variation loss&lt;/code&gt;라는 것을 추가해볼 수 있습니다. &lt;code&gt;variation loss&lt;/code&gt;란 어떤 픽셀과 바로 옆에 인접한 픽셀의 차이입니다. 이 차이가 작을수록 이미지는 매끄럽게 보입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;high_pass_x_y&lt;/span&gt;(image):
  x_var &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; image[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:, :] &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; image[:, :&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, :]
  y_var &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; image[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:, :, :] &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; image[:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, :, :]
  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; x_var, y_var

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;total_variation_loss&lt;/span&gt;(image):
  x_deltas, y_deltas &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; high_pass_x_y(image)
  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_mean(x_deltas&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_mean(y_deltas&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;high_pass_x_y(image)&lt;/code&gt; 함수에서는 입력된 &lt;code&gt;image&lt;/code&gt;의 &lt;code&gt;x축 방향&lt;/code&gt;과 &lt;code&gt;y축 방향&lt;/code&gt;의 차이를 구합니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;x_var&lt;/code&gt;는 &lt;code&gt;image(224, 224, 3)&lt;/code&gt;의 &lt;code&gt;Shape&lt;/code&gt;일 때 &lt;code&gt;(224, 223, 3)&lt;/code&gt;이 되고, &lt;code&gt;y_var&lt;/code&gt;는 &lt;code&gt;(223, 224, 3)&lt;/code&gt;으로 각각 x와 y의 방향으로 1픽셀씩 작은 image가 됩니다.&lt;/li&gt;
&lt;li&gt;total_variation_loss(image) 함수에서는 이렇게 구한 x, y축 방향의 차이를 제곱해서 평균을 낸 다음에 합해서 반환합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;왜 &lt;code&gt;variation loss&lt;/code&gt;가 필요한지 원본 텍스처와 타깃 텍스처, 그리고 랜덤 노이즈 텍스처의 &lt;code&gt;variation loss&lt;/code&gt;를 비교합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;target :&amp;#39;&lt;/span&gt;, total_variation_loss(image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_value()))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;noise : &amp;#39;&lt;/span&gt;, total_variation_loss(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uniform(style_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;original : &amp;#39;&lt;/span&gt;, total_variation_loss(style_image))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;target : tf.Tensor(0.101396605, shape=(), dtype=float32)
noise :  tf.Tensor(0.3360309, shape=(), dtype=float32)
original :  tf.Tensor(0.03641251305469578, shape=(), dtype=float64)
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;위 결과값은 타깃 텍스처의 &lt;code&gt;variation loss&lt;/code&gt;는 랜덤 노이즈의 1/3 정도로 작지만, 원본 텍스처보다는 3배 정도 큽니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;11-각-손실의-가중치-추가&#34;&gt;(11) 각 손실의 가중치 추가&lt;/h3&gt;
&lt;p&gt;이 차이가 줄어들게 된다면 타깃 텍스처는 원본 텍스처에 더 가까운 모습을 보일 것이라고 가정하고, &lt;code&gt;variation loss&lt;/code&gt;를 전체 손실 계산식에 추가합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;total_variation_weight &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1e9&lt;/span&gt;
style_weight &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1e-1&lt;/span&gt;

&lt;span style=&#34;color:#a6e22e&#34;&gt;@tf.function&lt;/span&gt;()
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;train_step&lt;/span&gt;(image):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;GradientTape() &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tape:
        outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_outputs(image)
        loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; style_weight &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; get_loss(outputs, style_outputs)
        loss &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; total_variation_weight &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; total_variation_loss(image)

    grad &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tape&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gradient(loss, image)
    opt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply_gradients([(grad, image)])
    image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;assign(clip_0_1(image))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;지금까지 구한 &lt;code&gt;Gram Matrix&lt;/code&gt;는 &lt;code&gt;style loss&lt;/code&gt;라고 부릅니다. 이 &lt;code&gt;style loss&lt;/code&gt;와 새로 추가된 &lt;code&gt;variation loss&lt;/code&gt;에 각각 가중치를 곱해서 전체 손실에 더합니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;variation loss&lt;/code&gt;는 &lt;code&gt;Gram Matrix&lt;/code&gt; 계산값에 비해 작기 때문에 큰 가중치를 곱하고, 반대로 &lt;code&gt;style loss&lt;/code&gt;는 값을 줄여줍니다. 여기에 들어가는 가중치인 &lt;code&gt;total_variation_weight&lt;/code&gt;와 &lt;code&gt;style_weight&lt;/code&gt;는 적절한 값을 찾을 때까지 꾸준한 실험이 필요합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;12-variation-loss를-추가한-텍스처-합성-알고리즘-실행&#34;&gt;(12) variation loss를 추가한 텍스처 합성 알고리즘 실행&lt;/h3&gt;
&lt;p&gt;개선된 결과를 얻을 수 있는지, 결과값의 &lt;code&gt;variation loss&lt;/code&gt;를 출력하면 다음과 같습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;start &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time()

target_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uniform(style_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Variable(target_image)

epochs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;
steps_per_epoch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;

step &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(epochs):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; m &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(steps_per_epoch):
        step &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
        train_step(image)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; epochs &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:
        imageio&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imwrite(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;style_epoch_{0}.png&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(n), image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_value()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy())
    display&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clear_output(wait&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_value())
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Train step: {}&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(step))
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

end &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time()
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Total time: {:.1f}&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(end&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;start))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_03_1/output_43_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Total time: 119.7
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;확실히 좀 더 개선된 결과를 얻을 수 있습니다. 이렇게 결과값의 &lt;code&gt;variation loss&lt;/code&gt;를 출력해보면 다음과 같습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;target :&amp;#39;&lt;/span&gt;, total_variation_loss(image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_value()))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;original : &amp;#39;&lt;/span&gt;, total_variation_loss(style_image))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;target : tf.Tensor(0.030996362, shape=(), dtype=float32)
original :  tf.Tensor(0.03641251305469578, shape=(), dtype=float64)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;타깃 텍스처의 &lt;code&gt;variation loss&lt;/code&gt;가 원본 텍스처보다도 더 작아진 것을 확인할 수 있습니다. 결과 이미지도 &lt;code&gt;style loss&lt;/code&gt;만 사용했을 때 보다 매끄럽게 변한 것 같습니다.&lt;/p&gt;
&lt;h3 id=&#34;13-결론&#34;&gt;(13) 결론&lt;/h3&gt;
&lt;p&gt;지금까지 배운 것은 &lt;code&gt;style loss&lt;/code&gt;와 &lt;code&gt;variation loss&lt;/code&gt;를 이용하여 텍스쳐 합성 방법을 알아보도록 합니다.&lt;/p&gt;
&lt;h2 id=&#34;iii-연습-파일&#34;&gt;III. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch8_3_1_Texture_Synthesis.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;vi-reference&#34;&gt;VI. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Leon A. Gatys, Alexander S. Ecker, Matthias Bethge., (2015). A Neural Algorithm of Artistic Style. &lt;a href=&#34;https://arxiv.org/abs/1508.06576&#34;&gt;https://arxiv.org/abs/1508.06576&lt;/a&gt; &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.textures.com/&#34;&gt;https://www.textures.com/&lt;/a&gt; 에서 텍스처 이미지를 다양하게 확인할 수 있습니다. &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Gram Matrix는 앞에서 본 각 뉴런의 특징 추출값을 1차원의 벡터로 변환한 다음에, 벡터를 쌓아올린 행렬을 그 자신의 전치(&lt;code&gt;transpose&lt;/code&gt;) 행렬과 행렬곱해서 얻는 값입니다. &lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Ivanov, S. (2017). &amp;ldquo;Picking an optimizer for Style Transfer&amp;rdquo;. Retrieved from &lt;a href=&#34;https://blog.slavv.com/picking-an-optimizer-for-style-transfer-86e7b8cba84b&#34;&gt;https://blog.slavv.com/picking-an-optimizer-for-style-transfer-86e7b8cba84b&lt;/a&gt; &lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch8.2 - 전이 학습과 &amp; Kaggle 대회</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch8_2_transfer_learning/</link>
      <pubDate>Wed, 29 Apr 2020 17:20:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch8_2_transfer_learning/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.2 - 다항분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/&#34;&gt;Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/&#34;&gt;Tensorflow 2.0 Tutorial ch6.1-2 - CNN 이론&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_3_fashion_mnist_with_cnn/&#34;&gt;Tensorflow 2.0 Tutorial ch6.3 - Fashion MNIST with CNN 실습&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_4_improve_performance/&#34;&gt;Tensorflow 2.0 Tutorial ch6.4 - 모형의 성능 높이기&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (1)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (2)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_3_sentimentanalysis/&#34;&gt;Tensorflow 2.0 Tutorial ch7.3 - 긍정, 부정 감성 분석&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (1) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (2) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_1_tensorflow_hub/&#34;&gt;Tensorflow 2.0 Tutorial ch8.1 - 텐서플로 허브&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요&#34;&gt;I. 개요&lt;/h2&gt;
&lt;p&gt;전이 학습이란 미리 훈련된 모델을 다른 작업에 사용하기 위해 추가적인 학습을 시키는 것입니다. 이 때 훈련된 모델은 데이터에서 유의미한 특징(feature)을 뽑아내기 위한 특징 추출기(&lt;code&gt;Feature Extractor&lt;/code&gt;)로 쓰이거나, 모델의 일부를 재학습시키기도 합니다.&lt;/p&gt;
&lt;p&gt;이 부분에 대한 구체적인 이론 설명[8.2.1 모델의 일부를 재학습시키기]은 교재를 참고하시기를 바랍니다. 전이학습은 간단하게 말하면 훈련 시킬 레이어와 그렇지 않을 레이어를 구분해야 하고, 이때 &lt;code&gt;freeze&lt;/code&gt;라는 용어를 사용합니다.&lt;/p&gt;
&lt;h3 id=&#34;1-이슈&#34;&gt;(1) 이슈&lt;/h3&gt;
&lt;p&gt;변경된 부분은 크게 2개입니다.&lt;/p&gt;
&lt;p&gt;텐서플로의 버전을 2.1.0으로 다시 설치한 후 진행하는 코드를 첫 부분에 추가했습니다. (기존 코드를 최대한 살리기 위해 ImageDataGenerator를 사용해서 직접 학습을 시키려고 했습니다만 현재(2020.04.08) 텐서플로 2.2.0-rc2 버전에서는 ImageDataGenerator를 사용해서 model.fit()이나 model.fit_generator()를 학습시키려 할 경우 1 epoch 진행 후 무한루프에 걸리는 문제가 있기 때문에 텐서플로를 2.1.0으로 다시 설치했습니다.)
예제 8.16을 예제 8.24, 예제 8.25의 내용을 이용하여 수정했고 예제 8.19의 학습 코드도 일부 수정했습니다. 수정된 부분은 최대한 자세하게 주석을 달았습니다. 독자분들께 불편을 드려 죄송합니다.&lt;/p&gt;
&lt;p&gt;[저자, 김환희]&lt;/p&gt;
&lt;h2 id=&#34;ii-캐글-데이터와-연동&#34;&gt;II. 캐글 데이터와 연동&lt;/h2&gt;
&lt;p&gt;캐글은 2010년에 설립된 예측 모델 및 분석 대회를 위한 플랫폼으로 2017년에 구글에 인수되었습니다. 초기에는 전통적인 머신러닝 기법으로 풀 수 있는 테이블 데이터 위주의 문제들이 많았지만, 딥러닝의 발전으로 이미지, 음성, 자연어, 동영상 등 다양한 데이터에 대한 문제들이 올라옵니다.&lt;/p&gt;
&lt;p&gt;한번 알면 어려운 부분은 아닙니다. 그러나 처음 접하는 분들에게는 늘 항상 어렵기 때문에, 잘 따라오시기를 바랍니다.&lt;/p&gt;
&lt;p&gt;또한, 혹, 접근 이미지가 바뀌면, 댓글로 남겨주시기를 바랍니다. 수정하도록 하겠습니다.&lt;/p&gt;
&lt;h3 id=&#34;1-kaggle-module-설치&#34;&gt;(1) Kaggle Module 설치&lt;/h3&gt;
&lt;p&gt;다음 셀에서 짧은 명령어를 실행합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;!&lt;/span&gt;pip install kaggle
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)
Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.4.5.1)
Requirement already satisfied: six&amp;gt;=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)
Requirement already satisfied: urllib3&amp;lt;1.25,&amp;gt;=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)
Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.38.0)
Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)
Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)
Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)
Requirement already satisfied: chardet&amp;lt;3.1.0,&amp;gt;=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests-&amp;gt;kaggle) (3.0.4)
Requirement already satisfied: idna&amp;lt;2.9,&amp;gt;=2.5 in /usr/local/lib/python3.6/dist-packages (from requests-&amp;gt;kaggle) (2.8)
Requirement already satisfied: text-unidecode&amp;gt;=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify-&amp;gt;kaggle) (1.3)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;설치가 끝나면 API Token을 생성해야 합니다. 캐글이 없으신 분은 &lt;a href=&#34;https://www.kaggle.com/&#34;&gt;캐글 가입&lt;/a&gt;을 하시기를 바랍니다.&lt;/p&gt;
&lt;h3 id=&#34;2-api-연동&#34;&gt;(2) API 연동&lt;/h3&gt;
&lt;p&gt;캐글 가입이 완료가 되면, &lt;code&gt;My Account&lt;/code&gt;를 클릭하시기를 바랍니다. (그림 참조)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_02/kaggle_01.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;클릭 이후에 페이지 중간에 &lt;code&gt;API&lt;/code&gt; 부분에서 &lt;code&gt;Create New API Token&lt;/code&gt;을 생성합니다. 그러면 &lt;code&gt;kaggle.json&lt;/code&gt; 파일이 다운로드 됩니다. 이 파일 에디터에 있는 &lt;code&gt;username&lt;/code&gt;과 &lt;code&gt;key&lt;/code&gt;를 google colab의 한 셀에 붙여 넣기를 합니다. 그리고 아래 코드처럼 작성을 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;environ[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;KAGGLE_USERNAME&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;user_id&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# 독자의 ID&lt;/span&gt;
os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;environ[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;KAGGLE_KEY&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;user_api_token&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# 독자의 캐글 API Token&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;위 코드를 작성합니다.&lt;/p&gt;
&lt;h3 id=&#34;3-dog-breed-identification-대회&#34;&gt;(3) Dog Breed Identification 대회&lt;/h3&gt;
&lt;p&gt;본 대회는 약 2년전에 개최된 대회입니다. 본 포스트에서는 캐글 대회에 제출해서 점수를 확인하는 것까지의 여정을 담았습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;대회 주소: &lt;a href=&#34;https://www.kaggle.com/c/dog-breed-identification&#34;&gt;https://www.kaggle.com/c/dog-breed-identification&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;iii-전이학습-모형-실습-예제&#34;&gt;III. 전이학습 모형 실습 예제&lt;/h2&gt;
&lt;h3 id=&#34;1-tensorflow-설치-버전-확인&#34;&gt;(1) tensorflow 설치 버전 확인&lt;/h3&gt;
&lt;p&gt;이슈에서 제기한 것처럼 반드시 아래 코드를 실행시키셔 2.1.0 버전으로 tensorflow를 설치하시기를 바랍니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;!&lt;/span&gt;pip install tensorflow&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2.1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Collecting tensorflow==2.1.0
[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)
[K     |████████████████████████████████| 421.8MB 35kB/s 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;.
.
.
Successfully installed gast-0.2.2 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0&lt;/p&gt;
&lt;h3 id=&#34;2-데이터-다운로드&#34;&gt;(2) 데이터 다운로드&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;environ[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;KAGGLE_USERNAME&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;j2hoon85&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# 독자의 ID&lt;/span&gt;
os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;environ[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;KAGGLE_KEY&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;10109b99cfbccf2eebbf5754a5b45cb7&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# 독자의 캐글 API Token&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# !kaggle competitions download -c dog-breed-identification&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;Notice 교재에서는 &lt;code&gt;!kaggle competitions download -c dog-breed-identification&lt;/code&gt; 코드가 나와 있지만, 아래 코드로 수정하시기를 바랍니다.&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow_hub &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; hub
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 2020.02.01 현재 kaggle의 Stanford Dog Dataset 파일 구조가 변경되었습니다. &lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# kaggle API를 사용하는 대신에 아래 링크에서 파일을 직접 받아오도록 수정되었습니다.&lt;/span&gt;
tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/labels.csv&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://bit.ly/2GDxsYS&amp;#39;&lt;/span&gt;)
tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/sample_submission.csv&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://bit.ly/2GGnMNd&amp;#39;&lt;/span&gt;)
tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/train.zip&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://bit.ly/31nIyel&amp;#39;&lt;/span&gt;)
tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/test.zip&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://bit.ly/2GHEsnO&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from http://bit.ly/2GDxsYS
483328/482063 [==============================] - 0s 1us/step
Downloading data from http://bit.ly/2GGnMNd
25206784/25200295 [==============================] - 1s 0us/step
Downloading data from http://bit.ly/31nIyel
361357312/361353329 [==============================] - 11s 0us/step
Downloading data from http://bit.ly/2GHEsnO
362848256/362841195 [==============================] - 11s 0us/step





&#39;/content/test.zip&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;다운로드가 완료되면 구글 코랩 좌측 상단에 있는 파일 메뉴를 클릭해서 정상적으로 다운로드를 받았는지 확인해봅니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;labels.csv&lt;/li&gt;
&lt;li&gt;sample_submission.csv&lt;/li&gt;
&lt;li&gt;test.zip&lt;/li&gt;
&lt;li&gt;train.zip&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;위 파일들이 있는지 확인한 뒤, train, test의 압축 데이터를 푼다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;!&lt;/span&gt;unzip train&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zip
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.[0m
  inflating: train/83bcff6b55ee179a7c123fa6103c377a.jpg  
  inflating: train/83be6d622ab74a5e7e08b53eb8fd566a.jpg  
  .
  .
  .
  inflating: train/ffd3f636f7f379c51ba3648a9ff8254f.jpg  
  inflating: train/fff43b07992508bc822f33d8ffd902ae.jpg  
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;3-라벨-데이터-확인&#34;&gt;(3) 라벨 데이터 확인&lt;/h3&gt;
&lt;p&gt;폴더가 있는 경우 먼저 폴더를 만들고 그 안에 압축 파일 안의 파일들을 복사하는 것을 확인할 수 있습니다. 이번에는 정답 라벨을 담고 있는 &lt;code&gt;csv&lt;/code&gt; 파일을 확인합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
label_text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;labels.csv&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(label_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;                                 id             breed
0  000bec180eb18c7604dcecc8fe0dba07       boston_bull
1  001513dfcb2ffafc82cccf4d8bbaba97             dingo
2  001cdf01b096e06d78e9e5112d419397          pekinese
3  00214f311d5d2247d5dfe4fe24b2303d          bluetick
4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;이번에는 &lt;code&gt;info()&lt;/code&gt; 함수를 활용해서 실행하도록 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;label_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;info()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;class &#39;pandas.core.frame.DataFrame&#39;&amp;gt;
RangeIndex: 10222 entries, 0 to 10221
Data columns (total 2 columns):
 #   Column  Non-Null Count  Dtype 
---  ------  --------------  ----- 
 0   id      10222 non-null  object
 1   breed   10222 non-null  object
dtypes: object(2)
memory usage: 159.8+ KB
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;총 10,222장의 사진이 훈련 데이터에 포함되어 있음을 확인할 수 있습니다.&lt;/p&gt;
&lt;p&gt;이번에는 &lt;code&gt;nunique()&lt;/code&gt; 함수를 활용하여 해당 값의 겹치지 않는 숫자를 구한다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;label_text[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;breed&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nunique()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;120
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;4-이미지-확인-시각화&#34;&gt;(4) 이미지 확인 시각화&lt;/h3&gt;
&lt;p&gt;실제로 어떤 사진들로 구성이 되어 있는지 이미지와 라벨을 함께 출력해서 확인합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; PIL.Image &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; Image
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;):
  image_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; label_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[c, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;id&amp;#39;&lt;/span&gt;]
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/train/&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; image_id &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.jpg&amp;#39;&lt;/span&gt;))
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(str(c) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;, &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; label_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[c, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;breed&amp;#39;&lt;/span&gt;])
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_02/output_27_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;각 견종은 다양한 각도에서 찍힌 것을 확인할 수 있습니다.&lt;/p&gt;
&lt;h3 id=&#34;5-가중치-초기화-모델&#34;&gt;(5) 가중치 초기화 모델&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;이 문제가 얼마나 어려운지 확인하기 위해 전이학습 전 먼저 &lt;code&gt;MobileNet V2&lt;/code&gt;의 모든 레이어의 가중치를 초기화한 상태에서 학습시킵니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;어떤 뜻이냐면, 레이어의 구조는 같지만, &lt;code&gt;ImageNet&lt;/code&gt;의 데이터로 미리 훈련된 이미지에 대한 지식은 전혀 없는 상태에서 학습시켜봅니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;텐서플로 허브를 이용하는 방법 외에 &lt;code&gt;tf.keras&lt;/code&gt;에서도 &lt;code&gt;MobileNet V2&lt;/code&gt;를 불러올 수 있습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras.applications &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; MobileNetV2
mobilev2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; MobileNetV2()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5
14540800/14536120 [==============================] - 1s 0us/step
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; layer &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; mobilev2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers[:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]:
    layer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trainable &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; True
    
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; layer &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; mobilev2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers[:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]: 
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;kernel&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; layer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__dict__:
        kernel_shape &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(layer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_weights())&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape
        &lt;span style=&#34;color:#75715e&#34;&gt;# weight를 평균이 0, 표준편차가 1인 random 변수로 초기화&lt;/span&gt;
        layer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_weights(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;normal(kernel_shape, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;위 코드는 MobileNetV2의 가중치를 모두 초기화한 것입니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;첫번째 for 문에서는 각 레이어의 훈련 가능 여부를 모두 True로 바꿉니다. 다만 마지막 레이어인 소프트맥스 &lt;code&gt;Dense&lt;/code&gt;층은 사용하지 않을 것이기 때문에 &lt;code&gt;Mobilev2.layers[:-1]&lt;/code&gt;명령으로 제외합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;두번째 for 문에서는 각 레이어에 &lt;code&gt;kernel&lt;/code&gt;이 있는지를 확인합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;3장에서 뉴런은 가중치 &lt;code&gt;w&lt;/code&gt;와 편향 &lt;code&gt;b&lt;/code&gt;가 있다고 설명합니다. 이 때의 &lt;code&gt;kernel&lt;/code&gt;은 바로 가중치 &lt;code&gt;w&lt;/code&gt;에 해당하고, &lt;code&gt;bias&lt;/code&gt;는 편향 &lt;code&gt;b&lt;/code&gt;를 의미합니다. &lt;code&gt;bias&lt;/code&gt;는 &lt;code&gt;MobileNet V2&lt;/code&gt;에 존재하지 않기 때문에 &lt;code&gt;kernel&lt;/code&gt;이 있는지만 검사해서 있을 경우 그 값을 모두 &lt;code&gt;random&lt;/code&gt;변수로 초기화합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;6-훈련데이터-메모리-로드&#34;&gt;(6) 훈련데이터 메모리 로드&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;초기화가 끝나면 이제 실제로 학습시킵니다. 마찬가지로 여기에 주의점이 있습니다. 용량문제로 인해 4.8일자로 소스코드가 변경되었습니다.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;따라서, 아래 코드로 작성하실 것을 권유 드립니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# # 8.16 train 데이터를 메모리에 로드&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# import cv2&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# train_X = []&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# for i in range(len(label_text)):&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#     img = cv2.imread(&amp;#39;/content/train/&amp;#39; + label_text[&amp;#39;id&amp;#39;][i] + &amp;#39;.jpg&amp;#39;)&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#     img = cv2.resize(img, dsize=(224, 224))&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#     img = img / 255.0&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#     train_X.append(img)&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# train_X = np.array(train_X)&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# print(train_X.shape)&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# print(train_X.size * train_X.itemsize, &amp;#39; bytes&amp;#39;)&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# 2020.04.08 수정된 부분입니다.&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 예제 8.16은 고용량 RAM 모드를 지원하지 않는 무료 버전의 경우 OOM(Out Of Memory) 문제를 일으키기 때문에 주석처리합니다.&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 대신에 예제 8.24와 8.25를 이용해서 ImageDataGenerator로 학습을 시킵니다.&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# 8.24 ImageDataGenerator가 처리할 수 있는 하위 디렉토리 구조로 데이터 복사&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; shutil

os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mkdir(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/train_sub&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(len(label_text)):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exists(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/train_sub/&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; label_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[i][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;breed&amp;#39;&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; False:
        os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mkdir(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/train_sub/&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; label_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[i][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;breed&amp;#39;&lt;/span&gt;])
    shutil&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;copy(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/train/&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; label_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[i][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;id&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.jpg&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/train_sub/&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; label_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[i][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;breed&amp;#39;&lt;/span&gt;])

&lt;span style=&#34;color:#75715e&#34;&gt;# 8.25 ImageDataGenerator를 이용한 train/validation 데이터 분리, Image Augmentation&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.python.keras.preprocessing.image &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; ImageDataGenerator
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; keras.applications.inception_resnet_v2 &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; preprocess_input

image_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# 이미지 사이즈가 299에서 224로 바뀌었습니다.&lt;/span&gt;
batch_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;

train_datagen &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ImageDataGenerator(rescale&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;255.&lt;/span&gt;, horizontal_flip&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, shear_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, zoom_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, width_shift_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, height_shift_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;)
valid_datagen &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ImageDataGenerator(rescale&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;255.&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;)

train_generator &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_datagen&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flow_from_directory(directory&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/content/train_sub/&amp;#34;&lt;/span&gt;, subset&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;training&amp;#34;&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;batch_size, seed&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;42&lt;/span&gt;, shuffle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, class_mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;categorical&amp;#34;&lt;/span&gt;, target_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(image_size, image_size))
valid_generator &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; valid_datagen&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flow_from_directory(directory&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/content/train_sub/&amp;#34;&lt;/span&gt;, subset&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;validation&amp;#34;&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, seed&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;42&lt;/span&gt;, shuffle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, class_mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;categorical&amp;#34;&lt;/span&gt;, target_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(image_size, image_size))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Using TensorFlow backend.


Found 7718 images belonging to 120 classes.
Found 2504 images belonging to 120 classes.
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;6-라벨-데이터-작성&#34;&gt;(6) 라벨 데이터 작성&lt;/h3&gt;
&lt;p&gt;이제 Y에 해당하는 라벨 데이터를 작성합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;unique_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; label_text[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;breed&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unique()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tolist()
train_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [unique_Y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;index(breed) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; breed &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; label_text[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;breed&amp;#39;&lt;/span&gt;]]
train_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(train_Y)

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_Y[:&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;])
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_Y[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;:])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[0 1 2 3 4 5 5 6 7 8]
[34 87 91 63 48  6 93 63 77 92]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;여기서 라벨 데이터는 &lt;code&gt;boston_bull&lt;/code&gt;, &lt;code&gt;dingo&lt;/code&gt;와 같은 텍스트로 되어 있기 때문에 먼저 숫자로 바꾸는 과정이 필요합니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;unique()&lt;/code&gt; 함수를 사용해 &lt;code&gt;label_text[&#39;breed&#39;]&lt;/code&gt;를 구성하는 겹치지 않는 유일한 원소들을 구합니다. 그리고 &lt;code&gt;tolist()&lt;/code&gt; 활용해 array에서 리스트로 변환합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;train_Y의 처음 값 10개와 마지막 값 10개를 확인합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;7-가중치-초기화-시킨-학습-모델-정의&#34;&gt;(7) 가중치 초기화 시킨 학습 모델 정의&lt;/h3&gt;
&lt;p&gt;이제 전이 학습 모델을 정의합니다. 이때 &lt;code&gt;loss&lt;/code&gt; &lt;code&gt;categorical_crossentropy&lt;/code&gt;로 바꿔주시기를 바랍니다. (교재와 다릅니다!)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mobilev2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;output
predictions &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;120&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;)(x)
model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Model(inputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;mobilev2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;input, outputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;predictions)

&lt;span style=&#34;color:#75715e&#34;&gt;# model.compile(optimizer=&amp;#39;sgd&amp;#39;, loss=&amp;#39;sparse_categorical_crossentropy&amp;#39;, metrics=[&amp;#39;accuracy&amp;#39;])&lt;/span&gt;
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sgd&amp;#39;&lt;/span&gt;, loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;categorical_crossentropy&amp;#39;&lt;/span&gt;, metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;]) &lt;span style=&#34;color:#75715e&#34;&gt;# 라벨이 원-핫 인코딩을 사용하기 때문에 sparse가 아닌 categorical_crossentropy를 사용합니다.&lt;/span&gt;
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;model&amp;quot;
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
.
.
.
global_average_pooling2d (Globa (None, 1280)         0           out_relu[0][0]                   
__________________________________________________________________________________________________
dense (Dense)                   (None, 120)          153720      global_average_pooling2d[0][0]   
==================================================================================================
Total params: 2,411,704
Trainable params: 2,377,592
Non-trainable params: 34,112
__________________________________________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;첫 번째 줄에서는 &lt;code&gt;MobileNet V2&lt;/code&gt;에서 마지막 &lt;code&gt;Dense&lt;/code&gt;레이어를 제외하기 위해 두 번째 레이어를 지정해서 그 레이어의 &lt;code&gt;output&lt;/code&gt;을 x라는 변수에 저장합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;그리고, 120개의 뉴런을 가진 &lt;code&gt;Dense&lt;/code&gt;레이어를 새롭게 만듭니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;predictions &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;120&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;)(x)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;보통 모델을 정의할 때, 지금까지는 &lt;code&gt;tf.keras.Sequential&lt;/code&gt; 모델만 사용했습니다. 그리고, 각 레이어는 모형의 안에 존재 했는데, 이번에는 조금 다릅니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;레이어를 함수처럼 사용하는 구문을 함수형(&lt;code&gt;Functional&lt;/code&gt;) API라고 합니다.&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; 자세한 설명은 교재 또는 공식 문서를 참조하시기를 바랍니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;8-정의된-모형-학습-가중치-초기화&#34;&gt;(8) 정의된 모형 학습 (가중치 초기화)&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;model.fit&lt;/code&gt;을 활용해서 학습을 진행합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# history = model.fit(train_X, train_Y, epochs=10, validation_split=0.25, batch_size=32)&lt;/span&gt;
steps_per_epoch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(&lt;span style=&#34;color:#ae81ff&#34;&gt;7718&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;) &lt;span style=&#34;color:#75715e&#34;&gt;# generator를 사용하기 때문에 1epoch 당 학습할 step수를 정합니다. batch_size인 32로 train_data의 크기를 나눠주면 됩니다.&lt;/span&gt;
history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit_generator(train_generator, validation_data&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;valid_generator, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, steps_per_epoch&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;steps_per_epoch) &lt;span style=&#34;color:#75715e&#34;&gt;# model.fit_generator()를 사용합니다.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  [&#39;...&#39;]
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  [&#39;...&#39;]
Train for 241 steps, validate for 2504 steps
Epoch 1/10
241/241 [==============================] - 124s 516ms/step - loss: 4.8789 - accuracy: 0.0101 - val_loss: 9.5161 - val_accuracy: 0.0096
Epoch 2/10
241/241 [==============================] - 124s 514ms/step - loss: 4.8576 - accuracy: 0.0100 - val_loss: 8.6696 - val_accuracy: 0.0104
Epoch 3/10
241/241 [==============================] - 124s 516ms/step - loss: 4.8677 - accuracy: 0.0107 - val_loss: 9.1874 - val_accuracy: 0.0096
Epoch 4/10
241/241 [==============================] - 124s 513ms/step - loss: 4.8604 - accuracy: 0.0108 - val_loss: 8.2864 - val_accuracy: 0.0088
Epoch 5/10
241/241 [==============================] - 124s 513ms/step - loss: 4.8434 - accuracy: 0.0101 - val_loss: 8.3031 - val_accuracy: 0.0080
Epoch 6/10
241/241 [==============================] - 124s 514ms/step - loss: 4.8401 - accuracy: 0.0133 - val_loss: 7.9722 - val_accuracy: 0.0064
Epoch 7/10
241/241 [==============================] - 124s 514ms/step - loss: 4.8345 - accuracy: 0.0130 - val_loss: 7.2442 - val_accuracy: 0.0080
Epoch 8/10
241/241 [==============================] - 124s 516ms/step - loss: 4.8256 - accuracy: 0.0129 - val_loss: 6.9645 - val_accuracy: 0.0120
Epoch 9/10
241/241 [==============================] - 125s 518ms/step - loss: 4.8099 - accuracy: 0.0139 - val_loss: 7.0742 - val_accuracy: 0.0076
Epoch 10/10
241/241 [==============================] - 125s 517ms/step - loss: 4.8077 - accuracy: 0.0147 - val_loss: 6.5409 - val_accuracy: 0.0080
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;9-모형-결과-학습-시각화&#34;&gt;(9) 모형 결과 학습 시각화&lt;/h3&gt;
&lt;p&gt;모형 학습에 대한 결과를 시각화 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;k--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylim(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_02/output_44_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;모형의 학습 결과는 일단, 결론적으로 학습이 잘 되고 있다고 말하기는 어렵습니다.&lt;/p&gt;
&lt;p&gt;다시 위 모형은 사전에 학습된 모형의 가중치를 제거한 모형을 학습 시킨 결과물입니다. 개념을 돕고자 이렇게 학습시키는 것이고, &lt;code&gt;실무에서는 이렇게 할 이유가 없습니다!&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&#34;10-전이-학습-모형-정의&#34;&gt;(10) 전이 학습 모형 정의&lt;/h3&gt;
&lt;p&gt;이번에는 전이 학습을 시도합니다. 일부 레이어의 가중치를 고정시킨 상태로 학습시킵니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras.applications &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; MobileNetV2
mobilev2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; MobileNetV2()

x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mobilev2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;output
predictions &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;120&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;)(x)
model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Model(inputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;mobilev2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;input, outputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;predictions)

&lt;span style=&#34;color:#75715e&#34;&gt;# 뒤에서 20개까지의 레이어는 훈련 가능, 나머지는 가중치 고정&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; layer &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers[:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;]:
    layer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trainable &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; False
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; layer &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;:]:
    layer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trainable &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; True

&lt;span style=&#34;color:#75715e&#34;&gt;# model.compile(optimizer=&amp;#39;sgd&amp;#39;, loss=&amp;#39;sparse_categorical_crossentropy&amp;#39;, metrics=[&amp;#39;accuracy&amp;#39;])&lt;/span&gt;
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sgd&amp;#39;&lt;/span&gt;, loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;categorical_crossentropy&amp;#39;&lt;/span&gt;, metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;]) &lt;span style=&#34;color:#75715e&#34;&gt;# 라벨이 원-핫 인코딩을 사용하기 때문에 sparse가 아닌 categorical_crossentropy를 사용합니다.&lt;/span&gt;
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;model_4&amp;quot;
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
.
.
__________________________________________________________________________________________________
global_average_pooling2d_4 (Glo (None, 1280)         0           out_relu[0][0]                   
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 120)          153720      global_average_pooling2d_4[0][0] 
==================================================================================================
Total params: 2,411,704
Trainable params: 1,204,280
Non-trainable params: 1,207,424
__________________________________________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;함수형 &lt;code&gt;API&lt;/code&gt;를 이용해 모델을 정의하는 과정은 그전과 비슷합니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;model.summary()&lt;/code&gt;의 출력 결과에서 훈련 가능한 가중치의 수와 고정된 값의 가중치가 반반 정도로 비슷해진 것을 확인할 수 있다.&lt;/li&gt;
&lt;li&gt;뒤에서 20개까지의 레이어를 훈련 가능하게 하고, 나머지 레이어의 가중치는 고정시키는 작업을 합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;11-모형-학습-전이-학습-및-결과-시각화&#34;&gt;(11) 모형 학습 (전이 학습) 및 결과 시각화&lt;/h3&gt;
&lt;p&gt;이제 학습을 시키고, 시각화를 진행합니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;모형 학습입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;steps_per_epoch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(&lt;span style=&#34;color:#ae81ff&#34;&gt;7718&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;) &lt;span style=&#34;color:#75715e&#34;&gt;# generator를 사용하기 때문에 1epoch 당 학습할 step수를 정합니다. batch_size인 32로 train_data의 크기를 나눠주면 됩니다.&lt;/span&gt;
history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit_generator(train_generator, validation_data&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;valid_generator, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, steps_per_epoch&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;steps_per_epoch) &lt;span style=&#34;color:#75715e&#34;&gt;# model.fit_generator()를 사용합니다.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  [&#39;...&#39;]
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  [&#39;...&#39;]
Train for 241 steps, validate for 2504 steps
Epoch 1/10
241/241 [==============================] - 170s 703ms/step - loss: 3.4284 - accuracy: 0.2918 - val_loss: 1.9956 - val_accuracy: 0.4772
Epoch 2/10
241/241 [==============================] - 167s 695ms/step - loss: 1.6856 - accuracy: 0.6227 - val_loss: 1.4928 - val_accuracy: 0.5843
Epoch 3/10
241/241 [==============================] - 166s 690ms/step - loss: 1.2359 - accuracy: 0.7022 - val_loss: 1.3797 - val_accuracy: 0.6082
Epoch 4/10
241/241 [==============================] - 166s 688ms/step - loss: 1.0110 - accuracy: 0.7482 - val_loss: 1.2314 - val_accuracy: 0.6522
Epoch 5/10
241/241 [==============================] - 166s 690ms/step - loss: 0.8846 - accuracy: 0.7791 - val_loss: 1.1955 - val_accuracy: 0.6526
Epoch 6/10
241/241 [==============================] - 166s 689ms/step - loss: 0.7828 - accuracy: 0.8078 - val_loss: 1.1607 - val_accuracy: 0.6697
Epoch 7/10
241/241 [==============================] - 166s 690ms/step - loss: 0.7045 - accuracy: 0.8246 - val_loss: 1.1379 - val_accuracy: 0.6733
Epoch 8/10
241/241 [==============================] - 166s 690ms/step - loss: 0.6532 - accuracy: 0.8380 - val_loss: 1.1241 - val_accuracy: 0.6865
Epoch 9/10
241/241 [==============================] - 166s 689ms/step - loss: 0.5957 - accuracy: 0.8557 - val_loss: 1.1469 - val_accuracy: 0.6737
Epoch 10/10
241/241 [==============================] - 166s 690ms/step - loss: 0.5488 - accuracy: 0.8631 - val_loss: 1.1132 - val_accuracy: 0.6809
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;이번엔 시각화입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;k--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylim(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_02/output_53_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;같은 네트워크 구조를 사용했지만, &lt;code&gt;val_accuray&lt;/code&gt;는 &lt;code&gt;1%&lt;/code&gt; 정도에 머물던 가중치 초기화 학습 모델에 비해 전혀 다른 결과(&lt;code&gt;86.3%&lt;/code&gt;)가 나온 것을 확인할 수 있습니다. &lt;code&gt;val_loss&lt;/code&gt;는 감소하는 추세이고, &lt;code&gt;val_accuracy&lt;/code&gt;는 증가 추세여서 학습을 추가적으로 해도 네트워크의 성능이 보다 향상 될 것 같습니다. (다만, 시간은 많이 소요 됩니다!)&lt;/p&gt;
&lt;h2 id=&#34;iii-특징-추출기&#34;&gt;III. 특징 추출기&lt;/h2&gt;
&lt;p&gt;미리 훈련된 모델에서 데이터의 특징만 추출하고, 그 특징을 작은 네트워크에 통과시켜서 정답을 예측하는 방법도 있습니다. 자세한 설명은 교재 (p. 270)을 참조하시기를 바랍니다.&lt;/p&gt;
&lt;h3 id=&#34;1-특징-추출기-불러오기&#34;&gt;(1) 특징 추출기 불러오기&lt;/h3&gt;
&lt;p&gt;텐서플로 허브에서 &lt;code&gt;Inception V3&lt;/code&gt;를 불러옵니다. &lt;code&gt;Inception&lt;/code&gt;은 2014년에 구글이 &lt;code&gt;ImageNet&lt;/code&gt; 대회를 위해 &lt;code&gt;GoogleNet&lt;/code&gt;이라는 이름으로 발표한 컨볼루션 신경망입니다. V3는 세 번째로 개선된 버전입니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow_hub &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; hub

inception_url &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4&amp;#39;&lt;/span&gt;
feature_model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
    hub&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;KerasLayer(inception_url, output_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2048&lt;/span&gt;,), trainable&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)
])
feature_model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;build([None, &lt;span style=&#34;color:#ae81ff&#34;&gt;299&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;299&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;])
feature_model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
keras_layer (KerasLayer)     multiple                  21802784  
=================================================================
Total params: 21,802,784
Trainable params: 0
Non-trainable params: 21,802,784
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;feature_model.build([None, 299, 299, 3])&lt;/code&gt; 함수는 입력 데이터의 차원을 정의해서 넣습니다. 첫번째 차원은 배치 차원이기 때문에 입력이 몇개가 들어와도 상관없습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-imagedatagenerator-파일-복사&#34;&gt;(2) ImageDataGenerator 파일 복사&lt;/h3&gt;
&lt;p&gt;ImageDataGenerator는 라벨이 있는 데이터를 처리할 때 각 라벨의 이름을 하위 디렉터리로 가지고 있는 디렉토리를 받아서 그 데이터를 처리합니다. 반면에 캐글에서 내려받은 데이터들은 하위 디렉터리의 구분 없이 &lt;code&gt;train&lt;/code&gt;폴더에 모든 이미지 파일이 저장되어 있습니다. 따라서 ImageDataGenerator가 처리할 수 있는 방식으로 데이터를 복사합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; shutil

os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mkdir(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/train_sub&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(len(label_text)):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exists(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/train_sub/&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; label_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[i][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;breed&amp;#39;&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; False:
        os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mkdir(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/train_sub/&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; label_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[i][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;breed&amp;#39;&lt;/span&gt;])
    shutil&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;copy(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/train/&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; label_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[i][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;id&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.jpg&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/train_sub/&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; label_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[i][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;breed&amp;#39;&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;3-훈련-및-검증-데이터-분리-그리고-이미지-보강&#34;&gt;(3) 훈련 및 검증 데이터 분리, 그리고 이미지 보강&lt;/h3&gt;
&lt;p&gt;먼저 훈련 및 검증 데이터로 분리하는 소스코드를 작성합니다.
_datagen 함수 안에 있는 인수에 대한 설명은 교재 274페이지를 참고합나디.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.python.keras.preprocessing.image &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; ImageDataGenerator
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; keras.applications.inception_resnet_v2 &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; preprocess_input

image_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;299&lt;/span&gt;
batch_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;

train_datagen &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ImageDataGenerator(rescale&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;255.&lt;/span&gt;, horizontal_flip&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, shear_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, zoom_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, width_shift_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, height_shift_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;)
valid_datagen &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ImageDataGenerator(rescale&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;255.&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;)

train_generator &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_datagen&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flow_from_directory(directory&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/content/train_sub/&amp;#34;&lt;/span&gt;, subset&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;training&amp;#34;&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;batch_size, seed&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;42&lt;/span&gt;, shuffle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, class_mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;categorical&amp;#34;&lt;/span&gt;, target_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(image_size, image_size))
valid_generator &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; valid_datagen&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flow_from_directory(directory&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/content/train_sub/&amp;#34;&lt;/span&gt;, subset&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;validation&amp;#34;&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, seed&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;42&lt;/span&gt;, shuffle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, class_mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;categorical&amp;#34;&lt;/span&gt;, target_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(image_size, image_size))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Found 7718 images belonging to 120 classes.
Found 2504 images belonging to 120 classes.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;이번에는 훈련 데이터를 특징 벡터로 변환합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;batch_step &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;7718&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt; batch_size
train_features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
train_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; idx &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(batch_step):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; idx &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(idx)
    x, y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_generator&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next()
    train_Y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;extend(y)
    
    feature &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; feature_model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(x)
    train_features&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;extend(feature)

train_features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(train_features)
train_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(train_Y)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_features&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_Y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;0
100
200
300
400
500
600
700
(23084, 2048)
(23084, 120)
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;첫번째 코드가 조금 중요한데, &lt;code&gt;batch_step&lt;/code&gt;은 부족한 RAM에 비해 훈련시 필요한 메모리 부족을 해소하기 위해 단계별로 진행핟나는 뜻입니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;batch_size로 나눠서 &lt;code&gt;training&lt;/code&gt; 부분 집합을 3번 정도 반복해서 특징 벡터를 뽑아냅니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;next()&lt;/code&gt; 함수를 사용하면 다음에 올 값을 반환받을 수 있습니다. 훈련 데이터는 이미지의 분류에 해당하는 &lt;code&gt;y&lt;/code&gt;값이 있기 때문에 식의 좌변에서 &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt;를 함께 받습ㄴ다. &lt;code&gt;y&lt;/code&gt;값은 바로 &lt;code&gt;train_Y&lt;/code&gt;에 저장해서 추후 활용하게 됩니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;x&lt;/code&gt;값은 이미지 데이터에 해당하는 부분입니다. 이미 학습이 완료된 특징 추출기를 사용하기 때문에 &lt;code&gt;predict()&lt;/code&gt;로 특징 벡터를 추출합니다. 특징 벡터는 &lt;code&gt;feature&lt;/code&gt;라는 변수에 저장한 뒤 추후에 사용할 수 있도록 &lt;code&gt;train_features&lt;/code&gt;에 저장합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;최종 출력되는 &lt;code&gt;Shape&lt;/code&gt;는 train_feature가 (23084, 2048)이고, train_Y가 (23084, 120)입니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;즉, 특징 벡터는 2,048차원의 벡터임을 확인할 수 있습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;마찬가지로 검증 데이터에도 적용하도록 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;valid_features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
valid_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; idx &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(valid_generator&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;n):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; idx &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(idx)
    x, y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; valid_generator&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next()
    valid_Y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;extend(y)
    
    feature &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; feature_model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(x)
    valid_features&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;extend(feature)

valid_features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(valid_features)
valid_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(valid_Y)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(valid_features&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(valid_Y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
(2504, 2048)
(2504, 120)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;4-작은-시퀀셜-모델-정의&#34;&gt;(4) 작은 시퀀셜 모델 정의&lt;/h3&gt;
&lt;p&gt;이제 분류 모형을 위한 &lt;code&gt;Sequential&lt;/code&gt; 모형을 정의합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2048&lt;/span&gt;,)),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;120&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;)
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;RMSprop(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.0001&lt;/span&gt;), loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;categorical_crossentropy&amp;#39;&lt;/span&gt;, metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential_1&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_5 (Dense)              (None, 256)               524544    
_________________________________________________________________
dropout (Dropout)            (None, 256)               0         
_________________________________________________________________
dense_6 (Dense)              (None, 120)               30840     
=================================================================
Total params: 555,384
Trainable params: 555,384
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;input_shape=(2048,)&lt;/code&gt;을 지정해서 특징 벡터를 받을 수 있도록 합니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Dense&lt;/code&gt; 레이어는 분류를 위해 &lt;code&gt;softmax&lt;/code&gt; 활성화 함수를 지정하고 뉴런의 수는 견종의 수와 같은 &lt;code&gt;120&lt;/code&gt;으로 지정합니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;categorical_crossentropy&lt;/code&gt;가 사용된 이유는 &lt;code&gt;train_Y&lt;/code&gt;의 마지막 차원이 1이 아닌 원-핫 벡터인 120이기 때문입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;정답의 인덱스만 기록된 희소 행렬(sparse matrix)을 Y로 사용할 때는 &lt;code&gt;sparse_categorical_crossentropy&lt;/code&gt;를 사용하고, &lt;code&gt;one-hot&lt;/code&gt; 벡터를 사용할 때는 &lt;code&gt;sparse&lt;/code&gt;가 없는 버전을 사용합니다.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;5-모형-학습-및-시각화&#34;&gt;(5) 모형 학습 및 시각화&lt;/h3&gt;
&lt;p&gt;모형을 학습시키고 시각화로 확인합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_features, train_Y, validation_data&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(valid_features, valid_Y), epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;)

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;k--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylim(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Train on 23084 samples, validate on 2504 samples
Epoch 1/10
23084/23084 [==============================] - 3s 123us/sample - loss: 2.8557 - accuracy: 0.4517 - val_loss: 0.9163 - val_accuracy: 0.8550
Epoch 2/10
23084/23084 [==============================] - 2s 105us/sample - loss: 0.9270 - accuracy: 0.7808 - val_loss: 0.4353 - val_accuracy: 0.8890
Epoch 3/10
23084/23084 [==============================] - 2s 105us/sample - loss: 0.6147 - accuracy: 0.8295 - val_loss: 0.3560 - val_accuracy: 0.8946
Epoch 4/10
23084/23084 [==============================] - 2s 105us/sample - loss: 0.5079 - accuracy: 0.8518 - val_loss: 0.3306 - val_accuracy: 0.8950
Epoch 5/10
23084/23084 [==============================] - 2s 104us/sample - loss: 0.4466 - accuracy: 0.8628 - val_loss: 0.3208 - val_accuracy: 0.8978
Epoch 6/10
23084/23084 [==============================] - 2s 105us/sample - loss: 0.4064 - accuracy: 0.8734 - val_loss: 0.3197 - val_accuracy: 0.8962
Epoch 7/10
23084/23084 [==============================] - 2s 105us/sample - loss: 0.3707 - accuracy: 0.8845 - val_loss: 0.3099 - val_accuracy: 0.9014
Epoch 8/10
23084/23084 [==============================] - 2s 105us/sample - loss: 0.3445 - accuracy: 0.8907 - val_loss: 0.3067 - val_accuracy: 0.9006
Epoch 9/10
23084/23084 [==============================] - 2s 106us/sample - loss: 0.3172 - accuracy: 0.9001 - val_loss: 0.3080 - val_accuracy: 0.8974
Epoch 10/10
23084/23084 [==============================] - 2s 106us/sample - loss: 0.2999 - accuracy: 0.9042 - val_loss: 0.3048 - val_accuracy: 0.8994
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_02/output_71_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;각 에포크당 3초가 걸릴 정도로 학습 속도가 매우 빨라진 것을 확인했습니다.&lt;/p&gt;
&lt;h3 id=&#34;6-학습-모형-테스트&#34;&gt;(6) 학습 모형 테스트&lt;/h3&gt;
&lt;p&gt;모델이 예측을 얼마나 잘하는지 알아보기 위해 검증 데이터의 이미지에 대한 분류를 시각화합니다.&lt;/p&gt;
&lt;p&gt;그 전에 먼저 라벨의 이름을 따로 저장하는데, &lt;code&gt;ImageDataGenerator&lt;/code&gt;에서 라벨을 인덱스로 저장할 때 알파벳 순으로 정렬된 순서로 저장하기 때문에 여기서도 마찬가지로 저장합니다.&lt;/p&gt;
&lt;p&gt;그리고 알파벳순 1~5까지를 순서대로 출력해서 확인합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;unique_sorted_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sorted(unique_Y)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(unique_sorted_Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[&#39;affenpinscher&#39;, &#39;afghan_hound&#39;, &#39;african_hunting_dog&#39;, &#39;airedale&#39;, &#39;american_staffordshire_terrier&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;이제 검증 데이터를 시각화합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; cv2
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; random
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;))
  
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;):
    image_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;choice(valid_generator&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;filepaths)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# 이미지 표시&lt;/span&gt;
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(image_path))
    real_y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; image_path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;]
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(real_y)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)
    idx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; unique_sorted_Y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;index(real_y)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# 예측값 표시&lt;/span&gt;
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(image_path)
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(img, dsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;299&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;299&lt;/span&gt;))
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; img &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(img, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# Inception V3를 이용한 특징 벡터 추출&lt;/span&gt;
    feature_vector &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; feature_model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(img)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# Sequential 모델을 이용한 예측&lt;/span&gt;
    prediction &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(feature_vector)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# 가장 높은 확률의 예측값 5개를 뽑음&lt;/span&gt;
    top_5_predict &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; prediction&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argsort()[::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][:&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;]
    labels &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [unique_sorted_Y[index] &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; index &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; top_5_predict]
    color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; idx &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; top_5_predict:
        color[top_5_predict&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tolist()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;index(idx)] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;green&amp;#39;&lt;/span&gt;
    color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; color[::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;barh(range(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;), prediction[top_5_predict][::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;color)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;yticks(range(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;), labels[::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_02/output_76_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Top-1으로 3개를 다 맞춘것으로 확인됩니다. 그러나 계속 실행하면 중간중간 잘 맞지 않는 부분도 있으나, 상위 5개에는 꼭 있음을 확인할 수 있습니다.&lt;/p&gt;
&lt;h2 id=&#34;iv-submission&#34;&gt;IV. Submission&lt;/h2&gt;
&lt;p&gt;예측 결과를 캐글에 올리도록 하는 소스코드를 구현합니다. 이미지와 관련된 캐글 대회에 나가더라도, 본 소스코드는 잘 숙지하셔서 응용하시기를 바랍니다.&lt;/p&gt;
&lt;h3 id=&#34;1-테스트-데이터-압축-풀기&#34;&gt;(1) 테스트 데이터 압축 풀기&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;!&lt;/span&gt;unzip test&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zip
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.[0m
  inflating: test/82e41a906dbd9ec362a3d49cf6bbe645.jpg  
  .
  .
  .
  inflating: test/fffbff22c1f51e3dc80c4bf04089545b.jpg  
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;2-submission-파일-확인&#34;&gt;(2) submission 파일 확인&lt;/h3&gt;
&lt;p&gt;submission 파일을 확인합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
submission &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sample_submission.csv&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(submission&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head())
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;()
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(submission&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;info())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;                                 id  ...  yorkshire_terrier
0  000621fb3cbb32d8935728e48679680e  ...           0.008333
1  00102ee9d8eb90812350685311fe5890  ...           0.008333
2  0012a730dfa437f5f3613fb75efcd4ce  ...           0.008333
3  001510bc8570bbeee98c8d80c8a95ec1  ...           0.008333
4  001a5f3114548acdefa3d4da05474c2e  ...           0.008333

[5 rows x 121 columns]

&amp;lt;class &#39;pandas.core.frame.DataFrame&#39;&amp;gt;
RangeIndex: 10357 entries, 0 to 10356
Columns: 121 entries, id to yorkshire_terrier
dtypes: float64(120), object(1)
memory usage: 9.6+ MB
None
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;데이터 프레임의 첫열은 label.csv와 같은 id입니다. 나머지 열은 120개의 견종의 이름이 있고, 각 id에 대한 각 견종의 예측 값은 랜덤한 선택을 했을 때의 값 0.008333으로 채워져 있습니다. 이 대로 캐글에 제출해도 &lt;code&gt;Multiclass Logloss&lt;/code&gt;로 산정되며 4.78749의 점수를 얻게 됩니다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_02/kaggle_03.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;3-테스트-데이터-정제&#34;&gt;(3) 테스트 데이터 정제&lt;/h3&gt;
&lt;p&gt;테스트 데이터도 훈련 데이터와 마찬가지로 ImageDataGenerator를 사용하도록 합니다. 이 때 &lt;code&gt;ImageDataGenerator&lt;/code&gt;가 &lt;code&gt;flow_from_directory()&lt;/code&gt; 함수로 이미지를 읽어 들이기 위해 하위 디렉토리가 꼭 필요합니다.&lt;/p&gt;
&lt;p&gt;현재 테스트 데이터는 각 사진이 어떤 범주에 속하는지 알 수 없기 때문에 &lt;code&gt;unknown&lt;/code&gt;이라는 폴더를 만들고 모든 데이터를 이곳에 복사하도록 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 8.34 ImageDataGenerator가 처리할 수 있는 하위 디렉토리 구조로 데이터 복사&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; shutil

os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mkdir(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/test_sub/&amp;#39;&lt;/span&gt;)
os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mkdir(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/test_sub/unknown/&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(len(submission)):
    shutil&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;copy(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/test/&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; submission&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[i][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;id&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.jpg&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/test_sub/unknown/&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;test_sub&lt;/code&gt; 폴더 하위에 &lt;code&gt;unknown&lt;/code&gt;이라는 폴더가 생기고 모든 파일이 이 안에 들어있음을 확인합니다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_02/kaggle_04.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;이제 테스트 데이터를 불러오는 &lt;code&gt;ImageDataGenerator&lt;/code&gt;를 정의합니다. 이미지 보강 등은 진행할 필요가 없기 때문에 보다 간소화됩니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.python.keras.preprocessing.image &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; ImageDataGenerator

test_datagen&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ImageDataGenerator(rescale&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;255.&lt;/span&gt;)
test_generator&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;test_datagen&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flow_from_directory(directory&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/content/test_sub/&amp;#34;&lt;/span&gt;,batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,seed&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;42&lt;/span&gt;,shuffle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False,target_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;299&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;299&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Found 10357 images belonging to 1 classes.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;위와 같이 정상적으로 &lt;code&gt;ImageDataGenerator&lt;/code&gt;가 만들어지면 이를 이용해서 벡터를 추출합니다.&lt;/p&gt;
&lt;h3 id=&#34;4-테스트-데이터의-벡터-변환&#34;&gt;(4) 테스트 데이터의 벡터 변환&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;test_features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; idx &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(test_generator&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;n):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; idx &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(idx)
        
    x, _ &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_generator&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next()
    feature &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; feature_model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(x)
    test_features&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;extend(feature)

test_features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(test_features)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(test_features&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;0
100
200
.
.
.
10100
10200
10300
(10357, 2048)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;각 이미지 데이터는 120의 길이를 가진 벡터로 변환이 되었습니다. 이렇게 생성된 벡터로 데스트 데이터의 정답을 예측합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;test_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(test_features, verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;10357/10357 [==============================] - 0s 41us/sample
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;model.predict()&lt;/code&gt; 함수는 &lt;code&gt;verbose&lt;/code&gt; 인수의 값이 0으로 설정되어 있기 때문에 진행 과정을 보기 위해서는 &lt;code&gt;verbose=1&lt;/code&gt;로 지정해야 합니다.&lt;/p&gt;
&lt;h3 id=&#34;5-테스트-데이터-분류-라벨-확인&#34;&gt;(5) 테스트 데이터 분류 라벨 확인&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; random
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; cv2
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;))
  
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;):
    image_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;choice(test_generator&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;filepaths)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# 이미지 표시&lt;/span&gt;
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(image_path))
    real_y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; image_path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;]
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(real_y)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# 예측값 표시&lt;/span&gt;
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(image_path)
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(img, dsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;299&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;299&lt;/span&gt;))
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; img &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(img, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# Inception V3를 이용한 특징 벡터 추출&lt;/span&gt;
    feature_vector &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; feature_model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(img)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# Sequential 모델을 이용한 예측&lt;/span&gt;
    prediction &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(feature_vector)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# 가장 높은 확률의 예측값 5개를 뽑음&lt;/span&gt;
    top_5_predict &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; prediction&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argsort()[::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][:&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;]
    labels &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [unique_sorted_Y[index] &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; index &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; top_5_predict]
    color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;barh(range(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;), prediction[top_5_predict][::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;color)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;yticks(range(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;), labels[::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_02/output_95_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;저난적으로 모형은 꽤 학신을 가지고 테스트 데이터에 대해 답을 예측하고 있습니다.&lt;/p&gt;
&lt;h3 id=&#34;6-submission-준비-및-파일-내보내기&#34;&gt;(6) Submission 준비 및 파일 내보내기&lt;/h3&gt;
&lt;p&gt;submission의 준비작업은 아래와 같이 코드를 작성하고 실제로 예측값이 잘 저장됐는지 확인하기 위해 데이터의 일부를 출력합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(len(test_Y)):
  &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;letter I &amp;#39;re on time &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%d&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; (i))
  &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(len(test_Y[i])):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;letter J&amp;#39;re on time &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%d&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; (j))
    breed_column &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; unique_sorted_Y[j]
    submission&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[i, breed_column] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_Y[i, j]

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(submission&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;iloc[:&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, :&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.[0m
We&#39;re on time 0
We&#39;re on time 1
.
.
.
We&#39;re on time 10317
We&#39;re on time 0
We&#39;re on time 1
.
.
                                 id  ...      airedale
0  000621fb3cbb32d8935728e48679680e  ...  6.192151e-07
1  00102ee9d8eb90812350685311fe5890  ...  2.064632e-07
2  0012a730dfa437f5f3613fb75efcd4ce  ...  3.297540e-06
3  001510bc8570bbeee98c8d80c8a95ec1  ...  1.829849e-07
4  001a5f3114548acdefa3d4da05474c2e  ...  6.606462e-07

[5 rows x 5 columns]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Submission 파일을 만드는데 생각보다 많은 시간이 소요됩니다. 인내심을 가지고 조금 기다리셔야 합니다. (약 28MB 용량의 파일)&lt;/p&gt;
&lt;p&gt;이제 csv파일로 저장합니다. 버전 관리를 할 수 있는 이름으로 파일을 저장 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;submission&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dogbreed_submission_inceptionV3_epoch10_299_20200429.csv&amp;#39;&lt;/span&gt;, index&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;위 코드를 실행하면 왼쪽 파일, 가상 환경에 저장되기 때문에 꼭 확인해서 다운로드 받기를 바랍니다. Colab에서는 연결이 끊기면 파일이 사라집니다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_02/kaggle_05.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;7-파일-업로드-및-점수-확인&#34;&gt;(7) 파일 업로드 및 점수 확인&lt;/h3&gt;
&lt;p&gt;submission 파일 싸이트로 돌아가서 다운로드 받은 파일을 업로드 하고 결과를 확인합니다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Score&lt;/code&gt;가 아래 그림에서 확인하는 것처럼 &lt;code&gt;0.32208&lt;/code&gt;인 것을 확인할 수 있습니다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_02/kaggle_06.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;참고로 위 대회는 2년전에 이미 마감되었기 때문에, 랭킹에 반영되지 않습니다. 그러나, 아래 그림을 통해서 현재 만든 모형의 결과가 어느정도 순위인지 확인은 할 수 있습니다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_02/kaggle_07.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;대략적으로 510위 정도에 해당하는 모형이라고 할 수 있습니다. 이 순위는 상위 약 40%에 해당한다고 할 수 있습니다.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;사실 이제 시작입니다. 모형을 반복해서 만들어서 성능을 끌어 올리는 것은 모든 머신러닝/딥러닝 개발자의 숙명이자 과제입니다.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;iii-연습-파일&#34;&gt;III. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch8_2_transfer_learning.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;vi-reference&#34;&gt;VI. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
&lt;p&gt;Karpathy, A. (2015). The Unreasonable Effectiveness of Recurrent Neural Networks. Retrieved April 26, 2020, from &lt;a href=&#34;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&#34;&gt;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&lt;/a&gt;&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;2020년 4월 8일에 &lt;a href=&#34;https://github.com/wikibook/tf2/blob/master/Chapter8_20200408%EC%88%98%EC%A0%95.ipynb&#34;&gt;수정본&lt;/a&gt;이 있습니다. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;텐서플로 홈페이지 &lt;a href=&#34;https://www.tensorflow.org/guide/keras/overview?hl=ko#%ED%95%A8%EC%88%98%ED%98%95_api&#34;&gt;함수형 API&lt;/a&gt;에 관한 문서를 살펴보시기를 바랍니다. &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch8.1 - 텐서플로 허브</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch8_1_tensorflow_hub/</link>
      <pubDate>Tue, 28 Apr 2020 17:20:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch8_1_tensorflow_hub/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.2 - 다항분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/&#34;&gt;Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/&#34;&gt;Tensorflow 2.0 Tutorial ch6.1-2 - CNN 이론&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_3_fashion_mnist_with_cnn/&#34;&gt;Tensorflow 2.0 Tutorial ch6.3 - Fashion MNIST with CNN 실습&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_4_improve_performance/&#34;&gt;Tensorflow 2.0 Tutorial ch6.4 - 모형의 성능 높이기&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (1)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (2)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_3_sentimentanalysis/&#34;&gt;Tensorflow 2.0 Tutorial ch7.3 - 긍정, 부정 감성 분석&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (1) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (2) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요&#34;&gt;I. 개요&lt;/h2&gt;
&lt;p&gt;딥러닝은 일반적인 개발과 다르게 사실 시간과의 싸움입니다. 코딩의 양에 비해, 결과물이 바로 나오지 않기 때문에 저녁에 모형을 돌리고 아침에 와서 확인하는 경우가 예사입니다.&lt;/p&gt;
&lt;p&gt;특히, 딥러닝의 경우, 기본적으로 좋은 성능을 보이려면 네트워크는 수십 및 또는 수백개의 레이어를 쌓은 경우가 대부분이고, 당연히 늘어난 레이어의 수만큼 네트워크를 훈련시키는 데 필요한 훈련 시간도 증가하게 됩니다.&lt;/p&gt;
&lt;p&gt;다행히, 딥러닝은 아직까지는 범용적으로 사용하는 상용단계라기보다는 연구, 실험, 그리고 이제서야 적용 단계에 있는 기술이기 때문에, 다른 IT기술보다는 개방적인 연구 환경을 갖추고 있습니다.&lt;/p&gt;
&lt;p&gt;이렇게 연구자들이 자신이 만든 사전 훈련된 모델(&lt;code&gt;pre-trained model&lt;/code&gt;)을 인터넷에 올려놓아 다른 사람들이 쉽게 내려받을 수 있도록 합니다.&lt;/p&gt;
&lt;p&gt;이렇게 내려받은 모델을 그대로 사용할 수도 있고, 전이 학습(&lt;code&gt;Transfer Learning&lt;/code&gt;)이나 신경 스타일 전이(&lt;code&gt;Neural Style Transfer&lt;/code&gt;)처럼 다른 과제를 위해 재가공해서 사용합니다.&lt;/p&gt;
&lt;h2 id=&#34;ii-텐서플로-허브-소개&#34;&gt;II. 텐서플로 허브 소개&lt;/h2&gt;
&lt;p&gt;텐서플로에서 제공하는 텐서플로 허브는 재사용 가능한 모델을 쉽게 이용할 수 있도록 하는 라이브러리입니다.&lt;/p&gt;
&lt;p&gt;텐서플로허브 홈페이지에서 확인해봅니다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_01/tensorflow_hub.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;텐서플로 허브에서 사전 훈련된 &lt;code&gt;MobileNet&lt;/code&gt; 모델을 불러와서 학습하는 것을 시도합니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;참고로, 텐서플로 2.0을 사용하시는 분들은 굳이 별도로 텐서플로 허브를 설치할 필요가 없지만, 1.x 버전을 사용하신다면 별도로 아래와 같이 설치하시기를 바랍니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-terminal&#34; data-lang=&#34;terminal&#34;&gt;!pip install tensorflow-hub
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;1-mobilenet-불러오기&#34;&gt;(1) MobileNet 불러오기&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;MobileNet&lt;/code&gt;은 계산 부담이 큰 컨볼루션 신경망을 연산 성능이 제한된 모바일 환경에서도 작동 가능하도록 네트워크 구조를 경량화한 것입니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 텐서플로 2 버전 선택&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
    &lt;span style=&#34;color:#75715e&#34;&gt;# %tensorflow_version only exists in Colab.&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;tensorflow_version &lt;span style=&#34;color:#ae81ff&#34;&gt;2.&lt;/span&gt;x
&lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Exception&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;pass&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow_hub &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; hub
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;mobile_net_url &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4&amp;#39;&lt;/span&gt;
model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
  hub&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;KerasLayer(handle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;mobile_net_url, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), trainable&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)
])
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
keras_layer (KerasLayer)     (None, 1001)              3540265   
=================================================================
Total params: 3,540,265
Trainable params: 0
Non-trainable params: 3,540,265
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;MobileNet&lt;/code&gt;은 &lt;code&gt;ImageNet&lt;/code&gt;에 존재하는 1,000 종류의 이미지를 분류할 수 있으며, 이 가운데 어떤 것에도 속하지 않는다고 판단될 때는 &lt;code&gt;background&lt;/code&gt;에 해당하는 인덱스 0을 반환합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras.applications &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; MobileNetV2

mobilev2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; MobileNetV2()
tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot_model(mobilev2)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_01/output_8_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;MobileNetV2&lt;/code&gt;의 구조는 이와 같이 도식화 되어 있습니다. 도식화에 대한 구체적인 설명은 교재 243페이를 확인하시기를 바랍니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;MobileNet&lt;/code&gt;의 성능을 평가하기 위해 이미지를 학습시켰을 때 얼마나 적합한 라벨로 분류하는지 알아봅니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-imagenet-불러오기&#34;&gt;(2) ImageNet 불러오기&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;ImageNet&lt;/code&gt;의 데이터 중 일부만 모아놓은 &lt;code&gt;ImageNetV2&lt;/code&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;를 사용합니다. &lt;code&gt;ImageNetV2&lt;/code&gt;는 &lt;a href=&#34;https://www.mturk.com/&#34;&gt;아마존 메커니컬 터크&lt;/a&gt;&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;를 이용해 다수의 참가자에게서 클래스 예측값을 받아서 선별한 데이터입니다.&lt;/p&gt;
&lt;p&gt;여기서는 각 클래스에서 가장 많은 선택을 받은 이미지 10장씩을 모아높은 10,000장의 이미지가 포함된 &lt;code&gt;TopImages&lt;/code&gt;데이터를 사용합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pathlib

content_data_url &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/sample_data&amp;#39;&lt;/span&gt;
data_root_orig &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;imagenetV2&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;https://s3-us-west-2.amazonaws.com/imagenetv2public/imagenetv2-topimages.tar.gz&amp;#39;&lt;/span&gt;, cache_dir&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;content_data_url, extract&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
data_root &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pathlib&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Path(content_data_url &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/datasets/imagenetv2-topimages&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(data_root)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;/content/sample_data/datasets/imagenetv2-topimages
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;tf.keras.utils.get_file()&lt;/code&gt; 함수로 &lt;code&gt;ImageNetV2&lt;/code&gt; 데이터를 불러올 수 있습니다. 함수의 인수 중 &lt;code&gt;extract=True&lt;/code&gt;로 지정했기 때문에, &lt;code&gt;tar.gz&lt;/code&gt; 형식의 압축 파일이 자동으로 해제됭 구글 코랩 가상 머신에 저장됩니다.&lt;/p&gt;
&lt;p&gt;디렉터리의 경로를 출력해서, 예제 데이터를 확인해 봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; idx, item &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(data_root&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;iterdir()):
  &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(item)
  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; idx &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;break&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;/content/sample_data/datasets/imagenetv2-topimages/462
/content/sample_data/datasets/imagenetv2-topimages/630
/content/sample_data/datasets/imagenetv2-topimages/687
/content/sample_data/datasets/imagenetv2-topimages/858
/content/sample_data/datasets/imagenetv2-topimages/172
/content/sample_data/datasets/imagenetv2-topimages/856
/content/sample_data/datasets/imagenetv2-topimages/407
/content/sample_data/datasets/imagenetv2-topimages/300
/content/sample_data/datasets/imagenetv2-topimages/374
/content/sample_data/datasets/imagenetv2-topimages/0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;하위 디렉토리는 0~999까지 총 1,000개입니다.&lt;/p&gt;
&lt;h3 id=&#34;3-라벨-텍스트-불러오기&#34;&gt;(3) 라벨 텍스트 불러오기&lt;/h3&gt;
&lt;p&gt;라벨에 대한 숫자가 어떤 데이터를 뜻하는지에 대한 정보인 라벨 텍스트는 따로 불러와야 합니다. &lt;code&gt;MobileNet&lt;/code&gt;에서 사용된 라벨은 &lt;code&gt;tf.keras.utils.get_file()&lt;/code&gt;함수로 불러옵니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;label_file &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;label&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt&amp;#39;&lt;/span&gt;)
label_text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; None
&lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; open(label_file, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r&amp;#39;&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; f:
    label_text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; f&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)[:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(len(label_text))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(label_text[:&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;])
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(label_text[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;:])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt
16384/10484 [==============================================] - 0s 0us/step
1001
[&#39;background&#39;, &#39;tench&#39;, &#39;goldfish&#39;, &#39;great white shark&#39;, &#39;tiger shark&#39;, &#39;hammerhead&#39;, &#39;electric ray&#39;, &#39;stingray&#39;, &#39;cock&#39;, &#39;hen&#39;]
[&#39;buckeye&#39;, &#39;coral fungus&#39;, &#39;agaric&#39;, &#39;gyromitra&#39;, &#39;stinkhorn&#39;, &#39;earthstar&#39;, &#39;hen-of-the-woods&#39;, &#39;bolete&#39;, &#39;ear&#39;, &#39;toilet tissue&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;4-이미지-확인-시각화&#34;&gt;(4) 이미지 확인 시각화&lt;/h3&gt;
&lt;p&gt;그럼, 이제 이미지를 확인해봅니다. &lt;code&gt;matplotlib.pyplot&lt;/code&gt;을 이용해서 이미지를 출력합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;all_image_paths &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; list(data_root&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;glob(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;*/*&amp;#39;&lt;/span&gt;))
all_image_paths &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [str(path) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; path &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; all_image_paths]

&lt;span style=&#34;color:#75715e&#34;&gt;# 이미지를 랜덤하게 섞습니다. &lt;/span&gt;
random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shuffle(all_image_paths)
image_count &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; len(all_image_paths)

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;image_count:&amp;#39;&lt;/span&gt;, image_count)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;image_count: 10000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;이미지의 개수가 10,000인 것을 확인합ㄴ디ㅏ.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; PIL.Image &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; Image
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; random

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;):
  image_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;choice(all_image_paths)
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(image_path))
  idx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(image_path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(str(idx) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;, &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; label_text[idx])
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_01/output_20_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;10,000장의 이미지 중 랜덤하게 뽑은 9장의 이미지이기 때문에 독자와는 조금 다를 수 있습니다. 전반적으로 사진들이 잘 분류가 되고 있음을 확인할 수 있습니다.&lt;/p&gt;
&lt;p&gt;위 코드에서 한가지 유의할 점은 라벨 텍스트는 &lt;code&gt;background&lt;/code&gt;가 포함되어 있어서, 총 1,001개의 텍스트가 있지만, 실제 데이터의 라벨은 0에서 999까지의, 1000개라는 점입니다. 이러한 차이를 무마하기 위해서, 코드 &lt;code&gt;idx = int(image_path.split(&#39;/&#39;)[-2]) + 1&lt;/code&gt;에서 파일 경로의 라벨 디렉토리에 해당하는 부분을 정수로 변환한 다음 1을 더해 첫번째부터 1,000번째까지의 라벨 텍스트와 동일한 값을 가리킵니다.&lt;/p&gt;
&lt;h3 id=&#34;5-모형-성능-테스트&#34;&gt;(5) 모형 성능 테스트&lt;/h3&gt;
&lt;p&gt;이제 이 이미지들을 &lt;code&gt;MobileNet&lt;/code&gt;이 얼마나 잘 분류하는지 확인해봅니다. 전통적으로 &lt;code&gt;ImageNet&lt;/code&gt; 대회에서는 예측하는 값 중 상위 5개 이내에 데이터의 실제 분류가 포함되어 있으면 정답으로 인정하는 &lt;code&gt;Top-5&lt;/code&gt; 정확도를 분류 정확도로 측정합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; cv2

top_1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
top_5 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; image_path &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; all_image_paths:
  img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(image_path)
  img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(img, dsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;))
  img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; img &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
  img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(img, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
  top_5_predict &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(img)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argsort()[::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][:&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;]
  idx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(image_path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;])&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; idx &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; top_5_predict:
    top_5 &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; top_5_predict[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; idx:
      top_1 &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Top-5 correctness:&amp;#39;&lt;/span&gt;, top_5 &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; len(all_image_paths) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;%&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Top-5 correctness:&amp;#39;&lt;/span&gt;, top_1 &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; len(all_image_paths) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;%&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Top-5 correctness: 83.84 %
Top-5 correctness: 59.45 %
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Top-5 정확도는 83.84%, Top-1 정확도는 59.45%가 나옵니다. 논문에서는 정확도를 높이기 위해 이미지에 여러 가지 전처리 기법을 사용하지만 여기서는 특별한 방법을 사용하지 않았기 때문에 정확도가 약간 낮게 나옵니다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;cv2&lt;/code&gt; 모듈은 &lt;code&gt;OpenCV(Open Source Computer Vision)&lt;/code&gt; 라이브러리입니다. 이미지를 메모리에 불러오고 크기를 조정하는 등의 작업을 편하게 해줍니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;top_5_predict &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(img)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argsort()[::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][:&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;여기에서 &lt;code&gt;argsort()&lt;/code&gt;는 인덱스를 정렬합니다. 그런데, 우리가 원하는 것은 예측확률이 높은 순서이기 때문에 &lt;code&gt;array[::-1]&lt;/code&gt;로 반전시키비다. 그 다음에 앞에서부터 5번째까지의 값을 &lt;code&gt;array[:5]&lt;/code&gt;로 잘라서 &lt;code&gt;top_5_predict&lt;/code&gt;에 저장합니다.&lt;/p&gt;
&lt;p&gt;소스코드를 보면 더 쉽게 이해가 갈 것입니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;99&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;])
arg &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argsort(a)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(arg)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sort(a))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(a[arg])
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(a[arg][::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(a[arg][::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][:&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[2 4 1 3 0]
[ 5 20 32 64 99]
[ 5 20 32 64 99]
[99 64 32 20  5]
[99 64]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;참고로 교재에서는 &lt;code&gt;print(a[arg][::-1])&lt;/code&gt; 와 &lt;code&gt;print(a[arg][::-1][:2])&lt;/code&gt;의 소스코드는 독자들의 이해를 더 구하기 위해 추가하였습니다.&lt;/p&gt;
&lt;h3 id=&#34;6-분류-라벨-확인&#34;&gt;(6) 분류 라벨 확인&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;MobileNet&lt;/code&gt;이 분류하는 라벨을 실제로 확인하고 &lt;code&gt;Top-5&lt;/code&gt;예측을 표시합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;))

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;softmax&lt;/span&gt;(x):
    e_x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(x &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;max(x))
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; e_x &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; e_x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
  
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;):
    image_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;choice(all_image_paths)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# 이미지 표시&lt;/span&gt;
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(image_path))
    idx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(image_path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(str(idx) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;, &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; label_text[idx])
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# 예측값 표시&lt;/span&gt;
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(image_path)
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(img, dsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;))
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; img &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(img, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# MobileNet을 이용한 예측&lt;/span&gt;
    logits &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(img)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
    prediction &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; softmax(logits)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# 가장 높은 확률의 예측값 5개를 뽑음&lt;/span&gt;
    top_5_predict &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; prediction&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argsort()[::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][:&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;]
    labels &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [label_text[index] &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; index &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; top_5_predict]
    color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; idx &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; top_5_predict:
        color[top_5_predict&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tolist()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;index(idx)] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;green&amp;#39;&lt;/span&gt;
    color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; color[::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;barh(range(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;), prediction[top_5_predict][::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;color)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;yticks(range(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;), labels[::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_08_01/output_28_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;랜덤하게 뽑은 세 개의 이미지 중 3개는 모두 &lt;code&gt;Top-1&lt;/code&gt; 예측을 맞췄습니다. 이렇게 별도의 훈련 과정 없이 미리 훈련된 모델을 텐서플로 허브에서 불러오는 것으로 네트워크를 그대로 사용할 수 있습니다.&lt;/p&gt;
&lt;h2 id=&#34;iii-연습-파일&#34;&gt;III. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch8_1_tensorflow_hub.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;vi-reference&#34;&gt;VI. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
&lt;p&gt;Karpathy, A. (2015). The Unreasonable Effectiveness of Recurrent Neural Networks. Retrieved April 26, 2020, from &lt;a href=&#34;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&#34;&gt;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&lt;/a&gt;&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/modestyachts/imageNetV2&#34;&gt;https://github.com/modestyachts/imageNetV2&lt;/a&gt; &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;사람의 수작업이 필요한 이미지 라벨링 등을 위해 비교적 저렴한 가격으로 서비스 구매자와 제공자를 연결해주는 작업 플랫폼 &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch7.4 - (2) 단어 단위 생성</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration2/</link>
      <pubDate>Mon, 27 Apr 2020 14:20:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration2/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.2 - 다항분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/&#34;&gt;Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/&#34;&gt;Tensorflow 2.0 Tutorial ch6.1-2 - CNN 이론&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_3_fashion_mnist_with_cnn/&#34;&gt;Tensorflow 2.0 Tutorial ch6.3 - Fashion MNIST with CNN 실습&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_4_improve_performance/&#34;&gt;Tensorflow 2.0 Tutorial ch6.4 - 모형의 성능 높이기&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (1)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (2)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_3_sentimentanalysis/&#34;&gt;Tensorflow 2.0 Tutorial ch7.3 - 긍정, 부정 감성 분석&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (1) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요&#34;&gt;I. 개요&lt;/h2&gt;
&lt;p&gt;테슬라 &lt;code&gt;AI Director&lt;/code&gt;인 안드레아 카르파티(&lt;code&gt;Andrej Karpathy&lt;/code&gt;)는 &lt;code&gt;The Unreasonable Effectiveness of Recurrent Neural Networks&lt;/code&gt;라는 글을 개인 블로그에 작성했는데, 짧게 요약하면 문자 단위의 순환 신경망이 셰익스피어의 희곡, 소스코드, &lt;code&gt;Latex&lt;/code&gt;등을 재생산하는데 순환 신경망이 효과적이라는 것을 보여줍니다.&lt;/p&gt;
&lt;p&gt;이를 바탕으로, 한글 원본 텍스트를 자소 단위와 단어 단위로 나눠서 순환 신경망으로 생성해보도록 합니다.&lt;/p&gt;
&lt;h2 id=&#34;ii-자소-단위-생성&#34;&gt;II. 자소 단위 생성&lt;/h2&gt;
&lt;p&gt;자소 단위 생성을 하기 위해서는 한글을 자소 단위로 분리하고 다시 합칠 수 있는 라이브러리가 필요합니다. 이러한 작업을 할 수 있도록 신해빈 님이 만든 &lt;a href=&#34;https://github.com/HaebinShin/jamotools&#34;&gt;jamotools&lt;/a&gt;가 있습니다.&lt;/p&gt;
&lt;p&gt;구글 코랩에서 배시 셀 명령어를 이용해 라이브러리를 설치합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;!&lt;/span&gt;pip install jamotools
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Collecting jamotools
  Downloading https://files.pythonhosted.org/packages/3d/d6/ec13c68f7ea6a8085966390d256d183bf8488f8b9770028359acb86df643/jamotools-0.1.10-py2.py3-none-any.whl
Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from jamotools) (1.18.3)
Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from jamotools) (1.12.0)
Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from jamotools) (0.16.0)
Installing collected packages: jamotools
Successfully installed jamotools-0.1.10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;jamotools의 기능을 테스트하기 위해 조선왕조실록 텍스트를 다시 사용합니다.&lt;/p&gt;
&lt;h3 id=&#34;1-데이터-로드&#34;&gt;(1) 데이터 로드&lt;/h3&gt;
&lt;p&gt;데이터 파일은 약 62MB 정도입니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 텐서플로 2 버전 선택&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
    &lt;span style=&#34;color:#75715e&#34;&gt;# %tensorflow_version only exists in Colab.&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;tensorflow_version &lt;span style=&#34;color:#ae81ff&#34;&gt;2.&lt;/span&gt;x
&lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Exception&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;pass&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; jamotools
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;path_to_train_file &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;input.txt&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;https://raw.githubusercontent.com/greentec/greentec.github.io/master/public/other/data/chosundynasty/corpus.txt&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from https://raw.githubusercontent.com/greentec/greentec.github.io/master/public/other/data/chosundynasty/corpus.txt
62013440/62012502 [==============================] - 1s 0us/step
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;데이터를 메모리에 불러옵니다. 인코딩 형식으로 &lt;code&gt;utf-8&lt;/code&gt;을 지정한 뒤 텍스트가 총 몇 자인지 확인해봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train_text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; open(path_to_train_file, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rb&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;decode(encoding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;)
s &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_text[:&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;]
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(s)

&lt;span style=&#34;color:#75715e&#34;&gt;# 한글 텍스트를 자모 단위로 분리합니다. 한자 등에는 영향이 없습니다. &lt;/span&gt;
s_split &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; jamotools&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split_syllables(s)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(s_split)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 
태조 강헌 지인 계운 성문 신무 대왕(太祖康獻至仁啓運聖文神武大王)의 성은 이씨(李氏)요, 휘
﻿ㅌㅐㅈㅗ ㅇㅣㅅㅓㅇㄱㅖ ㅅㅓㄴㄷㅐㅇㅢ ㄱㅏㄱㅖ. ㅁㅗㄱㅈㅗ ㅇㅣㅇㅏㄴㅅㅏㄱㅏ ㅈㅓㄴㅈㅜㅇㅔㅅㅓ ㅅㅏㅁㅊㅓㄱ·ㅇㅢㅈㅜㄹㅡㄹ ㄱㅓㅊㅕ ㅇㅏㄹㄷㅗㅇㅇㅔ ㅈㅓㅇㅊㅏㄱㅎㅏㄷㅏ 
ㅌㅐㅈㅗ ㄱㅏㅇㅎㅓㄴ ㅈㅣㅇㅣㄴ ㄱㅖㅇㅜㄴ ㅅㅓㅇㅁㅜㄴ ㅅㅣㄴㅁㅜ ㄷㅐㅇㅘㅇ(太祖康獻至仁啓運聖文神武大王)ㅇㅢ ㅅㅓㅇㅇㅡㄴ ㅇㅣㅆㅣ(李氏)ㅇㅛ, ㅎㅟ
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;split_syllables()&lt;/code&gt;함수를 이용해서 100글자의 한글이 자모 단위로 정상적으로 분리되는 것을 확인할 수 있습니다. &lt;code&gt;jamotools&lt;/code&gt;는 영문이나 한자 등에는 영향을 주지 않습니다. 분리한 자모를 다시 합칠 수도 있습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;s2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; jamotools&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;join_jamos(s_split)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(s2)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(s &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; s2)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 
태조 강헌 지인 계운 성문 신무 대왕(太祖康獻至仁啓運聖文神武大王)의 성은 이씨(李氏)요, 휘
True
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;자모를 분리했다가 다시 합친 &lt;code&gt;s2&lt;/code&gt;는 &lt;code&gt;s&lt;/code&gt;와 같다는 것을 두 번째 출력이 &lt;code&gt;True&lt;/code&gt;인 것에서 확인할 수 있습니다.&lt;/p&gt;
&lt;h3 id=&#34;2-자모-토큰화&#34;&gt;(2) 자모 토큰화&lt;/h3&gt;
&lt;p&gt;그럼 이제 자모를 토큰화합니다. 여기서는 따로 텍스트 전처리를 하지 않습니다. 괄호, 한자 등이 토큰에 모두 포함될 것입니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;텍스트를 자모 단위로 나눕니다. 데이터가 크기 때문에 약간 시간이 걸립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train_text_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; jamotools&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split_syllables(train_text)
vocab &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sorted(set(train_text_X))
vocab&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;UNK&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{} unique characters&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(len(vocab)))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;6198 unique characters
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;이제, vocal list를 숫자로 매핑하고, 반대도 실행합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;char2idx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {u:i &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i, u &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(vocab)}
idx2char &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(vocab)

test_as_int &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([char2idx[c] &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; train_text_X])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;이제 word2idx의 일부를 알아보기 쉽게 출력합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; char, _ &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(char2idx, range(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;)):
  &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; {:4s}: {:3d}, &amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(repr(char), char2idx[char]))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;   ...&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;}&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;index of UNK: {}&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(char2idx[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;UNK&amp;#39;&lt;/span&gt;]))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;{
 &#39;\n&#39;:   0, 
 &#39; &#39; :   1, 
 &#39;!&#39; :   2, 
 &#39;&amp;quot;&#39; :   3, 
 &amp;quot;&#39;&amp;quot; :   4, 
 &#39;(&#39; :   5, 
 &#39;)&#39; :   6, 
 &#39;+&#39; :   7, 
 &#39;,&#39; :   8, 
 &#39;-&#39; :   9, 
   ...
}
index of UNK: 6197
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;자모를 토큰화하고 혹시 사전에 정의되지 않은 기호를 만날수도 있으므로 &lt;code&gt;UNK&lt;/code&gt;도 사전에 추가합니다. 이렇게 중복되 않은 자모는 총 &lt;code&gt;6197&lt;/code&gt;개가 나옵니다. 단어에 비해 매우 적은 숫자임을 알 수 있습니다.&lt;/p&gt;
&lt;p&gt;이제 토큰 데이터를 출력합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_text_X[:&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;])
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(test_as_int[:&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;﻿ㅌㅐㅈㅗ ㅇㅣㅅㅓㅇㄱㅖ ㅅㅓㄴㄷㅐㅇ
[6158   83   87   79   94    1   78  106   76   90   78   56   93    1
   76   90   59   62   87   78]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;ㅌ&lt;/code&gt;은 6158, &lt;code&gt;ㅐ&lt;/code&gt;는 83 등으로 토큰화가 된 것을 확인할 수 있습니다.&lt;/p&gt;
&lt;h3 id=&#34;3-데이터-생성&#34;&gt;(3) 데이터 생성&lt;/h3&gt;
&lt;p&gt;단어 생성 단위에 있던 학습 데이터세트를 생성합니다. 이 부분의 코드는 큰 변경사항이 없습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;sentence_dataet&lt;/code&gt;에서 &lt;code&gt;char_dataset&lt;/code&gt;으로 변동하시면 됩니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;idx2word&lt;/code&gt;에서 &lt;code&gt;idx2char&lt;/code&gt;으로 변동하시면 됩니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;seq_length &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
examples_per_epoch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; len(test_as_int) &lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt; seq_length
char_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_tensor_slices(test_as_int)

char_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; char_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;batch(seq_length&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, drop_remainder&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; item &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; char_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;take(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(idx2char[item&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()])
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(item&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy())

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;split_input_target&lt;/span&gt;(chunk):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; [chunk[:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], chunk[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]]

train_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; char_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;map(split_input_target)
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; x,y &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; train_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;take(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(idx2char[x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()])
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy())
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(idx2char[y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()])
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy())

BATCH_SIZE &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;
steps_per_epoch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; examples_per_epoch &lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt; BATCH_SIZE
BUFFER_SIZE &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10000&lt;/span&gt;

train_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shuffle(BUFFER_SIZE)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;batch(BATCH_SIZE, drop_remainder&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[&#39;\ufeff&#39; &#39;ㅌ&#39; &#39;ㅐ&#39; &#39;ㅈ&#39; &#39;ㅗ&#39; &#39; &#39; &#39;ㅇ&#39; &#39;ㅣ&#39; &#39;ㅅ&#39; &#39;ㅓ&#39; &#39;ㅇ&#39; &#39;ㄱ&#39; &#39;ㅖ&#39; &#39; &#39; &#39;ㅅ&#39; &#39;ㅓ&#39; &#39;ㄴ&#39;
 &#39;ㄷ&#39; &#39;ㅐ&#39; &#39;ㅇ&#39; &#39;ㅢ&#39; &#39; &#39; &#39;ㄱ&#39; &#39;ㅏ&#39; &#39;ㄱ&#39; &#39;ㅖ&#39; &#39;.&#39; &#39; &#39; &#39;ㅁ&#39; &#39;ㅗ&#39; &#39;ㄱ&#39; &#39;ㅈ&#39; &#39;ㅗ&#39; &#39; &#39; &#39;ㅇ&#39;
 &#39;ㅣ&#39; &#39;ㅇ&#39; &#39;ㅏ&#39; &#39;ㄴ&#39; &#39;ㅅ&#39; &#39;ㅏ&#39; &#39;ㄱ&#39; &#39;ㅏ&#39; &#39; &#39; &#39;ㅈ&#39; &#39;ㅓ&#39; &#39;ㄴ&#39; &#39;ㅈ&#39; &#39;ㅜ&#39; &#39;ㅇ&#39; &#39;ㅔ&#39; &#39;ㅅ&#39; &#39;ㅓ&#39;
 &#39; &#39; &#39;ㅅ&#39; &#39;ㅏ&#39; &#39;ㅁ&#39; &#39;ㅊ&#39; &#39;ㅓ&#39; &#39;ㄱ&#39; &#39;·&#39; &#39;ㅇ&#39; &#39;ㅢ&#39; &#39;ㅈ&#39; &#39;ㅜ&#39; &#39;ㄹ&#39; &#39;ㅡ&#39; &#39;ㄹ&#39; &#39; &#39; &#39;ㄱ&#39; &#39;ㅓ&#39;
 &#39;ㅊ&#39; &#39;ㅕ&#39; &#39; &#39; &#39;ㅇ&#39; &#39;ㅏ&#39; &#39;ㄹ&#39; &#39;ㄷ&#39; &#39;ㅗ&#39; &#39;ㅇ&#39; &#39;ㅇ&#39;]
[6158   83   87   79   94    1   78  106   76   90   78   56   93    1
   76   90   59   62   87   78  105    1   56   86   56   93   10    1
   72   94   56   79   94    1   78  106   78   86   59   76   86   56
   86    1   79   90   59   79   99   78   91   76   90    1   76   86
   72   81   90   56   36   78  105   79   99   64  104   64    1   56
   90   81   92    1   78   86   64   62   94   78   78]
[&#39;\ufeff&#39; &#39;ㅌ&#39; &#39;ㅐ&#39; &#39;ㅈ&#39; &#39;ㅗ&#39; &#39; &#39; &#39;ㅇ&#39; &#39;ㅣ&#39; &#39;ㅅ&#39; &#39;ㅓ&#39; &#39;ㅇ&#39; &#39;ㄱ&#39; &#39;ㅖ&#39; &#39; &#39; &#39;ㅅ&#39; &#39;ㅓ&#39; &#39;ㄴ&#39;
 &#39;ㄷ&#39; &#39;ㅐ&#39; &#39;ㅇ&#39; &#39;ㅢ&#39; &#39; &#39; &#39;ㄱ&#39; &#39;ㅏ&#39; &#39;ㄱ&#39; &#39;ㅖ&#39; &#39;.&#39; &#39; &#39; &#39;ㅁ&#39; &#39;ㅗ&#39; &#39;ㄱ&#39; &#39;ㅈ&#39; &#39;ㅗ&#39; &#39; &#39; &#39;ㅇ&#39;
 &#39;ㅣ&#39; &#39;ㅇ&#39; &#39;ㅏ&#39; &#39;ㄴ&#39; &#39;ㅅ&#39; &#39;ㅏ&#39; &#39;ㄱ&#39; &#39;ㅏ&#39; &#39; &#39; &#39;ㅈ&#39; &#39;ㅓ&#39; &#39;ㄴ&#39; &#39;ㅈ&#39; &#39;ㅜ&#39; &#39;ㅇ&#39; &#39;ㅔ&#39; &#39;ㅅ&#39; &#39;ㅓ&#39;
 &#39; &#39; &#39;ㅅ&#39; &#39;ㅏ&#39; &#39;ㅁ&#39; &#39;ㅊ&#39; &#39;ㅓ&#39; &#39;ㄱ&#39; &#39;·&#39; &#39;ㅇ&#39; &#39;ㅢ&#39; &#39;ㅈ&#39; &#39;ㅜ&#39; &#39;ㄹ&#39; &#39;ㅡ&#39; &#39;ㄹ&#39; &#39; &#39; &#39;ㄱ&#39; &#39;ㅓ&#39;
 &#39;ㅊ&#39; &#39;ㅕ&#39; &#39; &#39; &#39;ㅇ&#39; &#39;ㅏ&#39; &#39;ㄹ&#39; &#39;ㄷ&#39; &#39;ㅗ&#39; &#39;ㅇ&#39;]
[6158   83   87   79   94    1   78  106   76   90   78   56   93    1
   76   90   59   62   87   78  105    1   56   86   56   93   10    1
   72   94   56   79   94    1   78  106   78   86   59   76   86   56
   86    1   79   90   59   79   99   78   91   76   90    1   76   86
   72   81   90   56   36   78  105   79   99   64  104   64    1   56
   90   81   92    1   78   86   64   62   94   78]
ㅇ
78
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;seq_length의 의미는 자소 단위에서는 80개의 자소를 입력받았을 때 1개의 자소를 출력하도록 합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;4-자소-단위-생성-모델-정의-및-학습&#34;&gt;(4) 자소 단위 생성 모델 정의 및 학습&lt;/h3&gt;
&lt;p&gt;자소 단위 생성 모델에서는 겹쳐진 순환 신경망을 사용하지 않고 &lt;code&gt;LSTM&lt;/code&gt;레이어를 하나만 사용했습니다. 대신 하나의 &lt;code&gt;LSTM&lt;/code&gt;레이어에서는 사용하는 뉴런의 수를 4배로 늘렸습니다. 또 단어의 수보다 자소의 수가 훨씬 적기 때문에 마지막 &lt;code&gt;Dense&lt;/code&gt;레이어의 뉴런 수가 적어집니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;total_chars &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; len(vocab)
model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Embedding(total_chars, &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, input_length&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;seq_length), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;LSTM(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;400&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(total_chars, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;)
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;adam&amp;#39;&lt;/span&gt;, loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sparse_categorical_crossentropy&amp;#39;&lt;/span&gt;, metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, 80, 100)           619800    
_________________________________________________________________
lstm (LSTM)                  (None, 400)               801600    
_________________________________________________________________
dense (Dense)                (None, 6198)              2485398   
=================================================================
Total params: 3,906,798
Trainable params: 3,906,798
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;모형을 학습시킵니다. 이 때 주의해야 하는 것은 &lt;code&gt;testmodel&lt;/code&gt; 함수에서, &lt;code&gt;jamotools&lt;/code&gt; 입력 부분을 추가해야 합니다. 이 소스코드의 위치를 살펴보시기를 바랍니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras.preprocessing.sequence &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pad_sequences

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testmodel&lt;/span&gt;(epoch, logs):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; epoch &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; epoch &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;49&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt;
    test_sentence &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_text[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
    test_sentence &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; jamotools&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split_syllables(test_sentence)

    next_chars &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;300&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; _ &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(next_chars):
        test_text_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_sentence&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; &amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;seq_length:]
        test_text_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([char2idx[c] &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; char2idx &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; char2idx[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;UNK&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; test_text_X])
        test_text_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pad_sequences([test_text_X], maxlen&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;seq_length, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pre&amp;#39;&lt;/span&gt;, value&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;char2idx[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;UNK&amp;#39;&lt;/span&gt;])

        output_idx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict_classes(test_text_X)
        test_sentence &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; idx2char[output_idx[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]]
    
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;()
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(test_sentence)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;()

testmodelcb &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;callbacks&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;LambdaCallback(on_epoch_end&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;testmodel)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;repeat(), epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, steps_per_epoch&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;steps_per_epoch, callbacks&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[testmodelcb], verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Epoch 1/100&lt;/p&gt;
&lt;p&gt;﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 이를 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을&lt;/p&gt;
&lt;p&gt;2364/2364 - 270s - loss: 2.5904 - accuracy: 0.3065
Epoch 2/100
2364/2364 - 266s - loss: 1.9905 - accuracy: 0.4264
Epoch 3/100
2364/2364 - 266s - loss: 1.8423 - accuracy: 0.4608
Epoch 4/100
2364/2364 - 266s - loss: 1.7423 - accuracy: 0.4823
Epoch 5/100
2364/2364 - 264s - loss: 1.6784 - accuracy: 0.4948
Epoch 6/100&lt;/p&gt;
&lt;p&gt;﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 일이 있었다. 임금이 있었다. 임금이 있었다. 임금이 있었다. 임금이 있었다. 임금이 있었다. 임금이 있었다. 임금이 있었다. 임금이 있었다. 임금이 있었다. 임금이 있었다. 임금이 있었다. 임금이 있었다. 임금이 있었다. 임금이 있었다. 임금이 있었다.&lt;/p&gt;
&lt;p&gt;2364/2364 - 265s - loss: 1.6241 - accuracy: 0.5070
Epoch 7/100
2364/2364 - 264s - loss: 1.5739 - accuracy: 0.5184
Epoch 8/100
2364/2364 - 264s - loss: 1.5297 - accuracy: 0.5286
Epoch 9/100
2364/2364 - 266s - loss: 1.4916 - accuracy: 0.5372
Epoch 10/100
2364/2364 - 268s - loss: 1.4595 - accuracy: 0.5451
Epoch 11/100&lt;/p&gt;
&lt;p&gt;﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 하였다. 임금이 말하기를,
&amp;ldquo;임금이 말하기를,
&amp;ldquo;임금이 말하기를,
&amp;ldquo;임금이 말하기를,
&amp;ldquo;임금이 말하기를,
&amp;ldquo;임금이 말하기를,
&amp;ldquo;임금이 말하기를,
&amp;ldquo;임금이 말하기를,
&amp;ldquo;임금이 말하기를,
&amp;ldquo;임금이 말하기를,
&amp;ldquo;임금이 말하기를,
&amp;ldquo;임금이 말하기를,
&amp;ldquo;임금이 말하기를,
&amp;ldquo;임그&lt;/p&gt;
&lt;p&gt;2364/2364 - 270s - loss: 1.4323 - accuracy: 0.5516
Epoch 12/100
2364/2364 - 269s - loss: 1.4059 - accuracy: 0.5585
Epoch 13/100
2364/2364 - 269s - loss: 1.3848 - accuracy: 0.5631
Epoch 14/100
2364/2364 - 269s - loss: 1.3646 - accuracy: 0.5685
Epoch 15/100
2364/2364 - 270s - loss: 1.3473 - accuracy: 0.5730
Epoch 16/100&lt;/p&gt;
&lt;p&gt;﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 하였다. 임금이 말하기를,
&amp;ldquo;이제 이를 받들고 전하께서 아뢰기를,
&amp;ldquo;이제 이를 받들고 전하께서 아뢰기를,
&amp;ldquo;이제 이를 받들고 전하께서 아뢰기를,
&amp;ldquo;이제 이를 받들고 전하께서 아뢰기를,
&amp;ldquo;이제 이를 받들고 전하께서 아뢰기를,
&amp;ldquo;이제 이를 받들고 전하께서 아뢰기를,
&amp;ldquo;이제 이를 받들&lt;/p&gt;
&lt;p&gt;2364/2364 - 272s - loss: 1.3297 - accuracy: 0.5777
Epoch 17/100
2364/2364 - 271s - loss: 1.3138 - accuracy: 0.5825
Epoch 18/100
2364/2364 - 270s - loss: 1.3013 - accuracy: 0.5857
Epoch 19/100
2364/2364 - 270s - loss: 1.2859 - accuracy: 0.5904
Epoch 20/100
2364/2364 - 272s - loss: 1.2727 - accuracy: 0.5941
Epoch 21/100&lt;/p&gt;
&lt;p&gt;﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 하는 것은 그 고을에 있으면 그 사람을 감하게 하였다. 임금이 말하기를,
&amp;ldquo;각각 15석을 가지고 감사(監司)에서 아뢰기를,
&amp;ldquo;각각 15석을 가지고 감사(監司)에서 아뢰기를,
&amp;ldquo;각각 15석을 가지고 감사(監司)에서 아뢰기를,
&amp;ldquo;각각 15석을 가지고 감사(監司)에서 아뢰기를,
&amp;ldquo;각각 15석을 가지&lt;/p&gt;
&lt;p&gt;2364/2364 - 275s - loss: 1.2607 - accuracy: 0.5970
Epoch 22/100
2364/2364 - 273s - loss: 1.2478 - accuracy: 0.6010
Epoch 23/100
2364/2364 - 273s - loss: 1.2370 - accuracy: 0.6044
Epoch 24/100
2364/2364 - 273s - loss: 1.2262 - accuracy: 0.6075
Epoch 25/100
2364/2364 - 273s - loss: 1.2161 - accuracy: 0.6101
Epoch 26/100&lt;/p&gt;
&lt;p&gt;﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 하였다. 임금이 말하기를,
&amp;ldquo;이제 임금이 말하기를,
&amp;ldquo;이제 임금이 말하기를,
&amp;ldquo;이제 임금이 말하기를,
&amp;ldquo;이제 임금이 말하기를,
&amp;ldquo;이제 임금이 말하기를,
&amp;ldquo;이제 임금이 말하기를,
&amp;ldquo;이제 임금이 말하기를,
&amp;ldquo;이제 임금이 말하기를,
&amp;ldquo;이제 임금이 말하기를,
&amp;ldquo;이제 임금이 말하기를,&lt;/p&gt;
&lt;p&gt;2364/2364 - 275s - loss: 1.2050 - accuracy: 0.6134
Epoch 27/100
2364/2364 - 273s - loss: 1.1956 - accuracy: 0.6167
Epoch 28/100
2364/2364 - 273s - loss: 1.1863 - accuracy: 0.6193
Epoch 29/100
2364/2364 - 274s - loss: 1.1771 - accuracy: 0.6223
Epoch 30/100
2364/2364 - 274s - loss: 1.1682 - accuracy: 0.6246
Epoch 31/100&lt;/p&gt;
&lt;p&gt;﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 하니, 임금이 말하기를,
&amp;ldquo;이 때에 이르기를,
&amp;ldquo;상석(成石)을 진향하게 하였다. 임금이 말하기를,
&amp;ldquo;이 때에 이르기를,
&amp;ldquo;그러나 이를 주게 하다
예조에서 아뢰기를,
&amp;ldquo;이 때에 이르기를,
&amp;ldquo;그러나 이를 주게 하다
예조에서 아뢰기를,
&amp;ldquo;이 때에 이르기를,
&amp;ldquo;그러나 이를 주게 하다
예조에서 아뢰기를,
&amp;ldquo;이 ㄸ&lt;/p&gt;
&lt;p&gt;2364/2364 - 276s - loss: 1.1608 - accuracy: 0.6267
Epoch 32/100
2364/2364 - 273s - loss: 1.1522 - accuracy: 0.6293
Epoch 33/100
2364/2364 - 273s - loss: 1.1448 - accuracy: 0.6321
Epoch 34/100
2364/2364 - 273s - loss: 1.1370 - accuracy: 0.6344
Epoch 35/100
2364/2364 - 273s - loss: 1.1303 - accuracy: 0.6361
Epoch 36/100&lt;/p&gt;
&lt;p&gt;﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 할 것입니다. 이것은 이를 받았다. 임금이 이를 받았다. 임금이 이를 받았다. 임금이 이를 받았다. 임금이 이를 받았다. 임금이 이를 받았다. 임금이 이를 받았다. 임금이 이를 받았다. 임금이 이를 받았다. 임금이 이를 받았다. 임금이 이를 받았다. 임금이&lt;/p&gt;
&lt;p&gt;2364/2364 - 275s - loss: 1.1220 - accuracy: 0.6390
Epoch 37/100
2364/2364 - 272s - loss: 1.1161 - accuracy: 0.6407
Epoch 38/100
2364/2364 - 273s - loss: 1.1087 - accuracy: 0.6429
Epoch 39/100
2364/2364 - 273s - loss: 1.1020 - accuracy: 0.6448
Epoch 40/100
2364/2364 - 272s - loss: 1.0957 - accuracy: 0.6467
Epoch 41/100&lt;/p&gt;
&lt;p&gt;﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 한다. 전하께서는 알지 못한 자가 있으면 나와서 아뢰다
예조에서 아뢰기를,
&amp;ldquo;이 앞서 있는 것이 어떻게 아뢰다
예조에서 아뢰기를,
&amp;ldquo;이 앞서 정지는 알지 못한 자가 있으면 날이 없으니, 이제 있는 것이 어떻겠습니까. 이제 상소하기를,
&amp;ldquo;이 앞서 중에 있는 것은 알지 못한 작&lt;/p&gt;
&lt;p&gt;2364/2364 - 268s - loss: 1.0895 - accuracy: 0.6494
Epoch 42/100
2364/2364 - 265s - loss: 1.0821 - accuracy: 0.6507
Epoch 43/100
2364/2364 - 265s - loss: 1.0770 - accuracy: 0.6527
Epoch 44/100
2364/2364 - 265s - loss: 1.0712 - accuracy: 0.6547
Epoch 45/100
2364/2364 - 266s - loss: 1.0654 - accuracy: 0.6565
Epoch 46/100&lt;/p&gt;
&lt;p&gt;﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 하여 그 직임을 만들어 보낸 자는 이러하였다. 임금이 말하기를,
&amp;ldquo;근일의 일을 이루지 않는다면 어찌 그 직임을 만들어 주는 것이 아니었다. ’고 하였습니다. 이제 상상도 염려되는 것이 아니었다. ’고 하였습니다. 신 등이 상소하기를,
&amp;ldquo;근일의 일을 이루지 않는다면 어ㅉ&lt;/p&gt;
&lt;p&gt;2364/2364 - 268s - loss: 1.0604 - accuracy: 0.6578
Epoch 47/100
2364/2364 - 266s - loss: 1.0563 - accuracy: 0.6588
Epoch 48/100
2364/2364 - 265s - loss: 1.0498 - accuracy: 0.6608
Epoch 49/100
2364/2364 - 266s - loss: 1.0455 - accuracy: 0.6626
Epoch 50/100
2364/2364 - 266s - loss: 1.0404 - accuracy: 0.6640
Epoch 51/100&lt;/p&gt;
&lt;p&gt;﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 하였으니 그 장(狀)을 강하게 하고, 상소를 이루게 하고, 이를 죽입니다. 이제 이미 정한 사람은 그 장(狀)을 기다리기를 청하였으니, 이것은 그를 구경하고 서울에 의거하여 아뢰기를,
&amp;ldquo;경연(經筵司) 이상의 아들이 이를 주고, 우의정 신주(春秋)를 사용하고, 한 사람은 그 장차 북쪽에 ㄷ&lt;/p&gt;
&lt;p&gt;2364/2364 - 270s - loss: 1.0354 - accuracy: 0.6654
Epoch 52/100
2364/2364 - 267s - loss: 1.0294 - accuracy: 0.6679
Epoch 53/100
2364/2364 - 265s - loss: 1.0260 - accuracy: 0.6683
Epoch 54/100
2364/2364 - 267s - loss: 1.0213 - accuracy: 0.6698
Epoch 55/100
2364/2364 - 270s - loss: 1.0165 - accuracy: 0.6715
Epoch 56/100&lt;/p&gt;
&lt;p&gt;﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 하였다. 이를 주었다. 임금이 말하기를,
&amp;ldquo;이 앞에 있어서 아뢰기를,
&amp;ldquo;이 사람이 일찍이 행하고, 인도하여 아뢰기를,
&amp;ldquo;이 사람이 있다. 그 아들이 아뢰기를,
&amp;ldquo;근일에 이르러 있다. 그 아들이 이를 주었다. 임금이 말하기를,
&amp;ldquo;이 앞에 있어서 아뢰기를,
&amp;ldquo;이 앞에 드리게 하다
임금이 말&lt;/p&gt;
&lt;p&gt;2364/2364 - 272s - loss: 1.0129 - accuracy: 0.6727
Epoch 57/100
2364/2364 - 270s - loss: 1.0085 - accuracy: 0.6744
Epoch 58/100
2364/2364 - 271s - loss: 1.0048 - accuracy: 0.6753
Epoch 59/100
2364/2364 - 270s - loss: 1.0004 - accuracy: 0.6765
Epoch 60/100
2364/2364 - 270s - loss: 0.9973 - accuracy: 0.6772
Epoch 61/100&lt;/p&gt;
&lt;p&gt;﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 하여 바라옵건대, 상소(上疏)하여 상고하여 아뢰기를,
&amp;ldquo;이 사람은 반드시 사이에 있었으니, 이것을 아뢰다
의정부에서 아뢰기를,
&amp;ldquo;이 사람은 임금이 말하기를, ‘고을의 각 고을의 성을 일으키고 돌아왔으나, 이는 이름을 인도하여 아뢰기를,
&amp;ldquo;성상의 의논을 인도하여 아뢰기를,
&amp;ldquo;이 ㅇ&lt;/p&gt;
&lt;p&gt;2364/2364 - 272s - loss: 0.9945 - accuracy: 0.6779
Epoch 62/100
2364/2364 - 270s - loss: 0.9906 - accuracy: 0.6801
Epoch 63/100
2364/2364 - 270s - loss: 0.9874 - accuracy: 0.6808
Epoch 64/100
2364/2364 - 270s - loss: 0.9834 - accuracy: 0.6817
Epoch 65/100
2364/2364 - 270s - loss: 0.9804 - accuracy: 0.6828
Epoch 66/100&lt;/p&gt;
&lt;p&gt;﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 하고, 이에 이미 다행하게 되면 일이 있었다. 임금이 말하기를,
&amp;ldquo;이 사람이 있었다. 임금이 말하기를,
&amp;ldquo;이 사람의 상소를 인도하여 아뢰기를,
&amp;ldquo;신 등이 이르기를,
&amp;ldquo;만약 대마도는 이러한 일을 맡아서 연훙한 일이 없었으나, 윤허하지 않고 있으니, 청컨대 이제 앞에 의하여 알&lt;/p&gt;
&lt;p&gt;2364/2364 - 272s - loss: 0.9771 - accuracy: 0.6839
Epoch 67/100
2364/2364 - 270s - loss: 0.9758 - accuracy: 0.6841
Epoch 68/100
2364/2364 - 270s - loss: 0.9714 - accuracy: 0.6859
Epoch 69/100
2364/2364 - 270s - loss: 0.9699 - accuracy: 0.6862
Epoch 70/100
2364/2364 - 270s - loss: 0.9658 - accuracy: 0.6871
Epoch 71/100&lt;/p&gt;
&lt;p&gt;﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 하여 그대로 따랐다.경상도 등을 아뢰다
상왕이 사신에게 말하기를,
&amp;ldquo;이보다 큰 곳을 정지하기를,
&amp;ldquo;이보다 큰 곳이 없었으므로 나와 같이 없어질 수 없는데, 이를 주다
의정부에서 상소하기를,
&amp;ldquo;이보다 큰 곳을 정지하기를 의심하고 있었는데, 지금 남을 것이다. 이제 상(喪)에 ㅇ&lt;/p&gt;
&lt;p&gt;2364/2364 - 272s - loss: 0.9634 - accuracy: 0.6882
Epoch 72/100
2364/2364 - 270s - loss: 0.9626 - accuracy: 0.6882
Epoch 73/100
2364/2364 - 270s - loss: 0.9582 - accuracy: 0.6893
Epoch 74/100
2364/2364 - 270s - loss: 0.9563 - accuracy: 0.6894
Epoch 75/100
2364/2364 - 270s - loss: 0.9539 - accuracy: 0.6913
Epoch 76/100&lt;/p&gt;
&lt;p&gt;﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 하겠습니다. 이를 금하게 하다가 집에 있으면 지금 아니라 이를 만들어 보내어 이를 만들어 보내어 이를 만약 관찰사(咸吉道都節制使) 윤장(印章)·정하여 인명하면서 군사를 가지고 있으니, 청컨대 이제부터는 이직(遞職)하여 아뢰기를,
&amp;ldquo;이제 이미 전하께서 이를 주다
정사(慶事)가 만약 그 인ㅇ&lt;/p&gt;
&lt;p&gt;2364/2364 - 272s - loss: 0.9535 - accuracy: 0.6909
Epoch 77/100
2364/2364 - 270s - loss: 0.9502 - accuracy: 0.6919
Epoch 78/100
2364/2364 - 270s - loss: 0.9518 - accuracy: 0.6904
Epoch 79/100
2364/2364 - 270s - loss: 0.9459 - accuracy: 0.6932
Epoch 80/100
2364/2364 - 269s - loss: 0.9433 - accuracy: 0.6941
Epoch 81/100&lt;/p&gt;
&lt;p&gt;﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 하다가 중국 종사를 보고 대장궁에 나아가 그 중에 있었으나, 이미 전에 의거하여 전하께서 아뢰기를,
&amp;ldquo;전일의 의논을 거느리고 돌아간 공신이 불을 드리는 것은 이미 공사를 보고 같은 것을 몹아서 임금을 입었으나, 이미 종사를 보고 대장군의 집에 있었으나 윤허하지 않ㅇ&lt;/p&gt;
&lt;p&gt;2364/2364 - 272s - loss: 0.9425 - accuracy: 0.6940
Epoch 82/100
2364/2364 - 270s - loss: 0.9436 - accuracy: 0.6937
Epoch 83/100
2364/2364 - 272s - loss: 0.9405 - accuracy: 0.6945
Epoch 84/100
2364/2364 - 270s - loss: 0.9372 - accuracy: 0.6959
Epoch 85/100
2364/2364 - 268s - loss: 0.9354 - accuracy: 0.6963
Epoch 86/100&lt;/p&gt;
&lt;p&gt;﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 하여, 일이 있으니, 청컨대 그 죄를 주고, 인사(人事)를 올리는 것이 없습니다. 그러나, 오직 관가(三文理)로 하여금 임금이 상소하여 사신에게 전지하기를,
&amp;ldquo;신이 임금이 있었다. 임금이 상성(宮城)을 정하여 일어나 전하께서 상소하여 사신에게 장숙주(申叔舟)에서 일찍이 각기 그 공이&lt;/p&gt;
&lt;p&gt;2364/2364 - 272s - loss: 0.9354 - accuracy: 0.6957
Epoch 87/100
2364/2364 - 271s - loss: 0.9322 - accuracy: 0.6968
Epoch 88/100
2364/2364 - 271s - loss: 0.9318 - accuracy: 0.6971
Epoch 89/100
2364/2364 - 271s - loss: 0.9336 - accuracy: 0.6964
Epoch 90/100
2364/2364 - 271s - loss: 0.9294 - accuracy: 0.6979
Epoch 91/100&lt;/p&gt;
&lt;p&gt;﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 하였으니, 일찍이 일을 무엇이 있었다. 임금이 말하기를,
&amp;ldquo;정성을 인송하게 하다
임금이 말하기를,
&amp;ldquo;이제부터 그 죄를 내렸다. 임금이 말하기를,
&amp;ldquo;이제부터 어려운 것이 없습니다. 신이 임금이 이를 비록 일으켜든 중일에 가서 주었다.상왕이 불을 다시 성하게 여기어 성서&lt;/p&gt;
&lt;p&gt;2364/2364 - 273s - loss: 0.9289 - accuracy: 0.6981
Epoch 92/100
2364/2364 - 272s - loss: 0.9283 - accuracy: 0.6979
Epoch 93/100
2364/2364 - 272s - loss: 0.9259 - accuracy: 0.6989
Epoch 94/100
2364/2364 - 272s - loss: 0.9252 - accuracy: 0.6992
Epoch 95/100
2364/2364 - 272s - loss: 0.9245 - accuracy: 0.6994
Epoch 96/100&lt;/p&gt;
&lt;p&gt;﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 하였다. 임금이 말하기를,
&amp;ldquo;정상이 들어온 자에게 정지하고, 이어서 상언(上言)하여 정하고, 또 정진수가 처음에 이르렀으니, 다음에는 아래에 있는 자가 있으면 마땅히 윤망한 것이 아니라, 이에 있어서 상언(上言)하여 상언(上言)하여 상언(上言)하여 상언(上言)하여 상언(上言)하여 정부에&lt;/p&gt;
&lt;p&gt;2364/2364 - 273s - loss: 0.9235 - accuracy: 0.6991
Epoch 97/100
2364/2364 - 271s - loss: 0.9234 - accuracy: 0.6989
Epoch 98/100
2364/2364 - 271s - loss: 0.9217 - accuracy: 0.6998
Epoch 99/100
2364/2364 - 272s - loss: 0.9215 - accuracy: 0.7000
Epoch 100/100&lt;/p&gt;
&lt;p&gt;﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 하여, 일이 있으면, 중국의 음사운의 청한 것은 아뢰기를,
&amp;ldquo;각도의 아들을 보내어 여러 신하들이 이르기를, ‘군사의 임금이 말하기를,
&amp;ldquo;이박한 그렇게 한 것은 아뢰기를,
&amp;ldquo;각도에 이르렀던 것이 없습니다. 그러나 이에 가서 수령을 감동하다
사헌부에서 계하기를,
&amp;ldquo;원산군(楊根&lt;/p&gt;
&lt;p&gt;2364/2364 - 274s - loss: 0.9206 - accuracy: 0.6999&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;모형 학습 시, 굉장히 많은 시간이 소요됩니다. 따라서 모형을 확인하려면 시간을 충분히 가지시고, 모형 학습을 진행합니다.&lt;/li&gt;
&lt;li&gt;단어 생성 모델처럼 같은 문장을 자소 단위로 넣어서 에포크가 끝날 때마다 생성 결과를 확인합니다.&lt;/li&gt;
&lt;li&gt;단어 생성 모델과 마찬가지로 처음에는 반복되는 패턴이 자주 나타나지만 점점 그럴듯한 결과를 만들어내기 시작합니다.&lt;/li&gt;
&lt;li&gt;특히 한자와 괄호를 그대로 학습에 사용하고 있기 때문에 한글과 한자의 병기도 잘 하는 것을 볼 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;5-학습모형-테스트&#34;&gt;(5) 학습모형 테스트&lt;/h3&gt;
&lt;p&gt;이제 임의의 문장을 통해서 학습을 진행합니다. 마찬가지로 기존 코드와 크게 달라진 것은 없으나 몇몇 변수만 수정하면 됩니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;next_words에서 next_chars로 변경&lt;/li&gt;
&lt;li&gt;word2idx에서 char2idx로 변경&lt;/li&gt;
&lt;li&gt;idx2word에서 idx2char로 변경&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras.preprocessing.sequence &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pad_sequences
test_sentence &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;동헌에 나가 공무를 본 후 활 십오 순을 쏘았다&amp;#39;&lt;/span&gt;
test_sentence &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; jamotools&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split_syllables(test_sentence)

next_chars &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;300&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; _ &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(next_chars):
    test_text_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_sentence[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;seq_length:]
    test_text_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([char2idx[c] &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; char2idx &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; char2idx[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;UNK&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; test_text_X])
    test_text_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pad_sequences([test_text_X], maxlen&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;seq_length, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pre&amp;#39;&lt;/span&gt;, value&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;char2idx[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;UNK&amp;#39;&lt;/span&gt;])
    
    output_idx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict_classes(test_text_X)
    test_sentence &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; idx2char[output_idx[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]]
    

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(jamotools&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;join_jamos(test_sentence))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;동헌에 나가 공무를 본 후 활 십오 순을 쏘았다. 임금이 말하기를,
&amp;ldquo;이보다 큰 공상은 그 집에 돌아오다
정사를 보았다. 임금이 말하기를,
&amp;ldquo;이방성을 아뢰다
함길도 감사가 이미 나라를 행하였다.상왕이 그 사람을 금하다
임금이 말하기를,
&amp;ldquo;이보다 큰 공상은 그 집에 돌아온다. 【모든 것을 보내어 여러 관원은 농산ㄱ&lt;/p&gt;
&lt;p&gt;여기서도 뒤로 가면 비슷한 문장이 다시 나오고 있지만, 한글을 정확하게 조합할 수 있도록 네트워크가 자소를 생성하고 있음을 보여주고 있습니다.&lt;/p&gt;
&lt;h2 id=&#34;iii-정리&#34;&gt;III. 정리&lt;/h2&gt;
&lt;p&gt;여기서 정리해야 하는 것은 순환신경망이 언제 쓰이는 것인지, LSTM, SimpleRNN, GRU레이어에 대해 학습하였습니다.&lt;/p&gt;
&lt;p&gt;기본적인 이론을 중심으로 재 학습을 하는 걸 권해드립니다. 특히, 자연어처리는 아직도 연구중인 분야고, 사실 굉장히 까다롭기 때문에, 학습자가 특별한 Mission이 있지 않으면 감정 분석 정도에서 마무리하는 것이 좋습니다. 자연어처리를 통한 비즈니스 활용 연구는 실제로 대기업에서 본격적인 연구가 가능합니다.&lt;/p&gt;
&lt;p&gt;자연어처리는 학습을 시켜서 아시겠지만, 학습시간이 매우 오래 걸리는 대신, 결과물이 사실 애매모호한 경우가 많습니다. 기본적인 이론을 바탕으로 실무에서는 클라우드를 활용한 서비스 개발(예: 챗봇)에 집중하시는 것을 권유드립니다.&lt;/p&gt;
&lt;h2 id=&#34;iv-연습-파일&#34;&gt;IV. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch7_4_naturalLanguageGeneration(2).ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v-reference&#34;&gt;V. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
&lt;p&gt;Karpathy, A. (2015). The Unreasonable Effectiveness of Recurrent Neural Networks. Retrieved April 26, 2020, from &lt;a href=&#34;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&#34;&gt;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch7.4 - (1) 단어 단위 생성</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration1/</link>
      <pubDate>Mon, 27 Apr 2020 10:20:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration1/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.2 - 다항분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/&#34;&gt;Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/&#34;&gt;Tensorflow 2.0 Tutorial ch6.1-2 - CNN 이론&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_3_fashion_mnist_with_cnn/&#34;&gt;Tensorflow 2.0 Tutorial ch6.3 - Fashion MNIST with CNN 실습&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_4_improve_performance/&#34;&gt;Tensorflow 2.0 Tutorial ch6.4 - 모형의 성능 높이기&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (1)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (2)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_3_sentimentanalysis/&#34;&gt;Tensorflow 2.0 Tutorial ch7.3 - 긍정, 부정 감성 분석&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요&#34;&gt;I. 개요&lt;/h2&gt;
&lt;p&gt;테슬라 &lt;code&gt;AI Director&lt;/code&gt;인 안드레아 카르파티(&lt;code&gt;Andrej Karpathy&lt;/code&gt;)는 &lt;code&gt;The Unreasonable Effectiveness of Recurrent Neural Networks&lt;/code&gt;라는 글을 개인 블로그에 작성했는데, 짧게 요약하면 문자 단위의 순환 신경망이 셰익스피어의 희곡, 소스코드, &lt;code&gt;Latex&lt;/code&gt;등을 재생산하는데 순환 신경망이 효과적이라는 것을 보여줍니다.&lt;/p&gt;
&lt;p&gt;이를 바탕으로, 한글 원본 텍스트를 자소 단위와 단어 단위로 나눠서 순환 신경망으로 생성해보도록 합니다.&lt;/p&gt;
&lt;h2 id=&#34;ii-단어-단위-생성&#34;&gt;II. 단어 단위 생성&lt;/h2&gt;
&lt;p&gt;이번에 작업할 원본 텍스트는 국사편찬위원회에서 제공하는 조선왕조실록 국문 번역본입니다. 먼저 &lt;a href=&#34;https://raw.githubusercontent.com/greentec/greentec.github.io/master/public/other/data/chosundynasty/corpus.txt&#34;&gt;데이터&lt;/a&gt;를 다운로드 합니다.&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;이제 본격적으로 소스코드를 작성하도록 합니다.&lt;/p&gt;
&lt;h3 id=&#34;1-데이터-로드&#34;&gt;(1) 데이터 로드&lt;/h3&gt;
&lt;p&gt;데이터 파일은 약 62MB 정도입니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 텐서플로 2 버전 선택&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
    &lt;span style=&#34;color:#75715e&#34;&gt;# %tensorflow_version only exists in Colab.&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;tensorflow_version &lt;span style=&#34;color:#ae81ff&#34;&gt;2.&lt;/span&gt;x
&lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Exception&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;pass&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;path_to_train_file &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;input.txt&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;https://raw.githubusercontent.com/greentec/greentec.github.io/master/public/other/data/chosundynasty/corpus.txt&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from https://raw.githubusercontent.com/greentec/greentec.github.io/master/public/other/data/chosundynasty/corpus.txt
62013440/62012502 [==============================] - 1s 0us/step
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;데이터를 메모리에 불러옵니다. 인코딩 형식으로 &lt;code&gt;utf-8&lt;/code&gt;을 지정한 뒤 텍스트가 총 몇 자인지 확인해봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train_text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; open(path_to_train_file, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rb&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;decode(encoding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Length of text: {} characters&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(len(train_text)))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Length of text: 26265493 characters
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;처음 100자를 확인한 후, 실제 &lt;a href=&#34;https://raw.githubusercontent.com/greentec/greentec.github.io/master/public/other/data/chosundynasty/corpus.txt&#34;&gt;데이터&lt;/a&gt;와 일치하는지 확인해봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_text[:&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 
태조 강헌 지인 계운 성문 신무 대왕(太祖康獻至仁啓運聖文神武大王)의 성은 이씨(李氏)요, 휘
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;일치하는지 확인이 완료되었다면, 다음 소스코드를 진행하면 됩니다. 다운로드 시, 링크가 달라졌다면, 꼭 댓글을 남겨주시기를 바랍니다.&lt;/p&gt;
&lt;h3 id=&#34;2-데이터-문자열-전처리&#34;&gt;(2) 데이터 문자열 전처리&lt;/h3&gt;
&lt;p&gt;한자가 많은 부분을 차지하는데, 여기에서는 단어 기반의 생성을 위해 한자와 한자가 들어간 괄호는 생략합니다. 이전 포스트에 비슷하지만, 조금 다릅니다. 특히 영문 관련 처리는 모두 삭제했습니다. 또한, 한자와 함께 들어가 있는 괄호도 같이 삭제합니다. 또한, 개행 문자(&#39;\n&amp;rsquo;)의 보존을 위해 텍스트를 먼저 개행 문자로 나눈 뒤에 다시 합칠 때 개행 문자를 추가합니다. 꼭 주의해서 사용자 정의 함수 &lt;code&gt;def&lt;/code&gt;를 작성하시기를 바랍니다. 이렇게 정제 과정을 거치면 한자어와 괄호는 보이지 않을 것입니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; re
&lt;span style=&#34;color:#75715e&#34;&gt;# From https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clean_str&lt;/span&gt;(string):    
    string &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;[^가-힣A-Za-z0-9(),!?\&amp;#39;\`]&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;, string)
    string &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;\&amp;#39;ll&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;ll&amp;#34;&lt;/span&gt;, string)
    string &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;,&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; , &amp;#34;&lt;/span&gt;, string)
    string &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;!&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; ! &amp;#34;&lt;/span&gt;, string)
    string &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;\(&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;, string)
    string &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;\)&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;, string)
    string &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;\?&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; \? &amp;#34;&lt;/span&gt;, string)
    string &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;\s{2,}&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;, string)
    string &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;\&amp;#39;{2,}&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, string)
    string &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;\&amp;#39;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;, string)

    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; string


train_text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
train_text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [clean_str(sentence) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; sentence &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; train_text]
train_text_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; sentence &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; train_text:
    train_text_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;extend(sentence&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; &amp;#39;&lt;/span&gt;))
    train_text_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
    
train_text_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [word &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; word &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; train_text_X &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; word &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;]

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_text_X[:&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[&#39;태조&#39;, &#39;이성계&#39;, &#39;선대의&#39;, &#39;가계&#39;, &#39;목조&#39;, &#39;이안사가&#39;, &#39;전주에서&#39;, &#39;삼척&#39;, &#39;의주를&#39;, &#39;거쳐&#39;, &#39;알동에&#39;, &#39;정착하다&#39;, &#39;\n&#39;, &#39;태조&#39;, &#39;강헌&#39;, &#39;지인&#39;, &#39;계운&#39;, &#39;성문&#39;, &#39;신무&#39;, &#39;대왕&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;결과가 잘 나온 것을 확인할 수 있습니다. 이제 단어를 토큰화합니다. 이 때, &lt;code&gt;Tokenizer&lt;/code&gt;를 쓰지 않고, 직접 토큰화합니다. 단어의 수가 너무 많고, 모든 단어를 사용할 것이기 때문에, 단어의 빈도 수로 단어를 정렬하는 &lt;code&gt;Tokenizer&lt;/code&gt;를 쓰면 불필요하게 많은 계산 시간을 쓰게 된다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;vocab &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sorted(set(train_text_X))
vocab&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;UNK&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; (&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{} unique words&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(len(vocab)))

&lt;span style=&#34;color:#75715e&#34;&gt;# vocab list를 숫자로 맵핑하고, 반대도 실행합니다.&lt;/span&gt;
word2idx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {u:i &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i, u &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(vocab)}
idx2word &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(vocab)

text_as_int &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([word2idx[c] &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; train_text_X])

&lt;span style=&#34;color:#75715e&#34;&gt;# word2idx 의 일부를 알아보기 쉽게 print 해봅니다.&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; word,_ &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(word2idx, range(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;)):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;  {:4s}: {:3d},&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(repr(word), word2idx[word]))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;  ...&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;}&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;index of UNK: {}&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(word2idx[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;UNK&amp;#39;&lt;/span&gt;]))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;332640 unique words
{
  &#39;\n&#39;:   0,
  &#39;!&#39; :   1,
  &#39;,&#39; :   2,
  &#39;000명으로&#39;:   3,
  &#39;001&#39;:   4,
  &#39;002&#39;:   5,
  &#39;003&#39;:   6,
  &#39;004&#39;:   7,
  &#39;005&#39;:   8,
  &#39;006&#39;:   9,
  ...
}
index of UNK: 332639
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;2번째 줄에서 텍스트에 들어간 각 단어가 중복되지 않는 리스트를 만든 다음에, 3번째 줄에서는 텍스트에 존재하지 않는 토큰을 &lt;code&gt;UNK&lt;/code&gt;를 넣습니다. 총 단어 수는 332,640이고, 이 중 &lt;code&gt;UNK&lt;/code&gt;의 인덱스는 332,639입니다. 이 인덱스는 나중에 임의의 문장을 입력할 때 텍스트에 미리 준비돼 있지 않았던 단어를 쓸 수 있기 때문에 그에 대한 토큰으로 쓰일 것입니다.&lt;/p&gt;
&lt;p&gt;토큰화가 잘 되었는지 확인하기 위해 처음 20개의 단어에 대한 토큰을 출력합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_text_X[:&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;])
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(text_as_int[:&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[&#39;태조&#39;, &#39;이성계&#39;, &#39;선대의&#39;, &#39;가계&#39;, &#39;목조&#39;, &#39;이안사가&#39;, &#39;전주에서&#39;, &#39;삼척&#39;, &#39;의주를&#39;, &#39;거쳐&#39;, &#39;알동에&#39;, &#39;정착하다&#39;, &#39;\n&#39;, &#39;태조&#39;, &#39;강헌&#39;, &#39;지인&#39;, &#39;계운&#39;, &#39;성문&#39;, &#39;신무&#39;, &#39;대왕&#39;]
[299305 229634 161443  17430 111029 230292 251081 155087 225462  29027
 190295 256129      0 299305  25624 273553  36147 163996 180466  84413]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;태조&lt;/code&gt;는 299,305로 &lt;code&gt;이성계&lt;/code&gt;는 229,634로, 개행 문자는 0으로 토큰 변환이 된 것을 확인할 수 있습니다. 이제 학습을 위한 데이터세트를 만듭니다.&lt;/p&gt;
&lt;h3 id=&#34;3-데이터셋-생성&#34;&gt;(3) 데이터셋 생성&lt;/h3&gt;
&lt;p&gt;이 때, 기존과는 다르게, &lt;code&gt;train_X&lt;/code&gt;, &lt;code&gt;train_Y&lt;/code&gt;를 넘파이 &lt;code&gt;array&lt;/code&gt;로 만드는 방식이 아닌 &lt;code&gt;tf.data.Dataset&lt;/code&gt;를 이용해봅니다. &lt;code&gt;Dataset&lt;/code&gt;의 장점은 간단한 코드로 데이터 섞기, 배치(&lt;code&gt;batch&lt;/code&gt;)수만큼 자르기, 다른 &lt;code&gt;Dataset&lt;/code&gt;에 매핑하기 등을 빠르게 수행할 수 있습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;seq_length &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;
examples_per_epoch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; len(text_as_int) &lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt; seq_length
sentence_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_tensor_slices(text_as_int)

sentence_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sentence_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;batch(seq_length&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, drop_remainder&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; item &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; sentence_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;take(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(idx2word[item&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()])
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(item&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[&#39;태조&#39; &#39;이성계&#39; &#39;선대의&#39; &#39;가계&#39; &#39;목조&#39; &#39;이안사가&#39; &#39;전주에서&#39; &#39;삼척&#39; &#39;의주를&#39; &#39;거쳐&#39; &#39;알동에&#39; &#39;정착하다&#39;
 &#39;\n&#39; &#39;태조&#39; &#39;강헌&#39; &#39;지인&#39; &#39;계운&#39; &#39;성문&#39; &#39;신무&#39; &#39;대왕&#39; &#39;의&#39; &#39;성은&#39; &#39;이씨&#39; &#39;요&#39; &#39;,&#39; &#39;휘&#39;]
[299305 229634 161443  17430 111029 230292 251081 155087 225462  29027
 190295 256129      0 299305  25624 273553  36147 163996 180466  84413
 224182 164549 230248 210912      2 330313]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;여기서는 &lt;code&gt;seq_length&lt;/code&gt;를 25로 설정해서 25개의 단어가 주어졌을 때, 다음 단어를 예측하도록 데이터를 만듭니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;sentence_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_tensor_slices(text_as_int)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;Dataset&lt;/code&gt;를 생성하는 코드는 위와 같이 한 줄로 간단합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;sentence_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sentence_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;batch(seq_length&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, drop_remainder&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Dataset&lt;/code&gt;에 쓰이는 &lt;code&gt;batch()&lt;/code&gt;함수는 &lt;code&gt;Dataset&lt;/code&gt;에서 한번에 반환하는 데이터의 숫자를 지정합니다.&lt;/li&gt;
&lt;li&gt;여기에서는 &lt;code&gt;seq_length_1&lt;/code&gt;을 지정했는데, 처음의 25개 단어와 그 뒤에 오는 정답이 될 1단어를 합쳐서 함께 반환하기 위해서입니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;drop_remainder=True&lt;/code&gt;옵션으로 남는 부분은 버리도록 합니다. 그러면 출력해서 의도한대로 26단어가 반환되는 것을 확인할 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;split_input_target&lt;/span&gt;(chunk):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; [chunk[:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], chunk[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]]

train_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sentence_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;map(split_input_target)
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; x,y &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; train_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;take(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(idx2word[x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()])
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy())
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(idx2word[y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()])
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[&#39;태조&#39; &#39;이성계&#39; &#39;선대의&#39; &#39;가계&#39; &#39;목조&#39; &#39;이안사가&#39; &#39;전주에서&#39; &#39;삼척&#39; &#39;의주를&#39; &#39;거쳐&#39; &#39;알동에&#39; &#39;정착하다&#39;
 &#39;\n&#39; &#39;태조&#39; &#39;강헌&#39; &#39;지인&#39; &#39;계운&#39; &#39;성문&#39; &#39;신무&#39; &#39;대왕&#39; &#39;의&#39; &#39;성은&#39; &#39;이씨&#39; &#39;요&#39; &#39;,&#39;]
[299305 229634 161443  17430 111029 230292 251081 155087 225462  29027
 190295 256129      0 299305  25624 273553  36147 163996 180466  84413
 224182 164549 230248 210912      2]
휘
330313
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;위 코드의 목적은 기존 &lt;code&gt;Dataset&lt;/code&gt;으로 새로운 &lt;code&gt;Dataset&lt;/code&gt;으로 만드는 과정입니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;26개의 단어가 각각 입력과 정답으로 묶어서([25단어], 1단어) 형태의 데이터를 반환하게 만드는 &lt;code&gt;Dataset&lt;/code&gt;을 만드는 것입니다.&lt;/li&gt;
&lt;li&gt;먼저, 26개의 단어를 25단어, 1단어로 잘라주는 함수를 &lt;code&gt;split_input_target(chunk)&lt;/code&gt;로 정의한 다음 이 함수를 기존 &lt;code&gt;sentence_dataset&lt;/code&gt;에 &lt;code&gt;map()&lt;/code&gt;함수(참조: 텐서플로 &lt;a href=&#34;http://bit.ly/2GZTyW1&#34;&gt;map 함수&lt;/a&gt;)를 이용해 새로운 데이터세트인 &lt;code&gt;train_dataset&lt;/code&gt;를 만듭니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;4-shuffle-batch-설정&#34;&gt;(4) Shuffle, Batch 설정&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Dataset&lt;/code&gt;의 데이터를 섞고, &lt;code&gt;batch_size&lt;/code&gt;를 다시 설정합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;BATCH_SIZE &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;512&lt;/span&gt;
steps_per_epoch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; examples_per_epoch &lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt; BATCH_SIZE
BUFFER_SIZE &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10000&lt;/span&gt;

train_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shuffle(BUFFER_SIZE)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;batch(BATCH_SIZE, drop_remainder&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;주의: 이 부분은 교재와 조금 상이합니다! 따라서, 위 코드로 구현 바랍니다.&lt;/p&gt;
&lt;p&gt;빠른 학습을 위해 한번에 512개의 데이터를 학습하게 하고, 데이터를 섞을 때의 &lt;code&gt;BUFFER_SIZE&lt;/code&gt;는 10,000으로 설정합니다. &lt;code&gt;tf.data&lt;/code&gt;는 이론적으로 무한한 데이터에 대해 대응 가능하기 때문에 한번에 모든 데이터를 섞지 않습니다. 따라서, 버퍼에 일정한 양의 데이터를 올려놓고 섞는데, 그 사이즈를 &lt;code&gt;10,000&lt;/code&gt;으로 설정한 것입니다.&lt;/p&gt;
&lt;h3 id=&#34;5-생성-모델-정의&#34;&gt;(5) 생성 모델 정의&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;total_words &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; len(vocab)
model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Embedding(total_words, &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, input_length&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;seq_length),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;LSTM(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, return_sequences&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;LSTM(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(total_words, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;)
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;adam&amp;#39;&lt;/span&gt;, loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sparse_categorical_crossentropy&amp;#39;&lt;/span&gt;, metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, 25, 100)           33264000  
_________________________________________________________________
lstm (LSTM)                  (None, 25, 100)           80400     
_________________________________________________________________
dropout (Dropout)            (None, 25, 100)           0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 100)               80400     
_________________________________________________________________
dense (Dense)                (None, 332640)            33596640  
=================================================================
Total params: 67,021,440
Trainable params: 67,021,440
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;위 소스코드를 통해서 얻고자 하는 결과물은 주어진 입력에 대해 332,640개의 단어 중 어떤 단어를 선택해야 하는지 고르게 하는 기능을 하게 만듭니다.&lt;/p&gt;
&lt;p&gt;이제 학습을 시킵니다. 그런데, 이번에 학습시키는 방법은 기존과 조금 다르니 주의깊게 소스코드를 확인하시기를 바랍니다.&lt;/p&gt;
&lt;p&gt;또한, 학습시간이 GPU로 할당해도 매우 길기 때문에, 모형 학습 시간 계획을 잘 세우기를 바랍니다. (참고: 안 에포크당 10분 정도 소요됨)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras.preprocessing.sequence &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pad_sequences

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testmodel&lt;/span&gt;(epoch, logs):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; epoch &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; epoch &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;49&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt;
    test_sentence &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_text[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]

    next_words &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; _ &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(next_words):
        test_text_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_sentence&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; &amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;seq_length:]
        test_text_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([word2idx[c] &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; word2idx &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; word2idx[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;UNK&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; test_text_X])
        test_text_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pad_sequences([test_text_X], maxlen&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;seq_length, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pre&amp;#39;&lt;/span&gt;, value&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;word2idx[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;UNK&amp;#39;&lt;/span&gt;])

        output_idx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict_classes(test_text_X)
        test_sentence &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; idx2word[output_idx[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]]
    
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;()
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(test_sentence)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;()

testmodelcb &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;callbacks&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;LambdaCallback(on_epoch_end&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;testmodel)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;repeat(), epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, steps_per_epoch&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;steps_per_epoch, callbacks&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[testmodelcb], verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Epoch 1/50&lt;/p&gt;
&lt;p&gt;태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다  , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,&lt;/p&gt;
&lt;p&gt;533/533 - 255s - loss: 9.3702 - accuracy: 0.0723
Epoch 2/50
533/533 - 249s - loss: 8.3646 - accuracy: 0.0741
Epoch 3/50
533/533 - 249s - loss: 8.0768 - accuracy: 0.0816
Epoch 4/50
533/533 - 249s - loss: 7.8147 - accuracy: 0.0911
Epoch 5/50
533/533 - 249s - loss: 7.5722 - accuracy: 0.1025
Epoch 6/50&lt;/p&gt;
&lt;p&gt;태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다  , , , , , , 그 , , 그 것은 , 그 것은 , 그 것은 , 그 것은 , 그 것은 , 그 것은 , 그 것은 , 그 것은 , 그 것은 , 그 것은 , 그 것은 , 그 것은 , 그 것은 , 그 것은 , 그 것은 , 그 것은 , 그 것은 , 그 것은 , 그 것은 , 그 것은 , 그 것은 , 그 것은 , 그 것은 , 그 것은 , 그 것은 , 그 것은 , 그 것은 , 그 것은 , 그 것은 , 그 것은 , 그&lt;/p&gt;
&lt;p&gt;533/533 - 250s - loss: 7.3301 - accuracy: 0.1165
Epoch 7/50
533/533 - 249s - loss: 7.0574 - accuracy: 0.1305
Epoch 8/50
533/533 - 249s - loss: 6.7848 - accuracy: 0.1433
Epoch 9/50
533/533 - 249s - loss: 6.5153 - accuracy: 0.1555
Epoch 10/50
533/533 - 249s - loss: 6.2694 - accuracy: 0.1679
Epoch 11/50&lt;/p&gt;
&lt;p&gt;태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다  등 것입니다
하니 , 임금이 말하기를 ,
상참을 받고 , 임금이 아뢰기를 ,
이 받고 그 일을 다 다 다 가지고 주고 , 그 거느리고 다 화살을 내어 주고 , 이는 아뢰기를 ,
함길도 의 서쪽에 서향하여 없는 것입니다 또 아뢰기를 ,
이 받고 반드시 보내어 가서 가지고 가서 가서 주고 , 그 거느리고 의하여 서향하여 있으니 , 그 받고 , 아뢰기를 ,
그 일을 가지고 서향하여 서게 하고 , 그 받고 몸을 아뢰기를 ,
예조에서 아뢰기를 ,
함길도 의 서쪽에 인도하여 가지고 주고 , 아뢰기를 ,
평안도 의 서쪽에 서향하여&lt;/p&gt;
&lt;p&gt;533/533 - 250s - loss: 6.0086 - accuracy: 0.1822
Epoch 12/50
533/533 - 249s - loss: 5.7584 - accuracy: 0.1960
Epoch 13/50
533/533 - 248s - loss: 5.5062 - accuracy: 0.2102
Epoch 14/50
533/533 - 249s - loss: 5.2491 - accuracy: 0.2261
Epoch 15/50
533/533 - 249s - loss: 4.9958 - accuracy: 0.2423
Epoch 16/50&lt;/p&gt;
&lt;p&gt;태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다  것이니 , 그 뜻을 다 알지 것이 없습니다 지금 내가 비록 여러 것은 모두 다 일을 다 일을 다 일을 다 말을 말을 다 알고 , 지금 만일 다시 가서 가서 아뢰게 하고 , 드디어 비가 보내어 가서 가서 토물 을 바쳤다 조회를 받았다 을축년 관찰사에게 이르기 살기가 , 의정부에서 아뢰기를 ,
맹규의 관찰사에게 유시하기를 ,
맹규의 벼슬만 아니오라 , 왕비가 관찰사에게 유시하기를 ,
중추원 관찰사에게 유시하기를 ,
중추원 부사 권맹경이
하였다 전 도절제사 부사 로 하여금 상언 하기를 ,
맹규의 관찰사에게 유시하기를 ,
맹규의 죄수 벌할 하게 ,
세자가 아뢰기를 ,&lt;/p&gt;
&lt;p&gt;533/533 - 249s - loss: 4.7473 - accuracy: 0.2599
Epoch 17/50
533/533 - 249s - loss: 4.5038 - accuracy: 0.2782
Epoch 18/50
533/533 - 249s - loss: 4.2670 - accuracy: 0.2984
Epoch 19/50
533/533 - 249s - loss: 4.0450 - accuracy: 0.3195
Epoch 20/50
533/533 - 249s - loss: 3.8258 - accuracy: 0.3440
Epoch 21/50&lt;/p&gt;
&lt;p&gt;태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다  것이다 고 하고 , 그 말을 있고 , 모두 같이 같이 같이 같이 한다 또한 있고 한 것은 더욱 말을 있는 것은 모두 이를 살피게 하라
하였다 일본국 정난 공신 에게 유시 하기를 ,
일본국 병조 에서 상서 하여 각각 더불어 제수 로 하여금 함께 의논하여 가서 아뢰니 , 일본국 명나라 정문 에 의거하여 아뢰니 , 임금이 말하기를 ,
일본국 상송포 새긴들 다만 정난 신숙주 에게 유시 하기를 ,
일본국 병조 에서 전지 하기를 ,
이 사람을 보내어 와서 와서 가서 와서 이르기를 ,
경 은 하직하니 , 그 죄는 와서 와서 의논하게 하였다&lt;/p&gt;
&lt;p&gt;533/533 - 250s - loss: 3.6157 - accuracy: 0.3703
Epoch 22/50
533/533 - 249s - loss: 3.4163 - accuracy: 0.3981
Epoch 23/50
533/533 - 249s - loss: 3.2208 - accuracy: 0.4284
Epoch 24/50
533/533 - 249s - loss: 3.0313 - accuracy: 0.4601
Epoch 25/50
533/533 - 249s - loss: 2.8555 - accuracy: 0.4897
Epoch 26/50&lt;/p&gt;
&lt;p&gt;태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다  것인데 , 만약 혹은 좋은 자는 백성을 주고 , 혹은 폐단이 있어 있어 오래 자가 나누어 주고 , 반드시 말을 일을 가지고 나누어 보내어 가게 하고 , 만일 병이 사실을 염려하여 , 드디어 말하기를 ,
함길도 도절제사 의 죄는 돌아와서 보내지 않은 것을 옮겨 주어 아뢰게 하고 , 만일 자기 베어 징계하소서
예조 에서 공조 판서 겸 형조 참판 제학 이조 등이 불러 불러서 조용히 전하다
경상도 상호군 박경무 으로 종이 대부 로 삼았다 함길도 도절제사 에서 와서 와서 내려 죄를 가서 아뢰다
사헌부에서 아뢰기를 ,
함길도 나라 일로 감사 의 개를 바치었다 햇무리가 쏘았다&lt;/p&gt;
&lt;p&gt;533/533 - 250s - loss: 2.6946 - accuracy: 0.5192
Epoch 27/50
533/533 - 248s - loss: 2.5327 - accuracy: 0.5480
Epoch 28/50
533/533 - 249s - loss: 2.3733 - accuracy: 0.5766
Epoch 29/50
533/533 - 249s - loss: 2.2233 - accuracy: 0.6036
Epoch 30/50
533/533 - 249s - loss: 2.0778 - accuracy: 0.6309
Epoch 31/50&lt;/p&gt;
&lt;p&gt;태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다  되고 , 청컨대 본조 수는 없는데 , 무릇 여러 일은 이미 심히 알지 자는 서로 알 것이다 또한 이미 여러 사람이 심히 말을 사람을 얻게 합니다 이에 갖추어 아뢰니 , 드디어 세자에게 거둥하여 사실을 묻게 하였으나 , 임금이 말하기를 ,
이 사람을 거느리고 가서 와서 이르기를 ,
이 사람을 보내 토산물을 바쳤다 나도 아뢴 않겠는가
하였다 임금이 말하기를 ,
전하께서 전지 에서 함께 사사로이 듣고 아뢰게 하고 , 만일 잘못 묻지는 를 올려 국문 하여 계문 하여 이러하였다
대간 으로 사제 를 하사하다
대간 에 내리니 , 전하께서 다시 와서 가서 잘 알지 것은&lt;/p&gt;
&lt;p&gt;533/533 - 250s - loss: 1.9361 - accuracy: 0.6555
Epoch 32/50
533/533 - 249s - loss: 1.8070 - accuracy: 0.6788
Epoch 33/50
533/533 - 249s - loss: 1.6785 - accuracy: 0.7029
Epoch 34/50
533/533 - 249s - loss: 1.5642 - accuracy: 0.7236
Epoch 35/50
533/533 - 249s - loss: 1.4530 - accuracy: 0.7431
Epoch 36/50&lt;/p&gt;
&lt;p&gt;태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다  된다 말하다 , 사의가 음악은 옳을 수는 없으니 , 본조 가 같이 같이 같이 있고 북쪽을 안 한 뒤에 모두 다 자리로 나아간다
창한다 마치면 , 통찬이 윤대를 행하고 , 신의 하나는 인도하여 내려와 제자리로 돌아간다 집례가 사배하라 찬하여 , 배 이하가 모두 꿇어앉는다 무릇 다음에 정한 것도 돌아간다 찬자가 사배하라 찬하면 , 감찰 는 단 가 자리에 나아간다 찬인이 감찰과 여러 때의 의식과 같이 한다 집례가 그 곡하라 하면 , 다음에 꿇어앉는다 여러 사람이 각기 각기 각기 자리에 나아간다 알자가 술잔을 씻고 올라가 인도하여 자리에 나간다 집례가 사배하라 찬하면 , 흥 , 흥 , 흥 , 흥 ,&lt;/p&gt;
&lt;p&gt;533/533 - 250s - loss: 1.3488 - accuracy: 0.7627
Epoch 37/50
533/533 - 249s - loss: 1.2497 - accuracy: 0.7815
Epoch 38/50
533/533 - 248s - loss: 1.1613 - accuracy: 0.7968
Epoch 39/50
533/533 - 249s - loss: 1.0768 - accuracy: 0.8122
Epoch 40/50
533/533 - 249s - loss: 0.9966 - accuracy: 0.8267
Epoch 41/50&lt;/p&gt;
&lt;p&gt;태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다  되고 , 청컨대 그전 무지한 곳이 없게 되니 , 물러가 가까이 가고 , 혹은 도로 사람이 있을 것이다 진실로 이미 가 서로 폐단이 심히 남겨서 대신의 무리들이 급히 주게 하고 , 그 온 1백 콩 1백 명을 조사하여 급히 오늘에 가서 크게 시종 중에 살펴보게 한다든가 허락하지 아니하였다 신이 그 죄가 와서 와서 가서 청하여 임금의 두게 하소서
하니 , 의금부에서 아뢰기를 ,
평안도 토관 죄수 벌송 애오라지 염법 을 내리어 의논하게 하므로 , 무릇 부득이하여 보면 , 무릇 성상께서 생각해 나아가 바로 전의 를 인도하여 주어 서향하게 하고 , 다음은 나라가 정한 지경에 너무 가지고 반드시 모두&lt;/p&gt;
&lt;p&gt;533/533 - 250s - loss: 0.9232 - accuracy: 0.8399
Epoch 42/50
533/533 - 249s - loss: 0.8571 - accuracy: 0.8523
Epoch 43/50
533/533 - 249s - loss: 0.7950 - accuracy: 0.8637
Epoch 44/50
533/533 - 249s - loss: 0.7335 - accuracy: 0.8753
Epoch 45/50
533/533 - 249s - loss: 0.6764 - accuracy: 0.8857
Epoch 46/50&lt;/p&gt;
&lt;p&gt;태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다  되고 , 청컨대 혹은 감한 많으며 , 겨우 휘 를 올리고 종자 가 서로 알 것이다 또한 감히 뒤에 모두 서로 폐단을 알 것이다 그러나 경 등과 천지 인 약정하기를 사직 과 더불어 글을 모여서 가서 본 말은 서울과 70이 민간에 시행할 있지 않는 것이니 , 이에 어질고 떨어져 구 에 참여하지 않을 것이니 , 마침내 그를 오지 아니하고 , 대개 속전 에 붙여 들지 아니할 것이니 , 그것을 그르다 힘쓰고 수양 3천 떼가 박천 2개는 모순 천하가 의논했다고 되었다 청백 양씨 중후 처소 740 강호덕 615 박사란 김선거 연변에 이등 씩 음식도 어리고 2명씩 뵙고 일본의 주었사오니 하옵고 침체&lt;/p&gt;
&lt;p&gt;533/533 - 250s - loss: 0.6241 - accuracy: 0.8957
Epoch 47/50
533/533 - 249s - loss: 0.5790 - accuracy: 0.9038
Epoch 48/50
533/533 - 249s - loss: 0.5355 - accuracy: 0.9114
Epoch 49/50
533/533 - 249s - loss: 0.4964 - accuracy: 0.9183
Epoch 50/50&lt;/p&gt;
&lt;p&gt;태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다  들을 것과 , 본조 가 없으면 서향하게 것입니다 만약 먼저 단 가 있고 , 한 법이 같이 같이 같이 되어 한 일이 있을 일이 없습니다 그러나 , 이제부터는 진휼사 에 술을 받들어 그 자리에 매우 옳지 를 나아가서 , 내가 그 아비를 가서 온 사람은 한번 가상히 부임 하여 이러한 때 아울러 국문 하여 외방 전의 일수 를 받들어 잡희 를 나아가서 나아가서 나가고 , 이어서 병법 과 악 을 외유 일어나고 , 의장 을 더하여 적당히 판위 에 올라 그치게 하되 , 앙제 에 나아가서 꿇어앉아 나아가서 선다 판통례가 , 다만 술 서문 궤 앞으로 나아가 부복하고 꿇어앉아 부복&lt;/p&gt;
&lt;p&gt;533/533 - 250s - loss: 0.4581 - accuracy: 0.9256&lt;/p&gt;
&lt;p&gt;먼저 모델을 학습시키면서 모델의 생성 결과물을 확인하기 위해 &lt;code&gt;testmodel&lt;/code&gt;이라는 이름으로 콜백 함수를 정의합니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;조금 더 콜백 함수에 대해서 정의를 내리면, 먼저 임의의 문장을 입력한 다음, &lt;code&gt;seq_length&lt;/code&gt;만큼의 단어 25개를 선택합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;test_test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_sentence&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; &amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;seg_length:]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;그 다음에는 문장의 단어를 인덱스 토큰으로 바꿉니다. 이 때 사전에 등록되어 있지 않은 단어의 경우에는 &lt;code&gt;UNK&lt;/code&gt; 토큰 값으로 바꿉니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;test_text_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pad_sequences([test_text_X], maxlen &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; seq_length, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pre&amp;#39;&lt;/span&gt;, value&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;word2idx[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;UNK&amp;#39;&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;pad_sequences()&lt;/code&gt;로 문장의 앞쪽이 빈 자리가 있을 경우 25단어가 채워지도록 패딩을 넣습니다. 이 때 패딩 갑인 &lt;code&gt;value&lt;/code&gt;인수에는 앞에서 지정했던 &lt;code&gt;UNK&lt;/code&gt; 토큰의 값인 &lt;code&gt;word2idx[&#39;UNK&#39;]&lt;/code&gt;를 사용합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;output_idx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict_classes(test_text_X)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;model.predict()&lt;/code&gt;는 &lt;code&gt;Dense&lt;/code&gt;레이어의 332,640개의 값을 반환하기 때문에 출력을 간결하게 하기 위해 &lt;code&gt;model.predict_classes()&lt;/code&gt;함수를 사용합니다. 이 함수는 출력 중에서 가장 값이 큰 인덱스를 반환합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;test_sentence &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; idx2word[output_idx[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;출력 단어는 test_sentence의 끝 부분에 저장되어 다음 스텝의 입력에 활용됩니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이렇게 정의된 콜백 함수는 &lt;code&gt;testmodelcb&lt;/code&gt;라는 이름으로 저장되어 &lt;code&gt;tf.keras&lt;/code&gt;의 &lt;code&gt;model.fit()&lt;/code&gt;의 &lt;code&gt;callbacks&lt;/code&gt;인수에 포함됩니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;마지막으로 모형을 학습시킵니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;repeat(), epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, steps_per_epoch&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;steps_per_epoch, callbacks&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[testmodelcb], verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;학습을 시킬 때도 위에서 정의한 &lt;code&gt;Dataset&lt;/code&gt;을 활용합니다. 그런데 주목해야 할 점은 &lt;code&gt;Dataset&lt;/code&gt;에서 데이터를 끊임없이 반환하도록 &lt;code&gt;repeat()&lt;/code&gt;함수를 사용합나다.&lt;/li&gt;
&lt;li&gt;넘파이 &lt;code&gt;array&lt;/code&gt; 형태의 데이터를 사용할 때는 에포크마다 데이터를 한번씩 순회시켰지만, &lt;code&gt;Dataset&lt;/code&gt;을 사용하면 데이터의 시작과 끝을 알 수 없기 때문에 에포크에 데이터를 얼마나 학습시키질를 &lt;code&gt;steps_per_epoch&lt;/code&gt; 인수로 지정합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;학습 결과를 살펴보면 처음에는 의미없는 단어가 반복되지만, 학습을 진행하면서 문맥이 연결되는 것을 확인할 수 있습니다.&lt;/p&gt;
&lt;h3 id=&#34;6-임의의-문장을-사용한-단어-생성-확인&#34;&gt;(6) 임의의 문장을 사용한 단어 생성 확인&lt;/h3&gt;
&lt;p&gt;이제 임의의 문장을 넣어 학습이 잘 되는지 난중일기의 한 구절을 입력해봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras.preprocessing.sequence &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pad_sequences
test_sentence &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;동헌에 나가 공무를 본 후 활 십오 순을 쏘았다&amp;#39;&lt;/span&gt;

next_words &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; _ &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(next_words):
    test_text_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_sentence&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; &amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;seq_length:]
    test_text_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([word2idx[c] &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; word2idx &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; word2idx[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;UNK&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; test_text_X])
    test_text_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pad_sequences([test_text_X], maxlen&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;seq_length, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pre&amp;#39;&lt;/span&gt;, value&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;word2idx[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;UNK&amp;#39;&lt;/span&gt;])
    
    output_idx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict_classes(test_text_X)
    test_sentence &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; idx2word[output_idx[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]]

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(test_sentence)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;동헌에 나가 공무를 본 후 활 십오 순을 쏘았다 그곳의 사로잡힌 대리하는 호군직 2개는 놓기도 토의 으로써 차임 되고 , 저들은 일시에 굳게 것으로서 주고 , 더욱 높은 바가 많아서 정위 라 같다 하는데 하였습니다 빈자 는 부의 에 도와서 알아야 하여 주소서
하니 , 형조 에서 교지 를 하사하고 충청도 도절제사 에서 다시 와서 와서 내려 쓸 하고 , 만일 잘 가는 것이 없었다 상수의 대한 한 한 뒤에 모두 능히 서로 알지 것은 감히 모두 모두 모두 사람을 죄를 죄를 사람을 죄를 온 한 사람을 삼가서 어질고 그믐날에 한다는 것이니 , 청컨대 이러한 정성을 알아서 난 를 정하여 급히 원하는 곳에 두고 특별히 징계하여 인도해 특별히&lt;/p&gt;
&lt;p&gt;전체적인 문장의 의미가 통하는 건 아닙니다만, 부분 부분에서는 자연스럽게 연결되는 단어들이 보이는 것을 확인할 수 있습니다.&lt;/p&gt;
&lt;h2 id=&#34;iii-연습-파일&#34;&gt;III. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch7_4_naturalLanguageGeneration(1).ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;iv-reference&#34;&gt;IV. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
&lt;p&gt;Karpathy, A. (2015). The Unreasonable Effectiveness of Recurrent Neural Networks. Retrieved April 26, 2020, from &lt;a href=&#34;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&#34;&gt;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&lt;/a&gt;&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;교재에서는 전체 데이터(400MB) 중, 62MB만 잘라낸 파일을 사용했습니다. &lt;a href=&#34;https://www.data.go.kr/&#34;&gt;공공데이터포털&lt;/a&gt;에서 조선왕조실록 데이터를 다운로드 받을 수 있습니다. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch7.3 - 긍정, 부정 감성 분석</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch7_3_sentimentanalysis/</link>
      <pubDate>Sat, 25 Apr 2020 11:08:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch7_3_sentimentanalysis/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.2 - 다항분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/&#34;&gt;Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/&#34;&gt;Tensorflow 2.0 Tutorial ch6.1-2 - CNN 이론&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_3_fashion_mnist_with_cnn/&#34;&gt;Tensorflow 2.0 Tutorial ch6.3 - Fashion MNIST with CNN 실습&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_4_improve_performance/&#34;&gt;Tensorflow 2.0 Tutorial ch6.4 - 모형의 성능 높이기&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (1)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (2)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요&#34;&gt;I. 개요&lt;/h2&gt;
&lt;p&gt;감성 분석은 입력된 자연어 안의 주관적 의견, 감정 등을 찾아내는 문제입니다. 문장의 긍정/부정이나 긍정/중립/부정을 분류합니다.&lt;/p&gt;
&lt;p&gt;영화 리뷰나 음식점 리뷰는 데이터의 양이 많고 별점을 함께 달기 때문에 긍정/중립/부정 라벨링이 쉬워서 극성 감성 분석에 쉽게 적용이 가능합니다.&lt;/p&gt;
&lt;h2 id=&#34;ii-감정분석-소스-작성-및-설명&#34;&gt;II. 감정분석 소스 작성 및 설명&lt;/h2&gt;
&lt;p&gt;네이버의 박은정 박사가 2015년에 발표한 &amp;ldquo;Naver Sentiment Movie Corpus v1.0&amp;quot;을 이용해 긍정/부정 감성 분석을 해봅니다.&lt;/p&gt;
&lt;p&gt;여기에는 훈련 데이터로 15만개, 테스트 데이터로 5만개로 총 20만개의 리뷰가 있습니다.&lt;/p&gt;
&lt;p&gt;리뷰 중 10만 개븐 별점이 1-4로 부정적인 리뷰이고, 나머지 10만개는 9-10으로 긍정적인 리뷰입니다. 별점 5-8에 해당하는 리뷰는 중립적이라고도 볼 수 있지만, 데이터 세트에서는 제외합니다.&lt;/p&gt;
&lt;h3 id=&#34;1-데이터-로드&#34;&gt;(1) 데이터 로드&lt;/h3&gt;
&lt;p&gt;박은정 박사 깃허브에 올라와 있는 데이터를 가져오도록 합니다. 별도 파일을 로컬로 내려받을 필요 없이 직접 깃허브에서 가져와서 구글 코랩에 연동할 수 있도록 하는 코드입니다. 특히 딥러닝 예제는 일반적인 머신러닝과 달리 데이터의 양이 클 수 밖에 없습니다. 그러니, 꼭 참조하시기를 바랍니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 텐서플로 2 버전 선택&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
    &lt;span style=&#34;color:#75715e&#34;&gt;# %tensorflow_version only exists in Colab.&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;tensorflow_version &lt;span style=&#34;color:#ae81ff&#34;&gt;2.&lt;/span&gt;x
&lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Exception&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;pass&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;path_to_train_file &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;train.txt&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt&amp;#39;&lt;/span&gt;)
path_to_test_file &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;test.txt&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt
14630912/14628807 [==============================] - 0s 0us/step
Downloading data from https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt
4898816/4893335 [==============================] - 0s 0us/step
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;다운로드가 완료되면 데이터를 메모리에 불러옵니다. 이 때 데이터가 어떻게 생겼는지 간단하게 확인해 볼 수 있습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train_text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; open(path_to_train_file, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rb&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;decode(encoding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;)
test_text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; open(path_to_test_file, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rb&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;decode(encoding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# 텍스트가 총 몇 자인지 확인해봅니다. &lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Length of text: {} characters&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(len(train_text)))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;((&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Length of text: {} characters&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(len(test_text))))

&lt;span style=&#34;color:#75715e&#34;&gt;# 처음 300자를 확인해봅니다. &lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_text[:&lt;span style=&#34;color:#ae81ff&#34;&gt;300&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Length of text: 6937271 characters
Length of text: 2318260 characters
id	document	label
9976970	아 더빙.. 진짜 짜증나네요 목소리	0
3819312	흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나	1
10265843	너무재밓었다그래서보는것을추천한다	0
9045019	교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정	0
6483659	사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다	1
5403919	막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.	0
7797314	원작의
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;데이터의 각 행은 탭 문자(\t)로 구분되어 있습니다. 처음의 &lt;code&gt;id&lt;/code&gt;는 각 데이터의 고유한 &lt;code&gt;id&lt;/code&gt;이고, document는 실제 리뷰 내용입니다. &lt;code&gt;label&lt;/code&gt;은 긍정/부정을 나타내는 값으로, 0은 부정, 1은 긍정입니다.&lt;/p&gt;
&lt;p&gt;책에는 기술되어 있지 않은 실무적인 내용을 조금 기술합니다 (물론 필자의 주관적인 견해입니다). 국내외 딥러닝의 연구 및 적용 사례는 대기업 수준에서는 활발하게 이루어지고 있지만, 실제 대다수가 사용되어야 할 일반적인 쇼핑몰 등에서는 거의 사용되지 않고 있습니다.&lt;/p&gt;
&lt;p&gt;감정 분석의 비즈니스 가치가 일반적인 소규모 기업에서는 매우 작을수도 있습니다. 그러나, 그럼에도 불구하고, 감정 분석은 각 제품 또는 기업의 이미지 개선에 많은 도움을 주는 것은 뻔합니다.&lt;/p&gt;
&lt;p&gt;그런데, 여기서 데이터상으로 말씀을 드리면, 위 데이터셋은 매우 깔끔하게 처리된 데이터셋입니다. 데이터셋 전처리의 End-Point는 위 데이터셋으로 진행하지만, 문제는 &lt;code&gt;Labeling&lt;/code&gt;입니다.&lt;/p&gt;
&lt;p&gt;그런데, 초기 댓글에는 라벨링이 존재하지 않습니다. 즉, 이 때 초기 데이터셋을 뽑아서 라벨링을 진행해주셔야 합니다. (수동으로)&lt;/p&gt;
&lt;p&gt;초기 수동으로 뽑은 데이터로 학습을 시킨 후, 계속 나오는 댓글을 테스트 데이터로 확인 후 재 라벨링하는 방법으로 오류를 개선하고 데이터층을 쌓는 노력을 계속해야 합니다.&lt;/p&gt;
&lt;h3 id=&#34;2-학습을-위한-정답-데이터-y-만들기&#34;&gt;(2) 학습을 위한 정답 데이터 (Y) 만들기&lt;/h3&gt;
&lt;p&gt;이제 학습을 위한 훈련 데이터와 테스트 데이터를 만들어 봅니다. 입력(X)에 해당하는 자연어의 처리는 복잡한 과정이기 때문에 조금 뒤에서 다루도록 하고 일단 0, 1만 존재하는 출력(Y)부터 처리해 봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 7.21 학습을 위한 정답 데이터(Y) 만들기&lt;/span&gt;
train_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[int(row&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;])] &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; row &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; train_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:] &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; row&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;count(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
test_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[int(row&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;])] &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; row &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; test_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:] &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; row&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;count(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_Y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, test_Y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_Y[:&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;(150000, 1) (50000, 1)
[[0]
 [1]
 [0]
 [0]
 [1]]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;train_Y, test_Y를 구하는 방법은,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;먼저 각 텍스트를 개행 문자(&lt;code&gt;\n&lt;/code&gt;)로 분리한 다음 헤더에 해당하는 부분(id document label)을 제외한 나머지([1:])에 대해 각 행을 처리합니다.&lt;/li&gt;
&lt;li&gt;각 행은 탭 문자(&lt;code&gt;\t&lt;/code&gt;)로 나눠진 후에 2번째 원소(파이썬은 0부터 숫자를 셉니다. 실제로는 3번째 원소입니다)를 정수(integer)로 변환해서 저장합니다.&lt;/li&gt;
&lt;li&gt;마지막에는 &lt;code&gt;np.array&lt;/code&gt;로 결과 리스트를 감싸서 네트워크에 입력하기 쉽게 만듭니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;훈련 데이터의 &lt;code&gt;Y&lt;/code&gt;의 첫 원소 다섯 개를 출력해보면 정답 라벨이 잘 들어있음을 확인할 수 있습니다.&lt;/p&gt;
&lt;h3 id=&#34;3-훈련-데이터의-정제&#34;&gt;(3) 훈련 데이터의 정제&lt;/h3&gt;
&lt;p&gt;입력으로 쓸 자연어를 토큰화(Tokenization)하고 정제(Cleansing)를 해야 합니다. 토큰화는 자연어를 처리 가능한 작은 단위로 나누는 것이고, 여기서는 단어를 사용하는 것이기 때문에 띄어쓰기 단위로 나누면 됩니다.&lt;/p&gt;
&lt;p&gt;정제란 원하지 않는 입력이나 불필요한 기호 등을 제거하는 것입니다. 정제를 위한 함수로는 김윤 박사의 &lt;code&gt;CNN_sentence&lt;/code&gt; 깃허브 저장소&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;의 코드를 사용합니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;원 소스코드는 &lt;code&gt;process_data.py&lt;/code&gt;에 있습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;import re

def clean_str(string, TREC=False):
    &amp;#34;&amp;#34;&amp;#34;
    Tokenization/string cleaning for all datasets except for SST.
    Every dataset is lower cased except for TREC
    &amp;#34;&amp;#34;&amp;#34;
    string = re.sub(r&amp;#34;[^A-Za-z0-9(),!?\&amp;#39;\`]&amp;#34;, &amp;#34; &amp;#34;, string)     
    string = re.sub(r&amp;#34;\&amp;#39;s&amp;#34;, &amp;#34; \&amp;#39;s&amp;#34;, string) 
    string = re.sub(r&amp;#34;\&amp;#39;ve&amp;#34;, &amp;#34; \&amp;#39;ve&amp;#34;, string) 
    string = re.sub(r&amp;#34;n\&amp;#39;t&amp;#34;, &amp;#34; n\&amp;#39;t&amp;#34;, string) 
    string = re.sub(r&amp;#34;\&amp;#39;re&amp;#34;, &amp;#34; \&amp;#39;re&amp;#34;, string) 
    string = re.sub(r&amp;#34;\&amp;#39;d&amp;#34;, &amp;#34; \&amp;#39;d&amp;#34;, string) 
    string = re.sub(r&amp;#34;\&amp;#39;ll&amp;#34;, &amp;#34; \&amp;#39;ll&amp;#34;, string) 
    string = re.sub(r&amp;#34;,&amp;#34;, &amp;#34; , &amp;#34;, string) 
    string = re.sub(r&amp;#34;!&amp;#34;, &amp;#34; ! &amp;#34;, string) 
    string = re.sub(r&amp;#34;\(&amp;#34;, &amp;#34; \( &amp;#34;, string) 
    string = re.sub(r&amp;#34;\)&amp;#34;, &amp;#34; \) &amp;#34;, string) 
    string = re.sub(r&amp;#34;\?&amp;#34;, &amp;#34; \? &amp;#34;, string) 
    string = re.sub(r&amp;#34;\s{2,}&amp;#34;, &amp;#34; &amp;#34;, string)    

    return string.strip() if TREC else string.strip().lower()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;우선 위 코드를 기반으로 코드를 작성합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 7.22 train 데이터의 입력(X)에 대한 정제(Cleaning)&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; re
&lt;span style=&#34;color:#75715e&#34;&gt;# From https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clean_str&lt;/span&gt;(string):    
    string &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;[^가-힣A-Za-z0-9(),!?\&amp;#39;\`]&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;, string)
    string &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;\&amp;#39;s&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;s&amp;#34;&lt;/span&gt;, string)
    string &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;\&amp;#39;ve&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;ve&amp;#34;&lt;/span&gt;, string)
    string &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;n\&amp;#39;t&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; n&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;t&amp;#34;&lt;/span&gt;, string)
    string &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;\&amp;#39;re&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;re&amp;#34;&lt;/span&gt;, string)
    string &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;\&amp;#39;d&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;d&amp;#34;&lt;/span&gt;, string)
    string &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;\&amp;#39;ll&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;ll&amp;#34;&lt;/span&gt;, string)
    string &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;,&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; , &amp;#34;&lt;/span&gt;, string)
    string &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;!&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; ! &amp;#34;&lt;/span&gt;, string)
    string &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;\(&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; \( &amp;#34;&lt;/span&gt;, string)
    string &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;\)&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; \) &amp;#34;&lt;/span&gt;, string)
    string &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;\?&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; \? &amp;#34;&lt;/span&gt;, string)
    string &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;\s{2,}&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;, string)
    string &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;\&amp;#39;{2,}&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, string)
    string &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;\&amp;#39;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;, string)

    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; string&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;lower()

train_text_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [row&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; row &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; train_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:] &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; row&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;count(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
train_text_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [clean_str(sentence) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; sentence &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; train_text_X]
&lt;span style=&#34;color:#75715e&#34;&gt;# 문장을 띄어쓰기 단위로 단어 분리&lt;/span&gt;
sentences &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [sentence&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; &amp;#39;&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; sentence &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; train_text_X]
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(sentences[i])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[&#39;아&#39;, &#39;더빙&#39;, &#39;진짜&#39;, &#39;짜증나네요&#39;, &#39;목소리&#39;]
[&#39;흠&#39;, &#39;포스터보고&#39;, &#39;초딩영화줄&#39;, &#39;오버연기조차&#39;, &#39;가볍지&#39;, &#39;않구나&#39;]
[&#39;너무재밓었다그래서보는것을추천한다&#39;]
[&#39;교도소&#39;, &#39;이야기구먼&#39;, &#39;솔직히&#39;, &#39;재미는&#39;, &#39;없다&#39;, &#39;평점&#39;, &#39;조정&#39;]
[&#39;사이몬페그의&#39;, &#39;익살스런&#39;, &#39;연기가&#39;, &#39;돋보였던&#39;, &#39;영화&#39;, &#39;!&#39;, &#39;스파이더맨에서&#39;, &#39;늙어보이기만&#39;, &#39;했던&#39;, &#39;커스틴&#39;, &#39;던스트가&#39;, &#39;너무나도&#39;, &#39;이뻐보였다&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;clean_str(string)&lt;/code&gt; 함수는 다수의 정규표현식을 사용하고 있습니다만 첫 줄을 제외하면 세 번째 인수인 &lt;code&gt;string&lt;/code&gt;에서 첫 번째 인수에 해당하는 내용을 찾아서 두 번째 인수로 단순히 교체해주는 것입니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;[^가-힣A-Za-z0-9(),!?\&amp;#39;\`]&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;, string)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;위 정규표현식에서 특이한 점은 대괄호([])로 묶은 부분의 처음에 &lt;code&gt;^&lt;/code&gt;가 들어가 있다는 점입니다. 이 기호는 대괄호 안의 내용을 찾은 다음에, 그에 포함되지 않는 나머지 모두를 선택한다는 뜻입니다. 즉, 한글, 영문, 숫자, 괄호, 쉽표, 느낌표, 물음표, 작은따옴표(&#39;), 역따옴표(`)를 제외한 나머지는 모두 찾아서 공백(&amp;rdquo; &amp;ldquo;)으로 바꾸겠다는 뜻입니다.&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;훈련 데이터의 처음 다섯 개를 출력해보면 구두점(.) 기호가 삭제된 것을 확인할 수 있습니다. 그런데, 아시다시피, 네트워크에 입력하려면 데이터의 크기(문장의 길이)는 동일해야 하는데, 그렇지 않습니다. 긴 문장은 줄이고, 짧은 문장에는 공백을 의미하는 (&lt;code&gt;padding&lt;/code&gt;)을 채워 넣어야 합니다.&lt;/p&gt;
&lt;p&gt;각 문장의 길이를 그래프로 그려봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
sentence_len &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [len(sentence) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; sentence &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; sentences]
sentence_len&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sort()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(sentence_len)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(sum([int(l&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; l &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; sentence_len]))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_07_03/output_16_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;142587
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;4-단어의-정제-및-문장-전처리&#34;&gt;(4) 단어의 정제 및 문장 전처리&lt;/h3&gt;
&lt;p&gt;그래프의 Y축은 문장의 단어 개수입니다. 15만 개의 문장 중에서 대부분이 40단어 이하로 구성되어 있음을 확인할 수 있습니다. 특히 25단어 이하인 문장의 수는 &lt;code&gt;142,587&lt;/code&gt;개로 전체의 95% 정도입니다. 따라서 기준이 되는 문장의 길이를 25단어로 잡고 이 이상은 생략, 이 이하는 패딩으로 길이를 25로 맞춰면 임베딩 레이어에 넣을 준비가 끝납니다.&lt;/p&gt;
&lt;p&gt;또 하나 고려해야 하는 것은 각 단어의 최대 길이를 조정하는 일입니다. 예를 들면, 훈련 데이터의 5번째 문장에서 &lt;code&gt;스파이더맨에서&lt;/code&gt;라는 단어가 있는데, 이 단어는 엄밀히 말하면 조사를 제거하면 &lt;code&gt;스파이더맨&lt;/code&gt;이라는 한 단어가 됩니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;sentence_new &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; sentence &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; sentences:
  sentence_new&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append([word[:&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;] &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; word &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; sentence][:&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;])

sentences &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sentence_new

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;):
  &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(sentences[i])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[&#39;아&#39;, &#39;더빙&#39;, &#39;진짜&#39;, &#39;짜증나네요&#39;, &#39;목소리&#39;]
[&#39;흠&#39;, &#39;포스터보고&#39;, &#39;초딩영화줄&#39;, &#39;오버연기조&#39;, &#39;가볍지&#39;, &#39;않구나&#39;]
[&#39;너무재밓었&#39;]
[&#39;교도소&#39;, &#39;이야기구먼&#39;, &#39;솔직히&#39;, &#39;재미는&#39;, &#39;없다&#39;, &#39;평점&#39;, &#39;조정&#39;]
[&#39;사이몬페그&#39;, &#39;익살스런&#39;, &#39;연기가&#39;, &#39;돋보였던&#39;, &#39;영화&#39;, &#39;!&#39;, &#39;스파이더맨&#39;, &#39;늙어보이기&#39;, &#39;했던&#39;, &#39;커스틴&#39;, &#39;던스트가&#39;, &#39;너무나도&#39;, &#39;이뻐보였다&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;단어의 길이가 최대 다섯 글자로 줄어든 것을 확인 할 수 있습니다.&lt;/p&gt;
&lt;p&gt;이제 앞에서 설명한 작업 중에서 짧은 문장을 같은 길이의 문장(25단어)으로 바꾸기 위한 패딩을 넣기 위해 &lt;code&gt;tf.keras&lt;/code&gt;에서 제공하는 &lt;code&gt;pad_sequences&lt;/code&gt;를 사용해봅니다. 또 모든 단어를 사용하지 않고 출현 빈도가 가장 높은 일부 단어만 사용하기 위해 &lt;code&gt;Tokenizer&lt;/code&gt;도 같이 병행해서 사용합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras.preprocessing.text &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Tokenizer
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras.preprocessing.sequence &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pad_sequences

tokenizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Tokenizer(num_words&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2000&lt;/span&gt;)
tokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit_on_texts(sentences)
train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;texts_to_sequences(sentences)
train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pad_sequences(train_X, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;post&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_X[:&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[[  25  884    8 1111    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0]
 [ 588    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0]
 [  71  346   31   35    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0]
 [ 106    4    2  869  573    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0]]
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Tokenizer&lt;/code&gt;는 데이터에 출현하는 모든 단어의 개수를 세고 빈도 수로 정렬해서 &lt;code&gt;num_words&lt;/code&gt;에 지정된 만큼만 숫자로 반환하고 나머지는 0으로 반환합니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tokenizer.fit_on_texts(sentences)&lt;/code&gt;는 &lt;code&gt;Tokenizer&lt;/code&gt;에 데이터를 실제로 입력합니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tokenizer.texts_to_sequences(sentence)&lt;/code&gt;는 문장을 입력받아 숫자를 반환합니다.&lt;/li&gt;
&lt;li&gt;마지막으로 &lt;code&gt;pad_sequences()&lt;/code&gt;는 입력된 데이터에 패딩을 더합니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pad_sequences()&lt;/code&gt;의 인수에는 &lt;code&gt;pre&lt;/code&gt; &amp;amp; &lt;code&gt;post&lt;/code&gt;가 있는데, &lt;code&gt;pre&lt;/code&gt;는 문장의 앞에 패딩을 넣고, &lt;code&gt;post&lt;/code&gt;는 문장의 뒤에 패딩을 넣습니다. 여기에서는 &lt;code&gt;post&lt;/code&gt;를 사용합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;이렇게 정제된 데이터는 보시다시피 숫자로 변환이 되는 것입니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; idx, word &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(range(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;26&lt;/span&gt;), &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
  &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(idx, tokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;index_word[word])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;1 
2 !
3 ,
4 영화
5 \?
6 너무
7 정말
8 진짜
9 이
10 그냥
11 왜
12 이런
13 더
14 수
15 영화를
16 다
17 잘
18 보고
19 좀
20 영화는
21 영화가
22 그
23 봤는데
24 본
25 아
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;각 번호마다 매칭되는 한글을 보려면 위와 같은 코드로 구현이 가능합니다. &lt;code&gt;range(1, 26)&lt;/code&gt;에서 26을 바꾸면 원하는 범위까지 출력이 가능합니다. 이제 본격적으로 딥러닝 소스코드를 구현해서 모형을 만들도록 합니다.&lt;/p&gt;
&lt;h3 id=&#34;5-딥러닝-모형-정의-및-학습&#34;&gt;(5) 딥러닝 모형 정의 및 학습&lt;/h3&gt;
&lt;p&gt;이제 실제로 네트워크를 정의하고 학습시켜봅니다. 먼저 임베딩 레이어와 &lt;code&gt;LSTM&lt;/code&gt;레이어를 연결한 뒤 마지막에 &lt;code&gt;Dense&lt;/code&gt;레이어의 소프트맥스 활성화 함수를 사용해 긍정/부정을 분류하는 네트워크를 정의합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Embedding(&lt;span style=&#34;color:#ae81ff&#34;&gt;20000&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;300&lt;/span&gt;, input_length&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;LSTM(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;)
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;adam&amp;#39;&lt;/span&gt;, loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sparse_categorical_crossentropy&amp;#39;&lt;/span&gt;, metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, 25, 300)           6000000   
_________________________________________________________________
lstm (LSTM)                  (None, 50)                70200     
_________________________________________________________________
dense (Dense)                (None, 2)                 102       
=================================================================
Total params: 6,070,302
Trainable params: 6,070,302
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;input_length 인수가 중요합니다. 데이터 전처리를 25기준으로 정해놨기 때문에, &lt;code&gt;input_length&lt;/code&gt;로 정의했습니다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;희소행렬(sparse_categorical_crossentropy)&lt;/code&gt;에 관한 내용은 튜토리얼 5장-6장을 확인하여 주시기 바랍니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_X, train_Y, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/5
938/938 [==============================] - 69s 73ms/step - loss: 0.4898 - accuracy: 0.7383 - val_loss: 0.4517 - val_accuracy: 0.7685
Epoch 2/5
938/938 [==============================] - 68s 72ms/step - loss: 0.4481 - accuracy: 0.7649 - val_loss: 0.4469 - val_accuracy: 0.7707
Epoch 3/5
938/938 [==============================] - 68s 73ms/step - loss: 0.4358 - accuracy: 0.7708 - val_loss: 0.4551 - val_accuracy: 0.7669
Epoch 4/5
938/938 [==============================] - 68s 73ms/step - loss: 0.4277 - accuracy: 0.7756 - val_loss: 0.4567 - val_accuracy: 0.7589
Epoch 5/5
938/938 [==============================] - 69s 73ms/step - loss: 0.4196 - accuracy: 0.7802 - val_loss: 0.4511 - val_accuracy: 0.7699
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;데이터가 많기 때문에 한번에 학습하는 데이터의 양인 batch_size를 128로 설정했고, 5에포크만 학습을 시킵니다. 학습 과정에서 &lt;code&gt;loss&lt;/code&gt;는 꾸준히 감소하지만 &lt;code&gt;val_loss&lt;/code&gt;는 점점 증가하는 것을 확인할 수 있습니다. 이는 네트워크가 과적합되고 있다는 것을 의미합니다.&lt;/p&gt;
&lt;h3 id=&#34;6-모형-결과-시각화&#34;&gt;(6) 모형 결과 시각화&lt;/h3&gt;
&lt;p&gt;학습 결과를 시각화로 확인해봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;k--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylim(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_07_03/output_29_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;왼쪽 그래프에서 &lt;code&gt;val_loss&lt;/code&gt;는 증가하는데 비해, 오른쪽 그래프에서는 &lt;code&gt;val_accuracy&lt;/code&gt;가 떨어지는 것으로 보아 네트워크가 과적합되는 것으로 보입니다.&lt;/p&gt;
&lt;p&gt;과적합의 이유는 임베딩 레이어를 랜덤한 값에서부터 시작해서 학습시키기 때문에 각 단어를 나타내는 벡터의 품질이 좋지 않아서입니다. 이를 개선하기 위해서는 임베딩 레이어를 별도로 학습시켜서 네트워크에 불러와서 사용하거나 &lt;code&gt;RNN&lt;/code&gt;이 아닌 &lt;code&gt;CNN&lt;/code&gt;을 사용하는 방법이 있습니다.&lt;/p&gt;
&lt;p&gt;이 부분은 추후 자료가 정리가 되면 추가적으로 기술하도록 합니다.&lt;/p&gt;
&lt;h3 id=&#34;7-학습-결과-테스트&#34;&gt;(7) 학습 결과 테스트&lt;/h3&gt;
&lt;p&gt;학습된 네트워크에서 테스트 데이터는 어떻게 평가를 할까요? 확인을 위해 &lt;code&gt;test_text&lt;/code&gt;에도 &lt;code&gt;train_text&lt;/code&gt;와 같은 변환 과정을 거쳐서 &lt;code&gt;test_X&lt;/code&gt;를 만듭니다.&lt;/p&gt;
&lt;p&gt;여기에서 한가지 주목해야 하는 것은 &lt;code&gt;train_X&lt;/code&gt;를 만들 때 학습시킨 &lt;code&gt;Tokenizer&lt;/code&gt;를 어떤 변경 없이 그대로 사용한다는 것입니다.&lt;/p&gt;
&lt;p&gt;이렇게 하는 이유는 테스트 데이터는 우리 손에 없다는 가정하에 작업을 진행합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;test_text_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [row&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; row &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; test_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:] &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; row&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;count(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
test_text_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [clean_str(sentence) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; sentence &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; test_text_X]

&lt;span style=&#34;color:#75715e&#34;&gt;# 문장을 띄어쓰기 단위로 단어 분리&lt;/span&gt;
sentences &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [sentence&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; &amp;#39;&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; sentence &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; test_text_X]
sentence_new &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; sentence &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; sentences:
  sentence_new&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append([word[:&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;] &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; word &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; sentence][:&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;])

sentences &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sentence_new

test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;texts_to_sequences(sentences)
test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pad_sequences(test_X, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;post&amp;#39;&lt;/span&gt;)

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(test_X, test_Y, verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[0.4587577283382416, 0.7637199759483337]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;테스트 데이터의 정확도는 약 76%로 나왔습니다. 이는 검증 데이터와 비슷한 값입니다. 그렇다면 임의의 문장에 대한 감성 분석은 어떨까요? 순환 신경망이 입력의 변화에 따라 값이 변한다는 것을 확인하기 위해 하나의 문장을 잘라서 앞에서부터 차례로 입력합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;test_sentence &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;재미있을 줄 알았는데 완전 실망했다. 너무 졸리고 돈이 아까웠다.&amp;#39;&lt;/span&gt;
test_sentence &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_sentence&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; &amp;#39;&lt;/span&gt;)
test_sentences &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
now_sentence &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; word &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; test_sentence:
    now_sentence&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(word)
    test_sentences&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(now_sentence[:])
    
test_X_1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;texts_to_sequences(test_sentences)
test_X_1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pad_sequences(test_X_1, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;post&amp;#39;&lt;/span&gt;, maxlen&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;)
prediction &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(test_X_1)
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; idx, sentence &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(test_sentences):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(sentence)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(prediction[idx])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[&#39;재미있을&#39;]
[0.5659361  0.43406394]
[&#39;재미있을&#39;, &#39;줄&#39;]
[0.55835325 0.44164675]
[&#39;재미있을&#39;, &#39;줄&#39;, &#39;알았는데&#39;]
[0.56154287 0.4384571 ]
[&#39;재미있을&#39;, &#39;줄&#39;, &#39;알았는데&#39;, &#39;완전&#39;]
[0.5674858  0.43251416]
[&#39;재미있을&#39;, &#39;줄&#39;, &#39;알았는데&#39;, &#39;완전&#39;, &#39;실망했다.&#39;]
[0.5674858  0.43251416]
[&#39;재미있을&#39;, &#39;줄&#39;, &#39;알았는데&#39;, &#39;완전&#39;, &#39;실망했다.&#39;, &#39;너무&#39;]
[0.64270234 0.35729766]
[&#39;재미있을&#39;, &#39;줄&#39;, &#39;알았는데&#39;, &#39;완전&#39;, &#39;실망했다.&#39;, &#39;너무&#39;, &#39;졸리고&#39;]
[0.64270234 0.35729766]
[&#39;재미있을&#39;, &#39;줄&#39;, &#39;알았는데&#39;, &#39;완전&#39;, &#39;실망했다.&#39;, &#39;너무&#39;, &#39;졸리고&#39;, &#39;돈이&#39;]
[0.98596686 0.0140331 ]
[&#39;재미있을&#39;, &#39;줄&#39;, &#39;알았는데&#39;, &#39;완전&#39;, &#39;실망했다.&#39;, &#39;너무&#39;, &#39;졸리고&#39;, &#39;돈이&#39;, &#39;아까웠다.&#39;]
[0.98596686 0.0140331 ]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;출력은 문장의 변화에 따른 감성 분석 예측 결과입니다. 단어의 문장이 길어지면 길어질수록 정확도가 올라가는데, 특이한 것이 있다면, &lt;code&gt;너무&lt;/code&gt;라는 단어 &lt;code&gt;졸리고&lt;/code&gt;가 나왔을 때 99%의 확률로 부정적 감성을 예측하는 것을 볼 수 있습니다.&lt;/p&gt;
&lt;p&gt;영화의 특성상, &lt;code&gt;졸립다&lt;/code&gt;라는 특성은 사실 굉장히 많은 부정적인 뜻을 내포하기 때문에 어쩌면 대표적인 단어일 수도 있다는 생각을 해봅니다.&lt;/p&gt;
&lt;h2 id=&#34;iii-연습-파일&#34;&gt;III. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch7_3_sentimentAnalysis.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;iv-reference&#34;&gt;IV. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;출처: &lt;a href=&#34;https://github.com/yoonkim/cnn_sentence&#34;&gt;https://github.com/yoonkim/cnn_sentence&lt;/a&gt; &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;파이썬 정규표현식 온라인 테스트: &lt;a href=&#34;https://regex101.com/&#34;&gt;https://regex101.com/&lt;/a&gt; &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (2)</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory2/</link>
      <pubDate>Thu, 23 Apr 2020 10:08:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory2/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.2 - 다항분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/&#34;&gt;Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/&#34;&gt;Tensorflow 2.0 Tutorial ch6.1-2 - CNN 이론&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_3_fashion_mnist_with_cnn/&#34;&gt;Tensorflow 2.0 Tutorial ch6.3 - Fashion MNIST with CNN 실습&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_4_improve_performance/&#34;&gt;Tensorflow 2.0 Tutorial ch6.4 - 모형의 성능 높이기&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (1)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요&#34;&gt;I. 개요&lt;/h2&gt;
&lt;p&gt;GRU(&lt;code&gt;Gated Recurrent Unit&lt;/code&gt;)레이어는 &lt;code&gt;LSTM&lt;/code&gt;레이어와 비슷한 역할을 하지만 구조가 더 간단하기 때문에 계산상의 이점이 있고, 어떤 문제에서는 &lt;code&gt;LSTM&lt;/code&gt; 레이어보다 좋은 성능을 보여주기도 합니다.&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; 셀로 나타낸 &lt;code&gt;GRU&lt;/code&gt; 레이어의 계산 흐름은 &lt;code&gt;LSTM&lt;/code&gt;과 비슷하지만, 조금 축약된 모습을 보입니다.&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_07_01_2/tutorial_02_RNN_LSTM_GRU.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;자세한 수식 및 이론 설명은 교재를 구매하셔서 194-5페이지를 참고하시기를 바랍니다. GRU의 성능이 LSTM보다 실제로 성능이 좋은지, 수식이 줄었기 때문에, 또한 연산속도는 빨라졌는지 확인해보도록 합니다.&lt;/p&gt;
&lt;h2 id=&#34;ii-gru-모델-정의-및-구현&#34;&gt;II. GRU 모델 정의 및 구현&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory1/&#34;&gt;ch7.1 - RNN(1)&lt;/a&gt; 이론에서 배웠던 곱셈 정의 문제를 다시 풀어보도록 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 텐서플로 2 버전 선택&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
    &lt;span style=&#34;color:#75715e&#34;&gt;# %tensorflow_version only exists in Colab.&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;tensorflow_version &lt;span style=&#34;color:#ae81ff&#34;&gt;2.&lt;/span&gt;x
&lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Exception&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;pass&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;3000&lt;/span&gt;): 
  &lt;span style=&#34;color:#75715e&#34;&gt;# 0 ~ 1 범위의 랜덤한 숫자 100개를 만듭니다. &lt;/span&gt;
  lst &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rand(&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;)

  &lt;span style=&#34;color:#75715e&#34;&gt;# 마킹할 숫자 2개의 인덱스를 뽑습니다. &lt;/span&gt;
  idx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;choice(&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, replace&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)

  &lt;span style=&#34;color:#75715e&#34;&gt;# 마킹 인덱스가 저장된 원-핫 인코딩 벡터를 만듭니다. &lt;/span&gt;
  zeros&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros(&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;)
  zeros[idx]&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
  
  &lt;span style=&#34;color:#75715e&#34;&gt;# 마킹 인덱스와 랜덤한 숫자를 합쳐서 X에 저장합니다. &lt;/span&gt;
  X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(list(zip(zeros, lst))))
  &lt;span style=&#34;color:#75715e&#34;&gt;# 마킹 인덱스가 1인 값만 서로 곱해서 Y에 저장합니다. &lt;/span&gt;
  Y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;prod(lst[idx]))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;GRU(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;30&lt;/span&gt;, return_sequences&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;GRU(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;30&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;adam&amp;#39;&lt;/span&gt;, loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mse&amp;#39;&lt;/span&gt;)
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru (GRU)                    (None, 100, 30)           3060      
_________________________________________________________________
gru_1 (GRU)                  (None, 30)                5580      
_________________________________________________________________
dense (Dense)                (None, 1)                 31        
=================================================================
Total params: 8,671
Trainable params: 8,671
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;기존 &lt;code&gt;LSTM&lt;/code&gt; 모델 정의 코드에서 &lt;code&gt;GRU&lt;/code&gt;로 바꿔서 간단히 모델을 정의할 수 있습니다. &lt;code&gt;GRU&lt;/code&gt;레이어를 사용한 네트워크의 파라미터 수는 &lt;code&gt;LSTM&lt;/code&gt;레이어의 파라미터 수보다 적습니다.&lt;/p&gt;
&lt;p&gt;이전 포스트에서 작성했던 파라미터 수를 비교하면 다음과 같습니다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;SimpleRNN&lt;/th&gt;
&lt;th&gt;LSTM&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;GRU&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;2,851&lt;/td&gt;
&lt;td&gt;11,311&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;8,671&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;그럼 이제 실제로 학습시켜서 결과가 어떻게 나오는지 확인합니다. 코드 역시, 그 전과 큰 차이점은 없기 때문에 전체 소스코드를 이어서 작성합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(X)
Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(Y)

&lt;span style=&#34;color:#75715e&#34;&gt;# 모형 학습&lt;/span&gt;
history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(X[:&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;], Y[:&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;], epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# 모형 학습 시각화 &lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

&lt;span style=&#34;color:#75715e&#34;&gt;# 모형 테스트 및 결과&lt;/span&gt;
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(X[&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;:], Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;:])
prediction&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(X[&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;])

&lt;span style=&#34;color:#75715e&#34;&gt;# 5개 테스트 데이터에 대한 예측을 표시합니다. &lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;): 
  &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;i], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;, prediction[i][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;diff:&amp;#39;&lt;/span&gt;, abs(prediction[i][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;i]))

prediction &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(X[&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;:])
fail &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(len(prediction)):
  &lt;span style=&#34;color:#75715e&#34;&gt;# 오차가 0.04 이상이면 오답입니다. &lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; abs(prediction[i][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;i]) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.04&lt;/span&gt;:
    fail &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;correctness:&amp;#39;&lt;/span&gt;, (&lt;span style=&#34;color:#ae81ff&#34;&gt;440&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;fail)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;440&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;%&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/100
64/64 [==============================] - 1s 19ms/step - loss: 0.0542 - val_loss: 0.0464
Epoch 2/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0498 - val_loss: 0.0465
Epoch 3/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0496 - val_loss: 0.0462
Epoch 4/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0496 - val_loss: 0.0466
Epoch 5/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0502 - val_loss: 0.0472
Epoch 6/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0498 - val_loss: 0.0462
Epoch 7/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0497 - val_loss: 0.0465
Epoch 8/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0496 - val_loss: 0.0462
Epoch 9/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0493 - val_loss: 0.0463
Epoch 10/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0491 - val_loss: 0.0464
Epoch 11/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0495 - val_loss: 0.0458
Epoch 12/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0492 - val_loss: 0.0491
Epoch 13/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0498 - val_loss: 0.0457
Epoch 14/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0488 - val_loss: 0.0460
Epoch 15/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0484 - val_loss: 0.0467
Epoch 16/100
64/64 [==============================] - 1s 11ms/step - loss: 0.0481 - val_loss: 0.0439
Epoch 17/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0239 - val_loss: 0.0153
Epoch 18/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0122 - val_loss: 0.0079
Epoch 19/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0070 - val_loss: 0.0072
Epoch 20/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0058 - val_loss: 0.0060
Epoch 21/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0045 - val_loss: 0.0033
Epoch 22/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0035 - val_loss: 0.0023
Epoch 23/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0030 - val_loss: 0.0022
Epoch 24/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0024 - val_loss: 0.0018
Epoch 25/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0023 - val_loss: 0.0016
Epoch 26/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0020 - val_loss: 0.0027
Epoch 27/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0016 - val_loss: 0.0011
Epoch 28/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0016 - val_loss: 0.0013
Epoch 29/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0015 - val_loss: 0.0012
Epoch 30/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0018 - val_loss: 0.0010
Epoch 31/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0014 - val_loss: 0.0010
Epoch 32/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 9.6678e-04
Epoch 33/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 8.7013e-04
Epoch 34/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 8.7790e-04
Epoch 35/100
64/64 [==============================] - 1s 10ms/step - loss: 9.3853e-04 - val_loss: 6.9370e-04
Epoch 36/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 0.0016
Epoch 37/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0010 - val_loss: 8.4368e-04
Epoch 38/100
64/64 [==============================] - 1s 10ms/step - loss: 9.6391e-04 - val_loss: 6.0684e-04
Epoch 39/100
64/64 [==============================] - 1s 10ms/step - loss: 7.8758e-04 - val_loss: 0.0015
Epoch 40/100
64/64 [==============================] - 1s 10ms/step - loss: 0.0013 - val_loss: 6.3157e-04
Epoch 41/100
64/64 [==============================] - 1s 10ms/step - loss: 9.7273e-04 - val_loss: 5.5738e-04
Epoch 42/100
64/64 [==============================] - 1s 10ms/step - loss: 7.0651e-04 - val_loss: 4.9343e-04
Epoch 43/100
64/64 [==============================] - 1s 10ms/step - loss: 8.7092e-04 - val_loss: 5.3667e-04
Epoch 44/100
64/64 [==============================] - 1s 10ms/step - loss: 6.4929e-04 - val_loss: 5.6655e-04
Epoch 45/100
64/64 [==============================] - 1s 10ms/step - loss: 6.5691e-04 - val_loss: 5.3359e-04
Epoch 46/100
64/64 [==============================] - 1s 10ms/step - loss: 8.4880e-04 - val_loss: 0.0017
Epoch 47/100
64/64 [==============================] - 1s 11ms/step - loss: 7.9048e-04 - val_loss: 4.8470e-04
Epoch 48/100
64/64 [==============================] - 1s 10ms/step - loss: 5.2750e-04 - val_loss: 4.5355e-04
Epoch 49/100
64/64 [==============================] - 1s 10ms/step - loss: 5.2346e-04 - val_loss: 0.0011
Epoch 50/100
64/64 [==============================] - 1s 11ms/step - loss: 5.2244e-04 - val_loss: 3.9339e-04
Epoch 51/100
64/64 [==============================] - 1s 11ms/step - loss: 5.1538e-04 - val_loss: 8.5248e-04
Epoch 52/100
64/64 [==============================] - 1s 10ms/step - loss: 5.0478e-04 - val_loss: 3.3874e-04
Epoch 53/100
64/64 [==============================] - 1s 10ms/step - loss: 5.4496e-04 - val_loss: 5.0151e-04
Epoch 54/100
64/64 [==============================] - 1s 10ms/step - loss: 4.3863e-04 - val_loss: 4.1039e-04
Epoch 55/100
64/64 [==============================] - 1s 10ms/step - loss: 7.4540e-04 - val_loss: 6.3658e-04
Epoch 56/100
64/64 [==============================] - 1s 10ms/step - loss: 5.3960e-04 - val_loss: 3.4416e-04
Epoch 57/100
64/64 [==============================] - 1s 11ms/step - loss: 3.6213e-04 - val_loss: 5.8370e-04
Epoch 58/100
64/64 [==============================] - 1s 10ms/step - loss: 4.8387e-04 - val_loss: 3.6832e-04
Epoch 59/100
64/64 [==============================] - 1s 10ms/step - loss: 4.4107e-04 - val_loss: 3.1697e-04
Epoch 60/100
64/64 [==============================] - 1s 11ms/step - loss: 3.9765e-04 - val_loss: 4.5374e-04
Epoch 61/100
64/64 [==============================] - 1s 11ms/step - loss: 3.8165e-04 - val_loss: 3.2876e-04
Epoch 62/100
64/64 [==============================] - 1s 10ms/step - loss: 6.8677e-04 - val_loss: 2.9420e-04
Epoch 63/100
64/64 [==============================] - 1s 10ms/step - loss: 5.2809e-04 - val_loss: 2.7272e-04
Epoch 64/100
64/64 [==============================] - 1s 10ms/step - loss: 2.7761e-04 - val_loss: 2.6852e-04
Epoch 65/100
64/64 [==============================] - 1s 10ms/step - loss: 3.0836e-04 - val_loss: 4.0206e-04
Epoch 66/100
64/64 [==============================] - 1s 10ms/step - loss: 4.4454e-04 - val_loss: 2.6554e-04
Epoch 67/100
64/64 [==============================] - 1s 10ms/step - loss: 5.0457e-04 - val_loss: 2.2702e-04
Epoch 68/100
64/64 [==============================] - 1s 10ms/step - loss: 3.1455e-04 - val_loss: 2.5735e-04
Epoch 69/100
64/64 [==============================] - 1s 10ms/step - loss: 3.4775e-04 - val_loss: 2.4464e-04
Epoch 70/100
64/64 [==============================] - 1s 10ms/step - loss: 2.5858e-04 - val_loss: 4.1233e-04
Epoch 71/100
64/64 [==============================] - 1s 10ms/step - loss: 2.6686e-04 - val_loss: 3.1173e-04
Epoch 72/100
64/64 [==============================] - 1s 10ms/step - loss: 3.2840e-04 - val_loss: 2.2496e-04
Epoch 73/100
64/64 [==============================] - 1s 10ms/step - loss: 3.2419e-04 - val_loss: 2.0555e-04
Epoch 74/100
64/64 [==============================] - 1s 10ms/step - loss: 2.3337e-04 - val_loss: 1.6153e-04
Epoch 75/100
64/64 [==============================] - 1s 10ms/step - loss: 2.4482e-04 - val_loss: 1.9017e-04
Epoch 76/100
64/64 [==============================] - 1s 10ms/step - loss: 3.5401e-04 - val_loss: 2.0578e-04
Epoch 77/100
64/64 [==============================] - 1s 11ms/step - loss: 2.8999e-04 - val_loss: 1.8757e-04
Epoch 78/100
64/64 [==============================] - 1s 10ms/step - loss: 2.0261e-04 - val_loss: 1.6617e-04
Epoch 79/100
64/64 [==============================] - 1s 10ms/step - loss: 2.2359e-04 - val_loss: 8.6003e-04
Epoch 80/100
64/64 [==============================] - 1s 10ms/step - loss: 3.8440e-04 - val_loss: 3.4750e-04
Epoch 81/100
64/64 [==============================] - 1s 10ms/step - loss: 2.7182e-04 - val_loss: 1.4401e-04
Epoch 82/100
64/64 [==============================] - 1s 10ms/step - loss: 2.7468e-04 - val_loss: 1.6795e-04
Epoch 83/100
64/64 [==============================] - 1s 10ms/step - loss: 2.4761e-04 - val_loss: 1.9169e-04
Epoch 84/100
64/64 [==============================] - 1s 10ms/step - loss: 2.5236e-04 - val_loss: 2.6484e-04
Epoch 85/100
64/64 [==============================] - 1s 10ms/step - loss: 2.3328e-04 - val_loss: 5.1060e-04
Epoch 86/100
64/64 [==============================] - 1s 10ms/step - loss: 4.0916e-04 - val_loss: 4.0131e-04
Epoch 87/100
64/64 [==============================] - 1s 10ms/step - loss: 2.9090e-04 - val_loss: 1.8709e-04
Epoch 88/100
64/64 [==============================] - 1s 10ms/step - loss: 2.0704e-04 - val_loss: 1.4023e-04
Epoch 89/100
64/64 [==============================] - 1s 10ms/step - loss: 2.4698e-04 - val_loss: 5.0055e-04
Epoch 90/100
64/64 [==============================] - 1s 10ms/step - loss: 2.5488e-04 - val_loss: 3.7641e-04
Epoch 91/100
64/64 [==============================] - 1s 10ms/step - loss: 3.4907e-04 - val_loss: 3.2548e-04
Epoch 92/100
64/64 [==============================] - 1s 10ms/step - loss: 4.0255e-04 - val_loss: 4.1547e-04
Epoch 93/100
64/64 [==============================] - 1s 10ms/step - loss: 5.1706e-04 - val_loss: 3.9099e-04
Epoch 94/100
64/64 [==============================] - 1s 10ms/step - loss: 2.2027e-04 - val_loss: 1.5537e-04
Epoch 95/100
64/64 [==============================] - 1s 10ms/step - loss: 2.9934e-04 - val_loss: 4.1400e-04
Epoch 96/100
64/64 [==============================] - 1s 12ms/step - loss: 5.6970e-04 - val_loss: 6.6119e-04
Epoch 97/100
64/64 [==============================] - 1s 10ms/step - loss: 3.3246e-04 - val_loss: 1.8468e-04
Epoch 98/100
64/64 [==============================] - 1s 10ms/step - loss: 2.1950e-04 - val_loss: 2.9611e-04
Epoch 99/100
64/64 [==============================] - 1s 10ms/step - loss: 1.9392e-04 - val_loss: 1.4212e-04
Epoch 100/100
64/64 [==============================] - 1s 10ms/step - loss: 1.7158e-04 - val_loss: 1.1689e-04
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_07_01_2/output_7_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;14/14 [==============================] - 0s 5ms/step - loss: 1.3132e-04
0.03254906333292209 	 0.028674547 	diff: 0.003874516703731644
0.0459566112724449 	 0.040693775 	diff: 0.005262836453070817
0.5360537450610645 	 0.5460534 	diff: 0.009999664515351503
0.14992662254277317 	 0.14886208 	diff: 0.0010645437568768679
0.38647776052320765 	 0.38145044 	diff: 0.005027316063292486
correctness: 99.31818181818181 %
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;정확도는 99.3%로 거의 99%에 가까운 값이 나옵니다. 이 문제에서는 &lt;code&gt;LSTM&lt;/code&gt; 레이어보다 &lt;code&gt;GRU&lt;/code&gt;레이어로 더 잘 풀리는 문제입니다.&lt;/p&gt;
&lt;p&gt;마지막 이론으로 임베딩 레이어에 대해 배우도록 합니다.&lt;/p&gt;
&lt;h2 id=&#34;iii-임베딩-레이어-기본-이론&#34;&gt;III. 임베딩 레이어 기본 이론&lt;/h2&gt;
&lt;p&gt;임베딩 레이어(&lt;code&gt;Embedding Layer&lt;/code&gt;)는 자연어를 수치화된 정보로 바꾸기 위한 레이어입니다. 자연어는 시간의 흐름에 따라 정보가 연속적으로 이어지는 시퀀스 데이터입니다. 이미지를 픽셀 단위로 잘게 쪼갤 수 있듯이 자연어도 정보를 잘게 쪼갤 수 있습니다. 영어는 문자(&lt;code&gt;character&lt;/code&gt;), 한글은 문자를 넘어 자소 단위로도 쪼갤 수 있습니다. 과거에는 n-gram보다 단어나 문자 단위의 자연어 처리가 많이 쓰입니다.&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;임베딩 레이어보다 좀 더 쉬운 기법은 자연어를 구성하는 단위에 대해 정수 인덱스(index)를 저장하는 방법입니다. 좀 더 쉽게 예로 들면, &amp;ldquo;This is a big cat&amp;quot;이라는 문장에 대해 정수 인덱스를 저장하면 처음 나오는 단어부터 인덱스를 저장합니다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;단어&lt;/th&gt;
&lt;th&gt;인덱스&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;this&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;is&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;a&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;big&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;cat&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;이렇게 새로운 수치화된 데이터로 변환될 수 있습니다. 이 때 &amp;ldquo;This is big.&amp;ldquo;이라는 새로운 문장도 [0,1,3]이라는 데이터로 바뀔 수 있습니다. 이렇게 바뀐 데이터는 아래 그림과 같이 원-핫 인코딩을 이용해 단어의 인덱스에 해당하는 원소만 1이고 나머지는 0인 배열로 바뀝니다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_07_01_2/tutorial_02_word_embedding.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;그런데, 인덱스를 사용할 때, 가장 큰 문제점은 사용하는 메모리의 양에 비해 너무 적은 정보량을 표현하는 것이고, 또 한가지 단점은 저장된 단어의 수가 많아질수록 원-핫 인코딩 배열의 두 번째 차원의 크기도 그에 비례해서 늘어나기 때문에 이 데이터가 차지하는 메모리의 양이 더욱 늘어나게 됩니다. 추가적인 이론에 대한 내용은 교재 201-3페이지를 확인하셔서 추가적인 이론 공부를 병행하는 것을 권합니다.&lt;/p&gt;
&lt;p&gt;임베딩 레이어에 대해 학습시키는 방법은 &lt;code&gt;Word2Vec&lt;/code&gt;, &lt;code&gt;GloVe&lt;/code&gt;, &lt;code&gt;FastText&lt;/code&gt;, &lt;code&gt;ELMo&lt;/code&gt;등과 같은 방법론이 있습니다.&lt;/p&gt;
&lt;p&gt;우선 단어 임베딩의 이론적인 코드 부분을 학습하고자 예제(감성분석)를 준비했습니다. 교재에는 조금 부족한 부분이라 판단되어, 텐서플로 공식홈페이지의 내용을 번역 및 축약합니다.&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h3 id=&#34;1-코드-작성-및-설명&#34;&gt;(1) 코드 작성 및 설명&lt;/h3&gt;
&lt;p&gt;먼저 관련 모듈과 데이터를 가져옵니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; keras
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; layers

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow_datasets &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tfds
tfds&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;disable_progress_bar()

&lt;span style=&#34;color:#75715e&#34;&gt;# 데이터 수집 / 영화 데이터&lt;/span&gt;
dataset, info &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfds&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;imdb_reviews/subwords8k&amp;#39;&lt;/span&gt;, with_info&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True,
                          as_supervised&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
train_examples, test_examples &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dataset[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;train&amp;#39;&lt;/span&gt;], dataset[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;test&amp;#39;&lt;/span&gt;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[1mDownloading and preparing dataset imdb_reviews/subwords8k/1.0.0 (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0...[0m
Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0.incomplete70Q64U/imdb_reviews-train.tfrecord
Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0.incomplete70Q64U/imdb_reviews-test.tfrecord
Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0.incomplete70Q64U/imdb_reviews-unsupervised.tfrecord
[1mDataset imdb_reviews downloaded and prepared to /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0. Subsequent calls will reuse this data.[0m
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;그리고, encoder를 통해서 실제 텍스트의 단어의 크기를 확인합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;encoder &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; info&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;features[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;text&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;encoder
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Vocabulary size: {}&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(encoder&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;vocab_size))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Vocabulary size: 8185
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;이론에서 배웠던, 입력된 &lt;code&gt;Sample String&lt;/code&gt;에 대해 인코딩된 값을 인덱스로 반환합니다. 그리고, 원 문자열도 같이 반환되어 어떻게 변환되는지 확인할 수 있습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;sample_string &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Hello ChloEvan.&amp;#39;&lt;/span&gt;
encoded_string &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; encoder&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;encode(sample_string)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Encoded string is {}&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(encoded_string))

original_string &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; encoder&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;decode(encoded_string)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;The original string: &amp;#34;{}&amp;#34;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(original_string))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Encoded string is [4025, 222, 6995, 1163, 6275, 8039, 7975]
The original string: &amp;quot;Hello ChloEvan.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;이제 다시 인덱스로 출력하면 전체 &lt;code&gt;vocab_size&lt;/code&gt;에서 샘플 문자열이 어떤식으로 구성이 되는지 확인할 수 있습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;assert&lt;/span&gt; original_string &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; sample_string
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; index &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; encoded_string:
  &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{} ----&amp;gt; {}&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(index, encoder&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;decode([index])))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;4025 ----&amp;gt; Hell
222 ----&amp;gt; o 
6995 ----&amp;gt; Ch
1163 ----&amp;gt; lo
6275 ----&amp;gt; Eva
8039 ----&amp;gt; n
7975 ----&amp;gt; .
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;이제 모형을 위해 학습 데이터를 준비합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;BUFFER_SIZE &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10000&lt;/span&gt;
BATCH_SIZE &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;

train_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (train_examples
                 &lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shuffle(BUFFER_SIZE)
                 &lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;padded_batch(BATCH_SIZE, padded_shapes&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;([None],[])))

test_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (test_examples
                &lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;padded_batch(BATCH_SIZE,  padded_shapes&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;([None],[])))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;그런데, 아래 코드에서 &lt;code&gt;pad&lt;/code&gt;라는 개념이 보일겁니다. &lt;code&gt;pad&lt;/code&gt;은 공백을 의미합니다. &lt;code&gt;padding&lt;/code&gt;의 개념이 있는 것은, 자연어에는 미리 정해놓을 수 없을 정도로 많은 단어가 존재하기 때문에, 보통은 정수 인덱스로 저장하지 않는 단어에 대한 임베딩 값을 별도로 마련합니다. 즉, 임베딩 레이어의 행 수가 10,000이라면 9,999는 미리 지정된 단어의 개수이고, 나머지 1은 지정되지 않은 단어를 위한 값입니다. 이것이 padding의 개념입니다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;padded_batch&lt;/code&gt;의 함수를 사용함으로써, UNK값으로 0을 넣어줍니다. 실제로 &lt;code&gt;padded_batch&lt;/code&gt;가 어떻게 구현이 되는지 확인해봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train_batch, train_labels &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; next(iter(train_dataset))
train_batch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;array([[  62,    9,   41, ...,    0,    0,    0],
       [ 134,  142, 7968, ...,    0,    0,    0],
       [  12, 6130,    7, ...,    0,    0,    0],
       ...,
       [ 684,  807,  455, ...,    0,    0,    0],
       [ 373,    6,    1, ...,    6, 1803, 7975],
       [  62,    9,   45, ...,    0,    0,    0]])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;위 값에 0이 있는 것을 확인할 수 있습니다. &lt;code&gt;padded_batch&lt;/code&gt;를 함으로써 일종의 길이의 정규화를 진행한다고 보면 됩니다.&lt;/p&gt;
&lt;p&gt;아래 코드는 모델 정의 및 학습에 관한 내용입니다. 튜토리얼에서 반복적으로 나오는 코드이기 때문에 여기에서는 설명을 생략합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Embedding(encoder&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;vocab_size, &lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Bidirectional(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;LSTM(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;)),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;losses&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;BinaryCrossentropy(from_logits&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True),
              optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(&lt;span style=&#34;color:#ae81ff&#34;&gt;1e-4&lt;/span&gt;),
              metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_dataset, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;,
                    validation_data&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;test_dataset, 
                    validation_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;30&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/10
391/391 [==============================] - 44s 113ms/step - loss: 0.6474 - accuracy: 0.5586 - val_loss: 0.4672 - val_accuracy: 0.7865
Epoch 2/10
391/391 [==============================] - 44s 113ms/step - loss: 0.3531 - accuracy: 0.8537 - val_loss: 0.3419 - val_accuracy: 0.8589
Epoch 3/10
391/391 [==============================] - 45s 114ms/step - loss: 0.2525 - accuracy: 0.9042 - val_loss: 0.3268 - val_accuracy: 0.8651
Epoch 4/10
391/391 [==============================] - 45s 114ms/step - loss: 0.2089 - accuracy: 0.9218 - val_loss: 0.3332 - val_accuracy: 0.8656
Epoch 5/10
391/391 [==============================] - 45s 116ms/step - loss: 0.1824 - accuracy: 0.9350 - val_loss: 0.3999 - val_accuracy: 0.8130
Epoch 6/10
391/391 [==============================] - 45s 115ms/step - loss: 0.1625 - accuracy: 0.9419 - val_loss: 0.3684 - val_accuracy: 0.8661
Epoch 7/10
391/391 [==============================] - 45s 116ms/step - loss: 0.1455 - accuracy: 0.9504 - val_loss: 0.3698 - val_accuracy: 0.8630
Epoch 8/10
391/391 [==============================] - 45s 115ms/step - loss: 0.1342 - accuracy: 0.9538 - val_loss: 0.4048 - val_accuracy: 0.8594
Epoch 9/10
391/391 [==============================] - 45s 116ms/step - loss: 0.1222 - accuracy: 0.9594 - val_loss: 0.4135 - val_accuracy: 0.8599
Epoch 10/10
391/391 [==============================] - 44s 114ms/step - loss: 0.1397 - accuracy: 0.9510 - val_loss: 0.4372 - val_accuracy: 0.8542
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;모형의 학습이 끝나면 실제로 잘 학습되는지 그래프를 작성합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt

history_dict &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

test_loss, test_acc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(test_dataset)

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Test Loss: {}&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(test_loss))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Test Accuracy: {}&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(test_acc))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_07_01_2/output_25_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;391/391 [==============================] - 16s 42ms/step - loss: 0.4282 - accuracy: 0.8523
Test Loss: 0.4281919002532959
Test Accuracy: 0.8522800207138062
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;iv-연습-파일&#34;&gt;IV. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch7_1_2_RNN_theory(2).ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;vi-reference&#34;&gt;VI. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Cho, K., Merrienboer, B. V., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., &amp;amp; Bengio, Y. (2014). Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation. Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). doi: 10.3115/v1/d14-1179 &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Chung, J., Gulcehre, C., Cho, K., &amp;amp; Bengio, Y. (2014). Empirical evaluation of gated recurrent neural networks on sequence modeling. In NIPS 2014 Workshop on Deep Learning, December 2014 &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;교재 195페이지를 확인하면 여러 수식이 나옵니다. 여기서 주목해야 하는 것은 &lt;code&gt;LSTM&lt;/code&gt;레이어보다 시그모이드 함수가 하나 적게 쓰였는데, 이것은 게이트의 수가 하나 줄어들었다는 것을 의미합니다. &lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;N-Gram은 간단하게 예를 들어 설명하면, &amp;ldquo;This is it&amp;quot;이라는 문장을 3개의 문자를 묶은 &lt;code&gt;3-gram&lt;/code&gt;으로 나타내면 [&amp;ldquo;Thi&amp;rdquo;, &amp;ldquo;his&amp;rdquo;, &amp;ldquo;is &amp;ldquo;, &amp;ldquo;s i&amp;rdquo;, &amp;quot; is&amp;rdquo;, &amp;ldquo;is &amp;ldquo;, &amp;ldquo;s i&amp;rdquo;, &amp;quot; it&amp;rdquo;, &amp;ldquo;it.&amp;quot;]이라는 배열로 나타낼 수 있습니다. &lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Word embeddings, &lt;a href=&#34;https://www.tensorflow.org/tutorials/text/word_embeddings&#34;&gt;https://www.tensorflow.org/tutorials/text/word_embeddings&lt;/a&gt; &lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (1)</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory1/</link>
      <pubDate>Wed, 22 Apr 2020 15:08:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory1/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.2 - 다항분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/&#34;&gt;Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/&#34;&gt;Tensorflow 2.0 Tutorial ch6.1-2 - CNN 이론&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_3_fashion_mnist_with_cnn/&#34;&gt;Tensorflow 2.0 Tutorial ch6.3 - Fashion MNIST with CNN 실습&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_4_improve_performance/&#34;&gt;Tensorflow 2.0 Tutorial ch6.4 - 모형의 성능 높이기&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요&#34;&gt;I. 개요&lt;/h2&gt;
&lt;p&gt;순환 신경망(Recurrent Neural Network; RNN)은 지금까지 살펴본 네트워크와는 입력을 받아들이는 방식과 처리하는 방식에 약간 차이가 있습니다. 순환 신경망은 순서가 있는 데이터를 입력으로 받고, 같은 네트워크를 이용해 변화하는 입력에 대한 출력을 얻어냅니다.&lt;/p&gt;
&lt;p&gt;순서가 있는 데이터는 음악, 자연어, 날씨, 주가 등 시간의 흐름에 따라 변화하고 그 변화가 의미를 갖는 데이터입니다.&lt;/p&gt;
&lt;h2 id=&#34;ii-순환-신경망의-구조&#34;&gt;II. 순환 신경망의 구조&lt;/h2&gt;
&lt;p&gt;우선 &lt;code&gt;CNN&lt;/code&gt;과 &lt;code&gt;RNN&lt;/code&gt;의 딥러닝 구조의 차이점에 대해 이미지&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;로 확인하면 보다 직관적으로 이해가 될 수 있습니다.&lt;/p&gt;
&lt;p&gt;CNN의 구조는 본 교재를 계속 따라오셨다면 익숙하다시피, 아래와 같은 구조로 되어 있습니다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_07_01_2/tutorial_01_CNN.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;그러나, RNN의 구조는 아래에서 확인할 수 있는 것처럼, 순환 모양의 화살표가 있다는 것이 차이점입니다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_07_01_2/tutorial_01_RNN.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;순환 신경망의 특징에 대해 간단하게 요약하면 다음과 같습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;입력 X를 받아서, 출력 Y를 반환합니다.&lt;/li&gt;
&lt;li&gt;순환구조를 가지고 있다; 어떤 레이어의 출력을 다시 입력으로 받는 구조를 말합니다.&lt;/li&gt;
&lt;li&gt;순환 신경망은 입력과 출력의 길이에 제한이 없습니다.&lt;/li&gt;
&lt;li&gt;순환 신경망은 이미지에 대한 설명을 생성하는 이미지 설명 생성, 문장의 긍정/부정을 판단하는 감성 분석, 하나의 언어를 다른 언어로 번역하는 기계 번역(Machine Translation) 등 다양한 용도로 활용됩니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;순환 신경망의 이론에 대한 자세한 설명은 교재 (&lt;code&gt;p. 174-5&lt;/code&gt;)를 참조하시기를 바랍니다.&lt;/p&gt;
&lt;h2 id=&#34;iii-주요-레이어-정리&#34;&gt;III. 주요 레이어 정리&lt;/h2&gt;
&lt;p&gt;순환 신경망의 가장 기초적인 레이어는 &lt;code&gt;SimpleRNN&lt;/code&gt; 레이어이며, 이 레이어에서 출발한 &lt;code&gt;LSTM&lt;/code&gt; 레이어 또는 &lt;code&gt;GRU&lt;/code&gt;레이어가 주로 쓰입니다. 그리고, 자연어 처리를 위해서 꼭 알아둬야 하는 임베딩(&lt;code&gt;Embedding&lt;/code&gt;)레이어도 같이 알아봅니다.&lt;/p&gt;
&lt;h3 id=&#34;1-simplernn-레이어&#34;&gt;(1) SimpleRNN 레이어&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;SimpleRNN&lt;/code&gt;레이어는 가장 간단한 형태의 &lt;code&gt;RNN&lt;/code&gt;레이업니다. 수식에 대한 설명은 교재(&lt;code&gt;p. 176&lt;/code&gt;)를 참고합니다. 이 때 주로 사용되는 활성화 함수로는 &lt;code&gt;tanh&lt;/code&gt;가 사용됩니다. &lt;code&gt;tanh&lt;/code&gt;는 실수 입력을 받아 -1에서 1사이의 출력 값을 반환하는 활성하 함수이며, 이 활성화 함수 자리에 &lt;code&gt;ReLU&lt;/code&gt;같은 다른 활성화함수를 쓸 수도 있습니다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;SimpleRNN&lt;/code&gt; 레이어는 &lt;code&gt;tf.keras&lt;/code&gt;에서 한 줄로 간단하게 생성이 가능합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;rnn1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;SimpleRNN(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;tanh&amp;#39;&lt;/span&gt;, return_sequences&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;units&lt;/code&gt;는 &lt;code&gt;SimpleRNN&lt;/code&gt;의 레이어에 존재하는 뉴런의 수를 의미합니다. &lt;code&gt;return_sequences&lt;/code&gt;는 출력으로 시퀀스 전체를 출력할지 여부를 나타내는 옵션이며, 여러 개의 &lt;code&gt;RNN 레이어&lt;/code&gt;를 쌓을 때 쓰입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;간단한 예제를 통해서 학습을 해봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 텐서플로 2 버전 선택&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
    &lt;span style=&#34;color:#75715e&#34;&gt;# %tensorflow_version only exists in Colab.&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;tensorflow_version &lt;span style=&#34;color:#ae81ff&#34;&gt;2.&lt;/span&gt;x
&lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Exception&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;pass&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;):
  &lt;span style=&#34;color:#75715e&#34;&gt;# [0, 1, 2, 3], [1, 2, 3, 4]&lt;/span&gt;
  lst &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; list(range(i,i&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))

  &lt;span style=&#34;color:#75715e&#34;&gt;# 위에서 구한 시퀀스의 숫자들을 각각 10으로 나눈 다음 저장합니다. &lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;# SimpleRNN에 각 타임스텝에 하나씩 숫자가 들어가기 때문에 여기서도 하나씩 분리해서 배열에 저장합니다. &lt;/span&gt;
  X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(list(map(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; c:[c&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;], lst)))

  &lt;span style=&#34;color:#75715e&#34;&gt;# 정답에 해당하는 4, 5 등의 정수 역시 앞에서처럼 10으로 나눠서 저장합니다. &lt;/span&gt;
  Y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append((i&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;)

X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(X)
Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(Y)

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(len(X)): 
  &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(X[i], Y[i])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[[0. ]
 [0.1]
 [0.2]
 [0.3]] 0.4
[[0.1]
 [0.2]
 [0.3]
 [0.4]] 0.5
[[0.2]
 [0.3]
 [0.4]
 [0.5]] 0.6
[[0.3]
 [0.4]
 [0.5]
 [0.6]] 0.7
[[0.4]
 [0.5]
 [0.6]
 [0.7]] 0.8
[[0.5]
 [0.6]
 [0.7]
 [0.8]] 0.9
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;이제 &lt;code&gt;SimpleRNN&lt;/code&gt; 레이어를 사용한 네트워크를 정의합니다. 모델 구조는 지금까지 계속 봐온 시퀀셜 모델이고, 출력을 위한 &lt;code&gt;Dense&lt;/code&gt; 레이어가 뒤에 추가되어 있습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 7.3 시퀀스 예측 모델 정의&lt;/span&gt;
model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;SimpleRNN(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, return_sequences&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;adam&amp;#39;&lt;/span&gt;, loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mse&amp;#39;&lt;/span&gt;)
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential_1&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_1 (SimpleRNN)     (None, 10)                120       
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 11        
=================================================================
Total params: 131
Trainable params: 131
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;여기에서 주목해야 하는 코드는 &lt;code&gt;input_shape&lt;/code&gt;입니다. 여기에서 &lt;code&gt;[4,1]&lt;/code&gt;은 각각 &lt;code&gt;timesteps&lt;/code&gt;, &lt;code&gt;input_dim&lt;/code&gt;을 나타냅니다. 타입스텝은(timesteps)이란 순환 신경망이 입력에 대해 계산을 반복하는 횟수를 말하고, &lt;code&gt;input_dim&lt;/code&gt;은 벡터의 크기를 나타냅니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[[0. ]
 [0.1]
 [0.2]
 [0.3]] 0.4
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;두번째의 4는 타임스텝, 세번째의 1은 &lt;code&gt;input_dim&lt;/code&gt;이 됩니다. 그림을 참조하면 훨씬 이해하기 쉽습니다. (교재, p.180)&lt;/p&gt;
&lt;p&gt;시퀀스 예측 모델은 4 타임스텝에 걸쳐 입력을 받고, 마지막에 출력값을 다음 레이어로 반환합니다. 우리가 추가한 &lt;code&gt;Dense&lt;/code&gt;레이어에는 별도의 활성화함수가 없기 때문에 $h_{3}$는 바로 $y_{3}$이 됩니다. 그리고 이 값과 0.4와의 차이가 &lt;code&gt;mse&lt;/code&gt;, 즉 평균 제곱 오차(&lt;code&gt;Mean Squared Error&lt;/code&gt;)가 됩니다.&lt;/p&gt;
&lt;p&gt;이제 훈련을 시킵니다. 이 때, &lt;code&gt;verbose&lt;/code&gt;값을 0으로 놓으면 훈련 과정에서의 출력이 나오지 않습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(X, Y, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(X))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[[0.37582147]
 [0.5110225 ]
 [0.6267948 ]
 [0.72202194]
 [0.7992587 ]
 [0.86209536]]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;X가 주어졌을 때 학습된 모델이 시퀀스를 어떻게 예측하는지 확인해보면 얼추 비슷하게 예측하고 있음을 확인할 수 있습니다. 그렇다면 학습과정에서 본 적이 없는 테스트 데이터를 넣으면 어떨까요? &lt;code&gt;X&lt;/code&gt;의 범위가 0.0~0.9 였으니, 양쪽으로 한 칸씩 더 나간 데이터를 입력합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[[&lt;span style=&#34;color:#ae81ff&#34;&gt;0.6&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;0.9&lt;/span&gt;]]])))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;0.0&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;]]])))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[[0.9137889]]
[[0.22816285]]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;1을 예측하기를 원한 데이터의 출력으로는 0.91을 0.3을 예측하기 원한 데이터의 출력으로는 0.22의 값을 반환했습니다.&lt;/p&gt;
&lt;p&gt;실무에서는 &lt;code&gt;SimpleRNN&lt;/code&gt;보다는 &lt;code&gt;LSTM&lt;/code&gt; 레이어와 &lt;code&gt;GRU&lt;/code&gt;레이어를 사용합니다.&lt;/p&gt;
&lt;h3 id=&#34;2-lstm-레이어&#34;&gt;(2) LSTM 레이어&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;SimpleRNN&lt;/code&gt; 레이어에는 한 가지 치명적인 단점이 존재합니다. 입력 데이터가 길어질수록, 즉 데이터의 타임스텝이 길어질수록 학습 능력이 떨어진다는 점입니다. 이를 장기의존성(Long-Term Dependency)문제라고 하며, 입력 데이터와 출력 사이의 길이가 멀어질수록 연관 관계가 적어집니다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_07_01_2/tutorial_02_LongTermDependency.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;위 그림이 이러한 문제를 적절하게 표현한 것입니다. 입력 데이터가 길어지면 길어질수록 출력값의 연관 관계가 적어지는 것을 볼 수 있습니다.&lt;/p&gt;
&lt;p&gt;이러한 문제점을 해결하기 위해 &lt;code&gt;LSTM&lt;/code&gt;이 제안 되었습니다.&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; 셀로 나타낸 SimpleRNN과 LSTM의 계산 흐름을 보면 조금 이해가 될 것입니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;먼저 SimpleRNN의 그림은 아래와 같습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_07_01_2/tutorial_02_SimpleRNN.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;여기에서는 타임스텝의 방향으로 $h_{t}$만 전달되고 있음을 확인할 수 있습니다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_07_01_2/tutorial_02_LSTM.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;그런데, 여기에서는 셀 상테인 $c_{t}$가 평생선을 그리며 함께 전달되고 있습니다. 이처럼 타임스텝을 가로지르며 &lt;code&gt;LSTM&lt;/code&gt; 셀 상태가 보존되기 때문에 장기의존성 문제를 해결할 수 있다는 것이 &lt;code&gt;LSTM&lt;/code&gt;의 핵심 아이디어입니다.&lt;/p&gt;
&lt;p&gt;교재 184페이지를 보면 위 셀에 대한 수식이 존재합니다만, 수식에 대한 구체적인 이해가 자료가 필요하다면 크리스토퍼 올라(&lt;code&gt;Christopher Olah&lt;/code&gt;)의 블로그 글을 참고합니다.&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;LSTM&lt;/code&gt;의 학습 능력을 확인하기 위한 예제는 &lt;code&gt;LSTM&lt;/code&gt;을 처음 제안한 논문에 나온 실험 여섯개 중 다섯 번째인 곱셈 문제(&lt;code&gt;Multiplication Problem&lt;/code&gt;)입니다. 이 문제는 말 그대로 실수에 대해 곱셈을 하는 문제인데, 고려해야 할 실수의 범위가 100개이고 그 중에서 마킹된 두개의 숫자만 곱해야 한다는 특이한 문제입니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 텐서플로 2 버전 선택&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
    &lt;span style=&#34;color:#75715e&#34;&gt;# %tensorflow_version only exists in Colab.&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;tensorflow_version &lt;span style=&#34;color:#ae81ff&#34;&gt;2.&lt;/span&gt;x
&lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Exception&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;pass&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;3000&lt;/span&gt;): 
  &lt;span style=&#34;color:#75715e&#34;&gt;# 0 ~ 1 범위의 랜덤한 숫자 100개를 만듭니다. &lt;/span&gt;
  lst &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rand(&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;)

  &lt;span style=&#34;color:#75715e&#34;&gt;# 마킹할 숫자 2개의 인덱스를 뽑습니다. &lt;/span&gt;
  idx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;choice(&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, replace&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)

  &lt;span style=&#34;color:#75715e&#34;&gt;# 마킹 인덱스가 저장된 원-핫 인코딩 벡터를 만듭니다. &lt;/span&gt;
  zeros&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros(&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;)
  zeros[idx]&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
  
  &lt;span style=&#34;color:#75715e&#34;&gt;# 마킹 인덱스와 랜덤한 숫자를 합쳐서 X에 저장합니다. &lt;/span&gt;
  X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(list(zip(zeros, lst))))
  &lt;span style=&#34;color:#75715e&#34;&gt;# 마킹 인덱스가 1인 값만 서로 곱해서 Y에 저장합니다. &lt;/span&gt;
  Y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;prod(lst[idx]))

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(X[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[[0.         0.56858055]
..
 [0.         0.12100308]
 [1.         0.14539513]
 [0.         0.43342875]
..
 [0.         0.5772363 ]
 [1.         0.21461413]
 [0.         0.95933064]
..
 [0.         0.55055634]
 [0.         0.20978592]] 0.03120384949137252
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;입력된 값이 길지만, 1은 두번만 들어가 있기 때문에, 1이 찍인 원소를 찾습니다. &lt;code&gt;[1.    0.08361932]&lt;/code&gt;과 &lt;code&gt;[1.         0.66439549]&lt;/code&gt;이 확인이 됩니다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;0.08361932&lt;/code&gt;와 &lt;code&gt;0.66439549&lt;/code&gt;를 곱하면 &lt;code&gt;0.055556298045436&lt;/code&gt;값이 나옵니다. &lt;code&gt;SimpleRNN&lt;/code&gt; 레이어를 이용한 곱셈 문제 모델을 정의합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;SimpleRNN(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;30&lt;/span&gt;, return_sequences&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;SimpleRNN(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;30&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;adam&amp;#39;&lt;/span&gt;, loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mse&amp;#39;&lt;/span&gt;)
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn (SimpleRNN)       (None, 100, 30)           990       
_________________________________________________________________
simple_rnn_1 (SimpleRNN)     (None, 30)                1830      
_________________________________________________________________
dense (Dense)                (None, 1)                 31        
=================================================================
Total params: 2,851
Trainable params: 2,851
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;RNN&lt;/code&gt; 레이어를 겹치기 위해 첫 번째 &lt;code&gt;SimpleRNN&lt;/code&gt;레이어에서 &lt;code&gt;return_sequences=True&lt;/code&gt;로 설정된 것을 확인할 수 있습니다. &lt;code&gt;return_sequences&lt;/code&gt;는 레이어의 출력을 다음 레이어로 그대로 넘겨주게 됩니다.&lt;/p&gt;
&lt;p&gt;겹치는 레이어의 구조에 대한 이론 설명은 교재 &lt;code&gt;188페이지&lt;/code&gt;를 참조하시기를 바랍니다. &lt;code&gt;RNN&lt;/code&gt;은 &lt;code&gt;CNN&lt;/code&gt;보다 학습 시간이 오래 걸리는 편이기 때문에 반드시 가속기를 &lt;code&gt;GPU&lt;/code&gt;로 바꿔줍니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(X)
Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(Y)

&lt;span style=&#34;color:#75715e&#34;&gt;# 2560개의 데이터만 학습시킵니다. 검증 데이터는 20%로 저장합니다. &lt;/span&gt;
history&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(X[:&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;], Y[:&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;], epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/100
64/64 [==============================] - 8s 118ms/step - loss: 0.0559 - val_loss: 0.0494
Epoch 2/100
64/64 [==============================] - 8s 119ms/step - loss: 0.0493 - val_loss: 0.0480
Epoch 3/100
64/64 [==============================] - 7s 114ms/step - loss: 0.0480 - val_loss: 0.0479
Epoch 4/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0487 - val_loss: 0.0471
Epoch 5/100
64/64 [==============================] - 7s 114ms/step - loss: 0.0478 - val_loss: 0.0539
Epoch 6/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0477 - val_loss: 0.0518
Epoch 7/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0481 - val_loss: 0.0473
Epoch 8/100
64/64 [==============================] - 7s 112ms/step - loss: 0.0472 - val_loss: 0.0490
Epoch 9/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0468 - val_loss: 0.0486
Epoch 10/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0464 - val_loss: 0.0507
Epoch 11/100
64/64 [==============================] - 7s 114ms/step - loss: 0.0482 - val_loss: 0.0481
Epoch 12/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0481 - val_loss: 0.0488
Epoch 13/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0475 - val_loss: 0.0491
Epoch 14/100
64/64 [==============================] - 7s 114ms/step - loss: 0.0468 - val_loss: 0.0473
Epoch 15/100
64/64 [==============================] - 7s 112ms/step - loss: 0.0464 - val_loss: 0.0496
Epoch 16/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0474 - val_loss: 0.0493
Epoch 17/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0458 - val_loss: 0.0495
Epoch 18/100
64/64 [==============================] - 7s 114ms/step - loss: 0.0458 - val_loss: 0.0495
Epoch 19/100
64/64 [==============================] - 7s 111ms/step - loss: 0.0452 - val_loss: 0.0487
Epoch 20/100
64/64 [==============================] - 7s 114ms/step - loss: 0.0456 - val_loss: 0.0505
Epoch 21/100
64/64 [==============================] - 7s 112ms/step - loss: 0.0449 - val_loss: 0.0490
Epoch 22/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0447 - val_loss: 0.0475
Epoch 23/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0444 - val_loss: 0.0494
Epoch 24/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0456 - val_loss: 0.0492
Epoch 25/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0446 - val_loss: 0.0501
Epoch 26/100
64/64 [==============================] - 7s 112ms/step - loss: 0.0450 - val_loss: 0.0508
Epoch 27/100
64/64 [==============================] - 7s 112ms/step - loss: 0.0442 - val_loss: 0.0519
Epoch 28/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0433 - val_loss: 0.0489
Epoch 29/100
64/64 [==============================] - 7s 115ms/step - loss: 0.0436 - val_loss: 0.0497
Epoch 30/100
64/64 [==============================] - 8s 118ms/step - loss: 0.0441 - val_loss: 0.0519
Epoch 31/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0442 - val_loss: 0.0501
Epoch 32/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0422 - val_loss: 0.0488
Epoch 33/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0427 - val_loss: 0.0564
Epoch 34/100
64/64 [==============================] - 7s 114ms/step - loss: 0.0429 - val_loss: 0.0511
Epoch 35/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0417 - val_loss: 0.0525
Epoch 36/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0411 - val_loss: 0.0520
Epoch 37/100
64/64 [==============================] - 7s 114ms/step - loss: 0.0429 - val_loss: 0.0525
Epoch 38/100
64/64 [==============================] - 7s 112ms/step - loss: 0.0412 - val_loss: 0.0502
Epoch 39/100
64/64 [==============================] - 7s 114ms/step - loss: 0.0410 - val_loss: 0.0556
Epoch 40/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0407 - val_loss: 0.0520
Epoch 41/100
64/64 [==============================] - 7s 114ms/step - loss: 0.0404 - val_loss: 0.0493
Epoch 42/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0388 - val_loss: 0.0541
Epoch 43/100
64/64 [==============================] - 7s 114ms/step - loss: 0.0391 - val_loss: 0.0563
Epoch 44/100
64/64 [==============================] - 7s 116ms/step - loss: 0.0392 - val_loss: 0.0506
Epoch 45/100
64/64 [==============================] - 7s 111ms/step - loss: 0.0400 - val_loss: 0.0556
Epoch 46/100
64/64 [==============================] - 7s 114ms/step - loss: 0.0390 - val_loss: 0.0554
Epoch 47/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0385 - val_loss: 0.0515
Epoch 48/100
64/64 [==============================] - 7s 115ms/step - loss: 0.0373 - val_loss: 0.0522
Epoch 49/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0373 - val_loss: 0.0556
Epoch 50/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0379 - val_loss: 0.0587
Epoch 51/100
64/64 [==============================] - 7s 112ms/step - loss: 0.0371 - val_loss: 0.0550
Epoch 52/100
64/64 [==============================] - 7s 115ms/step - loss: 0.0362 - val_loss: 0.0537
Epoch 53/100
64/64 [==============================] - 7s 112ms/step - loss: 0.0364 - val_loss: 0.0591
Epoch 54/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0356 - val_loss: 0.0537
Epoch 55/100
64/64 [==============================] - 7s 112ms/step - loss: 0.0348 - val_loss: 0.0591
Epoch 56/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0351 - val_loss: 0.0572
Epoch 57/100
64/64 [==============================] - 7s 115ms/step - loss: 0.0339 - val_loss: 0.0585
Epoch 58/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0336 - val_loss: 0.0593
Epoch 59/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0337 - val_loss: 0.0587
Epoch 60/100
64/64 [==============================] - 7s 115ms/step - loss: 0.0339 - val_loss: 0.0574
Epoch 61/100
64/64 [==============================] - 7s 112ms/step - loss: 0.0323 - val_loss: 0.0582
Epoch 62/100
64/64 [==============================] - 7s 115ms/step - loss: 0.0328 - val_loss: 0.0586
Epoch 63/100
64/64 [==============================] - 7s 112ms/step - loss: 0.0329 - val_loss: 0.0572
Epoch 64/100
64/64 [==============================] - 7s 114ms/step - loss: 0.0318 - val_loss: 0.0610
Epoch 65/100
64/64 [==============================] - 7s 116ms/step - loss: 0.0315 - val_loss: 0.0537
Epoch 66/100
64/64 [==============================] - 7s 114ms/step - loss: 0.0309 - val_loss: 0.0599
Epoch 67/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0305 - val_loss: 0.0585
Epoch 68/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0303 - val_loss: 0.0599
Epoch 69/100
64/64 [==============================] - 7s 115ms/step - loss: 0.0297 - val_loss: 0.0633
Epoch 70/100
64/64 [==============================] - 7s 114ms/step - loss: 0.0296 - val_loss: 0.0600
Epoch 71/100
64/64 [==============================] - 7s 114ms/step - loss: 0.0289 - val_loss: 0.0612
Epoch 72/100
64/64 [==============================] - 8s 120ms/step - loss: 0.0284 - val_loss: 0.0619
Epoch 73/100
64/64 [==============================] - 7s 115ms/step - loss: 0.0287 - val_loss: 0.0637
Epoch 74/100
64/64 [==============================] - 7s 115ms/step - loss: 0.0291 - val_loss: 0.0568
Epoch 75/100
64/64 [==============================] - 7s 111ms/step - loss: 0.0287 - val_loss: 0.0617
Epoch 76/100
64/64 [==============================] - 7s 115ms/step - loss: 0.0287 - val_loss: 0.0605
Epoch 77/100
64/64 [==============================] - 7s 115ms/step - loss: 0.0272 - val_loss: 0.0614
Epoch 78/100
64/64 [==============================] - 7s 116ms/step - loss: 0.0269 - val_loss: 0.0606
Epoch 79/100
64/64 [==============================] - 7s 116ms/step - loss: 0.0264 - val_loss: 0.0630
Epoch 80/100
64/64 [==============================] - 8s 117ms/step - loss: 0.0258 - val_loss: 0.0701
Epoch 81/100
64/64 [==============================] - 7s 117ms/step - loss: 0.0263 - val_loss: 0.0633
Epoch 82/100
64/64 [==============================] - 7s 115ms/step - loss: 0.0267 - val_loss: 0.0635
Epoch 83/100
64/64 [==============================] - 7s 117ms/step - loss: 0.0261 - val_loss: 0.0666
Epoch 84/100
64/64 [==============================] - 8s 119ms/step - loss: 0.0254 - val_loss: 0.0624
Epoch 85/100
64/64 [==============================] - 8s 119ms/step - loss: 0.0253 - val_loss: 0.0601
Epoch 86/100
64/64 [==============================] - 7s 115ms/step - loss: 0.0263 - val_loss: 0.0647
Epoch 87/100
64/64 [==============================] - 7s 116ms/step - loss: 0.0238 - val_loss: 0.0676
Epoch 88/100
64/64 [==============================] - 7s 115ms/step - loss: 0.0239 - val_loss: 0.0661
Epoch 89/100
64/64 [==============================] - 8s 118ms/step - loss: 0.0237 - val_loss: 0.0641
Epoch 90/100
64/64 [==============================] - 7s 116ms/step - loss: 0.0239 - val_loss: 0.0680
Epoch 91/100
64/64 [==============================] - 7s 116ms/step - loss: 0.0222 - val_loss: 0.0672
Epoch 92/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0230 - val_loss: 0.0659
Epoch 93/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0222 - val_loss: 0.0668
Epoch 94/100
64/64 [==============================] - 7s 114ms/step - loss: 0.0235 - val_loss: 0.0634
Epoch 95/100
64/64 [==============================] - 7s 114ms/step - loss: 0.0231 - val_loss: 0.0660
Epoch 96/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0224 - val_loss: 0.0654
Epoch 97/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0211 - val_loss: 0.0657
Epoch 98/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0217 - val_loss: 0.0689
Epoch 99/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0212 - val_loss: 0.0667
Epoch 100/100
64/64 [==============================] - 7s 113ms/step - loss: 0.0216 - val_loss: 0.0664
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;훈련 데이터의 손실(&lt;code&gt;loss&lt;/code&gt;)과 검증 데이터의 손실(&lt;code&gt;var_loss&lt;/code&gt;)는 감소하지 않고 오히려 증가하는 것 같습니다. 경향을 직관적으로 파악하기 위해 &lt;code&gt;history&lt;/code&gt; 변수에 저장된 값으로 그래프를 그려봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_07_01_2/output_18_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;학습 결과는 전형적인 과적합 그래프를 보여줍니다. 테스트 데이터에 대한 예측은 어떨까요? 논문에서는 오차가 0.04 이상일 때 오답으로 처리합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(X[&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;:], Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;:])
prediction&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(X[&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;])

&lt;span style=&#34;color:#75715e&#34;&gt;# 5개 테스트 데이터에 대한 예측을 표시합니다. &lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;): 
  &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;i], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;, prediction[i][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;diff:&amp;#39;&lt;/span&gt;, abs(prediction[i][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;i]))

prediction &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(X[&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;:])
fail &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(len(prediction)):
  &lt;span style=&#34;color:#75715e&#34;&gt;# 오차가 0.04 이상이면 오답입니다. &lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; abs(prediction[i][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;i]) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.04&lt;/span&gt;:
    fail &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;correctness:&amp;#39;&lt;/span&gt;, (&lt;span style=&#34;color:#ae81ff&#34;&gt;440&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;fail)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;440&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;%&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;14/14 [==============================] - 0s 16ms/step - loss: 0.0667
0.009316712705671063 	 -0.05508966 	diff: 0.06440637269455123
0.1595728709352136 	 0.051416673 	diff: 0.10815619816900496
0.343633615267837 	 0.27744463 	diff: 0.06618898440655463
0.047836290850227836 	 0.23675384 	diff: 0.1889175454239192
0.07471709800989841 	 0.19511518 	diff: 0.12039808081357266
correctness: 12.727272727272727 %
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;먼저 전체에 대한 평가는 &lt;code&gt;0.0667&lt;/code&gt;의 &lt;code&gt;loss&lt;/code&gt;가 나왔습니다. 위에서 본 100번째의 에포크의 &lt;code&gt;val_loss&lt;/code&gt;인 &lt;code&gt;0.0664&lt;/code&gt;보다도 높은 값으로, 네트워크가 학습 과정에서 한번도 못 본 테스트 데이터에 대해서는 잘 예측하지 못합니다. 5개의 테스트 데이터에 대한 샘플은 오차가 &lt;code&gt;0.01&lt;/code&gt;에서 &lt;code&gt;0.18&lt;/code&gt;까지 다양하게 나타나며, 가장 중요한 정확도는 &lt;code&gt;12.72&lt;/code&gt;로 확인 됩니다.&lt;/p&gt;
&lt;p&gt;그렇다면 &lt;code&gt;LSTM&lt;/code&gt;레이어는 어떨까요? 이 문제를 풀기 위해 시퀀셜 모델을 정의합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;LSTM(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;30&lt;/span&gt;, return_sequences&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;LSTM(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;30&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;adam&amp;#39;&lt;/span&gt;, loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mse&amp;#39;&lt;/span&gt;)
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential_1&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 100, 30)           3960      
_________________________________________________________________
lstm_1 (LSTM)                (None, 30)                7320      
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 31        
=================================================================
Total params: 11,311
Trainable params: 11,311
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;차이점은 &lt;code&gt;SimpleRNN&lt;/code&gt;을 &lt;code&gt;LSTM&lt;/code&gt;으로 바꾼 것 뿐입니다. 네트워크의 학습코드도 동일합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(X)
Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(Y)

&lt;span style=&#34;color:#75715e&#34;&gt;# 2560개의 데이터만 학습시킵니다. 검증 데이터는 20%로 저장합니다. &lt;/span&gt;
history&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(X[:&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;], Y[:&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;], epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;)

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/100
64/64 [==============================] - 3s 54ms/step - loss: 0.0507 - val_loss: 0.0470
Epoch 2/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0472 - val_loss: 0.0469
Epoch 3/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0473 - val_loss: 0.0482
Epoch 4/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0474 - val_loss: 0.0482
Epoch 5/100
64/64 [==============================] - 3s 44ms/step - loss: 0.0474 - val_loss: 0.0471
Epoch 6/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0474 - val_loss: 0.0476
Epoch 7/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0471 - val_loss: 0.0474
Epoch 8/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0477 - val_loss: 0.0474
Epoch 9/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0472 - val_loss: 0.0472
Epoch 10/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0469 - val_loss: 0.0471
Epoch 11/100
64/64 [==============================] - 3s 44ms/step - loss: 0.0471 - val_loss: 0.0484
Epoch 12/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0473 - val_loss: 0.0472
Epoch 13/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0467 - val_loss: 0.0483
Epoch 14/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0466 - val_loss: 0.0471
Epoch 15/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0470 - val_loss: 0.0470
Epoch 16/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0466 - val_loss: 0.0471
Epoch 17/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0464 - val_loss: 0.0470
Epoch 18/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0464 - val_loss: 0.0483
Epoch 19/100
64/64 [==============================] - 3s 42ms/step - loss: 0.0465 - val_loss: 0.0467
Epoch 20/100
64/64 [==============================] - 3s 42ms/step - loss: 0.0462 - val_loss: 0.0465
Epoch 21/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0481 - val_loss: 0.0468
Epoch 22/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0467 - val_loss: 0.0474
Epoch 23/100
64/64 [==============================] - 3s 42ms/step - loss: 0.0465 - val_loss: 0.0468
Epoch 24/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0463 - val_loss: 0.0471
Epoch 25/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0461 - val_loss: 0.0478
Epoch 26/100
64/64 [==============================] - 3s 42ms/step - loss: 0.0457 - val_loss: 0.0464
Epoch 27/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0456 - val_loss: 0.0462
Epoch 28/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0459 - val_loss: 0.0485
Epoch 29/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0454 - val_loss: 0.0460
Epoch 30/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0474 - val_loss: 0.0464
Epoch 31/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0457 - val_loss: 0.0475
Epoch 32/100
64/64 [==============================] - 3s 42ms/step - loss: 0.0455 - val_loss: 0.0461
Epoch 33/100
64/64 [==============================] - 3s 42ms/step - loss: 0.0451 - val_loss: 0.0455
Epoch 34/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0448 - val_loss: 0.0450
Epoch 35/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0438 - val_loss: 0.0524
Epoch 36/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0453 - val_loss: 0.0448
Epoch 37/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0427 - val_loss: 0.0408
Epoch 38/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0481 - val_loss: 0.0462
Epoch 39/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0457 - val_loss: 0.0455
Epoch 40/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0447 - val_loss: 0.0443
Epoch 41/100
64/64 [==============================] - 3s 42ms/step - loss: 0.0419 - val_loss: 0.0390
Epoch 42/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0353 - val_loss: 0.0254
Epoch 43/100
64/64 [==============================] - 3s 42ms/step - loss: 0.0223 - val_loss: 0.0199
Epoch 44/100
64/64 [==============================] - 3s 42ms/step - loss: 0.0188 - val_loss: 0.0155
Epoch 45/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0117 - val_loss: 0.0099
Epoch 46/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0092 - val_loss: 0.0070
Epoch 47/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0060 - val_loss: 0.0046
Epoch 48/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0062 - val_loss: 0.0043
Epoch 49/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0131 - val_loss: 0.0063
Epoch 50/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0050 - val_loss: 0.0041
Epoch 51/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0035 - val_loss: 0.0033
Epoch 52/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0032 - val_loss: 0.0034
Epoch 53/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0029 - val_loss: 0.0029
Epoch 54/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0033 - val_loss: 0.0024
Epoch 55/100
64/64 [==============================] - 3s 42ms/step - loss: 0.0034 - val_loss: 0.0025
Epoch 56/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0026 - val_loss: 0.0031
Epoch 57/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0023 - val_loss: 0.0023
Epoch 58/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0022 - val_loss: 0.0020
Epoch 59/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0017 - val_loss: 0.0023
Epoch 60/100
64/64 [==============================] - 3s 42ms/step - loss: 0.0018 - val_loss: 0.0032
Epoch 61/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0024 - val_loss: 0.0017
Epoch 62/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0018 - val_loss: 0.0040
Epoch 63/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0018 - val_loss: 0.0015
Epoch 64/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0018 - val_loss: 0.0016
Epoch 65/100
64/64 [==============================] - 3s 42ms/step - loss: 0.0013 - val_loss: 0.0017
Epoch 66/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0012 - val_loss: 0.0017
Epoch 67/100
64/64 [==============================] - 3s 42ms/step - loss: 0.0016 - val_loss: 0.0021
Epoch 68/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0013 - val_loss: 0.0015
Epoch 69/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0011 - val_loss: 0.0010
Epoch 70/100
64/64 [==============================] - 3s 42ms/step - loss: 8.9019e-04 - val_loss: 0.0012
Epoch 71/100
64/64 [==============================] - 3s 43ms/step - loss: 9.5466e-04 - val_loss: 9.1598e-04
Epoch 72/100
64/64 [==============================] - 3s 43ms/step - loss: 0.0012 - val_loss: 0.0013
Epoch 73/100
64/64 [==============================] - 3s 42ms/step - loss: 9.1245e-04 - val_loss: 9.0190e-04
Epoch 74/100
64/64 [==============================] - 3s 43ms/step - loss: 7.8530e-04 - val_loss: 8.0207e-04
Epoch 75/100
64/64 [==============================] - 3s 42ms/step - loss: 9.1405e-04 - val_loss: 8.6976e-04
Epoch 76/100
64/64 [==============================] - 3s 42ms/step - loss: 8.3703e-04 - val_loss: 8.9048e-04
Epoch 77/100
64/64 [==============================] - 3s 42ms/step - loss: 7.5276e-04 - val_loss: 8.5232e-04
Epoch 78/100
64/64 [==============================] - 3s 42ms/step - loss: 7.6209e-04 - val_loss: 8.4933e-04
Epoch 79/100
64/64 [==============================] - 3s 42ms/step - loss: 6.7965e-04 - val_loss: 6.3633e-04
Epoch 80/100
64/64 [==============================] - 3s 43ms/step - loss: 7.7308e-04 - val_loss: 6.0886e-04
Epoch 81/100
64/64 [==============================] - 3s 42ms/step - loss: 0.0020 - val_loss: 7.1028e-04
Epoch 82/100
64/64 [==============================] - 3s 42ms/step - loss: 5.6736e-04 - val_loss: 6.5136e-04
Epoch 83/100
64/64 [==============================] - 3s 42ms/step - loss: 0.0012 - val_loss: 0.0010
Epoch 84/100
64/64 [==============================] - 3s 43ms/step - loss: 5.5983e-04 - val_loss: 6.3431e-04
Epoch 85/100
64/64 [==============================] - 3s 42ms/step - loss: 5.7588e-04 - val_loss: 6.2150e-04
Epoch 86/100
64/64 [==============================] - 3s 43ms/step - loss: 5.1412e-04 - val_loss: 4.9473e-04
Epoch 87/100
64/64 [==============================] - 3s 42ms/step - loss: 4.5491e-04 - val_loss: 6.0971e-04
Epoch 88/100
64/64 [==============================] - 3s 42ms/step - loss: 5.9710e-04 - val_loss: 5.0932e-04
Epoch 89/100
64/64 [==============================] - 3s 43ms/step - loss: 3.7854e-04 - val_loss: 7.4333e-04
Epoch 90/100
64/64 [==============================] - 3s 43ms/step - loss: 5.4616e-04 - val_loss: 5.6270e-04
Epoch 91/100
64/64 [==============================] - 3s 43ms/step - loss: 4.5601e-04 - val_loss: 5.5043e-04
Epoch 92/100
64/64 [==============================] - 3s 43ms/step - loss: 4.3344e-04 - val_loss: 4.6876e-04
Epoch 93/100
64/64 [==============================] - 3s 42ms/step - loss: 5.3680e-04 - val_loss: 4.5829e-04
Epoch 94/100
64/64 [==============================] - 3s 43ms/step - loss: 7.5234e-04 - val_loss: 6.1782e-04
Epoch 95/100
64/64 [==============================] - 3s 42ms/step - loss: 3.7421e-04 - val_loss: 3.6062e-04
Epoch 96/100
64/64 [==============================] - 3s 43ms/step - loss: 3.9064e-04 - val_loss: 5.2667e-04
Epoch 97/100
64/64 [==============================] - 3s 43ms/step - loss: 4.5003e-04 - val_loss: 4.0708e-04
Epoch 98/100
64/64 [==============================] - 3s 43ms/step - loss: 5.4694e-04 - val_loss: 0.0011
Epoch 99/100
64/64 [==============================] - 3s 42ms/step - loss: 5.4764e-04 - val_loss: 7.6580e-04
Epoch 100/100
64/64 [==============================] - 3s 43ms/step - loss: 5.1314e-04 - val_loss: 4.5973e-04
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_07_01_2/output_24_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;loss&lt;/code&gt;와 &lt;code&gt;val_loss&lt;/code&gt;는 40에포크를 넘어가면서 매우 가파르게 줄어들어 0에 가까워집니다. &lt;code&gt;val_loss&lt;/code&gt;는 변동폭이 &lt;code&gt;loss&lt;/code&gt;보다 크지만 전체적으로는 계속 감소하는 경향을 보입니다. 학습이 매우 잘 된 것으로 보입니다.&lt;/p&gt;
&lt;p&gt;이번에는 실제로 테스트 데이터에 얼마나 정확하게 값을 예측하는지 확인해봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(X[&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;:], Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;:])
prediction&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(X[&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;])

&lt;span style=&#34;color:#75715e&#34;&gt;# 5개 테스트 데이터에 대한 예측을 표시합니다. &lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;): 
  &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;i], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;, prediction[i][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;diff:&amp;#39;&lt;/span&gt;, abs(prediction[i][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;i]))

prediction &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(X[&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;:])
fail &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(len(prediction)):
  &lt;span style=&#34;color:#75715e&#34;&gt;# 오차가 0.04 이상이면 오답입니다. &lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; abs(prediction[i][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;2560&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;i]) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.04&lt;/span&gt;:
    fail &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;correctness:&amp;#39;&lt;/span&gt;, (&lt;span style=&#34;color:#ae81ff&#34;&gt;440&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;fail)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;440&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;%&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;14/14 [==============================] - 0s 13ms/step - loss: 3.9453e-04
0.009316712705671063 	 0.02192213 	diff: 0.012605417432010898
0.1595728709352136 	 0.15154022 	diff: 0.008032651151430648
0.343633615267837 	 0.33932722 	diff: 0.004306399119460513
0.047836290850227836 	 0.03347582 	diff: 0.014360470875090126
0.07471709800989841 	 0.06377047 	diff: 0.01094662500651096
correctness: 95.9090909090909 %
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;테스트 데이터에 대한 &lt;code&gt;loss&lt;/code&gt;는 0에 가까운 값이 나오고, 다섯 개의 샘플에 대한 오차도 0.04를 넘는 값이 없습니다. 또한 정확도 역시, 95.9%로 거의 96%에 가까운 것을 확인할 수 있습니다.&lt;/p&gt;
&lt;p&gt;곱셈문제를 푸는데 있어서 &lt;code&gt;LSTM&lt;/code&gt;이 보다 적합하다는 것을 알 수 있습니다.&lt;/p&gt;
&lt;p&gt;다음 포스트에서는 &lt;code&gt;GRU&lt;/code&gt;레이어와 &lt;code&gt;임베딩&lt;/code&gt;레이어에 대해 학습하도록 합니다.&lt;/p&gt;
&lt;h2 id=&#34;iv-연습-파일&#34;&gt;IV. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch7_1_2_RNN_theory(1).ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;vi-reference&#34;&gt;VI. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Different between CNN，RNN（Quote） Retrieved from &lt;a href=&#34;https://medium.com/@Aj.Cheng/different-between-cnn-rnn-quote-7c224795db58&#34;&gt;https://medium.com/@Aj.Cheng/different-between-cnn-rnn-quote-7c224795db58&lt;/a&gt; &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;1997년 셉 호흐라이터(Sepp Hochreiter) 유르겐 슈미트후버(Jurgen Schmidhuber)에 의해 제안됨, (S. Hochreiter and J. Schmidhuber. Long short-term memory. Neural Computation, 1997. &lt;a href=&#34;https://www.bioinf.jku.at/publications/older/2604.pdf&#34;&gt;https://www.bioinf.jku.at/publications/older/2604.pdf&lt;/a&gt; &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Olah, Christopher. “Understanding LSTM Networks.” Understanding LSTM Networks &amp;ndash; Colah&amp;rsquo;s Blog, colah.github.io/posts/2015-08-Understanding-LSTMs/ &lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch6.4 - 모형의 성능 높이기</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch6_4_improve_performance/</link>
      <pubDate>Tue, 21 Apr 2020 21:08:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch6_4_improve_performance/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.2 - 다항분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/&#34;&gt;Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/&#34;&gt;Tensorflow 2.0 Tutorial ch6.1-2 - CNN 이론&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_3_fashion_mnist_with_cnn/&#34;&gt;Tensorflow 2.0 Tutorial ch6.3 - Fashion MNIST with CNN 실습&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요&#34;&gt;I. 개요&lt;/h2&gt;
&lt;p&gt;성능을 높이는 데는 그 중 대표적이면서 쉬운 두 가지 방법은 &lt;code&gt;더 많은 레이어 쌓기&lt;/code&gt;와 &lt;code&gt;이미지 보강(Image Augmentation)&lt;/code&gt; 기법입니다.&lt;/p&gt;
&lt;h2 id=&#34;ii-더-많은-레이어-쌓기&#34;&gt;II. 더 많은 레이어 쌓기&lt;/h2&gt;
&lt;p&gt;딥러닝의 역사는 더 깊은 신경망을 쌓기 위한 노력이라고 해도 과언이 아닙니다. 컨볼루션 레이어가 중첩된 더 깊은 구조가 계속해서 나타났고, 그럴 때마다 이전 구조의 성능을 개선 시켰습니다. (Teerapittayanon, et. all., 2017)&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_06_04/Figure_01_deeper_neural_networks.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;이번 예제에서는 &lt;code&gt;VGGNet&lt;/code&gt;의 스타일로 구성한 컨볼루션 신경망을 응용 및 사용합니다.&lt;/p&gt;
&lt;h2 id=&#34;iii-vggnet-모형-정의&#34;&gt;III. VGGNet 모형 정의&lt;/h2&gt;
&lt;p&gt;데이터를 불러온 뒤, 정규화를 진행합니다. 그리고 곧바로 모형을 만들도록 합니다.&lt;/p&gt;
&lt;h3 id=&#34;1-데이터-불러오기-및-정규화&#34;&gt;(1) 데이터 불러오기 및 정규화&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
fashion_mnist &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;datasets&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fashion_mnist
(train_X, train_Y), (test_X, test_Y) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; fashion_mnist&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load_data()

train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_X &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# reshape 이전&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)

train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# reshape 이후&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz
32768/29515 [=================================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz
26427392/26421880 [==============================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz
8192/5148 [===============================================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz
4423680/4422102 [==============================] - 0s 0us/step
(60000, 28, 28) (10000, 28, 28)
(60000, 28, 28, 1) (10000, 28, 28, 1)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;2-모형-정의&#34;&gt;(2) 모형 정의&lt;/h3&gt;
&lt;p&gt;이번에는 모형 정의를 진행합니다. 코드가 길어질 수 있으니 주의하기 바랍니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf

model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;MaxPool2D(pool_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout(rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),    
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;valid&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),  
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;MaxPool2D(pool_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)),
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout(rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;),
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Flatten(), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;512&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout(rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;),
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout(rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;),
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;)                           
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(), 
              loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sparse_categorical_crossentropy&amp;#39;&lt;/span&gt;, 
              metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential_1&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_4 (Conv2D)            (None, 28, 28, 32)        320       
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 28, 28, 64)        18496     
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 14, 14, 64)        0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 14, 14, 128)       73856     
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 12, 12, 256)       295168    
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 6, 6, 256)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 9216)              0         
_________________________________________________________________
dense_3 (Dense)              (None, 512)               4719104   
_________________________________________________________________
dropout_6 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 256)               131328    
_________________________________________________________________
dropout_7 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_5 (Dense)              (None, 10)                2570      
=================================================================
Total params: 5,240,842
Trainable params: 5,240,842
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;VGGNet&lt;/code&gt;은 여러 개의 구조로 실험했는데 그 중 19개의 레이어가 겹쳐진 &lt;code&gt;VGG-19&lt;/code&gt;가 제일 깊은 구조입니다. &lt;code&gt;VGG-19&lt;/code&gt;는 특징 추출기의 초반에 컨볼루션 레이어를 2개 겹친 뒤 풀링 레이어 1개를 사용하는 패턴을 2차례, 그 후 컨볼루션 레이어를 4개 겹친 뒤 풀링 레이어 1개를 사용하는 패턴을 3차례 반복합니다.&lt;/p&gt;
&lt;p&gt;그러나, 이 역시 대상 이미지의 크기 등에 따라 달라집니다.&lt;/p&gt;
&lt;p&gt;여기에서는 컨볼루션 레이어를 2개 겹치고 풀링 레이어를 1개 사용하는 패턴을 2차례 반복합니다. 풀링 레이어 다음에 드롭아웃 레이러를 위치시켜서 과적합을 방지합니다. 또한, Flatten 레이어 다음에 이어지는 3개의 Dense 레이어 사이에도 드롭아웃 레이어를 배치합니다. 컨볼루션 레이어와 Dense 레이어의 개수만 세면 &lt;code&gt;VGG-7&lt;/code&gt;레이어가 됩니다.&lt;/p&gt;
&lt;p&gt;오리지널 &lt;code&gt;VGG-19&lt;/code&gt;보다는 깊이가 얕지만 총 파라미터 개수는 약 &lt;code&gt;520만개&lt;/code&gt;로 적지 않습니다. (ch6_3. 24만개)&lt;/p&gt;
&lt;h3 id=&#34;3-모형-성능-확인&#34;&gt;(3) 모형 성능 확인&lt;/h3&gt;
&lt;p&gt;이 모델의 성능을 확인해봅니다. (이 때, 런타임 유형을 GPU로 변경 하는 것을 잊으면 안됩니다.)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_X, train_Y, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.5858 - accuracy: 0.7878 - val_loss: 0.3329 - val_accuracy: 0.8759
Epoch 2/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.3676 - accuracy: 0.8678 - val_loss: 0.2709 - val_accuracy: 0.9017
Epoch 3/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.3306 - accuracy: 0.8815 - val_loss: 0.2607 - val_accuracy: 0.8999
Epoch 4/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.3043 - accuracy: 0.8901 - val_loss: 0.2482 - val_accuracy: 0.9171
Epoch 5/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2878 - accuracy: 0.8965 - val_loss: 0.2296 - val_accuracy: 0.9163
Epoch 6/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2759 - accuracy: 0.9005 - val_loss: 0.2454 - val_accuracy: 0.9056
Epoch 7/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2649 - accuracy: 0.9049 - val_loss: 0.2153 - val_accuracy: 0.9227
Epoch 8/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2626 - accuracy: 0.9041 - val_loss: 0.2187 - val_accuracy: 0.9204
Epoch 9/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2546 - accuracy: 0.9093 - val_loss: 0.2130 - val_accuracy: 0.9227
Epoch 10/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2534 - accuracy: 0.9085 - val_loss: 0.2186 - val_accuracy: 0.9227
Epoch 11/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2517 - accuracy: 0.9110 - val_loss: 0.2101 - val_accuracy: 0.9272
Epoch 12/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2427 - accuracy: 0.9122 - val_loss: 0.2111 - val_accuracy: 0.9221
Epoch 13/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2397 - accuracy: 0.9150 - val_loss: 0.2025 - val_accuracy: 0.9294
Epoch 14/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2396 - accuracy: 0.9150 - val_loss: 0.2115 - val_accuracy: 0.9220
Epoch 15/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2338 - accuracy: 0.9166 - val_loss: 0.2102 - val_accuracy: 0.9247
Epoch 16/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2347 - accuracy: 0.9157 - val_loss: 0.2063 - val_accuracy: 0.9285
Epoch 17/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2352 - accuracy: 0.9172 - val_loss: 0.2064 - val_accuracy: 0.9237
Epoch 18/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2290 - accuracy: 0.9180 - val_loss: 0.2118 - val_accuracy: 0.9237
Epoch 19/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2331 - accuracy: 0.9171 - val_loss: 0.2027 - val_accuracy: 0.9286
Epoch 20/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2254 - accuracy: 0.9200 - val_loss: 0.2003 - val_accuracy: 0.9299
Epoch 21/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2312 - accuracy: 0.9199 - val_loss: 0.2064 - val_accuracy: 0.9250
Epoch 22/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2277 - accuracy: 0.9194 - val_loss: 0.1962 - val_accuracy: 0.9290
Epoch 23/25
1407/1407 [==============================] - 8s 6ms/step - loss: 0.2278 - accuracy: 0.9188 - val_loss: 0.1952 - val_accuracy: 0.9341
Epoch 24/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2258 - accuracy: 0.9208 - val_loss: 0.1999 - val_accuracy: 0.9290
Epoch 25/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2196 - accuracy: 0.9217 - val_loss: 0.2072 - val_accuracy: 0.9261
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;학습한 모형을 시각화로 다시 확인합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylim(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(test_X, test_Y, verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_06_04/output_8_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[0.23273345828056335, 0.9169999957084656]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;var_loss&lt;/code&gt;가 잘 증가하지 않는 드디어 괜찮은 모형을 얻었습니다. 또한 테스트 데이터에 대한 분류 성적도 &lt;code&gt;91.69%&lt;/code&gt;로 비교적 높은 성과를 거뒀습니다. 이렇게 네트워크 구조 변경만으로도 성능이 향상 된 것을 확인할 수 있습니다.&lt;/p&gt;
&lt;h2 id=&#34;iv-이미지-보강&#34;&gt;IV. 이미지 보강&lt;/h2&gt;
&lt;p&gt;이미지 보강은 훈련데이터에 없는 이미지를 새롭게 만들어내서 훈련데이터를 보강하는 기법을 말합니다. &lt;code&gt;Tensorflow&lt;/code&gt;에는 이미지 보강 작업을 쉽게 해주는 &lt;code&gt;ImageDataGenerator&lt;/code&gt;가 있습니다. 이를 활용해서 훈련 데이터의 첫 번째 이미지를 변형시킵니다.&lt;/p&gt;
&lt;p&gt;그리고 100개의 변형된 이미지를 그래프로 작성합니다.&lt;/p&gt;
&lt;h3 id=&#34;1-이미지-보강의-예&#34;&gt;(1) 이미지 보강의 예&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras.preprocessing.image &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; ImageDataGenerator
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np

image_generator &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ImageDataGenerator(
    rotation_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, 
    zoom_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.10&lt;/span&gt;, 
    shear_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;, 
    width_shift_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.10&lt;/span&gt;, 
    height_shift_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.10&lt;/span&gt;, 
    horizontal_flip&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True,
    vertical_flip&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)

augment_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;

x_augmented &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; image_generator&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flow(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tile(train_X[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;), &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), 
                                   np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros(augment_size), batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;augment_size, shuffle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next()[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]

&lt;span style=&#34;color:#75715e&#34;&gt;# 새롭게 생성된 이미지 표시&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;):
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(x_augmented[c]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;), cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_10_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ImageDataGenerator&lt;/code&gt;의 주요 인수들에 구체적인 설명은 &lt;code&gt;교재 169페이지&lt;/code&gt;를 참고하시기를 바랍니다. 또는 한글 번역문서가 있으니 해당 문서에서 추가적인 공부를 진행하기를 바랍니다. &lt;a href=&#34;https://keras.io/ko/preprocessing/image/&#34;&gt;(ImageDataGenerator 클래스)&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;2-3만개-이미지-보강&#34;&gt;(2) 3만개 이미지 보강&lt;/h2&gt;
&lt;p&gt;그러면 실제로 이미지를 보강하고 모형 학습에 추가하는 예제를 진행합니다. 전체적인 모형 학습 코드는 크게 달라지지 않으니, 기 진행했던 내용을 그대로 참조합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
fashion_mnist &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;datasets&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fashion_mnist
(train_X, train_Y), (test_X, test_Y) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; fashion_mnist&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load_data()

train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_X &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# reshape 이전&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)

train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# reshape 이후&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)

image_generator &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ImageDataGenerator(
    rotation_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, 
    zoom_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.10&lt;/span&gt;, 
    shear_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;, 
    width_shift_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.10&lt;/span&gt;, 
    height_shift_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.10&lt;/span&gt;, 
    horizontal_flip&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True,
    vertical_flip&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)

augment_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;30000&lt;/span&gt;

randidx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randint(train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;augment_size)
x_augmented &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X[randidx]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;copy()
y_augmented &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_Y[randidx]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;copy()
x_augmented &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; image_generator&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flow(x_augmented, np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros(augment_size), batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;augment_size, shuffle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next()[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]

&lt;span style=&#34;color:#75715e&#34;&gt;# 원래 데이터인 x_train에 이미지 보강된 x_augmented를 추가합니다. &lt;/span&gt;
train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;concatenate((train_X, x_augmented))
train_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;concatenate((train_Y, y_augmented))

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;(60000, 28, 28) (10000, 28, 28)
(60000, 28, 28, 1) (10000, 28, 28, 1)
(90000, 28, 28, 1)
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;훈련 데이터의 50%인 30,000개의 이미지를 추가하기 위해 &lt;code&gt;augment_size=30000&lt;/code&gt;으로 설정합니다.&lt;/li&gt;
&lt;li&gt;이미지를 변형할 원본 이미지를 찾기 위해 &lt;code&gt;np.random.randint()&lt;/code&gt;함수를 활용하여 0~59,999 범위의 정수 중에서 30,000개의 정수를 뽑았습니다. 이 때 정수는 중복 가능합니다.
&lt;ul&gt;
&lt;li&gt;만약, 중복을 원치 않으면, &lt;code&gt;np.random.ranint()&lt;/code&gt; 대신에 &lt;code&gt;np.random.choice()&lt;/code&gt; 함수를 사용하고 &lt;code&gt;replace&lt;/code&gt; 인수를 &lt;code&gt;False&lt;/code&gt;로 설정합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;copy()&lt;/code&gt; 함수를 사용하여 원본은 보전합니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;image_generator.flow()&lt;/code&gt; 함수를 사용하여 30,000개의 새로운 이미지를 생성했습니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;np.concatenate()&lt;/code&gt; 함수를 사용하여 훈련 데이터에 보강 이미지를 추가합니다. 그러면, 이미지 보강이 완료가 된 것입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3-모형-정의&#34;&gt;(3) 모형 정의&lt;/h3&gt;
&lt;p&gt;이제 보강된 훈련데이터를 &lt;code&gt;VGGNet&lt;/code&gt; 스타일의 네트워크에 추가하도록 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf

model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;MaxPool2D(pool_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout(rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),    
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;valid&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),  
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;MaxPool2D(pool_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)),
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout(rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;),
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Flatten(), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;512&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout(rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;),
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout(rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;),
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;)                           
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(), 
              loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sparse_categorical_crossentropy&amp;#39;&lt;/span&gt;, 
              metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])

&lt;span style=&#34;color:#75715e&#34;&gt;# model.summary()&lt;/span&gt;
history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_X, train_Y, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;)

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylim(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(test_X, test_Y, verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.5830 - accuracy: 0.7865 - val_loss: 0.5803 - val_accuracy: 0.7819
Epoch 2/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.3876 - accuracy: 0.8607 - val_loss: 0.5290 - val_accuracy: 0.8055
Epoch 3/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.3417 - accuracy: 0.8757 - val_loss: 0.4409 - val_accuracy: 0.8329
Epoch 4/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.3224 - accuracy: 0.8836 - val_loss: 0.4393 - val_accuracy: 0.8370
Epoch 5/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.3097 - accuracy: 0.8900 - val_loss: 0.4315 - val_accuracy: 0.8379
Epoch 6/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2997 - accuracy: 0.8927 - val_loss: 0.4283 - val_accuracy: 0.8452
Epoch 7/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2944 - accuracy: 0.8938 - val_loss: 0.4000 - val_accuracy: 0.8514
Epoch 8/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2907 - accuracy: 0.8967 - val_loss: 0.4203 - val_accuracy: 0.8428
Epoch 9/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2797 - accuracy: 0.9010 - val_loss: 0.3741 - val_accuracy: 0.8618
Epoch 10/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2835 - accuracy: 0.8986 - val_loss: 0.4227 - val_accuracy: 0.8424
Epoch 11/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2748 - accuracy: 0.9006 - val_loss: 0.3786 - val_accuracy: 0.8586
Epoch 12/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2764 - accuracy: 0.9018 - val_loss: 0.3736 - val_accuracy: 0.8668
Epoch 13/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2726 - accuracy: 0.9027 - val_loss: 0.3757 - val_accuracy: 0.8656
Epoch 14/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2737 - accuracy: 0.9023 - val_loss: 0.3790 - val_accuracy: 0.8589
Epoch 15/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2717 - accuracy: 0.9037 - val_loss: 0.3779 - val_accuracy: 0.8610
Epoch 16/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2689 - accuracy: 0.9049 - val_loss: 0.3768 - val_accuracy: 0.8643
Epoch 17/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2636 - accuracy: 0.9051 - val_loss: 0.3831 - val_accuracy: 0.8601
Epoch 18/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2686 - accuracy: 0.9045 - val_loss: 0.4098 - val_accuracy: 0.8484
Epoch 19/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2646 - accuracy: 0.9059 - val_loss: 0.3696 - val_accuracy: 0.8647
Epoch 20/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2630 - accuracy: 0.9078 - val_loss: 0.3510 - val_accuracy: 0.8728
Epoch 21/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2599 - accuracy: 0.9087 - val_loss: 0.3880 - val_accuracy: 0.8584
Epoch 22/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2626 - accuracy: 0.9072 - val_loss: 0.3749 - val_accuracy: 0.8673
Epoch 23/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2604 - accuracy: 0.9078 - val_loss: 0.3811 - val_accuracy: 0.8642
Epoch 24/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2619 - accuracy: 0.9088 - val_loss: 0.3790 - val_accuracy: 0.8585
Epoch 25/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2629 - accuracy: 0.9075 - val_loss: 0.3693 - val_accuracy: 0.8688
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_06_04/output_14_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[0.2110530138015747, 0.9251000285148621]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;소스코드는 기존에 했던 코드와 차이가 없기 때문에, 코드에 대한 설명은 생략합니다. 그래프 역시, 안정적인 것으로 봐서는 과적합은 일어나지 않았습니다. 그리고, 결과 역시 기존 분류 성적 &lt;code&gt;91.69%&lt;/code&gt;보다는 성능이 향상된 &lt;code&gt;92.51%&lt;/code&gt;값을 얻었습니다.&lt;/p&gt;
&lt;p&gt;이렇게 해서 더 많은 레이어를 쌓는 것과 이미지 보강 기법을 통해서 모형을 성능시키는 것까지 배웠습니다.&lt;/p&gt;
&lt;h2 id=&#34;v-결론&#34;&gt;V. 결론&lt;/h2&gt;
&lt;p&gt;이번장에서는 가장 중요한 개념은 컨볼루션 레이어의 개념, 풀링 레이어의 개념, 그리고 드롭아웃 레이어의 개념입니다. 각각의 역할은 조금씩 상이하다는 것을 꼭 기억하기를 바랍니다.&lt;/p&gt;
&lt;h2 id=&#34;vi-연습-파일&#34;&gt;VI. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch6_4_improve_performance.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;vii-reference&#34;&gt;VII. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Teerapittayanon, S., McDanel, B., &amp;amp; Kung, H.T. (2017). Distributed Deep Neural Networks Over the Cloud, the Edge and End Devices. 2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS), 328-339. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch6.3 - Fashion MNIST with CNN 실습</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch6_3_fashion_mnist_with_cnn/</link>
      <pubDate>Tue, 21 Apr 2020 16:08:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch6_3_fashion_mnist_with_cnn/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.2 - 다항분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/&#34;&gt;Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/&#34;&gt;Tensorflow 2.0 Tutorial ch6.1-2 - CNN 이론&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요&#34;&gt;I. 개요&lt;/h2&gt;
&lt;p&gt;이번 장은 앞에서 이론만 설명했기 때문에 이번에는 실습 위주로 진행합니다. 컨볼루션 레이어와 풀링 레이어, 드롭아웃을 사용해서 분류 문제를 푸는데 어떻게 해야 성능이 개선 되는지 알아봅니다.&lt;/p&gt;
&lt;h2 id=&#34;ii-데이터-불러오기-및-정규화&#34;&gt;II. 데이터 불러오기 및 정규화&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/&#34;&gt;5장&lt;/a&gt;에서 배운 내용을 근거로 데이터를 불러오고 정규화를 진행합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
fashion_mnist &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;datasets&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fashion_mnist
(train_X, train_Y), (test_X, test_Y) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; fashion_mnist&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load_data()

train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_X &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz
32768/29515 [=================================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz
26427392/26421880 [==============================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz
8192/5148 [===============================================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz
4423680/4422102 [==============================] - 0s 0us/step
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;그런데, 6장에서는 &lt;code&gt;Conv2D&lt;/code&gt;레이어로 컨볼루션 연산을 수행해야 합니다. 이미지는 보통 채널을 가지고 있고(컬러 이미지는 &lt;code&gt;RGB&lt;/code&gt;의 3채널, 흑백 이미지는 1채널), &lt;code&gt;Conv2D&lt;/code&gt;레이어는 채널을 가진 형태의 데이터를 받도록 기본적으로 설정되어 있기 때문에 예제 6.5에서는 채널을 갖도록 데이터의 &lt;code&gt;Shape&lt;/code&gt;를 바꿔줍니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# reshape 이전&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)

train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# reshape 이후&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;(60000, 28, 28) (10000, 28, 28)
(60000, 28, 28, 1) (10000, 28, 28, 1)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;Fashion MNIST&lt;/code&gt;데이터를 구성하는 흑백 이미지는 1개의 채널을 갖기 때문에 &lt;code&gt;reshape()&lt;/code&gt; 함수를 사용해 데이터의 가장 뒤쪽에 채널 차원을 추가합니다. 이 작업으로 데이터 수는 달라지지는 않습니다.&lt;/p&gt;
&lt;p&gt;데이터를 확인하는 시각화를 진행합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt

&lt;span style=&#34;color:#75715e&#34;&gt;# 전체 그래프의 크기를 width = 10, height = 10으로 지정합니다. &lt;/span&gt;
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;): 
  &lt;span style=&#34;color:#75715e&#34;&gt;# 4행 4열로 지정한 그리드에서 c+1번째의 칸에 그래프를 그립니다. 1~16번째 칸을 채우게 됩니다. &lt;/span&gt;
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(train_X[c]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;), cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

&lt;span style=&#34;color:#75715e&#34;&gt;# 훈련 데이터이 1~16번째 까지의 라벨 프린트합니다. &lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_Y[:&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_06_03/output_6_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[9 0 0 3 0 2 7 2 5 5 0 9 5 5 7 9]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;라벨의 정의는 아래와 같습니다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;라벨&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;범주&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;티셔츠/상의&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;바지&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;스웨터&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;드레스&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;코트&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;샌들&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;셔츠&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;운동화&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;가방&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;부츠&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;라벨의 정의와 비교해보면, 라벨이 잘 분류되어 있는 것을 확인할 수 있습니다. 이제 모델을 생성합니다.&lt;/p&gt;
&lt;h2 id=&#34;iii-딥러닝-모델-생성&#34;&gt;III. 딥러닝 모델 생성&lt;/h2&gt;
&lt;h3 id=&#34;1-컨볼루션-신경망-모델-정의&#34;&gt;(1) 컨볼루션 신경망 모델 정의&lt;/h3&gt;
&lt;p&gt;컨볼루션 신경망 모델 정의는 풀링 레이어 또는 드롭아웃 없이 정의된 모델을 말합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;),
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Flatten(), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;)                             
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(), 
              loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sparse_categorical_crossentropy&amp;#39;&lt;/span&gt;, 
              metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 26, 26, 16)        160       
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 24, 24, 32)        4640      
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 22, 22, 64)        18496     
_________________________________________________________________
flatten (Flatten)            (None, 30976)             0         
_________________________________________________________________
dense (Dense)                (None, 128)               3965056   
_________________________________________________________________
dense_1 (Dense)              (None, 10)                1290      
=================================================================
Total params: 3,989,642
Trainable params: 3,989,642
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;Conv2D&lt;/code&gt;의 인수에 대해 정리하도록 합니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;kernel_size&lt;/code&gt;: 필터 행렬의 크기를 말하며, 수용 영역(receptive filed)이라고 불리워집니다. 앞의 숫자는 높이, 뒤의 숫자는 너비이고, 숫자를 하나만 쓸 경우 높이와 너비를 동일한 값으로 사용한다는 뜻입니다.&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;filters&lt;/code&gt;: 필터의 개수를 의미하며, 네트워크가 깊어질수록 2배씩 늘려나갑니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;!&lt;/span&gt;nvidia&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;smi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Tue Apr 21 06:56:00 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |
| N/A   31C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;위 명령어는 현재 구글 코랩에서 지원하는 GPU의 성능입니다. &lt;code&gt;Tesla K80&lt;/code&gt;을 사용하고 있습니다.&lt;/p&gt;
&lt;p&gt;구글 코랩에서는 무료로 GPU를 사용할 수 있도록 도와줍니다. 하드웨어 가속기를 사용하려면 [메뉴]-[런타임]-[런타임 유형 변경]-[하드웨어 가속기]-[GPU]로 지정하면 됩니다.&lt;/p&gt;
&lt;h2 id=&#34;2-컨볼루션-신경망-모델-학습&#34;&gt;(2) 컨볼루션 신경망 모델 학습&lt;/h2&gt;
&lt;p&gt;신경망 모형을 학습하는데, 시간이 조금 소요되니 참고바란다. (약 10분)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_X, train_Y, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.4740 - accuracy: 0.8287 - val_loss: 0.3986 - val_accuracy: 0.8565
Epoch 2/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.3461 - accuracy: 0.8746 - val_loss: 0.3651 - val_accuracy: 0.8668
Epoch 3/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.2911 - accuracy: 0.8937 - val_loss: 0.3697 - val_accuracy: 0.8661
Epoch 4/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.2546 - accuracy: 0.9053 - val_loss: 0.3870 - val_accuracy: 0.8669
Epoch 5/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.2226 - accuracy: 0.9174 - val_loss: 0.4187 - val_accuracy: 0.8670
Epoch 6/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.1904 - accuracy: 0.9283 - val_loss: 0.4704 - val_accuracy: 0.8665
Epoch 7/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.1736 - accuracy: 0.9356 - val_loss: 0.4938 - val_accuracy: 0.8703
Epoch 8/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.1495 - accuracy: 0.9454 - val_loss: 0.5293 - val_accuracy: 0.8694
Epoch 9/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.1424 - accuracy: 0.9478 - val_loss: 0.5503 - val_accuracy: 0.8654
Epoch 10/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.1280 - accuracy: 0.9535 - val_loss: 0.6191 - val_accuracy: 0.8575
Epoch 11/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.1203 - accuracy: 0.9556 - val_loss: 0.7030 - val_accuracy: 0.8626
Epoch 12/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.1131 - accuracy: 0.9596 - val_loss: 0.7228 - val_accuracy: 0.8656
Epoch 13/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.1024 - accuracy: 0.9621 - val_loss: 0.8023 - val_accuracy: 0.8632
Epoch 14/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.1020 - accuracy: 0.9636 - val_loss: 0.7895 - val_accuracy: 0.8690
Epoch 15/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.0900 - accuracy: 0.9688 - val_loss: 1.0383 - val_accuracy: 0.8581
Epoch 16/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.0933 - accuracy: 0.9669 - val_loss: 0.8304 - val_accuracy: 0.8649
Epoch 17/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.0816 - accuracy: 0.9712 - val_loss: 1.0017 - val_accuracy: 0.8661
Epoch 18/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.0782 - accuracy: 0.9715 - val_loss: 0.9552 - val_accuracy: 0.8653
Epoch 19/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.0745 - accuracy: 0.9748 - val_loss: 1.0168 - val_accuracy: 0.8631
Epoch 20/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.0787 - accuracy: 0.9724 - val_loss: 1.0362 - val_accuracy: 0.8627
Epoch 21/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.0675 - accuracy: 0.9759 - val_loss: 1.1104 - val_accuracy: 0.8577
Epoch 22/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.0725 - accuracy: 0.9764 - val_loss: 1.2423 - val_accuracy: 0.8603
Epoch 23/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.0644 - accuracy: 0.9783 - val_loss: 1.2578 - val_accuracy: 0.8589
Epoch 24/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.0650 - accuracy: 0.9790 - val_loss: 1.3452 - val_accuracy: 0.8589
Epoch 25/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.0655 - accuracy: 0.9791 - val_loss: 1.2309 - val_accuracy: 0.8605
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;이렇게 생성된 모형은 시각화로 다시 확인한다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylim(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(test_X, test_Y, verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_06_03/output_14_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[1.3350350856781006, 0.855400025844574]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;왼쪽 그래프를 확인하면, &lt;code&gt;loss&lt;/code&gt;는 감소하고, 대신 &lt;code&gt;var_loss&lt;/code&gt;는 증가하는 전형적인 과적합의 형태를 나타냅니다. 이럴경우 모형에도 악영향이 있어서, 오히려 단순 딥러닝 모형의 성과가 더 좋은 것을 확인할 수 있습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;테스트 데이터의 85.21% Vs. 5.3장의 Dense Layer 88.5%&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;즉, 컨볼루션 레이어만 사용할 경우, 오히려 성능이 더 좋지 않은 것을 확인할 수 있었습니다. 이제 성능을 개선해봅니다.&lt;/p&gt;
&lt;h3 id=&#34;3-풀링-레이어-드롭아웃-레이어-추가-약-10분&#34;&gt;(3) 풀링 레이어, 드롭아웃 레이어 추가 (약 10분)&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;MaxPool2D(strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;MaxPool2D(strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Flatten(), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout(rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;),
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;)                             
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(), 
              loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sparse_categorical_crossentropy&amp;#39;&lt;/span&gt;, 
              metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential_3&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_9 (Conv2D)            (None, 26, 26, 32)        320       
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 13, 13, 32)        0         
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 11, 11, 64)        18496     
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 5, 5, 64)          0         
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 3, 3, 128)         73856     
_________________________________________________________________
flatten_3 (Flatten)          (None, 1152)              0         
_________________________________________________________________
dense_6 (Dense)              (None, 128)               147584    
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_7 (Dense)              (None, 10)                1290      
=================================================================
Total params: 241,546
Trainable params: 241,546
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;이번에 추가된 인수는 &lt;code&gt;MaxPool2D(strides=(2,2)&lt;/code&gt;)와 &lt;code&gt;Dropout(rate=0.3)&lt;/code&gt;입니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;strides: 필터가 계산 과정에서 한 스텝마다 이동하는 크기입니다. 기본값은 (1,1)이고, (2,2) 등으로 설정할 경우 한 칸씩 건너뛰면서 계산하게 되니다. strides=1일 때와 2일 때의 결과 이미지의 크기에 영향을 줍니다.&lt;/li&gt;
&lt;li&gt;rate: 제외할 뉴런의 비율을 나타냅니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;여기서 확인해야 하는 개수 &lt;code&gt;Param&lt;/code&gt;의 개수입니다.&lt;/p&gt;
&lt;p&gt;기존 &lt;code&gt;3,989,642&lt;/code&gt;에서 &lt;code&gt;241,546&lt;/code&gt;으로 대폭 줄어든 것을 확인할 수 있습니다. 이는 &lt;code&gt;Flatten&lt;/code&gt;에 들어오는 &lt;code&gt;Params&lt;/code&gt;의 개수가 기존 &lt;code&gt;(None, 30976)&lt;/code&gt;에 비해 &lt;code&gt;(None, 1152)&lt;/code&gt;에 비해 크게 줄어들었기 때문입니다.&lt;/p&gt;
&lt;p&gt;다시한번, 풀링 레이어와 드롭아웃 레어는 모두 과적합을 줄이는 데 기여합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_X, train_Y, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.5203 - accuracy: 0.8106 - val_loss: 0.3570 - val_accuracy: 0.8688
Epoch 2/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.3569 - accuracy: 0.8722 - val_loss: 0.3304 - val_accuracy: 0.8747
Epoch 3/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.3195 - accuracy: 0.8839 - val_loss: 0.3127 - val_accuracy: 0.8853
Epoch 4/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.2880 - accuracy: 0.8950 - val_loss: 0.2926 - val_accuracy: 0.8943
Epoch 5/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.2712 - accuracy: 0.9011 - val_loss: 0.3001 - val_accuracy: 0.8897
Epoch 6/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.2548 - accuracy: 0.9080 - val_loss: 0.2878 - val_accuracy: 0.8975
Epoch 7/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.2383 - accuracy: 0.9123 - val_loss: 0.3031 - val_accuracy: 0.8920
Epoch 8/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.2232 - accuracy: 0.9164 - val_loss: 0.2987 - val_accuracy: 0.9005
Epoch 9/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.2132 - accuracy: 0.9200 - val_loss: 0.2983 - val_accuracy: 0.8980
Epoch 10/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.2086 - accuracy: 0.9219 - val_loss: 0.3241 - val_accuracy: 0.8949
Epoch 11/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1937 - accuracy: 0.9284 - val_loss: 0.3066 - val_accuracy: 0.9017
Epoch 12/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1828 - accuracy: 0.9320 - val_loss: 0.3199 - val_accuracy: 0.9020
Epoch 13/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1862 - accuracy: 0.9305 - val_loss: 0.3195 - val_accuracy: 0.9034
Epoch 14/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1720 - accuracy: 0.9360 - val_loss: 0.3504 - val_accuracy: 0.8995
Epoch 15/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1661 - accuracy: 0.9372 - val_loss: 0.3565 - val_accuracy: 0.8953
Epoch 16/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1626 - accuracy: 0.9396 - val_loss: 0.3508 - val_accuracy: 0.9031
Epoch 17/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1567 - accuracy: 0.9406 - val_loss: 0.4112 - val_accuracy: 0.8989
Epoch 18/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1558 - accuracy: 0.9410 - val_loss: 0.3937 - val_accuracy: 0.8933
Epoch 19/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1506 - accuracy: 0.9434 - val_loss: 0.3724 - val_accuracy: 0.9003
Epoch 20/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1444 - accuracy: 0.9461 - val_loss: 0.4128 - val_accuracy: 0.9000
Epoch 21/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1397 - accuracy: 0.9482 - val_loss: 0.4300 - val_accuracy: 0.8975
Epoch 22/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1373 - accuracy: 0.9492 - val_loss: 0.4505 - val_accuracy: 0.9008
Epoch 23/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1377 - accuracy: 0.9497 - val_loss: 0.5026 - val_accuracy: 0.8955
Epoch 24/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1383 - accuracy: 0.9498 - val_loss: 0.5038 - val_accuracy: 0.8881
Epoch 25/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1293 - accuracy: 0.9516 - val_loss: 0.5226 - val_accuracy: 0.8945
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylim(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(test_X, test_Y, verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_06_03/output_19_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[0.5307855606079102, 0.8906999826431274]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;var_loss는 여전히 증가하지만, &lt;code&gt;val_accuracy&lt;/code&gt;는 일정한 수준에 머무르고 있습니다. 분류 성적도 &lt;code&gt;89.06%&lt;/code&gt;로 약 &lt;code&gt;0.4%&lt;/code&gt; 높은 수치가 나옵니다 (종전: &lt;code&gt;88.77%&lt;/code&gt;). 그러나, 확실히 컨볼루션 레이어만 활용했을 때 보다는 확실히 좋은 결과가 나온 것을 확인할 수 있습니다.&lt;/p&gt;
&lt;p&gt;이보다 더 좋은 성과를 낼 수 있습니다. Fashion MNIST의 공식 깃허브 저장소에는 테스트 데이터 분류 성적이 95% 이상을 달성한 방법들도 존재합니다. &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h2 id=&#34;iv-연습-파일&#34;&gt;IV. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch6_3_Fashion_MNIST_with_CNN.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v-reference&#34;&gt;V. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;이 부분은 교재 p. 145~147에 이미지로 설명이 잘 되어 있으니 참고하기를 바랍니다. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/zalandoresearch/fashion-mnist#benchmark&#34;&gt;https://github.com/zalandoresearch/fashion-mnist#benchmark&lt;/a&gt; 파이썬 실력이 되시는 분들은 95%이상의 성능을 보유한 Repo에 있는 코드를 직접 가져와 응용하는 것도 큰 도움이 될 수 있습니다. &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch6.1-2 - CNN 이론</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/</link>
      <pubDate>Tue, 21 Apr 2020 10:08:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.2 - 다항분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/&#34;&gt;Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요&#34;&gt;I. 개요&lt;/h2&gt;
&lt;p&gt;교재 &lt;code&gt;Chapter 6.1&lt;/code&gt;과 &lt;code&gt;Chapter 6.2&lt;/code&gt;에 &lt;code&gt;CNN&lt;/code&gt;의 기본적인 이론 배경들이 있습니다. 교재를 구매해서 꼭 한번 읽어보시기를 바랍니다. 주요 키워드를 정리하면 다음과 같습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;특징추출&lt;/li&gt;
&lt;li&gt;컨볼루션 연산 = 합성곱&lt;/li&gt;
&lt;li&gt;수작업 필터 (수직선/수평선 검출, 흐림(blur)효과, 날카로운 이미지(sharpen)효과
&lt;ul&gt;
&lt;li&gt;수작업 필터를 적용하기에는 3가지 문제점 존재, 도메인 지식 + 시간과 비용 + 좁은 확장성&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;컨볼루션의 역할은 &lt;code&gt;네트워크가 특징을 추출하는 필터를 자동으로 생성&lt;/code&gt;해줌&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;어떻게 특징을 자동으로 추출하는 것일까요?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;ii-주요-레이어-정리&#34;&gt;II. 주요 레이어 정리&lt;/h2&gt;
&lt;p&gt;지금까지 이 책에 나온 레이어는 &lt;code&gt;Dense&lt;/code&gt; 레이어와 &lt;code&gt;Flatten&lt;/code&gt; 레이어 두 종류입니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Dense&lt;/code&gt;레이어는 신경망에서 가장 기본이 되는 레이어이며 각 뉴런이 완전 연결(&lt;code&gt;Fully-Connected&lt;/code&gt;) 레이어라고 불리웁니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Flatten&lt;/code&gt;레이어는 다차원의 이미지를 1차원으로 평평하게 바꿔주는 레이어입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_06_01_2/tutorial_01.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;위 그림&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;에서 볼 수 있는 것처럼 &lt;code&gt;CNN&lt;/code&gt;은 특징 추출기(&lt;code&gt;Feature Extractor)&lt;/code&gt;와 분류기(&lt;code&gt;Classifier&lt;/code&gt;)가 합쳐진 형태입니다. 이 때, 특징 추출기의 역할을 하는 것은 &lt;code&gt;CNN 레이어&lt;/code&gt;와 &lt;code&gt;Pooling 레이어&lt;/code&gt;이며, &lt;code&gt;Dense 레이어&lt;/code&gt;는 분류기의 역할을 합니다.&lt;/p&gt;
&lt;p&gt;이론적인 자세한 부분은 여기에서는 생략하기로 한다. (교재를 참고하라!) 대신, 각 레이어의 특징 및 역할만 짧게 요약합니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;컨볼루션 레이어
&lt;ul&gt;
&lt;li&gt;네트워크의 학습을 통해 자동으로 특징을 추출함&lt;/li&gt;
&lt;li&gt;코드에서 지정해야 하는 값은 필터를 채우는 각 픽셀의 값이 아니라 필터의 개수 정도임&lt;/li&gt;
&lt;li&gt;2차원 이미지를 다루는 컨볼루션 레이어를 생성하는 코드는 다음과 같음&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;conv1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;valid&amp;#39;&lt;/span&gt;, filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;각 인수에 대한 설명은 전체 코드 때 재 설명합니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;풀링 레이어
&lt;ul&gt;
&lt;li&gt;인접한 픽셀의 경우 중요한 정보만 남기기 위해 서브샘플링(&lt;code&gt;subsampling&lt;/code&gt;)이라는 기법을 사용합니다. 컴퓨터의 메모리 크기가 한정되어 있다는 걸 고려한 레이어이며, 과적합 방지에 도움을 줍니다.&lt;/li&gt;
&lt;li&gt;풀링 레이어에는 &lt;code&gt;Max 풀링 레이어&lt;/code&gt;, &lt;code&gt;Average 풀링 레이어&lt;/code&gt; 등이 있씁니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;pool1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;MaxPool2D(pool_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;각 인수에 대한 설명은 전체 코드 때 재 설명합니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;드롭아웃 레이어
&lt;ul&gt;
&lt;li&gt;뉴런의 부분집을 제거하여 뉴런들간의 공모(&lt;code&gt;conspiracy&lt;/code&gt;)를 막고 과적합(&lt;code&gt;overfitting&lt;/code&gt;)을 감소시키는 것입니다.&lt;/li&gt;
&lt;li&gt;뉴런들은 결과값에 의해 서로 같은 영향을 받기 때문에, 결과값은 한쪽으로 치우치게 됩니다. 이러한 방지책으로 드롭아웃 레이어를 사용합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;pool1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout(rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;간단한 코드이지만 &lt;code&gt;AlexNet&lt;/code&gt;, &lt;code&gt;VGG&lt;/code&gt;, &lt;code&gt;GoogleNet&lt;/code&gt;, &lt;code&gt;DenseNet&lt;/code&gt; 등 거의 모든 주요 CNN에서 사용됩니다.&lt;/p&gt;
&lt;h2 id=&#34;iii-결론-및-정리&#34;&gt;III. 결론 및 정리&lt;/h2&gt;
&lt;p&gt;컨볼루션 신경망은 크게 3가지 레이어로 구성됩니다. 컨볼루션 레이어, 풀링 레이어, 드롭아웃 레이어입니다. 각 레이어의 역할은 조금씩 다릅니다. 컨볼루션 레이어는 특징을 추출하는 역할, 풀링 레이어는 중요 정보만 남기로 불필요한 연산 줄여주는 역할, 드롭아웃 레이어는 과적합을 방지하는 역할로 구분됩니다.&lt;/p&gt;
&lt;p&gt;이제 &lt;code&gt;Fashion MNIST&lt;/code&gt; 데이터세트에 &lt;code&gt;CNN&lt;/code&gt;을 적용하고, &lt;code&gt;88%&lt;/code&gt;대의 성능을 올려봅니다.&lt;/p&gt;
&lt;h2 id=&#34;iv-reference&#34;&gt;IV. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
&lt;p&gt;Ujjwal, Karn. “An Intuitive Explanation of Convolutional Neural Networks.” KDnuggets, 2016, &lt;a href=&#34;http://www.kdnuggets.com/2016/11/intuitive-explanation-convolutional-neural-networks.html/3&#34;&gt;www.kdnuggets.com/2016/11/intuitive-explanation-convolutional-neural-networks.html/3&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Hinton, G. E., Srivastava, N., Krizhevsky, A., Sutskever, I. &amp;amp; Salakhutdinov, R. R. (2012). Improving neural networks by preventing co-adaptation of feature detectors. CoRR, abs/1207.0580.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Karn, U. (2016)이 작성한 원서 논문에는 비교적 상세하게 CNN의 원리에 대해 설명하고 있다. 그러나, 한가지 아쉬운 부분은 드롭아웃 레이어에 대한 설명이 누락 되었기 때문에 드롭아웃 레이어에 관한 자세한 설명은 제프리 힌튼 교수팀의 논문을 참조하거나, 교재를 참조하기를 바란다. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/</link>
      <pubDate>Mon, 20 Apr 2020 17:08:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.2 - 다항분류&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요1&#34;&gt;I. 개요&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;MNIST&lt;/code&gt;는 머신러닝의 고전적인 문제로 손으로 쓴 숫자 글씨를 모아놓은 데이터 세트이며, &lt;code&gt;Fashion MNIST&lt;/code&gt;는 손글씨가 아닌 옷과 신발, 가방의 이미지 등을 모아 놓는다. 그레이스케일 이미지&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;라는 점과 범주의 수가 10개라는 점, 각 이미지의 크기가 28X28 픽셀이라는 점은 &lt;code&gt;MNIST&lt;/code&gt;와 동일하지만 좀 더 어려운 문제로 평가됩니다.&lt;/p&gt;
&lt;p&gt;라벨의 정의는 아래와 같습니다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;라벨&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;범주&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;티셔츠/상의&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;바지&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;스웨터&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;드레스&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;코트&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;샌들&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;셔츠&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;운동화&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;가방&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;부츠&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;ii-데이터-불러오기&#34;&gt;II. 데이터 불러오기&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Fashion MNIST&lt;/code&gt; 데이터세트는 &lt;code&gt;tf.keras&lt;/code&gt;에 기본으로 탑재가 되어 있기 때문에 간단하게 불러올 수 있다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 텐서플로 2 버전 선택&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
    &lt;span style=&#34;color:#75715e&#34;&gt;# %tensorflow_version only exists in Colab.&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;tensorflow_version &lt;span style=&#34;color:#ae81ff&#34;&gt;2.&lt;/span&gt;x
&lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Exception&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;pass&lt;/span&gt;

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tabulate &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tabulate

fashion_mnist &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;datasets&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fashion_mnist
(train_X, train_Y), (test_X, test_Y) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; fashion_mnist&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load_data()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz
32768/29515 [=================================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz
26427392/26421880 [==============================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz
8192/5148 [===============================================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz
4423680/4422102 [==============================] - 0s 0us/step
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(len(train_X), len(test_X))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;60000 10000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;훈련 데이터는 60,000장, 테스트 데이터는 10,000장의 패션 이미지를 포함하고 있습니다. 데이터세트를 불러온 후에는 이 데이터가 어떻게 생겼는지 확인해봐야 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(train_X[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;colorbar()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_05_03/output_6_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;9
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;imshow()&lt;/code&gt; 이미지를 그래프의 형태로 표시 할 수 있고, &lt;code&gt;colorbar()&lt;/code&gt; 함수는 그래프 옆에 색상의 값 정보를 (bar) 형태로 표시할 수 있습니다. 데이터의 이미지가 0에서 255까지의 값을 가지는 28X28 픽셀 크기의 2차원 이미지라는 것을 확인할 수 있습니다.&lt;/p&gt;
&lt;h2 id=&#34;iii-데이터-정규화&#34;&gt;III. 데이터 정규화&lt;/h2&gt;
&lt;p&gt;데이터를 정규화를 진행합니다. 여기에서는 최대값과 최소값을 이미 알고 있기 때문에 이미지의 각 픽셀값을 255로 나누기만 하면 0.0~1.0사이의 값으로 정규화됩니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_X &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_X[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[[0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.00392157 0.         0.         0.05098039 0.28627451 0.
  0.         0.00392157 0.01568627 0.         0.         0.
  0.         0.00392157 0.00392157 0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.01176471 0.         0.14117647 0.53333333 0.49803922 0.24313725
  0.21176471 0.         0.         0.         0.00392157 0.01176471
  0.01568627 0.         0.         0.01176471]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.02352941 0.         0.4        0.8        0.69019608 0.5254902
  0.56470588 0.48235294 0.09019608 0.         0.         0.
  0.         0.04705882 0.03921569 0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.60784314 0.9254902  0.81176471 0.69803922
  0.41960784 0.61176471 0.63137255 0.42745098 0.25098039 0.09019608
  0.30196078 0.50980392 0.28235294 0.05882353]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.00392157
  0.         0.27058824 0.81176471 0.8745098  0.85490196 0.84705882
  0.84705882 0.63921569 0.49803922 0.4745098  0.47843137 0.57254902
  0.55294118 0.34509804 0.6745098  0.25882353]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.00392157 0.00392157 0.00392157
  0.         0.78431373 0.90980392 0.90980392 0.91372549 0.89803922
  0.8745098  0.8745098  0.84313725 0.83529412 0.64313725 0.49803922
  0.48235294 0.76862745 0.89803922 0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.71764706 0.88235294 0.84705882 0.8745098  0.89411765
  0.92156863 0.89019608 0.87843137 0.87058824 0.87843137 0.86666667
  0.8745098  0.96078431 0.67843137 0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.75686275 0.89411765 0.85490196 0.83529412 0.77647059
  0.70588235 0.83137255 0.82352941 0.82745098 0.83529412 0.8745098
  0.8627451  0.95294118 0.79215686 0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.00392157 0.01176471 0.
  0.04705882 0.85882353 0.8627451  0.83137255 0.85490196 0.75294118
  0.6627451  0.89019608 0.81568627 0.85490196 0.87843137 0.83137255
  0.88627451 0.77254902 0.81960784 0.20392157]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.02352941 0.
  0.38823529 0.95686275 0.87058824 0.8627451  0.85490196 0.79607843
  0.77647059 0.86666667 0.84313725 0.83529412 0.87058824 0.8627451
  0.96078431 0.46666667 0.65490196 0.21960784]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.01568627 0.         0.
  0.21568627 0.9254902  0.89411765 0.90196078 0.89411765 0.94117647
  0.90980392 0.83529412 0.85490196 0.8745098  0.91764706 0.85098039
  0.85098039 0.81960784 0.36078431 0.        ]
 [0.         0.         0.00392157 0.01568627 0.02352941 0.02745098
  0.00784314 0.         0.         0.         0.         0.
  0.92941176 0.88627451 0.85098039 0.8745098  0.87058824 0.85882353
  0.87058824 0.86666667 0.84705882 0.8745098  0.89803922 0.84313725
  0.85490196 1.         0.30196078 0.        ]
 [0.         0.01176471 0.         0.         0.         0.
  0.         0.         0.         0.24313725 0.56862745 0.8
  0.89411765 0.81176471 0.83529412 0.86666667 0.85490196 0.81568627
  0.82745098 0.85490196 0.87843137 0.8745098  0.85882353 0.84313725
  0.87843137 0.95686275 0.62352941 0.        ]
 [0.         0.         0.         0.         0.07058824 0.17254902
  0.32156863 0.41960784 0.74117647 0.89411765 0.8627451  0.87058824
  0.85098039 0.88627451 0.78431373 0.80392157 0.82745098 0.90196078
  0.87843137 0.91764706 0.69019608 0.7372549  0.98039216 0.97254902
  0.91372549 0.93333333 0.84313725 0.        ]
 [0.         0.22352941 0.73333333 0.81568627 0.87843137 0.86666667
  0.87843137 0.81568627 0.8        0.83921569 0.81568627 0.81960784
  0.78431373 0.62352941 0.96078431 0.75686275 0.80784314 0.8745098
  1.         1.         0.86666667 0.91764706 0.86666667 0.82745098
  0.8627451  0.90980392 0.96470588 0.        ]
 [0.01176471 0.79215686 0.89411765 0.87843137 0.86666667 0.82745098
  0.82745098 0.83921569 0.80392157 0.80392157 0.80392157 0.8627451
  0.94117647 0.31372549 0.58823529 1.         0.89803922 0.86666667
  0.7372549  0.60392157 0.74901961 0.82352941 0.8        0.81960784
  0.87058824 0.89411765 0.88235294 0.        ]
 [0.38431373 0.91372549 0.77647059 0.82352941 0.87058824 0.89803922
  0.89803922 0.91764706 0.97647059 0.8627451  0.76078431 0.84313725
  0.85098039 0.94509804 0.25490196 0.28627451 0.41568627 0.45882353
  0.65882353 0.85882353 0.86666667 0.84313725 0.85098039 0.8745098
  0.8745098  0.87843137 0.89803922 0.11372549]
 [0.29411765 0.8        0.83137255 0.8        0.75686275 0.80392157
  0.82745098 0.88235294 0.84705882 0.7254902  0.77254902 0.80784314
  0.77647059 0.83529412 0.94117647 0.76470588 0.89019608 0.96078431
  0.9372549  0.8745098  0.85490196 0.83137255 0.81960784 0.87058824
  0.8627451  0.86666667 0.90196078 0.2627451 ]
 [0.18823529 0.79607843 0.71764706 0.76078431 0.83529412 0.77254902
  0.7254902  0.74509804 0.76078431 0.75294118 0.79215686 0.83921569
  0.85882353 0.86666667 0.8627451  0.9254902  0.88235294 0.84705882
  0.78039216 0.80784314 0.72941176 0.70980392 0.69411765 0.6745098
  0.70980392 0.80392157 0.80784314 0.45098039]
 [0.         0.47843137 0.85882353 0.75686275 0.70196078 0.67058824
  0.71764706 0.76862745 0.8        0.82352941 0.83529412 0.81176471
  0.82745098 0.82352941 0.78431373 0.76862745 0.76078431 0.74901961
  0.76470588 0.74901961 0.77647059 0.75294118 0.69019608 0.61176471
  0.65490196 0.69411765 0.82352941 0.36078431]
 [0.         0.         0.29019608 0.74117647 0.83137255 0.74901961
  0.68627451 0.6745098  0.68627451 0.70980392 0.7254902  0.7372549
  0.74117647 0.7372549  0.75686275 0.77647059 0.8        0.81960784
  0.82352941 0.82352941 0.82745098 0.7372549  0.7372549  0.76078431
  0.75294118 0.84705882 0.66666667 0.        ]
 [0.00784314 0.         0.         0.         0.25882353 0.78431373
  0.87058824 0.92941176 0.9372549  0.94901961 0.96470588 0.95294118
  0.95686275 0.86666667 0.8627451  0.75686275 0.74901961 0.70196078
  0.71372549 0.71372549 0.70980392 0.69019608 0.65098039 0.65882353
  0.38823529 0.22745098 0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.15686275 0.23921569 0.17254902 0.28235294 0.16078431
  0.1372549  0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;모든 데이터가 0에서 1사이의 값을 갖기 때문에 데이터 &lt;code&gt;정규화&lt;/code&gt;가 잘 된 것을 알 수 있습니다. 이 다음에 진행해야 하는 것은 &lt;code&gt;train_Y&lt;/code&gt;와 &lt;code&gt;test_Y&lt;/code&gt;에 원-핫 인코딩으로 바꾸는 부분입니다. &lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;(이전 강의 참조)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;to_categorical&lt;/code&gt; 함수를 이용해 정답 행렬을 원-핫 인코딩으로 바꾸면 아래와 같습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_categorical(train_Y, num_classes&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;)
test_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_categorical(test_Y, num_classes&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;이 때 9는 [0,0,0,0,0,0,0,0,0,1]로 바뀔 것입니다. 만약에 분류해야 하는 것이 &lt;code&gt;100&lt;/code&gt;이라면 어떻게 해야 할까요? 이러한 비효율성을 제거해줄 때 희소 행렬이라는 원리를 이용합니다. 행렬이 클 경우 수 많은 0을 위한 메모리를 모두 확보하는 것 자체가 매우 시스템적으로 낭비이기 때문입니다. 이렇게 이미지 분류의 경우에는 원-핫 인코딩보다는 희소행렬 원리를 이용해서 작성하는 경우가 많으니 참고하기를 바랍니다.&lt;/p&gt;
&lt;h2 id=&#34;iv-딥러닝-모형&#34;&gt;IV. 딥러닝 모형&lt;/h2&gt;
&lt;p&gt;이제 모형을 생성합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Flatten(input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;)), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;relu&amp;#34;&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;softmax&amp;#34;&lt;/span&gt;)
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(), 
              loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sparse_categorical_crossentropy&amp;#39;&lt;/span&gt;, 
              metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten (Flatten)            (None, 784)               0         
_________________________________________________________________
dense (Dense)                (None, 128)               100480    
_________________________________________________________________
dense_1 (Dense)              (None, 10)                1290      
=================================================================
Total params: 101,770
Trainable params: 101,770
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;여기에서 주의해서 봐야하는 것은 &lt;code&gt;loss&lt;/code&gt;에 &lt;code&gt;sparse_categorical_crossentropy&lt;/code&gt;로 기재하면 별도의 데이터 전처리 없이 희소 행렬을 나타내는 데이터를 정답 행렬로 사용할 수 있습니다.&lt;/li&gt;
&lt;li&gt;또한, &lt;code&gt;Dense&lt;/code&gt;대신에 &lt;code&gt;Flatten&lt;/code&gt;이 사용되었는데, 이는 다차원 데이터를 1차원으로 정렬하는 역할을 합니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Adam()&lt;/code&gt;의 기본값은 0,001로 매우 작습니다.&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_X, train_Y, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/25
1407/1407 [==============================] - 4s 3ms/step - loss: 0.5262 - accuracy: 0.8160 - val_loss: 0.4230 - val_accuracy: 0.8477
Epoch 2/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.3936 - accuracy: 0.8608 - val_loss: 0.3669 - val_accuracy: 0.8703
Epoch 3/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.3509 - accuracy: 0.8733 - val_loss: 0.3639 - val_accuracy: 0.8670
Epoch 4/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.3262 - accuracy: 0.8818 - val_loss: 0.3671 - val_accuracy: 0.8691
Epoch 5/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.3081 - accuracy: 0.8868 - val_loss: 0.3514 - val_accuracy: 0.8727
Epoch 6/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.2907 - accuracy: 0.8921 - val_loss: 0.3476 - val_accuracy: 0.8807
Epoch 7/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.2789 - accuracy: 0.8980 - val_loss: 0.3285 - val_accuracy: 0.8827
Epoch 8/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.2637 - accuracy: 0.9017 - val_loss: 0.3161 - val_accuracy: 0.8869
Epoch 9/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.2552 - accuracy: 0.9060 - val_loss: 0.3268 - val_accuracy: 0.8851
Epoch 10/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.2474 - accuracy: 0.9093 - val_loss: 0.3391 - val_accuracy: 0.8808
Epoch 11/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.2375 - accuracy: 0.9106 - val_loss: 0.3299 - val_accuracy: 0.8833
Epoch 12/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.2310 - accuracy: 0.9146 - val_loss: 0.3291 - val_accuracy: 0.8833
Epoch 13/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.2203 - accuracy: 0.9174 - val_loss: 0.3204 - val_accuracy: 0.8880
Epoch 14/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.2149 - accuracy: 0.9196 - val_loss: 0.3294 - val_accuracy: 0.8883
Epoch 15/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.2075 - accuracy: 0.9214 - val_loss: 0.3354 - val_accuracy: 0.8821
Epoch 16/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.2025 - accuracy: 0.9251 - val_loss: 0.3220 - val_accuracy: 0.8922
Epoch 17/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.1949 - accuracy: 0.9264 - val_loss: 0.3148 - val_accuracy: 0.8927
Epoch 18/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.1918 - accuracy: 0.9291 - val_loss: 0.3359 - val_accuracy: 0.8899
Epoch 19/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.1844 - accuracy: 0.9319 - val_loss: 0.3367 - val_accuracy: 0.8891
Epoch 20/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.1809 - accuracy: 0.9321 - val_loss: 0.3369 - val_accuracy: 0.8893
Epoch 21/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.1766 - accuracy: 0.9352 - val_loss: 0.3314 - val_accuracy: 0.8933
Epoch 22/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.1712 - accuracy: 0.9353 - val_loss: 0.3511 - val_accuracy: 0.8892
Epoch 23/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.1672 - accuracy: 0.9371 - val_loss: 0.3677 - val_accuracy: 0.8866
Epoch 24/25
1407/1407 [==============================] - 4s 3ms/step - loss: 0.1621 - accuracy: 0.9388 - val_loss: 0.3814 - val_accuracy: 0.8858
Epoch 25/25
1407/1407 [==============================] - 3s 2ms/step - loss: 0.1574 - accuracy: 0.9413 - val_loss: 0.3483 - val_accuracy: 0.8935
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;v-모형-결과-확인&#34;&gt;V. 모형 결과 확인&lt;/h2&gt;
&lt;p&gt;학습 출력 결과를 보면 훈련 데이터의 정확도는 점점 증가하고, 검증 데이터의 정확도는 일정한 수준으로 유지됩니다. 전체 학습 과정을 조망하기 위해 &lt;code&gt;history&lt;/code&gt; 변수에 저장된 학습 결과를 시각화 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylim(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_05_03/output_15_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;검증 데이터의 손실이 감소하다가 시간이 지날수록 서서히 증가하는 과적합 현상을 확인할 수 있는데, 이를 막기 위해서는 &lt;code&gt;tf.keras.callbacks.EarlyStopping&lt;/code&gt;을 사용합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(test_X, test_Y)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;313/313 [==============================] - 0s 1ms/step - loss: 0.3830 - accuracy: 0.8877





[0.3830251693725586, 0.8877000212669373]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;테스트 데이터에 대한 평가 정확도는 88.5%가 나왔습니다. 괜찮은 수치 같지만, 네트워크 구조 변경과 다른 학습 기법을 사용해서 정확도를 90%이상으로 끌어 올려야 합니다. 이를 컨볼루션 신경망(&lt;code&gt;CNN&lt;/code&gt;)에서 그 방법을 확인합니다.&lt;/p&gt;
&lt;h2 id=&#34;vi-연습-파일&#34;&gt;VI. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch5_3_Fashion_MNIST.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;vii-reference&#34;&gt;VII. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;책의 교재에도 각주로 설명이 되어 있지만, 텐서플로 홈페이지의 &lt;code&gt;첫 번째 신경망 훈련하기: 기초적인 분류 문제&lt;/code&gt; 페이지의 일부 내용을 참고하였다. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;컬러 이미지를 밝기 정보만 남긴 회색조로 변환한 이미지를 뜻함. &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;이렇게 기본값을 작게 해놓은 이유는 이 때의 값이 가장 좋았다는 &lt;a href=&#34;https://arxiv.org/pdf/1412.6980.pdf&#34;&gt;논문&lt;/a&gt;에 근거합니다. 물론 이를 이해하려면 수식을 전체 이해해야 하며, 추가적으로 성능 비교를 하려면 더 크거나 작은 값을 시도해야 합니다. &lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch5.2 - 다항분류</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/</link>
      <pubDate>Sun, 19 Apr 2020 14:08:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-다항분류&#34;&gt;I. 다항분류&lt;/h2&gt;
&lt;p&gt;지난 시간에 이항 분류에 대해 배웠다면 이번 시간에는 다항 분류에 대해서 배우는 시간을 갖도록 합니다. 다항 분류는 범주의 수가 2개를 초과하는 경우를 말합니다. 와인 데이터의 품질은 0에서 10까지의 숫자로 구분이 되어 있기 때문에, 품질을 종속변수로 생각하고 분류 할 수 있습니다.&lt;/p&gt;
&lt;p&gt;와인의 색깔이 아닌 와인의 품질에 대해 예측해보도록 합니다.&lt;/p&gt;
&lt;h2 id=&#34;ii-데이터-준비&#34;&gt;II. 데이터 준비&lt;/h2&gt;
&lt;p&gt;지난 시간에 배운 내용을 복습하면서 다시한번 소스코드를 작성합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 텐서플로 2 버전 선택&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
    &lt;span style=&#34;color:#75715e&#34;&gt;# %tensorflow_version only exists in Colab.&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;tensorflow_version &lt;span style=&#34;color:#ae81ff&#34;&gt;2.&lt;/span&gt;x
&lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Exception&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;pass&lt;/span&gt;

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tabulate &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tabulate


red &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv&amp;#39;&lt;/span&gt;, sep&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;;&amp;#39;&lt;/span&gt;)
white &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv&amp;#39;&lt;/span&gt;, sep&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;;&amp;#39;&lt;/span&gt;)

red[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;type&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
white[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;type&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
wine &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;concat([red, white])
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(wine&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;describe())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;       fixed acidity  volatile acidity  ...      quality         type
count    6497.000000       6497.000000  ...  6497.000000  6497.000000
mean        7.215307          0.339666  ...     5.818378     0.753886
std         1.296434          0.164636  ...     0.873255     0.430779
min         3.800000          0.080000  ...     3.000000     0.000000
25%         6.400000          0.230000  ...     5.000000     1.000000
50%         7.000000          0.290000  ...     6.000000     1.000000
75%         7.700000          0.400000  ...     6.000000     1.000000
max        15.900000          1.580000  ...     9.000000     1.000000

[8 rows x 13 columns]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;데이터셋이 준비가 되었다면, 품질 데이터가 어떤 비율로 구성이 되어 있는지 알아보도록 합니다.&lt;/p&gt;
&lt;h2 id=&#34;iii-종속변수-선정-및-재범주화&#34;&gt;III. 종속변수 선정 및 재범주화&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(wine[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;quality&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;describe())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;count    6497.000000
mean        5.818378
std         0.873255
min         3.000000
25%         5.000000
50%         6.000000
75%         6.000000
max         9.000000
Name: quality, dtype: float64
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;위 데이터 통계를 통해서 보면, 최소값은 3이고, 최대값은 9인 것으로 확인할 수 있습니다. &lt;code&gt;value_counts()&lt;/code&gt;에서는 각 분류의 개수를 확인해보면 각 항목의 수가 균일하지 않고 꽤 차이가 나는 것을 볼 수 있습니다. 좀 더 정확한 정보를 알기 위해 히스토그램 시각화를 진행합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;hist(wine[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;quality&amp;#39;&lt;/span&gt;], bins&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;, rwidth&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_05_02/output_6_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;데이터의 양이 작은 대신 범주의 수가 많은 것을 확인할 수 있습니다. 실제 값의 개수를 확인해도 마찬가지입니다.&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;count &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; wine[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;quality&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;value_counts()
ratio &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; wine[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;quality&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;value_counts(normalize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)

frame &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; { &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Count&amp;#39;&lt;/span&gt;: count, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Ratio&amp;#39;&lt;/span&gt;: ratio } 

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(tabulate(frame, headers&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;keys&amp;#39;&lt;/span&gt;, tablefmt&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;psql&amp;#39;&lt;/span&gt;))

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;+---------+-------------+
|   Count |       Ratio |
|---------+-------------|
|    2836 | 0.436509    |
|    2138 | 0.329075    |
|    1079 | 0.166077    |
|     216 | 0.0332461   |
|     193 | 0.029706    |
|      30 | 0.00461752  |
|       5 | 0.000769586 |
+---------+-------------+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;이 때 어떻게 재범주화 할 것인지가 중요한 요소가 됩니다. 여기서가 분석가와 현업사이에서의 커뮤니케이션이 발생하는 주요 지점이 됩니다. 이 부분에서 도메인 지식이 수반되는 지점이니 꼭 현업과 상의하면서 재범주화를 진행합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;wine&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[wine[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;quality&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;new_quality&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
wine&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[wine[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;quality&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;new_quality&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
wine&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[wine[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;quality&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;new_quality&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;

count &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; wine[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;new_quality&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;value_counts()
ratio &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; wine[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;new_quality&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;value_counts(normalize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)

frame &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; { &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Count&amp;#39;&lt;/span&gt;: count, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Ratio&amp;#39;&lt;/span&gt;: ratio } 
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(tabulate(frame, headers&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;keys&amp;#39;&lt;/span&gt;, tablefmt&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;psql&amp;#39;&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;+---------+----------+
|   Count |    Ratio |
|---------+----------|
|    2836 | 0.436509 |
|    2384 | 0.366939 |
|    1277 | 0.196552 |
+---------+----------+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;위 소스코드에서 &lt;code&gt;.loc&lt;/code&gt;는 특정한 데이터의 인덱스를 골라내는 역할을 합니다. 본 교재(p. 125~126)에서는 간단한 예제로 설명이 되어 있습니다만, 이 부분은 강사가 향후 준비하는 자료로 대체하도록 합니다. &lt;code&gt;.loc외에&lt;/code&gt; &lt;code&gt;.iloc&lt;/code&gt;등 기본 문법 등이 같이 소개가 되면 더 좋을 듯 합니다.&lt;/p&gt;
&lt;p&gt;정리가 되는대로 자료 링크를 걸어두도록 합니다.&lt;/p&gt;
&lt;h2 id=&#34;iv-데이터-정규화-및-데이터-분리&#34;&gt;IV. 데이터 정규화 및 데이터 분리&lt;/h2&gt;
&lt;p&gt;코드부터 작성한 뒤, 설명을 진행하도록 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;del&lt;/span&gt; wine[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;quality&amp;#39;&lt;/span&gt;]
wine_norm &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (wine &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; wine&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;min()) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; (wine&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;max() &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; wine&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;min())
wine_shuffle &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; wine_norm&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(frac&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
wine_np &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; wine_shuffle&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_numpy()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;우선 &lt;code&gt;new_quality&lt;/code&gt; 변수가 만들어졌기 때문에 기존의 &lt;code&gt;quality&lt;/code&gt; 변수를 삭제하였습니다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;min()&lt;/code&gt;, &lt;code&gt;max()&lt;/code&gt; 함수를 통해서 데이터 정규화를 진행합니다.&lt;/p&gt;
&lt;p&gt;판다스의 &lt;code&gt;sample()&lt;/code&gt; 함수는 전체 데이터프레임에서 &lt;code&gt;frac&lt;/code&gt;인수로 지정된 비율만큼의 행을 랜덤하게 뽑아서 새로운 데이터프레임을 만듭니다.
&lt;code&gt;frac=1&lt;/code&gt;로 지정됐기 때문에 &lt;code&gt;100%&lt;/code&gt;, 즉 모든 데이터를 뽑아서 섞는 것과 동일한 효과를 가집니다.&lt;/p&gt;
&lt;p&gt;*Tip: 입문자들이 처음 딥러닝 소스코드 작성하는 것을 어려워 하는 부분이 엑셀데이터와 같은 데이터프레임을 딥러닝의 Input 객체로 변환하는가인데, 위 소스코드는 굉장히 유용하며, 만약 반복적인 작업이 이루어지면 사용자 정의 함수를 사용하여 작성하여 사용하는 것도 도움이 된다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train_idx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(len(wine_np) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;)
train_X, train_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; wine_np[:train_idx, :&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], wine_np[:train_idx, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
test_X, test_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; wine_np[train_idx:, :&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], wine_np[train_idx:, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]

train_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_categorical(train_Y, num_classes&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
test_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_categorical(test_Y, num_classes&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;그리고, 훈련 데이터와 테스트 데이터를 분리한 뒤 모형 학습을 진행하도록 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;48&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;relu&amp;#34;&lt;/span&gt;, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, )), 
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;24&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;relu&amp;#34;&lt;/span&gt;), 
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;relu&amp;#34;&lt;/span&gt;), 
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;softmax&amp;#34;&lt;/span&gt;)
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(lr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.07&lt;/span&gt;), loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;categorical_crossentropy&amp;#39;&lt;/span&gt;, metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])
history&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_X, train_Y, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/25
122/122 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.8070 - val_loss: 0.4394 - val_accuracy: 0.7869
Epoch 2/25
122/122 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8101 - val_loss: 0.4491 - val_accuracy: 0.7869
Epoch 3/25
122/122 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.8134 - val_loss: 0.4175 - val_accuracy: 0.7869
Epoch 4/25
122/122 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8150 - val_loss: 0.4437 - val_accuracy: 0.7869
Epoch 5/25
122/122 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8047 - val_loss: 0.4189 - val_accuracy: 0.7869
Epoch 6/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.8134 - val_loss: 0.4269 - val_accuracy: 0.8123
Epoch 7/25
122/122 [==============================] - 0s 2ms/step - loss: 0.4039 - accuracy: 0.8152 - val_loss: 0.4094 - val_accuracy: 0.7946
Epoch 8/25
122/122 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8073 - val_loss: 0.4250 - val_accuracy: 0.7869
Epoch 9/25
122/122 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8068 - val_loss: 0.4353 - val_accuracy: 0.7869
Epoch 10/25
122/122 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.8132 - val_loss: 0.4061 - val_accuracy: 0.7869
Epoch 11/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8073 - val_loss: 0.4166 - val_accuracy: 0.7869
Epoch 12/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.8181 - val_loss: 0.4064 - val_accuracy: 0.8046
Epoch 13/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.8132 - val_loss: 0.3985 - val_accuracy: 0.8123
Epoch 14/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3976 - accuracy: 0.8163 - val_loss: 0.3994 - val_accuracy: 0.8108
Epoch 15/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8163 - val_loss: 0.4174 - val_accuracy: 0.8008
Epoch 16/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3993 - accuracy: 0.8134 - val_loss: 0.4261 - val_accuracy: 0.7869
Epoch 17/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8191 - val_loss: 0.4289 - val_accuracy: 0.8023
Epoch 18/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8222 - val_loss: 0.4129 - val_accuracy: 0.7877
Epoch 19/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8199 - val_loss: 0.4028 - val_accuracy: 0.8077
Epoch 20/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3972 - accuracy: 0.8075 - val_loss: 0.4200 - val_accuracy: 0.7869
Epoch 21/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8155 - val_loss: 0.4135 - val_accuracy: 0.8054
Epoch 22/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8150 - val_loss: 0.4130 - val_accuracy: 0.8115
Epoch 23/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3935 - accuracy: 0.8132 - val_loss: 0.4040 - val_accuracy: 0.8085
Epoch 24/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8124 - val_loss: 0.3962 - val_accuracy: 0.8123
Epoch 25/25
122/122 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.8029 - val_loss: 0.4029 - val_accuracy: 0.7869
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;모델 정의에서 마지막 레이어의 뉴런 수가 &lt;code&gt;2&lt;/code&gt;가 아닌 &lt;code&gt;3&lt;/code&gt;이 된 것 외에는 동일한 구조의 네트워크를 사용하였습니다. 검증 데이터에 대해 약 &lt;code&gt;79%&lt;/code&gt; 정도의 분류 성적을 거두고 있습니다.&lt;/p&gt;
&lt;p&gt;늘 강조하듯이, 모형을 학습한 뒤에는 항상 모형 결과를 시각화해야 합니다. 그래야, 학습이 잘 되고 있는지, 아니면 &lt;code&gt;오버피팅(Overfitting)&lt;/code&gt; 되고 있는지 확인해야 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylim(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_05_02/output_18_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;val_loss&lt;/code&gt;가 중간에 튀기도 하고, 전반적으로 &lt;code&gt;loss&lt;/code&gt;보다 큰 값인 것을 확인할 수 있습니다. 학습을 계속하면 &lt;code&gt;loss&lt;/code&gt;는 꾸준히 작아지지만 네트워크가 훈련 데이터에 과적합되기 때문에 &lt;code&gt;val_loss&lt;/code&gt;는 증가하기 시작합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(test_X, test_Y)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;41/41 [==============================] - 0s 1ms/step - loss: 0.4058 - accuracy: 0.7985





[0.40582624077796936, 0.7984615564346313]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;데스트 데이터의 정확도는 약 79.8% 정도로 검증 데이터의 정확도와 크게 차이가 없는 것으로 나온다. 이런 경우 해결방법은 네트워크의 구성도의 크기를 키우거나 학습률을 조정해보는 등 다양한 방면으로 노력해야 한다.&lt;/p&gt;
&lt;h2 id=&#34;v-결론&#34;&gt;V. 결론&lt;/h2&gt;
&lt;p&gt;지금까지는 주로 데이터프레임에 기반하여 연습을 진행하였다. 딥러닝을 하는 목적은 사실 이러한 데이터프레임보다는 이미지 분류, 텍스트 분류와 같은 비정형 데이터 분류를 위한 것에 더 많이 사용된다. 이제 앞으로는 이러한 비정형 데이터를 다루는 방법, 학습하는 방법에 대해 공부가 될 예정이다.&lt;/p&gt;
&lt;h2 id=&#34;vi-연습-파일&#34;&gt;VI. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch5_2_multi_classification.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;vii-reference&#34;&gt;VII. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;강사가 직접 작성한 코드입니다. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch5.1 - 분류</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/</link>
      <pubDate>Sat, 18 Apr 2020 11:08:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-분류의-개요&#34;&gt;I. 분류의 개요&lt;/h2&gt;
&lt;p&gt;분류는 크게 2가지로 구분됩니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;분류 문제에 명확한 정답이 있는 경우 Vs. 분류 문제에 명확한 정답이 없는 경우.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;보통 이러한 경우 지도학습 Vs. 비지도학습이라고 얘기를 하는데, 난이도로 따지면 비지도학습이 조금 더 어렵습니다. 예를 들면, 개인정보가 가려진 신용카드 사용 정보로 비슷한 유형의 구매자 군집을 분류하는 문제도 분류 문제의 일종입니다. 이 부분에 대한 설명이 오토인코더(AutoEncoder)라 불리우는 9장에서 조금더 다루도록합니다.
이번장에서는 지도학습(Supervised Learning)에 해당하는 분류 문제만 다룹니다.&lt;/p&gt;
&lt;p&gt;그 외에 조금 더 구체적인 이론적 개념이 필요하신 분들은 NVIDIA의 글을 한번 읽어보시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blogs.nvidia.co.kr/2018/09/03/supervised-unsupervised-learning/&#34;&gt;딥러닝 지도학습, 자율학습, 지도/자율 학습, 강화학습의 차이점은 무엇일까?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ii-이항분류&#34;&gt;II. 이항분류&lt;/h2&gt;
&lt;p&gt;와인 데이터세트로 이항분류를 진행합니다. 와인은 크게 레드 와인과 화이트 와인의 두 종류로 나눌 수 있습니다. 색깔 없이 단순히, 당도, 산도, 알코올 도수 등으로 분류하는 것은 쉽지 않습니다. 이번에는 데이터 정제 과정을 거쳐야 하기 때문에 주의깊게 살펴보시기를 바랍니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 텐서플로 2 버전 선택&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
    &lt;span style=&#34;color:#75715e&#34;&gt;# %tensorflow_version only exists in Colab.&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;tensorflow_version &lt;span style=&#34;color:#ae81ff&#34;&gt;2.&lt;/span&gt;x
&lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Exception&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;pass&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
red &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv&amp;#39;&lt;/span&gt;, sep&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;;&amp;#39;&lt;/span&gt;)
white &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv&amp;#39;&lt;/span&gt;, sep&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;;&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(red&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head())
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(white&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;   fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality
0            7.4              0.70         0.00  ...       0.56      9.4        5
1            7.8              0.88         0.00  ...       0.68      9.8        5
2            7.8              0.76         0.04  ...       0.65      9.8        5
3           11.2              0.28         0.56  ...       0.58      9.8        6
4            7.4              0.70         0.00  ...       0.56      9.4        5

[5 rows x 12 columns]
   fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality
0            7.0              0.27         0.36  ...       0.45      8.8        6
1            6.3              0.30         0.34  ...       0.49      9.5        6
2            8.1              0.28         0.40  ...       0.44     10.1        6
3            7.2              0.23         0.32  ...       0.40      9.9        6
4            7.2              0.23         0.32  ...       0.40      9.9        6

[5 rows x 12 columns]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;판다스 데이터프레임에 관한 설명은 강사가 작성해 놓은 자료를 참조하셔서 공부하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/pandas/pandas_dataframe/&#34;&gt;Pandas Dataframe&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;데이터프레임은 여러 개의 행으로 구성되어 있으며, &lt;code&gt;head()&lt;/code&gt;는 이 가운데 일부를 출력해서 보여줍니다. 각 데이터에 대한 속성은 영어로도 정리가 되어 있지만, 한글 독자분들은 교재 (108 p.)를 참고하시기를 바랍니다.&lt;/p&gt;
&lt;p&gt;원서의 정리는 다음 자료에서 확인합니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://archive.ics.uci.edu/ml/datasets/Wine+Quality&#34;&gt;Wine Quality Data Set&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;1-데이터-합치기&#34;&gt;(1) 데이터 합치기&lt;/h3&gt;
&lt;p&gt;와인 분류문제에서는 12개 속성으로 와인의 종류(레드/화이트)를 분류해야 합니다. 현재는 &lt;code&gt;red&lt;/code&gt;와 &lt;code&gt;white&lt;/code&gt;의 두 데이터프레임으로 데이터가 분리되어 있기 때문에 텐서플로에서 이 데이터를 사용하기 위해 두 데이터프레임을 하나로 합쳐야 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;red[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;type&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
white[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;type&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(red&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(white&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;))

wine &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;concat([red, white])
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(wine&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;describe())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;   fixed acidity  volatile acidity  citric acid  ...  alcohol  quality  type
0            7.4              0.70          0.0  ...      9.4        5     0
1            7.8              0.88          0.0  ...      9.8        5     0

[2 rows x 13 columns]
   fixed acidity  volatile acidity  citric acid  ...  alcohol  quality  type
0            7.0              0.27         0.36  ...      8.8        6     1
1            6.3              0.30         0.34  ...      9.5        6     1

[2 rows x 13 columns]
       fixed acidity  volatile acidity  ...      quality         type
count    6497.000000       6497.000000  ...  6497.000000  6497.000000
mean        7.215307          0.339666  ...     5.818378     0.753886
std         1.296434          0.164636  ...     0.873255     0.430779
min         3.800000          0.080000  ...     3.000000     0.000000
25%         6.400000          0.230000  ...     5.000000     1.000000
50%         7.000000          0.290000  ...     6.000000     1.000000
75%         7.700000          0.400000  ...     6.000000     1.000000
max        15.900000          1.580000  ...     9.000000     1.000000

[8 rows x 13 columns]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;각 코드에 대한 설명은 다음과 같습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;먼저 데이터프레임에 새로운 속성을 추가하는 방법은 단순히 &lt;code&gt;red[&#39;type&#39;] = 0&lt;/code&gt; 처럼 데이터프레임이 파이썬의 사전(&lt;code&gt;dictionary&lt;/code&gt;) 타입인 것처럼 속성명과 값을 지정합니다. 레드 와인은 0, 화이트 와인은 1로 지정했습니다. 이 부분이 이항분류의 종속변수가 될 것입니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pd.concat()&lt;/code&gt; 데이터 프레임을 단순히 위아래로 연결하는 새로운 데이터프레임을 만들어 냅니다.&lt;/li&gt;
&lt;li&gt;데이터가 잘 입력되었는지 가설을 확인하기 위해 간단한 그래프를 그려봅니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;hist(wine[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;type&amp;#39;&lt;/span&gt;])
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xticks([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(wine[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;type&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;value_counts())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_05_01/output_7_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1    4898
0    1599
Name: type, dtype: int64
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;위 그래프를 토대로 확인해보면 레드 와인보다 화이트 와인이 더 많다는 것을 알 수 있습니다. 정확한 수치로 표현하기 위해 &lt;code&gt;value_counts()&lt;/code&gt;함수를 사용했습니다.&lt;/p&gt;
&lt;h3 id=&#34;2-데이터-정규화&#34;&gt;(2) 데이터 정규화&lt;/h3&gt;
&lt;p&gt;데이터 정규화는 수치형 값에 적용하는 것이지, 문자열에 적용하는 건 아닙니다. 문제는 외부에서 불러오는 데이터의 경우 어떤 값으로 구성되어 있는지 알기 어려운데, 이 때 데이터의 파악을 도와주는 것이 판다스의 &lt;code&gt;info()&lt;/code&gt; 입니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(wine&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;info())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;class &#39;pandas.core.frame.DataFrame&#39;&amp;gt;
Int64Index: 6497 entries, 0 to 4897
Data columns (total 13 columns):
 #   Column                Non-Null Count  Dtype  
---  ------                --------------  -----  
 0   fixed acidity         6497 non-null   float64
 1   volatile acidity      6497 non-null   float64
 2   citric acid           6497 non-null   float64
 3   residual sugar        6497 non-null   float64
 4   chlorides             6497 non-null   float64
 5   free sulfur dioxide   6497 non-null   float64
 6   total sulfur dioxide  6497 non-null   float64
 7   density               6497 non-null   float64
 8   pH                    6497 non-null   float64
 9   sulphates             6497 non-null   float64
 10  alcohol               6497 non-null   float64
 11  quality               6497 non-null   int64  
 12  type                  6497 non-null   int64  
dtypes: float64(11), int64(2)
memory usage: 710.6 KB
None
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;다행히 모든 데이터가 &lt;code&gt;float64&lt;/code&gt; &amp;amp; &lt;code&gt;int64&lt;/code&gt;인 것을 확인할 수 있습니다. 데이터 정규화는 다음의 한줄 코드로 실현이 가능합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;wine_norm &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (wine &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; wine&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;min()) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; (wine&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;max() &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; wine&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;min())
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(wine_norm&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head())
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(wine_norm&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;describe())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;   fixed acidity  volatile acidity  citric acid  ...   alcohol   quality  type
0       0.297521          0.413333     0.000000  ...  0.202899  0.333333   0.0
1       0.330579          0.533333     0.000000  ...  0.260870  0.333333   0.0
2       0.330579          0.453333     0.024096  ...  0.260870  0.333333   0.0
3       0.611570          0.133333     0.337349  ...  0.260870  0.500000   0.0
4       0.297521          0.413333     0.000000  ...  0.202899  0.333333   0.0

[5 rows x 13 columns]
       fixed acidity  volatile acidity  ...      quality         type
count    6497.000000       6497.000000  ...  6497.000000  6497.000000
mean        0.282257          0.173111  ...     0.469730     0.753886
std         0.107143          0.109758  ...     0.145543     0.430779
min         0.000000          0.000000  ...     0.000000     0.000000
25%         0.214876          0.100000  ...     0.333333     1.000000
50%         0.264463          0.140000  ...     0.500000     1.000000
75%         0.322314          0.213333  ...     0.500000     1.000000
max         1.000000          1.000000  ...     1.000000     1.000000

[8 rows x 13 columns]
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;pandas&lt;/code&gt;에서는 &lt;code&gt;max()&lt;/code&gt;, &lt;code&gt;min()&lt;/code&gt;함수를 이용해 각 속성의 최대값과 최소값을 얻을 수 있고, 이 값들을 이용해 모든 속성과 모든 행에 대한 계산이 가능합니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;describe()&lt;/code&gt;함수에서 볼 수 있는 속성들이 0~1사이로 값이 모아진 것을 확인할 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3-데이터-변환-dataframe에서-array&#34;&gt;(3) 데이터 변환 (DataFrame에서 Array)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;이렇게 정규화된 데이터를 &lt;code&gt;NumPy Array&lt;/code&gt;로 변환합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
wine_shuffle &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; wine_norm&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(frac&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(wine_shuffle&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head())
wine_np &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; wine_shuffle&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_numpy()
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(wine_np[:&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;      fixed acidity  volatile acidity  citric acid  ...   alcohol   quality  type
3006       0.198347          0.053333     0.192771  ...  0.434783  0.500000   1.0
3757       0.223140          0.120000     0.204819  ...  0.391304  0.333333   1.0
3052       0.148760          0.080000     0.397590  ...  0.347826  0.666667   1.0
1270       0.099174          0.200000     0.006024  ...  0.869565  0.500000   0.0
1087       0.338843          0.073333     0.253012  ...  0.463768  0.500000   0.0

[5 rows x 13 columns]
[[0.19834711 0.05333333 0.19277108 0.00766871 0.0448505  0.25347222
  0.41013825 0.07422402 0.3875969  0.10674157 0.43478261 0.5
  1.        ]
 [0.2231405  0.12       0.20481928 0.01226994 0.05149502 0.08333333
  0.41013825 0.09735878 0.44186047 0.13483146 0.39130435 0.33333333
  1.        ]
 [0.14876033 0.08       0.39759036 0.14723926 0.05647841 0.26736111
  0.38940092 0.14247156 0.20155039 0.11797753 0.34782609 0.66666667
  1.        ]
 [0.09917355 0.2        0.0060241  0.01533742 0.06478405 0.08680556
  0.12442396 0.07191055 0.75968992 0.29775281 0.86956522 0.5
  0.        ]
 [0.33884298 0.07333333 0.25301205 0.01533742 0.07973422 0.05902778
  0.05529954 0.13283208 0.44186047 0.26404494 0.46376812 0.5
  0.        ]]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;판다스의 &lt;code&gt;sample()&lt;/code&gt; 함수는 전체 데이터프레임에서 &lt;code&gt;frac&lt;/code&gt;인수로 지정된 비율만큼의 행을 랜덤하게 뽑아서 새로운 데이터프레임을 만듭니다.
&lt;code&gt;frac=1&lt;/code&gt;로 지정됐기 때문에 &lt;code&gt;100%&lt;/code&gt;, 즉 모든 데이터를 뽑아서 섞는 것과 동일한 효과를 가집니다.&lt;/p&gt;
&lt;p&gt;*Tip: 입문자들이 처음 딥러닝 소스코드 작성하는 것을 어려워 하는 부분이 엑셀데이터와 같은 데이터프레임을 딥러닝의 Input 객체로 변환하는가인데, 위 소스코드는 굉장히 유용하며, 만약 반복적인 작업이 이루어지면 사용자 정의 함수를 사용하여 작성하여 사용하는 것도 도움이 된다.&lt;/p&gt;
&lt;h3 id=&#34;4-훈련-데이터와-테스트-데이터-분리&#34;&gt;(4) 훈련 데이터와 테스트 데이터 분리&lt;/h3&gt;
&lt;p&gt;훈련 데이터와 테스트 데이터로 나누어 진행합니다. 검증데이터는 훈련데이터서 일부를 떼서 자동으로 만들 예정이기 때문에, 여기에서는 훈련 데이터와 테스트 데이터로만 나누어 진행합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
train_idx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(len(wine_np) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;)
train_X, train_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; wine_np[:train_idx, :&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], wine_np[:train_idx, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
test_X, test_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; wine_np[train_idx:, :&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], wine_np[train_idx:, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_X[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(test_X[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(test_Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
train_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_categorical(train_Y, num_classes&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
test_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_categorical(test_Y, num_classes&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(test_Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[0.19834711 0.05333333 0.19277108 0.00766871 0.0448505  0.25347222
 0.41013825 0.07422402 0.3875969  0.10674157 0.43478261 0.5       ]
1.0
[0.84297521 0.22       0.37951807 0.04907975 0.13289037 0.01736111
 0.09447005 0.27549643 0.2248062  0.33146067 0.4057971  0.5       ]
0.0
[0. 1.]
[1. 0.]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;위 소스코드에 대한 설명은 아래와 같습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;먼저 80%에 해당하는 데이터를 훈련 데이터와 검증 데이터로 만들기 위해 wine_np의 수의 80%에 해당하는 인덱스를 &lt;code&gt;int&lt;/code&gt;값으로 저장합니다.&lt;/li&gt;
&lt;li&gt;그 다음 이 인덱스를 이용해 &lt;code&gt;wine_np&lt;/code&gt;를 분리합니다. NumPy Array에서는 2차원 이상의 인덱스에 접근할 때 쉼표(,)를 사용하기 때문에 쉼표를 이용해 &lt;code&gt;X&lt;/code&gt;와 &lt;code&gt;Y&lt;/code&gt;도 구분합니다. 12개의 기존 속성은 &lt;code&gt;X&lt;/code&gt;가 되고 새롭게 추가한 &lt;code&gt;type&lt;/code&gt;은 &lt;code&gt;Y&lt;/code&gt;가 됩니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;to_categorical&lt;/code&gt; 분류 문제에서 자주 쓰이는 함수로 정답 행렬을 &lt;code&gt;원-핫 인코딩(One-Hot Encoding)&lt;/code&gt; 방식으로 바꿉니다. 이 함수의 두번째 인수인 &lt;code&gt;num_classes&lt;/code&gt;는 정답 클래스의 개수입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;iii-딥러닝-학습&#34;&gt;III. 딥러닝 학습&lt;/h2&gt;
&lt;p&gt;시퀀셜 모델을 통해서 모형을 학습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 5.8 와인 데이터셋 분류 모델 생성&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;48&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;,)),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;24&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;)
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(lr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.07&lt;/span&gt;), loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;categorical_crossentropy&amp;#39;&lt;/span&gt;, metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential_8&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_32 (Dense)             (None, 48)                624       
_________________________________________________________________
dense_33 (Dense)             (None, 24)                1176      
_________________________________________________________________
dense_34 (Dense)             (None, 12)                300       
_________________________________________________________________
dense_35 (Dense)             (None, 2)                 26        
=================================================================
Total params: 2,126
Trainable params: 2,126
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;회귀모형과 다르게 분류 모델이기 때문에 소프트맥스(&lt;code&gt;softmax&lt;/code&gt;)를 사용했습니다. 소프트맥스의 역할은 큰 값을 강조하고 작은 값은 약화하는 효과를 갖습니다. (자세한 내용은 교재 117페이지 참고)&lt;/p&gt;
&lt;p&gt;우선, [2,1,0]이라는 값이 있습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;max로 변환 시, [2,0,0]이 됩니다.&lt;/li&gt;
&lt;li&gt;softmax로 변환하면 [0.67, 0.24, 0.09]의 확률값이 됩니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$e$를 밑으로 하는 지수함수를 취하기 때문에 위의 효과가 발생하며, 0이나 음수에도 적용 가능합니다. &lt;code&gt;softmax&lt;/code&gt;가 중요한 이유는 분류 문제나 언어 &lt;code&gt;RNN&lt;/code&gt;에서의 다음 토큰 예측, 강화학습에서 에이전트의 행동 확률을 구하는 결과값으로 확률이 필요한 다양한 분야에서 쓰입니다.&lt;/p&gt;
&lt;p&gt;여기에서는 예측값이 레드 와인일 확률과 화이트 와인일 확률을 구하는데 사용되며, [0.97, 0.03]처럼 합이 &lt;code&gt;1.0&lt;/code&gt;인 확률값이 될 것입니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; math
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.01&lt;/span&gt;)
e_x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; math&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;e &lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt; x

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axhline(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axvline(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(x, x, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;y=x&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(x, e_x, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g.&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;y=e^x&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;X&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Y&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_05_01/output_19_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;마지막 레이어에서 한 가지 더 주목할 점은 뉴런의 개수가 2로 설정되어 있다는 점입니다. 이는 종속변수의 클래스 숫자와 동일합니다.&lt;/p&gt;
&lt;p&gt;손실함수 &lt;code&gt;loss&lt;/code&gt;에는 &lt;code&gt;sparse_categorical_crossentropy&lt;/code&gt;라는 값이 들어가 있습니다. 이에 관한 구체적인 설명은 118~119 페이지에 있으니 참고바랍니다. 엔트로피와 정보이론에 관한 설명은 다음 자료를 참고하십시요.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.naver.com/gyrbsdl18/221013188633&#34;&gt;Cross Entropy 란 무엇인가 (information theory)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;이제 분류 네트워크를 학습시켜 봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_X, train_Y, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/25
122/122 [==============================] - 0s 3ms/step - loss: 0.2900 - accuracy: 0.8673 - val_loss: 0.1034 - val_accuracy: 0.9762
Epoch 2/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0825 - accuracy: 0.9800 - val_loss: 0.0609 - val_accuracy: 0.9823
Epoch 3/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.9833 - val_loss: 0.0786 - val_accuracy: 0.9754
Epoch 4/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0566 - accuracy: 0.9867 - val_loss: 0.0336 - val_accuracy: 0.9931
Epoch 5/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0493 - accuracy: 0.9885 - val_loss: 0.0334 - val_accuracy: 0.9877
Epoch 6/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 0.9908 - val_loss: 0.0365 - val_accuracy: 0.9931
Epoch 7/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0416 - accuracy: 0.9892 - val_loss: 0.0277 - val_accuracy: 0.9946
Epoch 8/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0479 - accuracy: 0.9864 - val_loss: 0.0237 - val_accuracy: 0.9931
Epoch 9/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0445 - accuracy: 0.9874 - val_loss: 0.0319 - val_accuracy: 0.9915
Epoch 10/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.9867 - val_loss: 0.0392 - val_accuracy: 0.9915
Epoch 11/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0422 - accuracy: 0.9879 - val_loss: 0.0330 - val_accuracy: 0.9869
Epoch 12/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 0.9918 - val_loss: 0.0274 - val_accuracy: 0.9946
Epoch 13/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 0.9885 - val_loss: 0.0203 - val_accuracy: 0.9969
Epoch 14/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.9900 - val_loss: 0.0238 - val_accuracy: 0.9946
Epoch 15/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0416 - accuracy: 0.9902 - val_loss: 0.0250 - val_accuracy: 0.9908
Epoch 16/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.9915 - val_loss: 0.0394 - val_accuracy: 0.9854
Epoch 17/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0435 - accuracy: 0.9900 - val_loss: 0.0321 - val_accuracy: 0.9908
Epoch 18/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.9905 - val_loss: 0.0282 - val_accuracy: 0.9938
Epoch 19/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0460 - accuracy: 0.9887 - val_loss: 0.0374 - val_accuracy: 0.9900
Epoch 20/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9920 - val_loss: 0.0251 - val_accuracy: 0.9946
Epoch 21/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.9913 - val_loss: 0.0251 - val_accuracy: 0.9938
Epoch 22/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 0.9867 - val_loss: 0.0432 - val_accuracy: 0.9846
Epoch 23/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.9887 - val_loss: 0.0324 - val_accuracy: 0.9938
Epoch 24/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 0.9900 - val_loss: 0.0239 - val_accuracy: 0.9946
Epoch 25/25
122/122 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9926 - val_loss: 0.0193 - val_accuracy: 0.9962
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;학습 과정에서의 training 데이터의 정확도와 검증 데이터의 정확도가 각각 accuracy와 val_accuracy라는 이름으로 표시됩니다.&lt;/p&gt;
&lt;p&gt;분류 모델의 학습 결과를 시각화해보면 정확도가 100%에 가까운 매우 좋은 결과를 유지하고 있음을 확인할 수 있습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;k--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylim(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_05_01/output_23_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;iv-딥러닝-모형-평가&#34;&gt;IV. 딥러닝 모형 평가&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;model.evaluate()&lt;/code&gt; 함수를 통해서 모델의 성능을 평가할 수 있습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(test_X, test_Y)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;41/41 [==============================] - 0s 1ms/step - loss: 0.0447 - accuracy: 0.9915





[0.044681474566459656, 0.9915384650230408]
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;v-연습-파일&#34;&gt;V. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch5_1_binary_classification.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;vi-reference&#34;&gt;VI. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>