<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>보스턴 주택 가격 데이터세트 on Data Science | ChloEvan</title>
    <link>https://chloevan.github.io/tags/%EB%B3%B4%EC%8A%A4%ED%84%B4-%EC%A3%BC%ED%83%9D-%EA%B0%80%EA%B2%A9-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%84%B8%ED%8A%B8/</link>
    <description>Recent content in 보스턴 주택 가격 데이터세트 on Data Science | ChloEvan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 16 Apr 2020 20:00:30 +0900</lastBuildDate>
    
        <atom:link href="https://chloevan.github.io/tags/%EB%B3%B4%EC%8A%A4%ED%84%B4-%EC%A3%BC%ED%83%9D-%EA%B0%80%EA%B2%A9-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%84%B8%ED%8A%B8/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/</link>
      <pubDate>Thu, 16 Apr 2020 20:00:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요-및-데이터-불러오기&#34;&gt;I. 개요 및 데이터 불러오기&lt;/h2&gt;
&lt;p&gt;딥러닝 네트워크를 이용한 회귀를 통해 보스턴 주택 가격 데이터세트(&lt;code&gt;Boston Housing Dataset&lt;/code&gt;)을 이용한 주택 가격 예측 네트워크를 만들어본다.&lt;/p&gt;
&lt;p&gt;데이터세트에 기본적인 설명은 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1978년 미국 보스턴 지역의 주택 가격&lt;/li&gt;
&lt;li&gt;506개의 타운의 주택 가격 중앙값을, 1,000달러 단위로 표현&lt;/li&gt;
&lt;li&gt;범죄율&lt;/li&gt;
&lt;li&gt;주택당 방 개수&lt;/li&gt;
&lt;li&gt;고속도로까지의 거리 등&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras.datasets &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; boston_housing
(train_X, train_Y), (test_X, test_Y) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; boston_housing&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load_data()

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(len(train_X), len(test_X))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_X[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;404 102
[  1.23247   0.        8.14      0.        0.538     6.142    91.7
   3.9769    4.      307.       21.      396.9      18.72   ]
15.2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;보스턴 주택 가격 데이터세트는 &lt;code&gt;keras&lt;/code&gt;에 기본으로 탑재되어 있다. &lt;code&gt;load_data()&lt;/code&gt; 함수를 사용해 데이터를 불러올 수 있는데, 이 때 훈련(&lt;code&gt;train&lt;/code&gt;) 데이터와 테스트(&lt;code&gt;test&lt;/code&gt;) 데이터를 나누게 된다.&lt;/p&gt;
&lt;h2 id=&#34;ii-데이터-분리훈련데이터--테스트데이터&#34;&gt;II. 데이터 분리(훈련데이터 &amp;amp; 테스트데이터)&lt;/h2&gt;
&lt;p&gt;교재 &lt;code&gt;P.91-2&lt;/code&gt;에 보면, 훈련 데이터, 검증 데이터, 테스트 데이터의 역할에 비교적 이해하기 쉽게 기술이 되어 있습니다. 이 부분을 처음 접하시는 분들은 꼭 한번 읽어보시기를 바랍니다.&lt;/p&gt;
&lt;p&gt;딥러닝과 관련해서 한가지 알아두면 좋은 것은 딥러닝 네트워크의 가중치에 영향을 주는 데이터는 훈련 데이터인데, 만약 교차검증(&lt;code&gt;cross-validation&lt;/code&gt;)기법을 통하면 훈련 데이터 중 일부를 검증 데이터로 주는 비율을 바꿔가면서 학습시킬 수 있습니다.&lt;/p&gt;
&lt;p&gt;보스턴 주택 가격 데이터세트는 훈련 데이터가 &lt;code&gt;404&lt;/code&gt;개, 테스트 데이터가 &lt;code&gt;102&lt;/code&gt;개이며, 비율로 따지면 약 &lt;code&gt;80:20&lt;/code&gt; 정도입니다.&lt;/p&gt;
&lt;p&gt;보스턴 주택 가격 데이터 속성은 아래와 같습니다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;속성&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;내용&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;CRIM&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;범죄율&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;ZN&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;25,000평방피트당 주거지역의 비율&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;INDUS&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;비소매 상업지구 비율(단위: 에이커)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;CHAS&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;찰스강에 인접해 있으면 1, 그렇지 않으면 0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;NOX&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;일산화질소 농도(단위:0.1ppm)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;RM&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;주택당 방의 수&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;AGE&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1940년 이전에 건설된 주택의 비율&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;DIS&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5개의 보스턴 직업고용센터와의 거리(가중 평균)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;RAD&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;고속도로 접근성&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;TAX&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;재산세율&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;PTRATIO&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;학생/교사비율&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;B&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;흑인비율&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;LSTAT&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;하위계층비율&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;MEDV&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;타운의 주택 가격 중앙값(단위: 1,000달러&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;딥러닝 모형을 만들기전, 데이터 전처리를 진행해야 하는데 이것과 관련한 논쟁거리를 하나 소개합니다.&lt;/p&gt;
&lt;h2 id=&#34;iii-언제-데이터-정규화를-해야할까&#34;&gt;III. 언제 데이터 정규화를 해야할까?&lt;/h2&gt;
&lt;p&gt;데이터 정규화의 기본적인 방법은 각 데이터에서 평균값을 뺀 다음 표준편차로 나눕니다. 그런데, 한가지 궁금한 것이 있다면, 데이터 정규화를 훈련 데이터와 테스트 데이터를 나누기 전에 해야 하는 것이 맞는 것인지, 아니면 나눈 후에 하는 것이 맞는 것인지, 헷갈릴 때가 종종 있습니다.&lt;/p&gt;
&lt;p&gt;스택오버플로우에 이러한 내용을 토대로 나온 좋은 토론글이 있습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://bit.ly/2JDmJ1D&#34;&gt;Normalize data before or after split of training and testing data?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;순서는 다음과 같습니다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;먼저 데이터를 분리합니다.&lt;/li&gt;
&lt;li&gt;훈련데이터를 가지고 정규화를 진행합니다.&lt;/li&gt;
&lt;li&gt;정규화를 진행한 이후, 훈련데이터 정규화로 나온 값의 평균과 분산을 확인합니다.&lt;/li&gt;
&lt;li&gt;훈련데이터 평균과 분산을 가지고 테스트 데이터를 정규화합니다.&lt;/li&gt;
&lt;li&gt;모형을 생성합니다.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;검증 데이터도 마찬가지입니다. 이제 코드를 작성합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 4.12 데이터 전처리(정규화)&lt;/span&gt;
x_mean &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
x_std &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;std(axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
train_X &lt;span style=&#34;color:#f92672&#34;&gt;-=&lt;/span&gt; x_mean
train_X &lt;span style=&#34;color:#f92672&#34;&gt;/=&lt;/span&gt; x_std
test_X &lt;span style=&#34;color:#f92672&#34;&gt;-=&lt;/span&gt; x_mean
test_X &lt;span style=&#34;color:#f92672&#34;&gt;/=&lt;/span&gt; x_std

y_mean &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_Y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
y_std &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_Y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;std(axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
train_Y &lt;span style=&#34;color:#f92672&#34;&gt;-=&lt;/span&gt; y_mean
train_Y &lt;span style=&#34;color:#f92672&#34;&gt;/=&lt;/span&gt; y_std
test_Y &lt;span style=&#34;color:#f92672&#34;&gt;-=&lt;/span&gt; y_mean
test_Y &lt;span style=&#34;color:#f92672&#34;&gt;/=&lt;/span&gt; y_std

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_X[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[-0.27224633 -0.48361547 -0.43576161 -0.25683275 -0.1652266  -0.1764426
  0.81306188  0.1166983  -0.62624905 -0.59517003  1.14850044  0.44807713
  0.8252202 ]
-0.7821526033779157
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;iv-딥러닝-네트워크-학습&#34;&gt;IV. 딥러닝 네트워크 학습&lt;/h2&gt;
&lt;p&gt;정규화가 완료된 이후에는 시퀀셜 모델을 활용하여 딥러닝 네트워크를 학습 시킵니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;52&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;13&lt;/span&gt;, )), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;39&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;26&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(lr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.07&lt;/span&gt;), loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mse&amp;#39;&lt;/span&gt;)
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential_1&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_4 (Dense)              (None, 52)                728       
_________________________________________________________________
dense_5 (Dense)              (None, 39)                2067      
_________________________________________________________________
dense_6 (Dense)              (None, 26)                1040      
_________________________________________________________________
dense_7 (Dense)              (None, 1)                 27        
=================================================================
Total params: 3,862
Trainable params: 3,862
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;코드 설명은 다음과 같습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;첫 번째 레이어에서는 X 데이터의 속성을 모두 불러오기 위해 &lt;code&gt;input_shape&lt;/code&gt;의 첫 번째 차원을 13으로 지정합니다.&lt;/li&gt;
&lt;li&gt;마지막 레이어는 주택가격인 Y값 1개만 예측하면 되기 때문에 뉴런의 수가 1개입니다.&lt;/li&gt;
&lt;li&gt;활성화함수로는 &lt;code&gt;relu&lt;/code&gt;만 사용합니다.&lt;/li&gt;
&lt;li&gt;모델 정의가 끝나면 &lt;code&gt;model.fit()&lt;/code&gt; 함수로 회귀 모델을 학습시킵니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;1-그림-45-출력-코드&#34;&gt;(1) 그림 4.5. 출력 코드&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 그림 4.5 출력 코드&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; math
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sigmoid&lt;/span&gt;(x):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; math&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;x))

x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.01&lt;/span&gt;)
sigmoid_x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [sigmoid(z) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; z &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; x]
tanh_x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [math&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tanh(z) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; z &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; x]
relu &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; z &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; z &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; z &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; x]

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axhline(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axvline(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(x, sigmoid_x, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sigmoid&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(x, tanh_x, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;tanh&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(x, relu, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g.&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_04_03/output_8_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_X, train_Y, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/25
10/10 [==============================] - 0s 5ms/step - loss: 0.2009 - val_loss: 0.4002
Epoch 2/25
10/10 [==============================] - 0s 5ms/step - loss: 0.2382 - val_loss: 0.2915
Epoch 3/25
10/10 [==============================] - 0s 5ms/step - loss: 0.2133 - val_loss: 0.2996
Epoch 4/25
10/10 [==============================] - 0s 5ms/step - loss: 0.2024 - val_loss: 0.3201
Epoch 5/25
10/10 [==============================] - 0s 4ms/step - loss: 0.1887 - val_loss: 0.3605
Epoch 6/25
10/10 [==============================] - 0s 5ms/step - loss: 0.2041 - val_loss: 0.3185
Epoch 7/25
10/10 [==============================] - 0s 4ms/step - loss: 0.1815 - val_loss: 0.2961
Epoch 8/25
10/10 [==============================] - 0s 5ms/step - loss: 0.1984 - val_loss: 0.3034
Epoch 9/25
10/10 [==============================] - 0s 5ms/step - loss: 0.2154 - val_loss: 0.3473
Epoch 10/25
10/10 [==============================] - 0s 5ms/step - loss: 0.2441 - val_loss: 0.3394
Epoch 11/25
10/10 [==============================] - 0s 5ms/step - loss: 0.2401 - val_loss: 0.3083
Epoch 12/25
10/10 [==============================] - 0s 5ms/step - loss: 0.1671 - val_loss: 0.3178
Epoch 13/25
10/10 [==============================] - 0s 4ms/step - loss: 0.1613 - val_loss: 0.2963
Epoch 14/25
10/10 [==============================] - 0s 4ms/step - loss: 0.1587 - val_loss: 0.2522
Epoch 15/25
10/10 [==============================] - 0s 5ms/step - loss: 0.1973 - val_loss: 0.3850
Epoch 16/25
10/10 [==============================] - 0s 4ms/step - loss: 0.2309 - val_loss: 0.4120
Epoch 17/25
10/10 [==============================] - 0s 5ms/step - loss: 0.1818 - val_loss: 0.2867
Epoch 18/25
10/10 [==============================] - 0s 6ms/step - loss: 0.1592 - val_loss: 0.2601
Epoch 19/25
10/10 [==============================] - 0s 4ms/step - loss: 0.1483 - val_loss: 0.2544
Epoch 20/25
10/10 [==============================] - 0s 5ms/step - loss: 0.1416 - val_loss: 0.2757
Epoch 21/25
10/10 [==============================] - 0s 4ms/step - loss: 0.1475 - val_loss: 0.2622
Epoch 22/25
10/10 [==============================] - 0s 4ms/step - loss: 0.1441 - val_loss: 0.2380
Epoch 23/25
10/10 [==============================] - 0s 4ms/step - loss: 0.1692 - val_loss: 0.2581
Epoch 24/25
10/10 [==============================] - 0s 5ms/step - loss: 0.1739 - val_loss: 0.2449
Epoch 25/25
10/10 [==============================] - 0s 5ms/step - loss: 0.1652 - val_loss: 0.3004
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;코드 설명 및 출력 결과에 대한 해석은 다음과 같습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;validation_split&lt;/code&gt;은 훈련데이터에서 일정 비율로 떼서 학습 결과를 검증하기 위한 것입니다. 출력의 경향을 보면, &lt;code&gt;loss&lt;/code&gt;는 꾸준하게 감소하지만, &lt;code&gt;val_loss&lt;/code&gt;는 &lt;code&gt;loss&lt;/code&gt;보다 높은 값을 유지하는 것을 볼 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;이를 시각화하면 다음과 같습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_04_03/output_11_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;훈련 데이터의 손실은 꾸준히 감소하지만, 검증데이터의 손실이 항상 감소하는 것은 아닙니다. 모형이 마음에 드는 것이나 일단 회귀 모형을 평가해봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(test_X, test_Y)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;4/4 [==============================] - 0s 2ms/step - loss: 8023.7656





8023.765625
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;테스트 데이터의 손실은 &lt;code&gt;0.9155&lt;/code&gt;가 나옵니다. 위 그래프에서 훈련 데이터가 보여주는 &lt;code&gt;0.6&lt;/code&gt; 정도의 낮은 손실과는 거리가 있어 보입니다.&lt;/p&gt;
&lt;p&gt;네트워크가 &lt;code&gt;Y&lt;/code&gt;값을 얼마나 잘 예측하는지 확인해보기 위해 실제 주택 가격과 예측 주택 가격을 &lt;code&gt;1:1&lt;/code&gt;로 비교해봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt

pred_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(test_X)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;))
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(test_Y, pred_Y, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b.&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis([min(test_Y), max(test_Y), min(test_Y), max(test_Y)])

&lt;span style=&#34;color:#75715e&#34;&gt;# y=x에 해당하는 대각선&lt;/span&gt;
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot([min(test_Y), max(test_Y)], [min(test_Y), max(test_Y)], ls&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;--&amp;#34;&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;.3&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;test_Y&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pred_Y&amp;#39;&lt;/span&gt;)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_04_03/output_15_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;v-모형-업그레이드&#34;&gt;V. 모형 업그레이드&lt;/h2&gt;
&lt;p&gt;검증 데이터와 테스트 데이터에 대해 모두 좋은 예측 성적을 내려면 어떻게 해야 할까요? 검증 데이터와 테스트 데이터는 훈련 데이터아 달리 네트워크의 가중치에 영향을 미치지 않는다는 공통점이 있으니, 이를 활용합니다. 이 때, 검증 데이터에 대한 성적이 좋아지려면 &lt;code&gt;val_loss&lt;/code&gt;가 높아지지 않도록, 즉 네트워크가 훈련 데이터에 과적합되지 않도록 학습 도중에 끼어들어서 학습을 멈추도록 합니다.&lt;/p&gt;
&lt;p&gt;학습 도중에 끼어들기 위해서는 콜백(&lt;code&gt;callback&lt;/code&gt;) 함수를 사용합니다. 콜백 함수는 모델을 학습할 때 에포크가 끝날 때마다 호출됩니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;52&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;13&lt;/span&gt;, )), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;39&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;26&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(lr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.07&lt;/span&gt;), loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mse&amp;#39;&lt;/span&gt;)
history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_X, train_Y, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;, 
                    callbacks&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;callbacks&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;EarlyStopping(patience&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, monitor&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/25
10/10 [==============================] - 0s 10ms/step - loss: 1.2692 - val_loss: 0.6573
Epoch 2/25
10/10 [==============================] - 0s 4ms/step - loss: 0.3468 - val_loss: 0.3027
Epoch 3/25
10/10 [==============================] - 0s 4ms/step - loss: 0.2343 - val_loss: 0.3601
Epoch 4/25
10/10 [==============================] - 0s 4ms/step - loss: 0.2485 - val_loss: 0.2040
Epoch 5/25
10/10 [==============================] - 0s 4ms/step - loss: 0.1606 - val_loss: 0.1463
Epoch 6/25
10/10 [==============================] - 0s 5ms/step - loss: 0.1371 - val_loss: 0.1716
Epoch 7/25
10/10 [==============================] - 0s 5ms/step - loss: 0.1561 - val_loss: 0.1441
Epoch 8/25
10/10 [==============================] - 0s 5ms/step - loss: 0.1223 - val_loss: 0.1498
Epoch 9/25
10/10 [==============================] - 0s 4ms/step - loss: 0.0983 - val_loss: 0.1318
Epoch 10/25
10/10 [==============================] - 0s 4ms/step - loss: 0.0915 - val_loss: 0.1206
Epoch 11/25
10/10 [==============================] - 0s 4ms/step - loss: 0.0849 - val_loss: 0.1418
Epoch 12/25
10/10 [==============================] - 0s 4ms/step - loss: 0.1200 - val_loss: 0.2197
Epoch 13/25
10/10 [==============================] - 0s 5ms/step - loss: 0.1105 - val_loss: 0.1319
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;tf.keras.callbacks.EarlyStopping&lt;/code&gt;는 말 그대로 학습을 일찍 멈추는 기능을 하는 함수로, &lt;code&gt;patience&lt;/code&gt;는 몇 번의 에포크를 기준으로 삼을 것인지, &lt;code&gt;monitor&lt;/code&gt;는 어떤 값을 지켜볼 것인지에 대한 인수입니다. 여기서는 &lt;code&gt;val_loss&lt;/code&gt;가 3회의 에포크를 수행하는 동안 최고 기록을 갱신하지 못하면 학습을 멈춥니다. 즉, 10 에포크에서 &lt;code&gt;0.1206&lt;/code&gt;이 최고치인데, 11, 12, 13에서 갱신하지 못했기 때문에 학습을 멈췄습니다.&lt;/p&gt;
&lt;p&gt;이를 다시 시각화하면 아래와 같습니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_04_03/output_19_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;검증 데이터의 손실에서 뚜렷한 증가세는 조금 덜 보입니다. 모형을 평가한뒤 다시 실제 주택 가격과 예측 주택 가격을 1:1로 시각홰봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(test_X, test_Y)
pred_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(test_X)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;))
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(test_Y, pred_Y, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b.&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis([min(test_Y), max(test_Y), min(test_Y), max(test_Y)])

&lt;span style=&#34;color:#75715e&#34;&gt;# y=x에 해당하는 대각선&lt;/span&gt;
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot([min(test_Y), max(test_Y)], [min(test_Y), max(test_Y)], ls&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;--&amp;#34;&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;.3&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;test_Y&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pred_Y&amp;#39;&lt;/span&gt;)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;4/4 [==============================] - 0s 2ms/step - loss: 0.3753
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_04_03/output_21_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;조금 더 모형이 다듬어진 것을 볼 수 있습니다. 이렇게 EarlyStopping을 활용하면 과적합 방지도 가능한 기법을 배웠습니다.&lt;/p&gt;
&lt;p&gt;이제 분류로 넘어갑니다.&lt;/p&gt;
&lt;h2 id=&#34;vi-연습-파일&#34;&gt;VI. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch4_4_boston_housing_deeplearning.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;vii-reference&#34;&gt;VII. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>