<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>오토인코더 on Data Science | ChloEvan</title>
    <link>https://chloevan.github.io/tags/%EC%98%A4%ED%86%A0%EC%9D%B8%EC%BD%94%EB%8D%94/</link>
    <description>Recent content in 오토인코더 on Data Science | ChloEvan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 11 May 2020 12:20:30 +0900</lastBuildDate>
    
        <atom:link href="https://chloevan.github.io/tags/%EC%98%A4%ED%86%A0%EC%9D%B8%EC%BD%94%EB%8D%94/rss.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch9.5 - 이미지 분할</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch9_5_image_segmentation/</link>
      <pubDate>Mon, 11 May 2020 12:20:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch9_5_image_segmentation/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.2 - 다항분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/&#34;&gt;Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/&#34;&gt;Tensorflow 2.0 Tutorial ch6.1-2 - CNN 이론&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_3_fashion_mnist_with_cnn/&#34;&gt;Tensorflow 2.0 Tutorial ch6.3 - Fashion MNIST with CNN 실습&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_4_improve_performance/&#34;&gt;Tensorflow 2.0 Tutorial ch6.4 - 모형의 성능 높이기&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (1)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (2)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_3_sentimentanalysis/&#34;&gt;Tensorflow 2.0 Tutorial ch7.3 - 긍정, 부정 감성 분석&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (1) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (2) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_1_tensorflow_hub/&#34;&gt;Tensorflow 2.0 Tutorial ch8.1 - 텐서플로 허브&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_2_transfer_learning/&#34;&gt;Tensorflow 2.0 Tutorial ch8.2 - 전이 학습과 &amp;amp; Kaggle 대회&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_3_1_texture_synthesis/&#34;&gt;Tensorflow 2.0 Tutorial ch8.3.1 - 컨볼루션 신경망을 사용한 텍스처 합성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_3_2_neural_style_transfer/&#34;&gt;Tensorflow 2.0 Tutorial ch8.3.2 - 컨볼루션 신경망을 사용한 신경 스타일 전이&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch9_1_auto_encoder/&#34;&gt;Tensorflow 2.0 Tutorial ch9.1-2 - 오토인코더 &amp;amp; MNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch9_3_k_means_clustering/&#34;&gt;Tensorflow 2.0 Tutorial ch9.3 - 클러스터링&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch9_4_super_resolution/&#34;&gt;Tensorflow 2.0 Tutorial ch9.4 - 초해상도&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요&#34;&gt;I. 개요&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;이미지에서 단순히 경계선을 추출하는 작업은 전통적인 알고리즘의 필터나 한 층의 컨볼루션 레이어로도 가능하지만, 의미 있는 부분과 그렇지 않은 부분으로 분할하기 위해서는 학습이 필요합니다.&lt;/li&gt;
&lt;li&gt;앞 절에서 정의한 &lt;code&gt;REDNet&lt;/code&gt;을 조금만 수정하면 이미지 분할(&lt;code&gt;Segmentation&lt;/code&gt;)에서 사용할 수 있습니다.&lt;/li&gt;
&lt;li&gt;이미지의 경계선과 내용, 그리고 외곽의 3가지로 분류하는 &lt;code&gt;Oxford-IIIT Pet&lt;/code&gt; 데이터세트로 이미지 분할 문제를 학습합니다.&lt;/li&gt;
&lt;li&gt;교재에 있는 코드에서 몇몇 에러가 발생하였습니다. 내용상 텐서플로 홈페이지와 유사하여 텐서플로 공식 홈페이지에 있는 소스코드를 참고하였습니다.&lt;/li&gt;
&lt;li&gt;먼저 필수 파일들을 &lt;code&gt;pip&lt;/code&gt; 도구를 활용하여 설치합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;!&lt;/span&gt;pip install git&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;https:&lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt;github&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;com&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;tensorflow&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;examples&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;git
&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;!&lt;/span&gt;pip install &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;U tfds&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;nightly
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Collecting git+https://github.com/tensorflow/examples.git
  Cloning https://github.com/tensorflow/examples.git to /tmp/pip-req-build-36g0gu68
  Running command git clone -q https://github.com/tensorflow/examples.git /tmp/pip-req-build-36g0gu68
Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow-examples===63ee35adcc3e3dd2d228bc3283e27f6a1e2158ab-) (0.9.0)
Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorflow-examples===63ee35adcc3e3dd2d228bc3283e27f6a1e2158ab-) (1.12.0)
Building wheels for collected packages: tensorflow-examples
  Building wheel for tensorflow-examples (setup.py) ... [?25l[?25hdone
  Created wheel for tensorflow-examples: filename=tensorflow_examples-63ee35adcc3e3dd2d228bc3283e27f6a1e2158ab_-cp36-none-any.whl size=125226 sha256=f2f0d0a9e57edde6593979e55a26983574dba25b3f7008be261173181109f5b8
  Stored in directory: /tmp/pip-ephem-wheel-cache-f32yqfdy/wheels/83/64/b3/4cfa02dc6f9d16bf7257892c6a7ec602cd7e0ff6ec4d7d714d
Successfully built tensorflow-examples
Installing collected packages: tensorflow-examples
Successfully installed tensorflow-examples-63ee35adcc3e3dd2d228bc3283e27f6a1e2158ab-
Collecting tfds-nightly
[?25l  Downloading https://files.pythonhosted.org/packages/8c/42/df5f05f2124f9d1b6e16b88c518f04a7d282d77daf3113ba548baadc4ce5/tfds_nightly-3.1.0.dev202005100106-py3-none-any.whl (3.3MB)
[K     |████████████████████████████████| 3.3MB 11.6MB/s 
[?25hRequirement already satisfied, skipping upgrade: wrapt in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (1.12.1)
Requirement already satisfied, skipping upgrade: requests&amp;gt;=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (2.23.0)
Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (4.41.1)
Requirement already satisfied, skipping upgrade: attrs&amp;gt;=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (19.3.0)
Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (0.16.0)
Requirement already satisfied, skipping upgrade: absl-py in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (0.9.0)
Requirement already satisfied, skipping upgrade: dill in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (0.3.1.1)
Requirement already satisfied, skipping upgrade: promise in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (2.3)
Collecting tensorflow-metadata&amp;lt;0.16,&amp;gt;=0.15
  Downloading https://files.pythonhosted.org/packages/3b/0c/afb81ea6998f6e26521671585d1cd9d3f7945a8b9834764e91757453dc25/tensorflow_metadata-0.15.2-py2.py3-none-any.whl
Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (1.12.0)
Requirement already satisfied, skipping upgrade: protobuf&amp;gt;=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (3.10.0)
Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (1.18.4)
Requirement already satisfied, skipping upgrade: termcolor in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (1.1.0)
Requirement already satisfied, skipping upgrade: chardet&amp;lt;4,&amp;gt;=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests&amp;gt;=2.19.0-&amp;gt;tfds-nightly) (3.0.4)
Requirement already satisfied, skipping upgrade: certifi&amp;gt;=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests&amp;gt;=2.19.0-&amp;gt;tfds-nightly) (2020.4.5.1)
Requirement already satisfied, skipping upgrade: idna&amp;lt;3,&amp;gt;=2.5 in /usr/local/lib/python3.6/dist-packages (from requests&amp;gt;=2.19.0-&amp;gt;tfds-nightly) (2.9)
Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,&amp;lt;1.26,&amp;gt;=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests&amp;gt;=2.19.0-&amp;gt;tfds-nightly) (1.24.3)
Requirement already satisfied, skipping upgrade: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata&amp;lt;0.16,&amp;gt;=0.15-&amp;gt;tfds-nightly) (1.51.0)
Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf&amp;gt;=3.6.1-&amp;gt;tfds-nightly) (46.1.3)
Installing collected packages: tensorflow-metadata, tfds-nightly
  Found existing installation: tensorflow-metadata 0.21.2
    Uninstalling tensorflow-metadata-0.21.2:
      Successfully uninstalled tensorflow-metadata-0.21.2
Successfully installed tensorflow-metadata-0.15.2 tfds-nightly-3.1.0.dev202005100106
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;ii-rednet1&#34;&gt;II. REDNet[^1]&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;REDNet&lt;/code&gt;은 &lt;code&gt;Residual Encoder-Decoder Network&lt;/code&gt;의 약자이며, &lt;code&gt;Residual&lt;/code&gt;은 &lt;code&gt;ResNet&lt;/code&gt;등에서 사용하는 건너뛴 연결(&lt;code&gt;skip-connection&lt;/code&gt;)입니다.&lt;/li&gt;
&lt;li&gt;다수의 레이어가 중첩되는 구조에서 앞쪽의 정보를 잃어버리기 않기 위해 뒤쪽에 정보를 그대로 전달해줄 때 건너뛴 연결이 사용됩니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow_examples.models.pix2pix &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pix2pix

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow_datasets &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tfds
tfds&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;disable_progress_bar()

&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; IPython.display &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; clear_output
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;iii-데이터-불러오기&#34;&gt;III. 데이터 불러오기&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;tf.keras.utils.get_file()&lt;/code&gt; 데이터를 불러옵니다.&lt;/li&gt;
&lt;li&gt;교재에서는 &lt;code&gt;oxford_iiit_pet:3.0.0&lt;/code&gt;으로 되어 있었는데, 버전을 &lt;code&gt;3.*.*&lt;/code&gt;으로 수정하여 다운로드를 하기를 바랍니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;dataset, info &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfds&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;oxford_iiit_pet:3.*.*&amp;#39;&lt;/span&gt;, with_info&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[1mDownloading and preparing dataset oxford_iiit_pet/3.2.0 (download: 773.52 MiB, generated: 774.69 MiB, total: 1.51 GiB) to /root/tensorflow_datasets/oxford_iiit_pet/3.2.0...[0m
Shuffling and writing examples to /root/tensorflow_datasets/oxford_iiit_pet/3.2.0.incompleteONHCBY/oxford_iiit_pet-train.tfrecord
Shuffling and writing examples to /root/tensorflow_datasets/oxford_iiit_pet/3.2.0.incompleteONHCBY/oxford_iiit_pet-test.tfrecord
[1mDataset oxford_iiit_pet downloaded and prepared to /root/tensorflow_datasets/oxford_iiit_pet/3.2.0. Subsequent calls will reuse this data.[0m
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;info
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;tfds.core.DatasetInfo(
    name=&#39;oxford_iiit_pet&#39;,
    version=3.2.0,
    description=&#39;The Oxford-IIIT pet dataset is a 37 category pet image dataset with roughly 200
images for each class. The images have large variations in scale, pose and
lighting. All images have an associated ground truth annotation of breed.&#39;,
    homepage=&#39;http://www.robots.ox.ac.uk/~vgg/data/pets/&#39;,
    features=FeaturesDict({
        &#39;file_name&#39;: Text(shape=(), dtype=tf.string),
        &#39;image&#39;: Image(shape=(None, None, 3), dtype=tf.uint8),
        &#39;label&#39;: ClassLabel(shape=(), dtype=tf.int64, num_classes=37),
        &#39;segmentation_mask&#39;: Image(shape=(None, None, 1), dtype=tf.uint8),
        &#39;species&#39;: ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
    }),
    total_num_examples=7349,
    splits={
        &#39;test&#39;: 3669,
        &#39;train&#39;: 3680,
    },
    supervised_keys=(&#39;image&#39;, &#39;label&#39;),
    citation=&amp;quot;&amp;quot;&amp;quot;@InProceedings{parkhi12a,
      author       = &amp;quot;Parkhi, O. M. and Vedaldi, A. and Zisserman, A. and Jawahar, C.~V.&amp;quot;,
      title        = &amp;quot;Cats and Dogs&amp;quot;,
      booktitle    = &amp;quot;IEEE Conference on Computer Vision and Pattern Recognition&amp;quot;,
      year         = &amp;quot;2012&amp;quot;,
    }&amp;quot;&amp;quot;&amp;quot;,
    redistribution_info=,
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;Dataset&lt;/code&gt;의 주요 정보를 구성하고 있는 부분은 &lt;code&gt;features&lt;/code&gt;입니다. 여기에는 &lt;code&gt;image&lt;/code&gt;, &lt;code&gt;label&lt;/code&gt;, &lt;code&gt;segmentation_mask&lt;/code&gt;가 보입니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;label&lt;/code&gt;은 각 애완동물에 대한 클래스 정보를 담고 있습니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;image&lt;/code&gt;는 3차원인 것으로 보아 &lt;code&gt;컬러 이미지&lt;/code&gt;일 것이라고 추측할 수 있습니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;segmentation_mask&lt;/code&gt;는 마지막 차원이 &lt;code&gt;1&lt;/code&gt;로 구성된 것을 볼 때 흑백 이미지처럼 다룰 수 있다고 추측해 볼 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;iv-rednet-모형-학습&#34;&gt;IV. &lt;code&gt;REDNET&lt;/code&gt; 모형 학습&lt;/h2&gt;
&lt;p&gt;모형 학습을 위해 데이터 수집 부터 모델 정의까지 진행합니다.&lt;/p&gt;
&lt;h3 id=&#34;1-데이터-정규화&#34;&gt;(1) 데이터 정규화&lt;/h3&gt;
&lt;p&gt;The following code performs a simple augmentation of flipping an image. In addition, image is normalized to [0,1]. Finally, as mentioned above the pixels in the segmentation mask are labeled either {1, 2, 3}. For the sake of convenience, let&amp;rsquo;s subtract 1 from the segmentation mask, resulting in labels that are : {0, 1, 2}.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;다음 코드는 이미지를 뒤집는 Simple Augmentation을 수행합니다.&lt;/li&gt;
&lt;li&gt;또한 이미지는 [0,1]로 정규화 합니다.&lt;/li&gt;
&lt;li&gt;마지막으로, 위에서 언급한 바와 같이 분할 마스크의 픽셀은 {1, 2, 3} 중 하나로 라벨이 표시되어 있다.&lt;/li&gt;
&lt;li&gt;편의상 분할 마스크에서 1을 빼서 {0, 1, 2}의 레이블을 생성해 봅시다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;normalize&lt;/span&gt;(input_image, input_mask):
  input_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(input_image, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
  input_mask &lt;span style=&#34;color:#f92672&#34;&gt;-=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; input_image, input_mask
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;여기에서 마스크에서 1을 빼는 연산이 있습니다. 이 부분은 데이터를 출력 후 재 설명하도록 합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-훈련데이터-테스트데이터-불러오기&#34;&gt;(2) 훈련데이터, 테스트데이터 불러오기&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;훈련데이터와 테스트 불러오는 함수를 작성합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;@tf.function&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;load_image_train&lt;/span&gt;(datapoint):
  input_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(datapoint[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;image&amp;#39;&lt;/span&gt;], (&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;))
  input_mask &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(datapoint[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;segmentation_mask&amp;#39;&lt;/span&gt;], (&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;))

  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uniform(()) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;:
    input_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flip_left_right(input_image)
    input_mask &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flip_left_right(input_mask)

  input_image, input_mask &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; normalize(input_image, input_mask)

  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; input_image, input_mask
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;load_image_test&lt;/span&gt;(datapoint):
  input_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(datapoint[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;image&amp;#39;&lt;/span&gt;], (&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;))
  input_mask &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(datapoint[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;segmentation_mask&amp;#39;&lt;/span&gt;], (&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;))

  input_image, input_mask &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; normalize(input_image, input_mask)

  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; input_image, input_mask
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;TRAIN_LENGTH &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; info&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;splits[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;train&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;num_examples
BATCH_SIZE &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;
BUFFER_SIZE &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;
STEPS_PER_EPOCH &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; TRAIN_LENGTH &lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt; BATCH_SIZE
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;데이터를 불러오면서 &lt;code&gt;image&lt;/code&gt;의 &lt;code&gt;flip&lt;/code&gt;을 주어 변형시켰다. 또한, &lt;code&gt;image&lt;/code&gt;와 &lt;code&gt;mask&lt;/code&gt;를 통해 정규화를 진행하고, &lt;code&gt;128 X 128&lt;/code&gt;로 변환합니다. 크기가 다르면 &lt;code&gt;tf.keras&lt;/code&gt;에서 학습이 되지 않기 때문에 그렇습니다.&lt;/li&gt;
&lt;li&gt;이제 데이터를 불러오도록 합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dataset[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;train&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;map(load_image_train, num_parallel_calls&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;experimental&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;AUTOTUNE)
test &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dataset[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;test&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;map(load_image_test)

train_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cache()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shuffle(BUFFER_SIZE)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;batch(BATCH_SIZE)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;repeat()
train_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;prefetch(buffer_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;experimental&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;AUTOTUNE)
test_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;batch(BATCH_SIZE)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;정의된 &lt;code&gt;load_image_*&lt;/code&gt; 함수로 이미지와 마스크를 반환하고, 데이터를 계속 학습시킬 수 있도록 &lt;code&gt;repeat()&lt;/code&gt; 함수를 적용합니다.&lt;/li&gt;
&lt;li&gt;그리고, 배치 사이즈를 각각 적용하도록 합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3-시각화-함수-정의-및-시각화&#34;&gt;(3) 시각화 함수 정의 및 시각화&lt;/h3&gt;
&lt;p&gt;우선 함수를 정의하도록 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;display&lt;/span&gt;(display_list):
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;))

  title &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Input Image&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;True Mask&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Predicted Mask&amp;#39;&lt;/span&gt;]

  &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(len(display_list)):
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, len(display_list), i&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(title[i])
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;preprocessing&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array_to_img(display_list[i]))
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;colorbar()  
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;정의된 함수를 사용하여 이미지와 마스크를 출력합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; image, mask &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; train&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;take(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
  sample_image, sample_mask &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; image, mask
display([sample_image, sample_mask])

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_05/output_23_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;왼쪽은 원본 이미지가 보이고, 오른쪽에는 마스크와 각 숫자의 값을 나타내는 &lt;code&gt;colorbar&lt;/code&gt;를 표시했습니다.&lt;/li&gt;
&lt;li&gt;마스크 데이터에는 중심부, 외곽선 배경을 뜻하는 &lt;code&gt;1, 3, 2&lt;/code&gt;의 숫자가 각 픽셀에 대해 저장되어 있습니다.&lt;/li&gt;
&lt;li&gt;이미지 분할 문제는 기본적으로 각 픽셀을 분류하는 문제이기 때문에 라벨이 0부터 시작할 수 있게 1,2,3을 0,1,2로 바꿔줍니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;4-모형의-정의&#34;&gt;(4) 모형의 정의&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;이미지 분할 네트워크의 학습은 원본 이미지를 입력했을 때 마스크를 출력하게 합니다. 이를 위해서는 ch9_4에서 사용했던 &lt;code&gt;REDNet&lt;/code&gt;에서 마지막 레이어를 수정합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;REDNet_segmentation&lt;/span&gt;(num_layers):
    conv_layers &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    deconv_layers &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    residual_layers &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []

    inputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Input(shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(None, None, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;))
    conv_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;))

    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(num_layers&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
        conv_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;))
        deconv_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2DTranspose(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;))

    deconv_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2DTranspose(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;))

    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; conv_layers[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;](inputs)

    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(num_layers&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; conv_layers[i&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;](x)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
            residual_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(x)

    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(num_layers&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:
            x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Add()([x, residual_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pop()])
            x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Activation(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;)(x)
        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; deconv_layers[i](x) 

    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; deconv_layers[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;](x)
    
    model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Model(inputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;inputs, outputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;x)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; model
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;수정된 부분은 마지막 레이어의 활성화함수입니다. 원래 활성화 함수가 없었기 때문에, &lt;code&gt;linear&lt;/code&gt; 활성화함수로 입력값을 그대로 출력하던 것을 소프트맥스 활성화함수로 교체합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;분류 문제로 바뀌었기 때문에 네트워크를 컴파일할 때의 &lt;code&gt;loss&lt;/code&gt;도 바꿔줍니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; REDNet_segmentation(&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;)
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.0001&lt;/span&gt;),
              loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sparse_categorical_crossentropy&amp;#39;&lt;/span&gt;,
              metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;분류를 위해 &lt;code&gt;loss&lt;/code&gt;에 &lt;code&gt;sparse_categorical_crossentropy&lt;/code&gt;를 사용했고, 분류의 정확도를 측정하기 위해 &lt;code&gt;metrics&lt;/code&gt;에 &lt;code&gt;accuracy&lt;/code&gt;를 넣었습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;모형의 구조를 출력해봅니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot_model(model, show_shapes&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_05/output_31_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;5-정의된-모형의-예측&#34;&gt;(5) 정의된 모형의 예측&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;모형을 학습시키기 전에 간단하게 예측을 통해서 어떤 결과값이 나타나는지 확인해봅니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;create_mask&lt;/span&gt;(pred_mask):
  pred_mask &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argmax(pred_mask, axis&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
  pred_mask &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pred_mask[&lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis]
  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; pred_mask[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;show_predictions&lt;/span&gt;(dataset&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None, num&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; dataset:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; image, mask &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;take(num):
      pred_mask &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(image)
      display([image[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], mask[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], create_mask(pred_mask)])
  &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
    display([sample_image, sample_mask,
             create_mask(model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(sample_image[tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis, &lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;]))])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;show_predictions()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_05/output_35_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;6-모형-학습&#34;&gt;(6) 모형 학습&lt;/h3&gt;
&lt;p&gt;이제 본격적으로 네트워크를 학습해봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;DisplayCallback&lt;/span&gt;(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;callbacks&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Callback):
  &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;on_epoch_end&lt;/span&gt;(self, epoch, logs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None):
    clear_output(wait&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
    show_predictions()
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; (&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Sample Prediction after epoch {}&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(epoch&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;EPOCHS &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;
VAL_SUBSPLITS &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;
VALIDATION_STEPS &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; info&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;splits[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;test&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;num_examples&lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt;BATCH_SIZE&lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt;VAL_SUBSPLITS

model_history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_dataset, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;EPOCHS,
                          steps_per_epoch&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;STEPS_PER_EPOCH,
                          validation_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;VALIDATION_STEPS,
                          validation_data&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;test_dataset,
                          callbacks&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[DisplayCallback()])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_05/output_38_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Sample Prediction after epoch 20

57/57 [==============================] - 112s 2s/step - loss: 0.5203 - accuracy: 0.7806 - val_loss: 0.5203 - val_accuracy: 0.7839
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;이미지 분할은 초해상도 이미지를 얻는 문제보다는 쉽기 때문에 에포크를 20으로 설정했습니다.&lt;/li&gt;
&lt;li&gt;학습결과 훈련 데이터와 검증 데이터에서의 정확도는 각각 78%, 78%로 확인되었습니다.&lt;/li&gt;
&lt;li&gt;가운데 정답 마스크고, 가장 오른쪽이 예측결과인데, 몸통 부위에 대해 예측을 하지 못했습니다.&lt;/li&gt;
&lt;li&gt;학습을 더 시켜도 될 것 같습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;7-학습-모형-결과-시각화&#34;&gt;(7) 학습 모형 결과 시각화&lt;/h3&gt;
&lt;p&gt;학습된 모형에 대해 시각화를 진행하도록 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model_history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;]
val_loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model_history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;]

epochs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; range(EPOCHS)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(epochs, loss, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Training loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(epochs, val_loss, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bo&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Validation loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Training and Validation Loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Loss Value&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylim([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_05/output_41_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;위 시각화를 볼 때, 에포크를 늘려도 무난할 것 같습니다.&lt;/li&gt;
&lt;li&gt;이미지 보강 등의 방법을 사용하면 더 좋은 결과를 얻을 수 있을 것입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;8-테스트-이미지-분할-확인&#34;&gt;(8) 테스트 이미지 분할 확인&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;각 행의 가운데 세로줄이 정답 마스크이고, 가장 오른쪽 열이 재구성된 마스크입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;show_predictions(test_dataset, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_05/output_44_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_05/output_44_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_05/output_44_2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;위 3가지에서 조금 주목할만 것이 있다면, 첫번째 사진입니다. 정답 마스크에 비해 예측 마스크의 노란색이 조금 더 옅어진 것을 확인할 수 있습니다. 이는 오히려 정답 이미지에 비해 오히려 세밀한 예측을 하고 있다고 보여집니다.&lt;/li&gt;
&lt;li&gt;다만, 전반적으로 이미지가 깨지는 부분이 많아서 에포크를 늘리거나 이미지 보강등의 기법으로 진행하면 더 좋은 결과를 얻어낼 수 있을 것 같습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v-결론-및-정리&#34;&gt;V. 결론 및 정리&lt;/h2&gt;
&lt;p&gt;이번 9장에서는 컨볼루션 레이어와 디컨볼루션 레이어를 대칭적으로 쌓아올려 만든 오토인코더에 대해 살펴봅니다. 기본적인 형태의 오토인코더는 자기 자신을 재생성하는 특징이 있고, 오토인코더의 입력에 저해상도 이미지를 넣으면 초해상도 이미지를 얻을 수 있고, 출력에 분할 이미지를 넣으면 이미지 분할 문제를 학습시킬 수도 있습니다.&lt;/p&gt;
&lt;p&gt;오토인코더의 중심에서 잠재변수를 추출하여, 정보를 압축하는 과정에서 데이터의 특징을 가장 잘 나타내도록 학습되기 때문에 이를 클러스터링에 사용해 고차원의 데이터를 저차원으로 시각화도 할 수 있습니다.&lt;/p&gt;
&lt;h2 id=&#34;vi-reference&#34;&gt;VI. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch9.4 - 초해상도</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch9_4_super_resolution/</link>
      <pubDate>Thu, 07 May 2020 07:20:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch9_4_super_resolution/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.2 - 다항분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/&#34;&gt;Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/&#34;&gt;Tensorflow 2.0 Tutorial ch6.1-2 - CNN 이론&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_3_fashion_mnist_with_cnn/&#34;&gt;Tensorflow 2.0 Tutorial ch6.3 - Fashion MNIST with CNN 실습&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_4_improve_performance/&#34;&gt;Tensorflow 2.0 Tutorial ch6.4 - 모형의 성능 높이기&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (1)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (2)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_3_sentimentanalysis/&#34;&gt;Tensorflow 2.0 Tutorial ch7.3 - 긍정, 부정 감성 분석&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (1) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (2) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_1_tensorflow_hub/&#34;&gt;Tensorflow 2.0 Tutorial ch8.1 - 텐서플로 허브&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_2_transfer_learning/&#34;&gt;Tensorflow 2.0 Tutorial ch8.2 - 전이 학습과 &amp;amp; Kaggle 대회&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_3_1_texture_synthesis/&#34;&gt;Tensorflow 2.0 Tutorial ch8.3.1 - 컨볼루션 신경망을 사용한 텍스처 합성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_3_2_neural_style_transfer/&#34;&gt;Tensorflow 2.0 Tutorial ch8.3.2 - 컨볼루션 신경망을 사용한 신경 스타일 전이&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch9_1_auto_encoder/&#34;&gt;Tensorflow 2.0 Tutorial ch9.1-2 - 오토인코더 &amp;amp; MNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch9_3_k_means_clustering/&#34;&gt;Tensorflow 2.0 Tutorial ch9.3 - 클러스터링&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요&#34;&gt;I. 개요&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;저해상도에서 고해상도의 이미지로 변환하는 것은 어려운 연산입니다.&lt;/li&gt;
&lt;li&gt;픽셀로 구성된 이미지는 고해상도로 변환(확대)하면 이미지에서 사각형이 두드러져 보이는 것이 바로 초해상도(&lt;code&gt;Super Resolution&lt;/code&gt;) 작업입니다.&lt;/li&gt;
&lt;li&gt;전통적으로는 &lt;code&gt;interpolation(보간)&lt;/code&gt; 등의 기법이 있지만, 선명함을 잃고 흐릿해지는 단점이 있습니다.&lt;/li&gt;
&lt;li&gt;오토인코더로 초해상도 작업을 하는 과정을 진행합니다.&lt;/li&gt;
&lt;li&gt;이 때, &lt;code&gt;REDNet&lt;/code&gt;이라는 네트워크를 사용합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ii-rednet1&#34;&gt;II. REDNet&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;REDNet&lt;/code&gt;은 &lt;code&gt;Residual Encoder-Decoder Network&lt;/code&gt;의 약자이며, &lt;code&gt;Residual&lt;/code&gt;은 &lt;code&gt;ResNet&lt;/code&gt;등에서 사용하는 건너뛴 연결(&lt;code&gt;skip-connection&lt;/code&gt;)입니다.&lt;/li&gt;
&lt;li&gt;다수의 레이어가 중첩되는 구조에서 앞쪽의 정보를 잃어버리기 않기 위해 뒤쪽에 정보를 그대로 전달해줄 때 건너뛴 연결이 사용됩니다.&lt;/li&gt;
&lt;li&gt;논문에서 사용한 이미지는 &lt;code&gt;BSD (Berkeley Segmentation Dataset)&lt;/code&gt; 이며, 책에서도 동일하게 사용합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 텐서플로 2 버전 선택&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
    &lt;span style=&#34;color:#75715e&#34;&gt;# %tensorflow_version only exists in Colab.&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;tensorflow_version &lt;span style=&#34;color:#ae81ff&#34;&gt;2.&lt;/span&gt;x
&lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Exception&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;pass&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow_hub &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; hub
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; cv2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;iii-데이터-불러오기&#34;&gt;III. 데이터 불러오기&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;tf.keras.utils.get_file()&lt;/code&gt; 데이터를 불러옵니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/bsd_images.zip&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://bit.ly/35pHZlC&amp;#39;&lt;/span&gt;, extract&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from http://bit.ly/35pHZlC
37527552/37520292 [==============================] - 0s 0us/step





&#39;/content/bsd_images.zip&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;!&lt;/span&gt;unzip &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;content&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;bsd_images&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zip
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Archive:  /content/bsd_images.zip
   creating: images/
   creating: images/test/
  inflating: images/test/100007.jpg  
  inflating: images/test/100039.jpg  
  .
  .
  .
  .
  inflating: images/val/97033.jpg    
  inflating: images/val/Thumbs.db    
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;이미지 경로 저장 및 확인을 합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pathlib
image_root &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pathlib&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Path(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/images&amp;#39;&lt;/span&gt;)
all_images_paths&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;list(image_root&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;glob(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;*/*&amp;#39;&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(all_images_paths[:&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[PosixPath(&#39;/content/images/val/62096.jpg&#39;), PosixPath(&#39;/content/images/val/361010.jpg&#39;), PosixPath(&#39;/content/images/val/Thumbs.db&#39;), PosixPath(&#39;/content/images/val/54082.jpg&#39;), PosixPath(&#39;/content/images/val/87046.jpg&#39;), PosixPath(&#39;/content/images/val/38082.jpg&#39;), PosixPath(&#39;/content/images/val/156065.jpg&#39;), PosixPath(&#39;/content/images/val/33039.jpg&#39;), PosixPath(&#39;/content/images/val/14037.jpg&#39;), PosixPath(&#39;/content/images/val/159008.jpg&#39;)]
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;각 이미지의 경로는 &lt;code&gt;root&lt;/code&gt; 디렉터리에서 &lt;code&gt;glob()&lt;/code&gt; 함수를 사용해 하단의 모든 파일을 불러올 수 있습니다.&lt;/li&gt;
&lt;li&gt;각 파일의 경로는 &lt;code&gt;PosixPath&lt;/code&gt;라는 객체가 되는데, 이 객체에서 경로를 가져오기 위해서는 문자열로 변환하는 &lt;code&gt;str()&lt;/code&gt;함수를 사용합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;1-이미지-시각화&#34;&gt;(1) 이미지 시각화&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;matplotlib.pyplot&lt;/code&gt;으로 확인합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; PIL.Image &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; Image
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;):
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(all_images_paths[c]))
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(all_images_paths[c])
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;/img/tensorflow2.0/tutorial_09_04/output_7_1.png
&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_04/output_7_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;데이터를 보면 아시겠지만, 가로와 세로 길이가 모두 다릅니다. 또한, 이미지의 내용은 사람, 동물, 자연등으로 다양합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-이미지-경로-분리-저장&#34;&gt;(2) 이미지 경로 분리 저장&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;BSD500&lt;/code&gt;은 200장의 훈련 데이터, 100장의 검증 데이터, 200장의 테스트 데이터로 구성되어 있습니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;를 각 데이터세트마다 만듭니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train_path, valid_path, test_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [], [], []

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; image_path &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; all_images_paths:
  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; str(image_path)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;jpg&amp;#34;&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;continue&lt;/span&gt;
  
  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; str(image_path)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;train&amp;#39;&lt;/span&gt;: 
    train_path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(str(image_path))
  &lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; str(image_path)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val&amp;#39;&lt;/span&gt;:
    valid_path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(str(image_path))
  &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
    test_path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(str(image_path))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;3-원본-이미지-조각-추출-입력-출력-데이터-변환-함수-정의&#34;&gt;(3) 원본 이미지 조각 추출, 입력, 출력 데이터 변환 함수 정의&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;현재의 이미지는 고해상도이기 때문에, 저해상도는 일부러 낮추고 원본과 함께 반환하는 함수를 만듭니다.&lt;/li&gt;
&lt;li&gt;원본 이미지에서 조각을 추출해서 입력, 출력 데이터를 생성하는 구조에 관한 이미지는 교재 360페이지를 확인해봅니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_hr_and_lr&lt;/span&gt;(image_path):
  img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;io&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_file(image_path)
  img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;decode_jpeg(img, channels&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
  img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convert_image_dtype(img, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)

  hr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random_crop(img, [&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;])
  lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(hr, [&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;])
  lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(lr, [&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;])

  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; lr, hr 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;JPEG&lt;/code&gt; 이미지는 &lt;code&gt;tf.io.read_file()&lt;/code&gt;로 불러올 수 있습니다.&lt;/li&gt;
&lt;li&gt;이미지를 불러온 후 &lt;code&gt;decode_jpeg()&lt;/code&gt; 함수를 사용해서 프로그램이 이해할 수 있는 데이터 형태로 만들어야 하고, &lt;code&gt;convert_image_dtype()&lt;/code&gt;함수로 데이터 타입을 딥러닝에서 가장 범용적으로 사용하는 &lt;code&gt;float32&lt;/code&gt; 데이터 타입으로 바꿉니다.&lt;/li&gt;
&lt;li&gt;가로 X 세로 50픽셀의 이미지를 &lt;code&gt;random_crop()&lt;/code&gt;이라는 함수로 쉽게 얻을 수 있습니다.&lt;/li&gt;
&lt;li&gt;마지막의 3은 컬러 채널의 수를 의미합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;4-train-valid-dataset-정의&#34;&gt;(4) &lt;code&gt;train, valid Dataset 정의&lt;/code&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Dataset&lt;/code&gt;를 정의할 차례이며, 학습 과정에서 사용할 훈련 데이터와 검증 데이터를 사용하는 &lt;code&gt;Dataset&lt;/code&gt;를 각각 정의합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;list_files(train_path)
train_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;map(get_hr_and_lr)
train_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;repeat()
train_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;batch(&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;)

valid_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;list_files(train_path)
valid_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; valid_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;map(get_hr_and_lr)
valid_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; valid_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;repeat()
valid_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; valid_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;batch(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;먼저 파일의 경로 리스트를 가지고 있다면 &lt;code&gt;tf.data.Dataset.list_files()&lt;/code&gt; 함수의 인수로 파일 경로 리스트를 넣어서 &lt;code&gt;Dataset&lt;/code&gt;를 쉽게 정의할 수 있습니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;get_hr_and_lr()&lt;/code&gt; 함수를 &lt;code&gt;map()&lt;/code&gt;함수를 적용해 새로운 &lt;code&gt;Dataset&lt;/code&gt;을 만듭니다.&lt;/li&gt;
&lt;li&gt;이렇게 연결되면 &lt;code&gt;Dataset&lt;/code&gt;는 먼저 &lt;code&gt;train_path&lt;/code&gt; 리스트의 이미지를 불러온 다음에 저해상도와 고해상도 조각인 &lt;code&gt;lr&lt;/code&gt;, &lt;code&gt;hr&lt;/code&gt;을 반환합니다. 여기까지 선언하면 쉽게 사용할 수 있는 &lt;code&gt;Dataset&lt;/code&gt;을 1차로 완성한 것입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;5-rednet-30의-정의&#34;&gt;(5) REDNet-30의 정의&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;REDNet-30&lt;/code&gt;에 대한 구조에 대한 설명은 교재 &lt;code&gt;362-363 p&lt;/code&gt;를 확인합니다. 다음 소스코드로 네트워크 정의를 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;REDNet&lt;/span&gt;(num_layers):
    conv_layers &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    deconv_layers &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    residual_layers &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []

    inputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Input(shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(None, None, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;))
    conv_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;))

    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(num_layers&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
        conv_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;))
        deconv_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2DTranspose(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;))

    deconv_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2DTranspose(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;))

    &lt;span style=&#34;color:#75715e&#34;&gt;# 인코더 시작&lt;/span&gt;
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; conv_layers[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;](inputs)

    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(num_layers&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; conv_layers[i&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;](x)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
            residual_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(x)

    &lt;span style=&#34;color:#75715e&#34;&gt;# 디코더 시작&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(num_layers&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:
            x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Add()([x, residual_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pop()])
            x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Activation(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;)(x)
        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; deconv_layers[i](x) 

    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; deconv_layers[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;](x)
    
    model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Model(inputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;inputs, outputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;x)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; model
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;위 함수를 통해서, &lt;code&gt;REDNet-10, REDNet-20, REDNet-30&lt;/code&gt;등 다양한 네트워크를 함수 호출 한 번으로 만들 수 있습니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;num_layers&lt;/code&gt;는 컨볼루션 레이어와 디컨볼루션 레이어의 수입니다. 같은 수의 컨볼루션 레이어가 존재하기 때문에, &lt;code&gt;REDNet-30&lt;/code&gt;이라면 &lt;code&gt;num_layers=15&lt;/code&gt;를 입력하면 됩니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;conv_layers&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[]
deconv_layers&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[]
residual_layers&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;먼저 세 개의 리스트에 각각 컨볼루션 레이어, 디컨볼루션 레이어, 잔류(&lt;code&gt;residual&lt;/code&gt;)레이어를 저장합니다.&lt;/p&gt;
&lt;p&gt;각 레이어를 따로 저장할 리스트가 별도로 필요로 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;
    inputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Input(shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(None, None, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;))
    conv_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;))

    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(num_layers&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
        conv_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;))
        deconv_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2DTranspose(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;))

    deconv_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2DTranspose(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;))
    &lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;먼저 입력 레이어를 정의합니다. 입력 레이어의 &lt;code&gt;shape&lt;/code&gt;에서 이미지의 높이와 너비를 &lt;code&gt;None&lt;/code&gt;으로 지정해서 어떤 크기의 이미지라도 입력으로 받을 수 있습니다.&lt;/li&gt;
&lt;li&gt;첫 번째 컨볼루션 레이어와 마지막 디컨볼루션 레이어를 제외한 레이어들은 &lt;code&gt;for&lt;/code&gt; 문 안에서 정의해서 각 리스트에 저장합니다.&lt;/li&gt;
&lt;li&gt;첫번째 컨볼루션 레이어와 마지막 디컨볼루션 레이어는 필터의 수가 다른데 이는 필터의 수로 &lt;code&gt;RGB&lt;/code&gt; 채널의 수인 &lt;code&gt;3&lt;/code&gt;을 그대로 받기 위함입니다. 나머지 레이어에서는 64개의 필터를 사용합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# 인코더 시작&lt;/span&gt;
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; conv_layers[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;](inputs)

    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(num_layers&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; conv_layers[i&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;](x)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
            residual_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(x)

    &lt;span style=&#34;color:#75715e&#34;&gt;# 디코더 시작&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(num_layers&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:
            x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Add()([x, residual_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pop()])
            x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Activation(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;)(x)
        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; deconv_layers[i](x) 

    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; deconv_layers[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;](x)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;여기에서는 &lt;code&gt;x&lt;/code&gt;라는 변수에 레이어를 계속 적용해서 함수형 &lt;code&gt;API&lt;/code&gt;를 사용합니다. 마지막에 &lt;code&gt;x&lt;/code&gt;는 모든 레이어가 적용된 결과가 되기 때문에 모델의 출력이 됩니다.&lt;/li&gt;
&lt;li&gt;이렇게 하나의 변수 이름을 재사용하여 레이어를 적용해나가는 방법은 케라스의 함수형 &lt;code&gt;API&lt;/code&gt;나 &lt;code&gt;torch&lt;/code&gt;에서 일반적으로 쓰이는 문법입니다.&lt;/li&gt;
&lt;li&gt;첫번째 명령인 &lt;code&gt;x = conv_layers[0](inputs)&lt;/code&gt;의 결과로 &lt;code&gt;x&lt;/code&gt;는 입력 레이어에 첫 번째 컨볼루션 레이어를 적용한 결과가 됩니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(num_layers&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; conv_layers[i&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;](x)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
            residual_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(x)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;그 다음으로는 &lt;code&gt;for&lt;/code&gt; 문 안에서 &lt;code&gt;x&lt;/code&gt;에 나머지 컨볼루션 레이어를 계속 적용시키며, 짝수번재 컨볼루션 레이어를 지날 때마다 &lt;code&gt;x&lt;/code&gt;를 잔류 레이어 리스트에도 저장합니다.&lt;/li&gt;
&lt;li&gt;잔류 레이어에 &lt;code&gt;x&lt;/code&gt;를 저장한 다음 스텝에서 &lt;code&gt;x&lt;/code&gt;는 다시 컨볼루션 레이어를 통과해서 새로운 값이 되지만 잔류 레이어에 이미 저장된 값은 사라지지 않습니다.&lt;/li&gt;
&lt;li&gt;교재 366페이지에 그림설명이 있기 때문에 한번 더 확인하시기를 바랍니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# 디코더 시작&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(num_layers&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:
            x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Add()([x, residual_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pop()])
            x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Activation(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;)(x)
        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; deconv_layers[i](x) 

    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; deconv_layers[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;](x)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;두 번째 &lt;code&gt;for&lt;/code&gt; 문 안에서는 홀수 번째의 디컨볼루션 레이어를 통과할 경우 잔류 레이어 리스트에 저장돼 있던 값을 &lt;code&gt;residual_layers.pop()&lt;/code&gt;으로 뒤에서부터 하나씩 가져옵니다. 그 다음 합연산과 &lt;code&gt;ReLU&lt;/code&gt; 활성화함수를 통과한 후 다음 디컨볼루션 레이어에 연결시킵니다.&lt;/li&gt;
&lt;li&gt;짝수 번째일 때는 디컨볼루션 레이어만 연결합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;model = tf.keras.Model(inputs=inputs, outputs=x)
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;tf.keras&lt;/code&gt;의 함수형 &lt;code&gt;API&lt;/code&gt;로 &lt;code&gt;Model&lt;/code&gt;을 만들기 위해서는 입력과 출력만 지정하면 됩니다.&lt;/li&gt;
&lt;li&gt;입력인 &lt;code&gt;inputs&lt;/code&gt;는 함수의 가장 앞에서 정의한 입력 레이어로, 출력인 &lt;code&gt;outputs&lt;/code&gt;는 지금까지 레이어 연산을 쭉 따라온 변수 이름인 &lt;code&gt;x&lt;/code&gt;로 넣고, &lt;code&gt;model&lt;/code&gt;을 반환합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;6-psnr-계산-공식-및-함수-정의&#34;&gt;(6) PSNR 계산 공식 및 함수 정의&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;고해상도 이미지가 잘 복원됐는지 알기 위해서 특별한 측정값을 컴파일에 추가해서 테스트할 수 있습니다.&lt;/li&gt;
&lt;li&gt;이 측정값은 &lt;code&gt;PSNR(Peak Signal-to-Noise Ratio)&lt;/code&gt;, 즉 &amp;ldquo;신호 대 잡임비&amp;quot;입니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;PSNR&lt;/code&gt;의 계산 공식은 다음과 같습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$PSNR = 20\ast log_{10}\frac{Max(pixel)}{\sqrt{MSE}}$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;여기서 &lt;code&gt;Max(pixel)&lt;/code&gt;은 픽셀의 최대값으로, 앞에서 &lt;code&gt;float32&lt;/code&gt;로 계산했기 때문에 이 값은 &lt;code&gt;1.0&lt;/code&gt;이 됩니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MSE&lt;/code&gt;는 우리가 잘 알고 있는 평균 제곱 오차(&lt;code&gt;Mean Squared Error&lt;/code&gt;)입니다.&lt;/li&gt;
&lt;li&gt;평균 제곱 오차가 로그의 분모에 있기 때문에 이 식은 평균 제곱 오차가 낮을수록 큰 값을 갖게 됩니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;psnr_metric&lt;/span&gt;(y_true, y_pred):
  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;psnr(y_true, y_pred, max_val&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Metric&lt;/code&gt;은 분류의 정확도(&lt;code&gt;accuracy&lt;/code&gt;)처럼 &lt;code&gt;tf.keras&lt;/code&gt;에 등록되어 있을 경우 그대로 사용하면 되지만 &lt;code&gt;PSNR&lt;/code&gt;은 지원하지 않기 때문에 함수를 만들어줍니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;y_true&lt;/code&gt;는 정답에 해당하는 값이고, &lt;code&gt;y_pred&lt;/code&gt;는 네트워크가 학습 결과 예측한 값입니다.&lt;/li&gt;
&lt;li&gt;이 둘의 &lt;code&gt;tf.image.psnr()&lt;/code&gt;을 계산해서 반환하는 것이 &lt;code&gt;psnr_metric()&lt;/code&gt; 함수의 역할입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;7-rednet-30-네트워크-초기화-및-컴파일&#34;&gt;(7) REDNet-30 네트워크 초기화 및 컴파일&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;이제 &lt;code&gt;REDNet()&lt;/code&gt; 함수로 네트워크를 초기화하고 컴파일합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; REDNet(&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;)
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.0001&lt;/span&gt;), loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mse&amp;#39;&lt;/span&gt;, metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[psnr_metric])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;컴파일된 네트워크 시각화를 작성해봅니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot_model(model)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;8-rednet-30-네트워크-학습&#34;&gt;(8) REDNet-30 네트워크 학습&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;이제 네트워크를 학습합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit_generator(train_dataset, 
                              epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;, 
                              steps_per_epoch&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;len(train_path)&lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;, 
                              validation_data&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;valid_dataset, 
                              validation_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;len(valid_path), 
                              verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;WARNING:tensorflow:From &amp;lt;ipython-input-15-11785503027a&amp;gt;:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
Please use Model.fit, which supports generators.
Epoch 1/1000
12/12 - 4s - loss: 0.2467 - psnr_metric: 7.6192 - val_loss: 0.2287 - val_psnr_metric: 8.1383
Epoch 2/1000
12/12 - 3s - loss: 0.1935 - psnr_metric: 8.8387 - val_loss: 0.0982 - val_psnr_metric: 11.4855
.
.
.
Epoch 998/1000
12/12 - 3s - loss: 0.0015 - psnr_metric: 32.7882 - val_loss: 0.0013 - val_psnr_metric: 32.6776
Epoch 999/1000
12/12 - 3s - loss: 0.0015 - psnr_metric: 32.2986 - val_loss: 0.0015 - val_psnr_metric: 32.9123
Epoch 1000/1000
12/12 - 3s - loss: 0.0015 - psnr_metric: 32.4111 - val_loss: 0.0014 - val_psnr_metric: 32.6642
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Dataset&lt;/code&gt;를 이용한 학습은 &lt;code&gt;fit()&lt;/code&gt; 함수 대신 &lt;code&gt;fit_generator()&lt;/code&gt; 함수를 사용합니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Dataset&lt;/code&gt;에 &lt;code&gt;repeat()&lt;/code&gt; 함수를 사용했기 때문에 한 번의 에포크에 몇 개의 데이터를 학습시킬지를 지정하는 &lt;code&gt;steps_per_epoch&lt;/code&gt;인수를 설정해야 합니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;batch size&lt;/code&gt;가 16이기 때문에 &lt;code&gt;steps_per_epoch&lt;/code&gt;는 &lt;code&gt;len(train_path)//16&lt;/code&gt;으로 훈련 데이터의 크기를 &lt;code&gt;batch size&lt;/code&gt;로 나눕니다.
&lt;ul&gt;
&lt;li&gt;//는 결과가 정수로 나오는 나눗셈을 의미합니다. 예를 들면 200//16의 결과는 12가 됩니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;verbose=2&lt;/code&gt;의 의미니느 출력제한에 걸리지 않도록 하며, 진행 상황 애니메이션은 생략하고 각 에포크의 결과만 출력합니다.&lt;/li&gt;
&lt;li&gt;학습 결과, 훈련 데이터의 &lt;code&gt;PSNR&lt;/code&gt;은 31~32, 검증데이터의 29-32정도가 나옵니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;9-네트워크-학습-결과-확인&#34;&gt;(9) 네트워크 학습 결과 확인&lt;/h3&gt;
&lt;p&gt;학습 겨로가를 확인합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;psnr_metric&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;psnr&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_psnr_metric&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_psnr&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_04/output_37_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;PSNR 수치 모두 학습할수록 증가하는 경향을 보입니다. 이렇게 학습된 데이터가 실제 이미지를 어떻게 복원하는지 확인합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;io&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_file(test_path[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;decode_jpeg(img, channels&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
hr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convert_image_dtype(img, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)

lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(hr, [hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;])
lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(lr, [hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]])
predict_hr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(lr, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;psnr(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(predict_hr, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;), hr, max_val&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;psnr(lr, hr, max_val&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;tf.Tensor(26.110872, shape=(), dtype=float32)
tf.Tensor(24.853115, shape=(), dtype=float32)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;10-테스트-이미지에-대한-초해상도-결과-확인&#34;&gt;(10) 테스트 이미지에 대한 초해상도 결과 확인&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;테스트 데이터 중 첫 번째 이미지를 불러와서 저해상도 버전을 만든 다음 &lt;code&gt;REDNet-30&lt;/code&gt; 네트워크에 통과시켜서 복원 이미지를 얻어냅니다.&lt;/li&gt;
&lt;li&gt;결과에서 &lt;code&gt;PSNR&lt;/code&gt; 점수는 복원 이미지가 저해상도 이미지보다 아주 살짝 높은 것으로 나옵니다.&lt;/li&gt;
&lt;li&gt;이미지를 출력합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(hr)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;original - hr&amp;#39;&lt;/span&gt;)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(lr)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lr&amp;#39;&lt;/span&gt;)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(predict_hr, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sr&amp;#39;&lt;/span&gt;)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;첫번째 사진이 이미지의 원본이고, 두번째 사진이 저해상도, 세번째 줄이 복원된 이미지입니다.&lt;/li&gt;
&lt;li&gt;이 작업의 성능을 비교하기 위해 &lt;code&gt;Set5&lt;/code&gt;라는 데이터세트가 있습니다. 이 중에서도 자주 쓰이는 나비의 사진을 불러와서 확인합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;image_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;butterfly.png&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://bit.ly/2oAOxgH&amp;#39;&lt;/span&gt;)
img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;io&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_file(image_path)
img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;decode_jpeg(img, channels&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
hr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convert_image_dtype(img, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)

lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(hr, [hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;])
lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(lr, [hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]])
predict_hr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(lr, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;psnr(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(predict_hr, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;), hr, max_val&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;psnr(lr, hr, max_val&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;))


plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;))
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(hr)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;original - hr&amp;#39;&lt;/span&gt;)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(lr)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lr&amp;#39;&lt;/span&gt;)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(predict_hr, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sr&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from http://bit.ly/2oAOxgH
131072/127529 [==============================] - 0s 0us/step
tf.Tensor(20.3429, shape=(), dtype=float32)
tf.Tensor(20.217585, shape=(), dtype=float32)





Text(0.5, 1.0, &#39;sr&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_04/output_43_2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;벤치마크답게 &lt;code&gt;PSNR&lt;/code&gt; 점수에서 성능 차이가 뚜렷하게 드러납니다.&lt;/li&gt;
&lt;li&gt;조금 더 어려운 과제로는 확대 비율을 늘려볼 수 있습니다. 현재는 2배인데, 이를 4배로 늘려봅니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;11-확대비율-4배로-수정-이미지-보강-rednet-30-네트워크-학습&#34;&gt;(11) 확대비율 4배로 수정, 이미지 보강 REDNet-30 네트워크 학습&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Dataset&lt;/code&gt;에서는 쉽게 이미지 보강을 할 수 있습니다. 이미지에서 랜덤한 부분을 잘라서 고해상도와 저해상도 버전을 추출하던 &lt;code&gt;get_hr_and_lr()&lt;/code&gt; 함수를 다음과 같이 바꿉니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; random
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_hr_and_lr_flip_s4&lt;/span&gt;(image_path):
  img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;io&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_file(image_path)
  img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;decode_jpeg(img, channels&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
  img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convert_image_dtype(img, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)

  hr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random_crop(img, [&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;])
  lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(hr, [&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;])
  lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(lr, [&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;])

  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random() &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;:
    hr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flip_left_right(hr)
    lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flip_left_right(lr)
  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random() &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;:
    hr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flip_up_down(hr)
    lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flip_up_down(lr)

  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; lr, hr 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;앞부분은 축소/확대 비율을 2배에서 4배로 바꾸는 부분을 제외하면 &lt;code&gt;get_hr_and_lr()&lt;/code&gt; 함수와 같고, 뒤쪽에서 &lt;code&gt;25%&lt;/code&gt;의 확률로 좌우 반전, 또 &lt;code&gt;25%&lt;/code&gt;의 확률로 상하 반전을 시켜줍니다.&lt;/li&gt;
&lt;li&gt;결과적으로 &lt;code&gt;Dataset&lt;/code&gt;을 다시 정의하고 바뀐 함수를 적용합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;12-rednet-30-네트워크-학습&#34;&gt;(12) REDNet-30 네트워크 학습&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;list_files(train_path)
train_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;map(get_hr_and_lr_flip_s4)
train_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;repeat()
train_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;batch(&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;)

valid_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;list_files(valid_path)
valid_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; valid_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;map(get_hr_and_lr_flip_s4)
valid_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; valid_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;repeat()
valid_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; valid_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;batch(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)

model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; REDNet(&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;)
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.0001&lt;/span&gt;), loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mse&amp;#39;&lt;/span&gt;, metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[psnr_metric])

history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit_generator(train_dataset, 
                              epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4000&lt;/span&gt;, 
                              steps_per_epoch&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;len(train_path)&lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;, 
                              validation_data&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;valid_dataset, 
                              validation_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;len(valid_path), 
                              verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;12/12 - 3s - loss: 0.0046 - psnr_metric: 27.3362 - val_loss: 0.0050 - val_psnr_metric: 27.4308
Epoch 3548/4000
12/12 - 3s - loss: 0.0046 - psnr_metric: 26.8918 - val_loss: 0.0045 - val_psnr_metric: 26.7091
.
.
.
Epoch 3999/4000
12/12 - 3s - loss: 0.0048 - psnr_metric: 26.8295 - val_loss: 0.0055 - val_psnr_metric: 25.5176
Epoch 4000/4000
12/12 - 3s - loss: 0.0046 - psnr_metric: 27.5956 - val_loss: 0.0048 - val_psnr_metric: 27.2664
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;이미지 보강으로 데이터가 4배 정도 늘어난 것과 같은 효과이기 때문에 에포크를 1,000에서 4,000으로 늘렸씁니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Set5&lt;/code&gt;의 나비 이미지를 테스트해보면 다음과 같은 결과가 나옵니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;13-학습-결과-확인-및-set5-이미지-시각화&#34;&gt;(13) 학습 결과 확인 및 &lt;code&gt;Set5&lt;/code&gt; 이미지 시각화&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;psnr_metric&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;psnr&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_psnr_metric&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_psnr&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_04/output_52_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;image_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;butterfly.png&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://bit.ly/2oAOxgH&amp;#39;&lt;/span&gt;)
img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;io&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_file(image_path)
img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;decode_jpeg(img, channels&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
hr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convert_image_dtype(img, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)

lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(hr, [hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;])
lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(lr, [hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]])
predict_hr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(lr, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;psnr(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(predict_hr, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;), hr, max_val&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;psnr(lr, hr, max_val&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;))


plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;))
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(hr)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;original - hr&amp;#39;&lt;/span&gt;)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(lr)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lr&amp;#39;&lt;/span&gt;)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(predict_hr, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sr&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).


tf.Tensor(22.349665, shape=(), dtype=float32)
tf.Tensor(20.217585, shape=(), dtype=float32)





Text(0.5, 1.0, &#39;sr&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_04/output_53_3.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이미지를 불러온 다음 각 이미지에 대한 저해상도 버전과 복원 이미지의 &lt;code&gt;PSNR&lt;/code&gt; 점수를 구해서 평균을 비교합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;image_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/Set5.zip&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://bit.ly/2MEG4kr&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;!&lt;/span&gt;unzip Set5&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zip
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from http://bit.ly/2MEG4kr
860160/852576 [==============================] - 0s 0us/step
Archive:  Set5.zip
   creating: Set5/
 extracting: Set5/baby.png           
 extracting: Set5/bird.png           
 extracting: Set5/butterfly.png      
 extracting: Set5/head.png           
  inflating: Set5/woman.png          
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;set5_image_root &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pathlib&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Path(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/Set5&amp;#39;&lt;/span&gt;)
set5_image_paths &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; list(set5_image_root&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;glob(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;*.*&amp;#39;&lt;/span&gt;))

sr_psnr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
lr_psnr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; image_path &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; set5_image_paths:
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;io&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_file(str(image_path))
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;decode_jpeg(img, channels&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
    hr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convert_image_dtype(img, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)

    lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(hr, [hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;])
    lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(lr, [hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]])
    predict_hr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(lr, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))
    
    sr_psnr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;psnr(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(predict_hr, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;), hr, max_val&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy())
    lr_psnr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;psnr(lr, hr, max_val&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy())
    
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sr:&amp;#39;&lt;/span&gt;, sr_psnr)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sr mean:&amp;#39;&lt;/span&gt;, np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(sr_psnr))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;()
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lr:&amp;#39;&lt;/span&gt;, lr_psnr)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lr mean:&amp;#39;&lt;/span&gt;, np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(lr_psnr))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;WARNING:tensorflow:5 out of the last 5 calls to &amp;lt;function Model.make_predict_function.&amp;lt;locals&amp;gt;.predict_function at 0x7fc446f63158&amp;gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
sr: [28.628256, 22.349665, 25.808668, 27.925306, 30.419857]
sr mean: 27.026352

lr: [28.569517, 20.217585, 24.495182, 27.31659, 29.72251]
lr mean: 26.064276
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;복원 이미지의 &lt;code&gt;PSNR&lt;/code&gt; 점수가 저해상도 버전보다 전반적으로 높게 나타나는 것을 확인할 수 있습니다.&lt;/li&gt;
&lt;li&gt;4배 확대 초해상도에 대한 벤치마크 사이트에서 &lt;code&gt;REDNet-30&lt;/code&gt;은 &lt;code&gt;Set5&lt;/code&gt; 이미지에 대해 최고 31.51점의 &lt;code&gt;PSNR&lt;/code&gt;점수를 기록하고 있습니다.&lt;/li&gt;
&lt;li&gt;학습을 시킬수록 &lt;code&gt;PSNR&lt;/code&gt; 점수는 증가하는 경향을 보이기 때문에 과적합되지 않을 정도로 충분한 에포크 동안 학습시키고 입력 이미지를 다양하게 만들어서 더 좋은 &lt;code&gt;PSNR&lt;/code&gt;점수를 얻을 수 있을 겁니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;iv-연습-파일&#34;&gt;IV. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch9_4_super_resolution.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v-reference&#34;&gt;V. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;X. Mao, C. Shen, and Y. Yang. (2016, September 1). Image Restoration Using Very Deep Convolutional Encoder-Decoder Networks with Symmetric Skip Connections. Retrieved from &lt;a href=&#34;https://arxiv.org/abs/1603.09056&#34;&gt;https://arxiv.org/abs/1603.09056&lt;/a&gt; &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch9.3 - 클러스터링</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch9_3_k_means_clustering/</link>
      <pubDate>Mon, 04 May 2020 17:10:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch9_3_k_means_clustering/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.2 - 다항분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/&#34;&gt;Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/&#34;&gt;Tensorflow 2.0 Tutorial ch6.1-2 - CNN 이론&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_3_fashion_mnist_with_cnn/&#34;&gt;Tensorflow 2.0 Tutorial ch6.3 - Fashion MNIST with CNN 실습&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_4_improve_performance/&#34;&gt;Tensorflow 2.0 Tutorial ch6.4 - 모형의 성능 높이기&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (1)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (2)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_3_sentimentanalysis/&#34;&gt;Tensorflow 2.0 Tutorial ch7.3 - 긍정, 부정 감성 분석&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (1) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (2) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_1_tensorflow_hub/&#34;&gt;Tensorflow 2.0 Tutorial ch8.1 - 텐서플로 허브&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_2_transfer_learning/&#34;&gt;Tensorflow 2.0 Tutorial ch8.2 - 전이 학습과 &amp;amp; Kaggle 대회&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_3_1_texture_synthesis/&#34;&gt;Tensorflow 2.0 Tutorial ch8.3.1 - 컨볼루션 신경망을 사용한 텍스처 합성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_3_2_neural_style_transfer/&#34;&gt;Tensorflow 2.0 Tutorial ch8.3.2 - 컨볼루션 신경망을 사용한 신경 스타일 전이&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch9_1_auto_encoder/&#34;&gt;Tensorflow 2.0 Tutorial ch9.1-2 - 오토인코더 &amp;amp; MNIST&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요&#34;&gt;I. 개요&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;오토인코더(&lt;code&gt;AutoEncoder&lt;/code&gt;)는 입력에 대한 출력을 학습해야 한다는 점은 기존 지도학습 네트워크와 동일합니다.&lt;/li&gt;
&lt;li&gt;그러나 그 출력이 입력과 동일하다는 점이 조금 다릅니다.&lt;/li&gt;
&lt;li&gt;오토인코더는 자기 자신을 재생성하는 네트워크입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_01-2/tutorial_01.png&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;위 그림에서 보는 것처럼, 오토인코더는 크게 3가지 부분으로 구성됩니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;z&lt;/code&gt;는 잠재 변수(&lt;code&gt;Latent Vector&lt;/code&gt;)를 중심으로, 입력에 가까운 부분을 인코더(&lt;code&gt;Encoder&lt;/code&gt;), 출력에 가까운 부분을 디코더(&lt;code&gt;Decoder&lt;/code&gt;)라 분류합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;인코더의 역할은 &lt;code&gt;입력&lt;/code&gt;에서 &lt;code&gt;잠재 변수&lt;/code&gt;를 만드는 것입니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;디코더의 역할은 &lt;code&gt;잠재 변수&lt;/code&gt;를 &lt;code&gt;출력&lt;/code&gt;으로 만드는 것입니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;위 그림이 잠재변수를 기준으로 하나의 대칭구조를 이루는 것처럼, 레이어 역시 대칭되는 구조로 쌓아올려서 만듭니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;음. 조금 쉽게 얘기하면, 오토인코더는 일종의 파일 압축과 유사합니다. 압축 파일은 압축하기 전과 압축을 해제한 뒤의 내용이 동일합니다. 컴퓨터공학 용어로 이러한 내용을 비손실 압축이라고 합니다. 내용적으로는 그러합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;그러나, &lt;code&gt;$x$&lt;/code&gt;와 &lt;code&gt;$x^i$&lt;/code&gt;의 차이점처럼 유사하지만 동일하지는 않습니다. 즉, 오토인코더는 손실 압축이라고 표현합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;딥러닝 생성 모델 중 최근 가장 주목받고 있는 적대적 생성 모델(&lt;code&gt;Generative Adversarial Network&lt;/code&gt; 이하 &lt;code&gt;GAN&lt;/code&gt;)의 생성자에서는 랜덤하게 생성된 변수를 잠재변수처럼 활용해서 새로운 이미지를 얻습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ii-클러스터링&#34;&gt;II. 클러스터링&lt;/h2&gt;
&lt;p&gt;클러스터링은 대표적인 비지도학습 방법의 한 종류입니다. 비지도학습은 입력에 대한 출력이 존재하지 않습니다. 비지도학습과 관련된 문제는 다음과 같은 예로 표현할 수 있습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;사람의 얼굴 이미지를 몇 개의 집단으로 분류하는 것이 적절할까요?&lt;/li&gt;
&lt;li&gt;단편 소설의 장르를 몇 개로 구분해야 할까요?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;쉽게 답을 내기 어렵습니다. 그러나, 클러스터링 알고리즘을 이용해 군집을 나누는 시도를 해볼 수 있습니다.&lt;/p&gt;
&lt;p&gt;K-평균 클러스터링은 주어진 입력 중 &lt;code&gt;K&lt;/code&gt;개의 클러스터 중심을 임의로 정한 다음에 각 데이터와 &lt;code&gt;K&lt;/code&gt;개의 중심과의 거리를 비교해서 가장 가까운 클러스터로 배당하고, &lt;code&gt;K&lt;/code&gt;개의 중심의 위치를 해당 클러스터로 옮긴 후, 이를 반복하는 알고리즘입니다.&lt;/p&gt;
&lt;h3 id=&#34;1-모듈-설치-및-데이터세트-확인&#34;&gt;(1) 모듈 설치 및 데이터세트 확인&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;데이터는 (&lt;code&gt;train_X&lt;/code&gt;, &lt;code&gt;train_Y&lt;/code&gt;), (&lt;code&gt;test_X&lt;/code&gt;, &lt;code&gt;test_Y&lt;/code&gt;)처럼 훈련 데이터와 테스트 데이터의 튜플 쌍으로 불러 올 수 있습니다.&lt;/li&gt;
&lt;li&gt;데이터를 로드한 후에 &lt;code&gt;train_X&lt;/code&gt;와 &lt;code&gt;test_X&lt;/code&gt;를 255.0으로 나눠서 픽셀 정규화를 하게 됩니다.&lt;/li&gt;
&lt;li&gt;데이터가 잘 불러와졌는지 시각화를 통해 확인합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 텐서플로 2 버전 선택&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
    &lt;span style=&#34;color:#75715e&#34;&gt;# %tensorflow_version only exists in Colab.&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;tensorflow_version &lt;span style=&#34;color:#ae81ff&#34;&gt;2.&lt;/span&gt;x
&lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Exception&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;pass&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow_hub &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; hub
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; cv2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;(train_X, train_Y), (test_X, test_Y) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;datasets&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mnist&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load_data()
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, train_Y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
11493376/11490434 [==============================] - 0s 0us/step
(60000, 28, 28) (60000,)
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_X &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(train_X[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;), cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;colorbar()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;/img/tensorflow2.0/tutorial_09_03/&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_03/output_7_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;5
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;MNIST&lt;/code&gt;는 &lt;code&gt;Fashion MNIST&lt;/code&gt;처럼 가로와 세로가 각각 28픽셀인 흑백 이미지를 입력으로 하고, 0~9까지의 숫자를 출력으로 합니다. (5장과 6장 참조)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-잠재변수-분리-모델&#34;&gt;(2) 잠재변수 분리 모델&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;잠재변수를 분리할 수 있는 모델을 만듭니다.&lt;/li&gt;
&lt;li&gt;지난시간에 학습했던 &lt;code&gt;elu&lt;/code&gt;모델의 가중치를 그대로 사용하고, 8장에 등장했던 함수형 &lt;code&gt;API&lt;/code&gt;를 이용해서 만듭니다. 입력은 &lt;code&gt;model&lt;/code&gt;의 입력을 그대로 사용하고, 출력은 4번째 레이어의 (3번째 인덱스)의 &lt;code&gt;Dense&lt;/code&gt;레이어의 출력을 사용합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)

model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;elu&amp;#39;&lt;/span&gt;, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;elu&amp;#39;&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Flatten(),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;elu&amp;#39;&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;elu&amp;#39;&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Reshape(target_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;)),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2DTranspose(filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;elu&amp;#39;&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2DTranspose(filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sigmoid&amp;#39;&lt;/span&gt;)
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(), loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mse&amp;#39;&lt;/span&gt;)
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_X, train_X, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/20
235/235 [==============================] - 2s 7ms/step - loss: 0.0532
Epoch 2/20
235/235 [==============================] - 2s 6ms/step - loss: 0.0181
Epoch 3/20
235/235 [==============================] - 2s 6ms/step - loss: 0.0114
Epoch 4/20
235/235 [==============================] - 2s 7ms/step - loss: 0.0094
Epoch 5/20
235/235 [==============================] - 2s 7ms/step - loss: 0.0085
Epoch 6/20
235/235 [==============================] - 2s 7ms/step - loss: 0.0080
Epoch 7/20
235/235 [==============================] - 2s 7ms/step - loss: 0.0076
Epoch 8/20
235/235 [==============================] - 2s 7ms/step - loss: 0.0073
Epoch 9/20
235/235 [==============================] - 2s 7ms/step - loss: 0.0071
Epoch 10/20
235/235 [==============================] - 2s 7ms/step - loss: 0.0070
Epoch 11/20
235/235 [==============================] - 2s 7ms/step - loss: 0.0069
Epoch 12/20
235/235 [==============================] - 2s 7ms/step - loss: 0.0067
Epoch 13/20
235/235 [==============================] - 2s 7ms/step - loss: 0.0065
Epoch 14/20
235/235 [==============================] - 2s 7ms/step - loss: 0.0064
Epoch 15/20
235/235 [==============================] - 2s 7ms/step - loss: 0.0063
Epoch 16/20
235/235 [==============================] - 2s 6ms/step - loss: 0.0062
Epoch 17/20
235/235 [==============================] - 2s 7ms/step - loss: 0.0061
Epoch 18/20
235/235 [==============================] - 2s 7ms/step - loss: 0.0059
Epoch 19/20
235/235 [==============================] - 2s 7ms/step - loss: 0.0058
Epoch 20/20
235/235 [==============================] - 2s 7ms/step - loss: 0.0056





&amp;lt;tensorflow.python.keras.callbacks.History at 0x7f724b0a5be0&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;한줄로 모델을 만들고 훈련 데이터를 64차원의 잠재변수로 만듭니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;latent_vector_model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Model(inputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;input, outputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers[&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;output)
latent_vector&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;latent_vector_model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(train_X)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(latent_vector&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(latent_vector[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;(60000, 64)
[ 8.581287   13.880566   -0.9973878  -0.99999976 17.375837   -0.9999998
 21.470583    7.486889   10.730955   17.930098   -0.9999982  -0.999995
 18.012827   -0.99999994 10.878519    0.84252346 12.058126   -0.9999992
 -0.9999996  -0.99999964 10.97095     8.179257   10.740526    2.934045
 15.918473    6.9685793  -0.9999925  15.430024    5.45632    13.583059
 11.942195    3.0618956   8.68406     7.022519    3.3600893  -0.22935408
 -0.9999999  21.116535    5.195381   21.416206   11.435531   -0.9999959
 12.934925    8.710132   16.295168   -0.9999958   9.566681   -0.9999999
 -0.9999997  11.260084    3.3911107  15.630404   12.752275   21.86347
 -0.9999942   7.3721986  11.828167   12.603353    6.7158327   9.415517
 -0.9999996  -0.99998534  3.7850168  -0.9999999 ]
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;3-사이킷런의-k-평균-클러스터링-알고리즘-사용&#34;&gt;(3) 사이킷런의 &lt;code&gt;K-평균&lt;/code&gt; 클러스터링 알고리즘 사용&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;이제 이 잠재변수에 &lt;code&gt;K-평균 클러스터링&lt;/code&gt; 알고리즘을 사용해 클러스터링을 시도합니다. 이 때에는 &lt;code&gt;scikit-learn&lt;/code&gt;라이브러리를 활용합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%%&lt;/span&gt;time
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; sklearn.cluster &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; KMeans

kmeans&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;KMeans(n_clusters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, n_init&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, random_state&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;42&lt;/span&gt;)
kmeans&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(latent_vector)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;CPU times: user 12.7 s, sys: 3.06 s, total: 15.8 s
Wall time: 12 s
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;Wall Time&lt;/code&gt;은 실제로 걸린 시간을 의미하며, &lt;code&gt;CPU Time&lt;/code&gt;은 멀티 코어 사용시 모든 코어의 계산 시간을 합쳐서 표시합니다.&lt;/p&gt;
&lt;h3 id=&#34;4-계산-결과-및-클러스터링-결과-출력&#34;&gt;(4) 계산 결과 및 클러스터링 결과 출력&lt;/h3&gt;
&lt;p&gt;다음과 같은 코드로 계산 결과를 확인합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(kmeans&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;labels_)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(kmeans&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cluster_centers_&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(kmeans&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cluster_centers_[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[0 1 5 ... 3 8 3]
(10, 64)
[12.022522   12.878943   -0.9730305  -0.99999547 11.162719   -0.99999875
 10.717042    4.197002   10.867007   10.656286   -0.9999948  -0.9999962
 11.743372   -0.9999997  18.646065    2.8977199  12.208149   -0.9999985
 -0.9999977  -0.9999986   9.804234   10.8237     11.522504   14.51758
 12.841155    8.481935   -0.99997735 12.95512     9.044333   12.863187
 15.309784    8.42041     4.893768    9.139908    4.298092    9.0015545
 -0.9999992  16.420288   12.175448   17.10225    11.114536   -0.9999808
 17.079649   14.277916   14.1573305  -0.9999922  11.437085   -0.9999989
 -0.9999989  15.305092    7.9359035  11.408762    9.687219   14.03581
 -0.99999744 10.3641405  12.274414   12.197285    8.345043   11.521661
 -0.9999953  -0.99990386 12.515451   -0.9999994 ]
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;labels_&lt;/code&gt;에는 각 데이터가 0부터 9사이의 어떤 클러스터에 속하는지에 대한 정보가 저장됩니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cluster_cetners_&lt;/code&gt;에는 각 클러스터의 중심 좌표가 저장되고, 잠재변수와 마찬가지로 64차원이기 때문에 이 좌표가 각각 무엇을 의미지하는지 직관적으로 알기 어렵습니다.&lt;/li&gt;
&lt;li&gt;각 클러스터에 속하는 이미지가 어떤 것인지 출력합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; random
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;))

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;): 
  images&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;train_X[kmeans&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;labels_ &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; i]
  &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;):
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, i&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;c&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(images[c]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;), cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_03/output_19_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;출력 이미지의 각 행은 0번 클러스터, 1번 클러스터, &amp;hellip;, 9번 클러스터를 나타냅니다.&lt;/li&gt;
&lt;li&gt;그런데, 숫자가 다르면서 같은 클러스터로 분류된 이미지들이 문제입니다.&lt;/li&gt;
&lt;li&gt;잠재변수의 차원수를 늘리거나 &lt;code&gt;KMeans()&lt;/code&gt;의 &lt;code&gt;n_init&lt;/code&gt;을 늘려서 좀 더 분류가 잘 되도록 시도해볼 수 있습니다.&lt;/li&gt;
&lt;li&gt;그러나, 여전히 클러스터링 결과를 시각화를 해야 문제가 남고, 이를 시행하려면 2차원 또는 3차원의 잠재변수가 가진 자원을 축소해야 합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;5-t-sne의-개념&#34;&gt;(5) t-SNE의 개념&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;t-SNE는 강력한 시각화 도구로 고차원의 데이터를 저차원(주로 2차원 혹은 3차원)의 시각화를 위한 데이터로 변환합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;K-평균 클러스터링이 클러스터를 계산하기 위한 단위로 중심과 각 데이터의 거리를 계산하는 데 비해, &lt;code&gt;t-SNE&lt;/code&gt;는 각 데이터의 유사도를 정의하고, 원래 공간에서 유사도와 저차원 공간에서의 유사도가 비슷해지도록 학습시킵니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;SNE&lt;/code&gt;는 &lt;code&gt;Stochastic Neighbor Embedding&lt;/code&gt;의 약자로, 여기에서 유사도는 확률적(&lt;code&gt;Stochastic&lt;/code&gt;)으로 표현됩니다. &lt;code&gt;t&lt;/code&gt;는 &lt;code&gt;t-분포를 나타냅니다.&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;t-분포와 정규분포의 모양 차이 그래프&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; scipy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; sp
t_dist &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stats&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;t(&lt;span style=&#34;color:#ae81ff&#34;&gt;2.74&lt;/span&gt;)
normal_dist &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stats&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;norm()

x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linspace(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;)
t_pdf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; t_dist&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pdf(x)
normal_pdf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; normal_dist&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pdf(x)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(x, t_pdf, c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;red&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;t-dist&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(x, normal_pdf, c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;blue&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;normal-dist&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_03/output_22_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;t-분포는 정규분포와 비슷하게 생겼지만 중심이 좀 더 낮고 꼬리가 좀 더 두꺼운 분포이입니다.&lt;/li&gt;
&lt;li&gt;거리를 확률로 표현한다는 것은 데이터 하나를 중심으로 다른 데이터를 거리에 대한 &lt;code&gt;t-분포&lt;/code&gt;의 확률로 치환시키는 것입니다.&lt;/li&gt;
&lt;li&gt;t-SNE 알고리즘의 주요 핵심 내용은 고차원과 저차원에서 확률값을 각각 구한 다음, 저차원의 확률값이 고차원에 가까워지도록 학습시키는 것입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%%&lt;/span&gt;time
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; sklearn.manifold &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; TSNE

tsne &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; TSNE(n_components&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, learning_rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, perplexity&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;, random_state&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
tsne_vector&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tsne&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit_transform(latent_vector[:&lt;span style=&#34;color:#ae81ff&#34;&gt;5000&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;CPU times: user 1min, sys: 499 µs, total: 1min
Wall time: 32.7 s
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;tsne &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; TSNE(n_components&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, learning_rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, perplexity&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;, random_state&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;n_components는 저차원의 수를 의미합니다. 2차원 공간이기 때문에 2를 넣습니다.&lt;/li&gt;
&lt;li&gt;learning_rate는 학습률로 10에서 1000사이의 큰 숫자를 넣습니다.&lt;/li&gt;
&lt;li&gt;perplexity는 알고리즘 계산에서 고려할 최근접 이웃의 숫자이며, 보통 5-50사이의 숫자를 넣습니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;random_state&lt;/code&gt;는 KMeans와 마찬가지로 랜덤 초기화 숫자입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;tsne_vector&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tsne&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit_transform(latent_vector[:&lt;span style=&#34;color:#ae81ff&#34;&gt;5000&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;TSNE는 학습과 변환 과정을 동시에 진행하는 &lt;code&gt;fit_transform()&lt;/code&gt; 결과값을 반환합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;cmap &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_cmap(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rainbow&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;)
fig &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(tsne_vector[:,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], tsne_vector[:,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], marker&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.&amp;#39;&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;train_Y[:&lt;span style=&#34;color:#ae81ff&#34;&gt;5000&lt;/span&gt;], cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;cmap)
cb &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;colorbar(fig, ticks&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;range(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;))
n_clusters &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;
tick_locs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(n_clusters) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;(n_clusters&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;n_clusters
cb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_ticks(tick_locs)
cb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_ticklabels(range(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;))

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_03/output_26_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;위 시각화 내용은 여기에서는 생략합니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;출력 이미지의 클러스터링을 보면 이미지 라벨에 따라 같은 숫자끼리 비교적 잘 뭉쳐있는 것을 확인할 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;6-t-sne-결과-시각화&#34;&gt;(6) t-SNE 결과 시각화&lt;/h3&gt;
&lt;p&gt;우선 코드를 작성하고, 결과물을 확인해봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%%&lt;/span&gt;time

perplexities &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;]
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;))

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;):
    tsne &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; TSNE(n_components&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, learning_rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, perplexity&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;perplexities[c], random_state&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
    tsne_vector &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tsne&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit_transform(latent_vector[:&lt;span style=&#34;color:#ae81ff&#34;&gt;5000&lt;/span&gt;])

    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(tsne_vector[:,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], tsne_vector[:,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], marker&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.&amp;#39;&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;train_Y[:&lt;span style=&#34;color:#ae81ff&#34;&gt;5000&lt;/span&gt;], cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rainbow&amp;#39;&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;perplexity: {0}&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(perplexities[c]))

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_03/output_29_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CPU times: user 7min 18s, sys: 1.17 s, total: 7min 19s
Wall time: 3min 52s
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;perplexity&lt;/code&gt;가 높아질수록 뭉치는 클러스터도 있지만, 뒤섞이는 클러스터도 보이는 것으로 볼 때 최적의 값을 찾기 위해서는 다른 하이퍼파라미터처럼 여러번의 실험이 필요한 것 같습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;7-t-sne-클러스터-위에-mnist-이미지-표시&#34;&gt;(7) t-SNE 클러스터 위에 MNIST 이미지 표시&lt;/h3&gt;
&lt;p&gt;클러스터 분리 결과를 좀 더 직관적으로 확인하기 위해 &lt;code&gt;t-SNE&lt;/code&gt;로 분리된 클러스터 위에 &lt;code&gt;MNIST&lt;/code&gt;이미지를 표시합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; matplotlib.offsetbox &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; TextArea, DrawingArea, OffsetImage, AnnotationBbox

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;))

tsne&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;TSNE(n_components&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, learning_rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, perplexity&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;, random_state&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
tsne_vector&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tsne&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit_transform(latent_vector[:&lt;span style=&#34;color:#ae81ff&#34;&gt;5000&lt;/span&gt;])

ax &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(tsne_vector[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], tsne_vector[:,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], marker&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.&amp;#39;&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;train_Y[:&lt;span style=&#34;color:#ae81ff&#34;&gt;5000&lt;/span&gt;], cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rainbow&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;200&lt;/span&gt;):
  imagebox &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; OffsetImage(train_X[i]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;))
  ab &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; AnnotationBbox(imagebox, (tsne_vector[i, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], tsne_vector[i, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]), frameon&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False, pad&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.0&lt;/span&gt;)
  ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_artist(ab)

ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_xticks([])
ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_yticks([])
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_03/output_32_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;전체적인 분포와 이미지를 같이 확인하기 위해 이미지는 200개만 표시합니다. 출력 이미지에서도 각 숫자는 대부분 자신이 속한 클러스터에 표시되고 있습니다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;t-SNE&lt;/code&gt; 시각화 위해 데이터를 표시하면 오토인코더로 추출된 잠재변수가 데이터를 효율적으로 압축하고 있음을 알 수 있습니다.&lt;/p&gt;
&lt;h2 id=&#34;iii-연습-파일&#34;&gt;III. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch9_3_k-means_clustering.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;vi-reference&#34;&gt;VI. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch9.1-2 - 오토인코더 &amp; MNIST</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch9_1_auto_encoder/</link>
      <pubDate>Sun, 03 May 2020 15:20:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch9_1_auto_encoder/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.2 - 다항분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/&#34;&gt;Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/&#34;&gt;Tensorflow 2.0 Tutorial ch6.1-2 - CNN 이론&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_3_fashion_mnist_with_cnn/&#34;&gt;Tensorflow 2.0 Tutorial ch6.3 - Fashion MNIST with CNN 실습&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_4_improve_performance/&#34;&gt;Tensorflow 2.0 Tutorial ch6.4 - 모형의 성능 높이기&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (1)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (2)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_3_sentimentanalysis/&#34;&gt;Tensorflow 2.0 Tutorial ch7.3 - 긍정, 부정 감성 분석&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (1) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (2) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_1_tensorflow_hub/&#34;&gt;Tensorflow 2.0 Tutorial ch8.1 - 텐서플로 허브&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_2_transfer_learning/&#34;&gt;Tensorflow 2.0 Tutorial ch8.2 - 전이 학습과 &amp;amp; Kaggle 대회&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_3_1_texture_synthesis/&#34;&gt;Tensorflow 2.0 Tutorial ch8.3.1 - 컨볼루션 신경망을 사용한 텍스처 합성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_3_2_neural_style_transfer/&#34;&gt;Tensorflow 2.0 Tutorial ch8.3.2 - 컨볼루션 신경망을 사용한 신경 스타일 전이&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요&#34;&gt;I. 개요&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;오토인코더(&lt;code&gt;AutoEncoder&lt;/code&gt;)는 입력에 대한 출력을 학습해야 한다는 점은 기존 지도학습 네트워크와 동일합니다.&lt;/li&gt;
&lt;li&gt;그러나 그 출력이 입력과 동일하다는 점이 조금 다릅니다.&lt;/li&gt;
&lt;li&gt;오토인코더는 자기 자신을 재생성하는 네트워크입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_01-2/tutorial_01.png&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;위 그림에서 보는 것처럼, 오토인코더는 크게 3가지 부분으로 구성됩니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;z&lt;/code&gt;는 잠재 변수(&lt;code&gt;Latent Vector&lt;/code&gt;)를 중심으로, 입력에 가까운 부분을 인코더(&lt;code&gt;Encoder&lt;/code&gt;), 출력에 가까운 부분을 디코더(&lt;code&gt;Decoder&lt;/code&gt;)라 분류합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;인코더의 역할은 &lt;code&gt;입력&lt;/code&gt;에서 &lt;code&gt;잠재 변수&lt;/code&gt;를 만드는 것입니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;디코더의 역할은 &lt;code&gt;잠재 변수&lt;/code&gt;를 &lt;code&gt;출력&lt;/code&gt;으로 만드는 것입니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;위 그림이 잠재변수를 기준으로 하나의 대칭구조를 이루는 것처럼, 레이어 역시 대칭되는 구조로 쌓아올려서 만듭니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;음. 조금 쉽게 얘기하면, 오토인코더는 일종의 파일 압축과 유사합니다. 압축 파일은 압축하기 전과 압축을 해제한 뒤의 내용이 동일합니다. 컴퓨터공학 용어로 이러한 내용을 비손실 압축이라고 합니다. 내용적으로는 그러합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;그러나, &lt;code&gt;$x$&lt;/code&gt;와 &lt;code&gt;$x^i$&lt;/code&gt;의 차이점처럼 유사하지만 동일하지는 않습니다. 즉, 오토인코더는 손실 압축이라고 표현합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;딥러닝 생성 모델 중 최근 가장 주목받고 있는 적대적 생성 모델(&lt;code&gt;Generative Adversarial Network&lt;/code&gt; 이하 &lt;code&gt;GAN&lt;/code&gt;)의 생성자에서는 랜덤하게 생성된 변수를 잠재변수처럼 활용해서 새로운 이미지를 얻습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ii-mnist-데이터세트에-적용하기&#34;&gt;II. MNIST 데이터세트에 적용하기&lt;/h2&gt;
&lt;p&gt;6장에서 다룬 MNIST 데이터셋을 활용해서 재실습하도록 합니다.&lt;/p&gt;
&lt;h3 id=&#34;1-모듈-설치-및-데이터세트-확인&#34;&gt;(1) 모듈 설치 및 데이터세트 확인&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;데이터는 (&lt;code&gt;train_X&lt;/code&gt;, &lt;code&gt;train_Y&lt;/code&gt;), (&lt;code&gt;test_X&lt;/code&gt;, &lt;code&gt;test_Y&lt;/code&gt;)처럼 훈련 데이터와 테스트 데이터의 튜플 쌍으로 불러 올 수 있습니다.&lt;/li&gt;
&lt;li&gt;데이터를 로드한 후에 &lt;code&gt;train_X&lt;/code&gt;와 &lt;code&gt;test_X&lt;/code&gt;를 255.0으로 나눠서 픽셀 정규화를 하게 됩니다.&lt;/li&gt;
&lt;li&gt;데이터가 잘 불러와졌는지 시각화를 통해 확인합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 텐서플로 2 버전 선택&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
    &lt;span style=&#34;color:#75715e&#34;&gt;# %tensorflow_version only exists in Colab.&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;tensorflow_version &lt;span style=&#34;color:#ae81ff&#34;&gt;2.&lt;/span&gt;x
&lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Exception&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;pass&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow_hub &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; hub
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; cv2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;(train_X, train_Y), (test_X, test_Y) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;datasets&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mnist&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load_data()
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, train_Y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
11493376/11490434 [==============================] - 0s 0us/step
(60000, 28, 28) (60000,)
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_X &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(train_X[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;), cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;colorbar()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_Y[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_01-2/output_7_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;5
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;MNIST&lt;/code&gt;는 &lt;code&gt;Fashion MNIST&lt;/code&gt;처럼 가로와 세로가 각각 28픽셀인 흑백 이미지를 입력으로 하고, 0~9까지의 숫자를 출력으로 합니다. (5장과 6장 참조)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-dense-오토인코더-모델-정의&#34;&gt;(2) Dense 오토인코더 모델 정의&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Dense 오토인코더&lt;/code&gt; 모델을 다음과 같이 정의합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;)
test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, train_Y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;(60000, 784) (60000,)
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;784&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;784&lt;/span&gt;,)),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;784&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sigmoid&amp;#39;&lt;/span&gt;)
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(), loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mse&amp;#39;&lt;/span&gt;)
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential_1&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_3 (Dense)              (None, 784)               615440    
_________________________________________________________________
dense_4 (Dense)              (None, 64)                50240     
_________________________________________________________________
dense_5 (Dense)              (None, 784)               50960     
=================================================================
Total params: 716,640
Trainable params: 716,640
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;입력데이터를 처리하기 위해 &lt;code&gt;Flatten&lt;/code&gt;레이어를 사용하는 대신 &lt;code&gt;train_X&lt;/code&gt;와 &lt;code&gt;test_X&lt;/code&gt;의 차원을 직접 &lt;code&gt;reshape()&lt;/code&gt; 함수로 변환했습니다. 그 이유는 입력과 출력의 형태가 같아야 하기 때문입니다.&lt;/li&gt;
&lt;li&gt;입력을 변환하지 않은 채로 &lt;code&gt;Flatten&lt;/code&gt;레이어를 넣어서 (28, 28) 차원의 입력을 넣으면 뒤에서도 출력의 차원을 (28, 28)로 맞추기 위해 &lt;code&gt;Reshape&lt;/code&gt; 레이어를 사용해야 하는 번거로움이 있습니다. (구조에 대한 이해 필요)&lt;/li&gt;
&lt;li&gt;dense와 dense_2의 레이어는 뉴런의 수가 같아서 대칭을 이루며, 각각 인코더와 디코더의 역할을 합니다.&lt;/li&gt;
&lt;li&gt;desne_1는 잠재변수로 뉴런의 수가 적은 것을 확인할 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3-dense-오토-인코더-모델-학습&#34;&gt;(3) Dense 오토 인코더 모델 학습&lt;/h3&gt;
&lt;p&gt;이제 모형을 학습시킵니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_X, train_X, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/10
235/235 [==============================] - 1s 5ms/step - loss: 0.0507
Epoch 2/10
235/235 [==============================] - 1s 5ms/step - loss: 0.0178
Epoch 3/10
235/235 [==============================] - 1s 5ms/step - loss: 0.0122
Epoch 4/10
235/235 [==============================] - 1s 5ms/step - loss: 0.0101
Epoch 5/10
235/235 [==============================] - 1s 5ms/step - loss: 0.0089
Epoch 6/10
235/235 [==============================] - 1s 5ms/step - loss: 0.0082
Epoch 7/10
235/235 [==============================] - 1s 5ms/step - loss: 0.0077
Epoch 8/10
235/235 [==============================] - 1s 5ms/step - loss: 0.0073
Epoch 9/10
235/235 [==============================] - 1s 5ms/step - loss: 0.0069
Epoch 10/10
235/235 [==============================] - 1s 5ms/step - loss: 0.0067





&amp;lt;tensorflow.python.keras.callbacks.History at 0x7f63a332b0b8&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;4-모형-시각화&#34;&gt;(4) 모형 시각화&lt;/h3&gt;
&lt;p&gt;실제로 모형이 잘 학습되었는지 시각화를 통해 확인합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; random

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;):
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    rand_index &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randint(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(test_X[rand_index]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;), cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)
    
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(test_X[rand_index], axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(img&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;), cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)
    
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(test_X, test_X)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_01-2/output_16_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;313/313 [==============================] - 1s 2ms/step - loss: 0.0063





0.006336142309010029
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;5-cnn-모형-신경망-업데이트&#34;&gt;(5) CNN 모형 신경망 업데이트&lt;/h3&gt;
&lt;p&gt;더 좋은 성과를 내기 위해 CNN을 활용하도록 합니다. 모형 정의를 다시 해봅니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)

model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Flatten(),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Reshape(target_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;)),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2DTranspose(filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2DTranspose(filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sigmoid&amp;#39;&lt;/span&gt;)
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(), loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mse&amp;#39;&lt;/span&gt;)
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential_2&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 14, 14, 32)        160       
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 7, 7, 64)          8256      
_________________________________________________________________
flatten (Flatten)            (None, 3136)              0         
_________________________________________________________________
dense_6 (Dense)              (None, 64)                200768    
_________________________________________________________________
dense_7 (Dense)              (None, 3136)              203840    
_________________________________________________________________
reshape (Reshape)            (None, 7, 7, 64)          0         
_________________________________________________________________
conv2d_transpose (Conv2DTran (None, 14, 14, 32)        8224      
_________________________________________________________________
conv2d_transpose_1 (Conv2DTr (None, 28, 28, 1)         129       
=================================================================
Total params: 421,377
Trainable params: 421,377
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;하나씩 살펴보도록 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;먼저, &lt;code&gt;train_X&lt;/code&gt;와 &lt;code&gt;train_Y&lt;/code&gt;부분에 대한 설명입니다.&lt;/li&gt;
&lt;li&gt;흑백 이미지이기 때문에 마지막 차원의 수는 1입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)),
tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),
&lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Conv2D 레이어를 2개 쌓았습니다.&lt;/li&gt;
&lt;li&gt;그런데, 풀링 레이어가 빠져 있습니다. 대신에 &lt;code&gt;kernel_size=2&lt;/code&gt;, &lt;code&gt;strides=(2,2)&lt;/code&gt;로 설정해서 풀링 레이어를 쓰는 것과 같은 효과를 줍니다.&lt;/li&gt;
&lt;li&gt;Conv2D를 통과할 때마다 50%씩 감소하여 두번째 &lt;code&gt;Conv2D&lt;/code&gt;를 통과하면 이미지의 크지는 &lt;code&gt;7X7&lt;/code&gt;이 됩니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;, 
tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Flatten(),
tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),
&lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;3차원의 데이터를 1차원으로 바꿔주기 위해 &lt;code&gt;Flatten()&lt;/code&gt;을 통과해야 합니다.&lt;/li&gt;
&lt;li&gt;그 다음에는 잠재 변수를 만들기 위해 &lt;code&gt;Dense&lt;/code&gt; 오토인코더와 동일한 크기로 64개의 뉴런을 가지는 &lt;code&gt;Dense&lt;/code&gt;레이어를 배치합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;잠재 변수를 만든 다음에는 디코더를 만듭니다. 디코더는 인코더와 대칭이 되도록 다시 쌓아올립니다. 잠재변수 레이어와 연결된 레이어는 &lt;code&gt;7X7&lt;/code&gt; 이미지를 만들기 위해 64개의 채널만큼 가지고 있는 &lt;code&gt;Conv2D&lt;/code&gt;레이어입니다.&lt;/li&gt;
&lt;li&gt;레이어와 뉴런수를 동일하게 만들기 위해서 &lt;code&gt;Dense&lt;/code&gt;레이어의 뉴런 수를 &lt;code&gt;7*7*64&lt;/code&gt;로 넣습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Reshape(target_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;1차원인 데이터를 3차원으로 바꿔주기 위해 64개의 채널만큼 &lt;code&gt;Reshape&lt;/code&gt;레이어를 사용합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2DTranspose(filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2DTranspose(filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sigmoid&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;마지막으로 이어지는 2개의 레이어는 &lt;code&gt;Conv2DTranspose&lt;/code&gt;입니다.&lt;/li&gt;
&lt;li&gt;Conv2D레이어가 하는 일의 반대되는 계산으로 이해하면 됩니다. (즉, 이 함수를 쓰는 이유는 대칭 구조를 만들기 위함입니다.)&lt;/li&gt;
&lt;li&gt;필터의 개수가 1인 것은 흑백이인 출력 이미지와 같습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;6-cnn-모형-학습&#34;&gt;(6) CNN 모형 학습&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;이제 모형을 학습시킵니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_X, train_X, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/10
235/235 [==============================] - 2s 9ms/step - loss: 0.0757
Epoch 2/10
235/235 [==============================] - 2s 8ms/step - loss: 0.0322
Epoch 3/10
235/235 [==============================] - 2s 8ms/step - loss: 0.0247
Epoch 4/10
235/235 [==============================] - 2s 9ms/step - loss: 0.0222
Epoch 5/10
235/235 [==============================] - 2s 8ms/step - loss: 0.0211
Epoch 6/10
235/235 [==============================] - 2s 8ms/step - loss: 0.0204
Epoch 7/10
235/235 [==============================] - 2s 8ms/step - loss: 0.0200
Epoch 8/10
235/235 [==============================] - 2s 9ms/step - loss: 0.0197
Epoch 9/10
235/235 [==============================] - 2s 8ms/step - loss: 0.0195
Epoch 10/10
235/235 [==============================] - 2s 9ms/step - loss: 0.0193





&amp;lt;tensorflow.python.keras.callbacks.History at 0x7f63a0fa5438&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;7-오토인코더의-이미지-재생성-및-모형-성능-평가&#34;&gt;(7) 오토인코더의 이미지 재생성 및 모형 성능 평가&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;얼마나 잘 재현하는지 확인해봅니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; random

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;):
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    rand_index &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randint(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(test_X[rand_index]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;), cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)
    
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(test_X[rand_index], axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(img&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;), cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)
    
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(test_X, test_X)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_01-2/output_23_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;313/313 [==============================] - 1s 3ms/step - loss: 0.0188





0.01879417710006237
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;보면 알겠지만, 조금 이상합니다. 왜 이상할까요? 이 때 한번 고민해야 하는 것이 &lt;code&gt;활성화함수(=activation)&lt;/code&gt;입니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;마지막 레이어를 제외하면 &lt;code&gt;relu&lt;/code&gt;를 사용했습니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;relu&lt;/code&gt;는 양수는 그대로 반환하고 0이나 음수가 들어오면 0을 반환합니다. 즉, 이말은 뉴런의 계산값 중 음수가 되는 결과가 많을 경우 뉴런의 출력은 무조건 0이 됩니다.&lt;/li&gt;
&lt;li&gt;출력이 0인건 알겠는데, 왜 그게 문제가 될까요? 출력은 다음 레이어의 가중치에 곱해지기 때문에 출력이 0이면 가중치의 효과를 모두 0으로 만들어버립니다. (교재 340페이지 문제점에 대해 이미지로 표현되었으니 꼭 확인 바랍니다.&lt;/li&gt;
&lt;li&gt;이러한 문제점을 해결하고자 &lt;code&gt;elu&lt;/code&gt;라는 개념이 도입되었습니다. (이론은 교재 340페이지를 확인합니다!)
&lt;ul&gt;
&lt;li&gt;간단하게 표현하면 &lt;code&gt;Relu&lt;/code&gt;와 다르게 &lt;code&gt;elu&lt;/code&gt;는 0으로 수렴하지 않고 &lt;code&gt;-1&lt;/code&gt;로 수렴하게 됩니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;8-elu의-적용&#34;&gt;(8) elu의 적용&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;이제 &lt;code&gt;elu&lt;/code&gt;로 바꾼 후 모형을 재학습 시킵니다.&lt;/li&gt;
&lt;li&gt;반복되는 내용이기 때문에 전체 코드로 시각화까지 확인합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)

model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;elu&amp;#39;&lt;/span&gt;, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;elu&amp;#39;&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Flatten(),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;elu&amp;#39;&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;elu&amp;#39;&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Reshape(target_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;)),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2DTranspose(filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;elu&amp;#39;&lt;/span&gt;),
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2DTranspose(filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sigmoid&amp;#39;&lt;/span&gt;)
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(), loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mse&amp;#39;&lt;/span&gt;)
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_X, train_X, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;)

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; random

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;):
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    rand_index &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randint(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(test_X[rand_index]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;), cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)
    
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(test_X[rand_index], axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(img&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;), cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)
    
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(test_X, test_X)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential_4&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_4 (Conv2D)            (None, 14, 14, 32)        160       
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 7, 7, 64)          8256      
_________________________________________________________________
flatten_2 (Flatten)          (None, 3136)              0         
_________________________________________________________________
dense_10 (Dense)             (None, 64)                200768    
_________________________________________________________________
dense_11 (Dense)             (None, 3136)              203840    
_________________________________________________________________
reshape_2 (Reshape)          (None, 7, 7, 64)          0         
_________________________________________________________________
conv2d_transpose_4 (Conv2DTr (None, 14, 14, 32)        8224      
_________________________________________________________________
conv2d_transpose_5 (Conv2DTr (None, 28, 28, 1)         129       
=================================================================
Total params: 421,377
Trainable params: 421,377
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
235/235 [==============================] - 2s 9ms/step - loss: 0.0574
Epoch 2/10
235/235 [==============================] - 2s 9ms/step - loss: 0.0194
Epoch 3/10
235/235 [==============================] - 2s 9ms/step - loss: 0.0123
Epoch 4/10
235/235 [==============================] - 2s 9ms/step - loss: 0.0103
Epoch 5/10
235/235 [==============================] - 2s 9ms/step - loss: 0.0094
Epoch 6/10
235/235 [==============================] - 2s 8ms/step - loss: 0.0089
Epoch 7/10
235/235 [==============================] - 2s 9ms/step - loss: 0.0085
Epoch 8/10
235/235 [==============================] - 2s 9ms/step - loss: 0.0081
Epoch 9/10
235/235 [==============================] - 2s 9ms/step - loss: 0.0077
Epoch 10/10
235/235 [==============================] - 2s 9ms/step - loss: 0.0075
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_01-2/output_26_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;313/313 [==============================] - 1s 3ms/step - loss: 0.0072





0.007230293471366167
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;relu&lt;/code&gt;와 다르게 이전의 각진 모습은 거의 찾아볼 수 없고, &lt;code&gt;loss&lt;/code&gt; 역시 보다 낮게 측정된 것을 확인할 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;iii-연습-파일&#34;&gt;III. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch9_1_auto_encoder.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;vi-reference&#34;&gt;VI. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>