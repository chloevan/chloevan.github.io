<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>컨볼루션 신경망 on Data Science | ChloEvan</title>
    <link>https://chloevan.github.io/tags/%EC%BB%A8%EB%B3%BC%EB%A3%A8%EC%85%98-%EC%8B%A0%EA%B2%BD%EB%A7%9D/</link>
    <description>Recent content in 컨볼루션 신경망 on Data Science | ChloEvan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 21 Apr 2020 21:08:30 +0900</lastBuildDate>
    
        <atom:link href="https://chloevan.github.io/tags/%EC%BB%A8%EB%B3%BC%EB%A3%A8%EC%85%98-%EC%8B%A0%EA%B2%BD%EB%A7%9D/rss.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch6.4 - 모형의 성능 높이기</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch6_4_improve_performance/</link>
      <pubDate>Tue, 21 Apr 2020 21:08:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch6_4_improve_performance/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.2 - 다항분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/&#34;&gt;Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/&#34;&gt;Tensorflow 2.0 Tutorial ch6.1-2 - CNN 이론&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_3_fashion_mnist_with_cnn/&#34;&gt;Tensorflow 2.0 Tutorial ch6.3 - Fashion MNIST with CNN 실습&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요&#34;&gt;I. 개요&lt;/h2&gt;
&lt;p&gt;성능을 높이는 데는 그 중 대표적이면서 쉬운 두 가지 방법은 &lt;code&gt;더 많은 레이어 쌓기&lt;/code&gt;와 &lt;code&gt;이미지 보강(Image Augmentation)&lt;/code&gt; 기법입니다.&lt;/p&gt;
&lt;h2 id=&#34;ii-더-많은-레이어-쌓기&#34;&gt;II. 더 많은 레이어 쌓기&lt;/h2&gt;
&lt;p&gt;딥러닝의 역사는 더 깊은 신경망을 쌓기 위한 노력이라고 해도 과언이 아닙니다. 컨볼루션 레이어가 중첩된 더 깊은 구조가 계속해서 나타났고, 그럴 때마다 이전 구조의 성능을 개선 시켰습니다. (Teerapittayanon, et. all., 2017)&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_06_04/Figure_01_deeper_neural_networks.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;이번 예제에서는 &lt;code&gt;VGGNet&lt;/code&gt;의 스타일로 구성한 컨볼루션 신경망을 응용 및 사용합니다.&lt;/p&gt;
&lt;h2 id=&#34;iii-vggnet-모형-정의&#34;&gt;III. VGGNet 모형 정의&lt;/h2&gt;
&lt;p&gt;데이터를 불러온 뒤, 정규화를 진행합니다. 그리고 곧바로 모형을 만들도록 합니다.&lt;/p&gt;
&lt;h3 id=&#34;1-데이터-불러오기-및-정규화&#34;&gt;(1) 데이터 불러오기 및 정규화&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
fashion_mnist &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;datasets&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fashion_mnist
(train_X, train_Y), (test_X, test_Y) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; fashion_mnist&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load_data()

train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_X &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# reshape 이전&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)

train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# reshape 이후&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz
32768/29515 [=================================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz
26427392/26421880 [==============================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz
8192/5148 [===============================================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz
4423680/4422102 [==============================] - 0s 0us/step
(60000, 28, 28) (10000, 28, 28)
(60000, 28, 28, 1) (10000, 28, 28, 1)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;2-모형-정의&#34;&gt;(2) 모형 정의&lt;/h3&gt;
&lt;p&gt;이번에는 모형 정의를 진행합니다. 코드가 길어질 수 있으니 주의하기 바랍니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf

model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;MaxPool2D(pool_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout(rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),    
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;valid&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),  
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;MaxPool2D(pool_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)),
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout(rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;),
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Flatten(), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;512&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout(rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;),
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout(rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;),
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;)                           
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(), 
              loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sparse_categorical_crossentropy&amp;#39;&lt;/span&gt;, 
              metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential_1&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_4 (Conv2D)            (None, 28, 28, 32)        320       
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 28, 28, 64)        18496     
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 14, 14, 64)        0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 14, 14, 128)       73856     
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 12, 12, 256)       295168    
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 6, 6, 256)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 9216)              0         
_________________________________________________________________
dense_3 (Dense)              (None, 512)               4719104   
_________________________________________________________________
dropout_6 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 256)               131328    
_________________________________________________________________
dropout_7 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_5 (Dense)              (None, 10)                2570      
=================================================================
Total params: 5,240,842
Trainable params: 5,240,842
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;VGGNet&lt;/code&gt;은 여러 개의 구조로 실험했는데 그 중 19개의 레이어가 겹쳐진 &lt;code&gt;VGG-19&lt;/code&gt;가 제일 깊은 구조입니다. &lt;code&gt;VGG-19&lt;/code&gt;는 특징 추출기의 초반에 컨볼루션 레이어를 2개 겹친 뒤 풀링 레이어 1개를 사용하는 패턴을 2차례, 그 후 컨볼루션 레이어를 4개 겹친 뒤 풀링 레이어 1개를 사용하는 패턴을 3차례 반복합니다.&lt;/p&gt;
&lt;p&gt;그러나, 이 역시 대상 이미지의 크기 등에 따라 달라집니다.&lt;/p&gt;
&lt;p&gt;여기에서는 컨볼루션 레이어를 2개 겹치고 풀링 레이어를 1개 사용하는 패턴을 2차례 반복합니다. 풀링 레이어 다음에 드롭아웃 레이러를 위치시켜서 과적합을 방지합니다. 또한, Flatten 레이어 다음에 이어지는 3개의 Dense 레이어 사이에도 드롭아웃 레이어를 배치합니다. 컨볼루션 레이어와 Dense 레이어의 개수만 세면 &lt;code&gt;VGG-7&lt;/code&gt;레이어가 됩니다.&lt;/p&gt;
&lt;p&gt;오리지널 &lt;code&gt;VGG-19&lt;/code&gt;보다는 깊이가 얕지만 총 파라미터 개수는 약 &lt;code&gt;520만개&lt;/code&gt;로 적지 않습니다. (ch6_3. 24만개)&lt;/p&gt;
&lt;h3 id=&#34;3-모형-성능-확인&#34;&gt;(3) 모형 성능 확인&lt;/h3&gt;
&lt;p&gt;이 모델의 성능을 확인해봅니다. (이 때, 런타임 유형을 GPU로 변경 하는 것을 잊으면 안됩니다.)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_X, train_Y, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.5858 - accuracy: 0.7878 - val_loss: 0.3329 - val_accuracy: 0.8759
Epoch 2/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.3676 - accuracy: 0.8678 - val_loss: 0.2709 - val_accuracy: 0.9017
Epoch 3/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.3306 - accuracy: 0.8815 - val_loss: 0.2607 - val_accuracy: 0.8999
Epoch 4/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.3043 - accuracy: 0.8901 - val_loss: 0.2482 - val_accuracy: 0.9171
Epoch 5/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2878 - accuracy: 0.8965 - val_loss: 0.2296 - val_accuracy: 0.9163
Epoch 6/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2759 - accuracy: 0.9005 - val_loss: 0.2454 - val_accuracy: 0.9056
Epoch 7/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2649 - accuracy: 0.9049 - val_loss: 0.2153 - val_accuracy: 0.9227
Epoch 8/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2626 - accuracy: 0.9041 - val_loss: 0.2187 - val_accuracy: 0.9204
Epoch 9/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2546 - accuracy: 0.9093 - val_loss: 0.2130 - val_accuracy: 0.9227
Epoch 10/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2534 - accuracy: 0.9085 - val_loss: 0.2186 - val_accuracy: 0.9227
Epoch 11/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2517 - accuracy: 0.9110 - val_loss: 0.2101 - val_accuracy: 0.9272
Epoch 12/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2427 - accuracy: 0.9122 - val_loss: 0.2111 - val_accuracy: 0.9221
Epoch 13/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2397 - accuracy: 0.9150 - val_loss: 0.2025 - val_accuracy: 0.9294
Epoch 14/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2396 - accuracy: 0.9150 - val_loss: 0.2115 - val_accuracy: 0.9220
Epoch 15/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2338 - accuracy: 0.9166 - val_loss: 0.2102 - val_accuracy: 0.9247
Epoch 16/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2347 - accuracy: 0.9157 - val_loss: 0.2063 - val_accuracy: 0.9285
Epoch 17/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2352 - accuracy: 0.9172 - val_loss: 0.2064 - val_accuracy: 0.9237
Epoch 18/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2290 - accuracy: 0.9180 - val_loss: 0.2118 - val_accuracy: 0.9237
Epoch 19/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2331 - accuracy: 0.9171 - val_loss: 0.2027 - val_accuracy: 0.9286
Epoch 20/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2254 - accuracy: 0.9200 - val_loss: 0.2003 - val_accuracy: 0.9299
Epoch 21/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2312 - accuracy: 0.9199 - val_loss: 0.2064 - val_accuracy: 0.9250
Epoch 22/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2277 - accuracy: 0.9194 - val_loss: 0.1962 - val_accuracy: 0.9290
Epoch 23/25
1407/1407 [==============================] - 8s 6ms/step - loss: 0.2278 - accuracy: 0.9188 - val_loss: 0.1952 - val_accuracy: 0.9341
Epoch 24/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2258 - accuracy: 0.9208 - val_loss: 0.1999 - val_accuracy: 0.9290
Epoch 25/25
1407/1407 [==============================] - 9s 6ms/step - loss: 0.2196 - accuracy: 0.9217 - val_loss: 0.2072 - val_accuracy: 0.9261
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;학습한 모형을 시각화로 다시 확인합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylim(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(test_X, test_Y, verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_06_04/output_8_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[0.23273345828056335, 0.9169999957084656]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;var_loss&lt;/code&gt;가 잘 증가하지 않는 드디어 괜찮은 모형을 얻었습니다. 또한 테스트 데이터에 대한 분류 성적도 &lt;code&gt;91.69%&lt;/code&gt;로 비교적 높은 성과를 거뒀습니다. 이렇게 네트워크 구조 변경만으로도 성능이 향상 된 것을 확인할 수 있습니다.&lt;/p&gt;
&lt;h2 id=&#34;iv-이미지-보강&#34;&gt;IV. 이미지 보강&lt;/h2&gt;
&lt;p&gt;이미지 보강은 훈련데이터에 없는 이미지를 새롭게 만들어내서 훈련데이터를 보강하는 기법을 말합니다. &lt;code&gt;Tensorflow&lt;/code&gt;에는 이미지 보강 작업을 쉽게 해주는 &lt;code&gt;ImageDataGenerator&lt;/code&gt;가 있습니다. 이를 활용해서 훈련 데이터의 첫 번째 이미지를 변형시킵니다.&lt;/p&gt;
&lt;p&gt;그리고 100개의 변형된 이미지를 그래프로 작성합니다.&lt;/p&gt;
&lt;h3 id=&#34;1-이미지-보강의-예&#34;&gt;(1) 이미지 보강의 예&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras.preprocessing.image &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; ImageDataGenerator
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np

image_generator &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ImageDataGenerator(
    rotation_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, 
    zoom_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.10&lt;/span&gt;, 
    shear_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;, 
    width_shift_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.10&lt;/span&gt;, 
    height_shift_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.10&lt;/span&gt;, 
    horizontal_flip&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True,
    vertical_flip&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)

augment_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;

x_augmented &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; image_generator&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flow(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tile(train_X[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;), &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), 
                                   np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros(augment_size), batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;augment_size, shuffle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next()[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]

&lt;span style=&#34;color:#75715e&#34;&gt;# 새롭게 생성된 이미지 표시&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;):
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(x_augmented[c]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;), cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_10_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ImageDataGenerator&lt;/code&gt;의 주요 인수들에 구체적인 설명은 &lt;code&gt;교재 169페이지&lt;/code&gt;를 참고하시기를 바랍니다. 또는 한글 번역문서가 있으니 해당 문서에서 추가적인 공부를 진행하기를 바랍니다. &lt;a href=&#34;https://keras.io/ko/preprocessing/image/&#34;&gt;(ImageDataGenerator 클래스)&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;2-3만개-이미지-보강&#34;&gt;(2) 3만개 이미지 보강&lt;/h2&gt;
&lt;p&gt;그러면 실제로 이미지를 보강하고 모형 학습에 추가하는 예제를 진행합니다. 전체적인 모형 학습 코드는 크게 달라지지 않으니, 기 진행했던 내용을 그대로 참조합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
fashion_mnist &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;datasets&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fashion_mnist
(train_X, train_Y), (test_X, test_Y) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; fashion_mnist&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load_data()

train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_X &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# reshape 이전&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)

train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# reshape 이후&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)

image_generator &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ImageDataGenerator(
    rotation_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, 
    zoom_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.10&lt;/span&gt;, 
    shear_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;, 
    width_shift_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.10&lt;/span&gt;, 
    height_shift_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.10&lt;/span&gt;, 
    horizontal_flip&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True,
    vertical_flip&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)

augment_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;30000&lt;/span&gt;

randidx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randint(train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;augment_size)
x_augmented &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X[randidx]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;copy()
y_augmented &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_Y[randidx]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;copy()
x_augmented &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; image_generator&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flow(x_augmented, np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros(augment_size), batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;augment_size, shuffle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next()[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]

&lt;span style=&#34;color:#75715e&#34;&gt;# 원래 데이터인 x_train에 이미지 보강된 x_augmented를 추가합니다. &lt;/span&gt;
train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;concatenate((train_X, x_augmented))
train_Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;concatenate((train_Y, y_augmented))

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;(60000, 28, 28) (10000, 28, 28)
(60000, 28, 28, 1) (10000, 28, 28, 1)
(90000, 28, 28, 1)
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;훈련 데이터의 50%인 30,000개의 이미지를 추가하기 위해 &lt;code&gt;augment_size=30000&lt;/code&gt;으로 설정합니다.&lt;/li&gt;
&lt;li&gt;이미지를 변형할 원본 이미지를 찾기 위해 &lt;code&gt;np.random.randint()&lt;/code&gt;함수를 활용하여 0~59,999 범위의 정수 중에서 30,000개의 정수를 뽑았습니다. 이 때 정수는 중복 가능합니다.
&lt;ul&gt;
&lt;li&gt;만약, 중복을 원치 않으면, &lt;code&gt;np.random.ranint()&lt;/code&gt; 대신에 &lt;code&gt;np.random.choice()&lt;/code&gt; 함수를 사용하고 &lt;code&gt;replace&lt;/code&gt; 인수를 &lt;code&gt;False&lt;/code&gt;로 설정합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;copy()&lt;/code&gt; 함수를 사용하여 원본은 보전합니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;image_generator.flow()&lt;/code&gt; 함수를 사용하여 30,000개의 새로운 이미지를 생성했습니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;np.concatenate()&lt;/code&gt; 함수를 사용하여 훈련 데이터에 보강 이미지를 추가합니다. 그러면, 이미지 보강이 완료가 된 것입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3-모형-정의&#34;&gt;(3) 모형 정의&lt;/h3&gt;
&lt;p&gt;이제 보강된 훈련데이터를 &lt;code&gt;VGGNet&lt;/code&gt; 스타일의 네트워크에 추가하도록 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf

model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;MaxPool2D(pool_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout(rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),    
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;valid&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),  
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;MaxPool2D(pool_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)),
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout(rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;),
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Flatten(), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;512&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout(rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;),
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;),
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout(rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;),
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;)                           
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(), 
              loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sparse_categorical_crossentropy&amp;#39;&lt;/span&gt;, 
              metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])

&lt;span style=&#34;color:#75715e&#34;&gt;# model.summary()&lt;/span&gt;
history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_X, train_Y, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;)

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylim(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(test_X, test_Y, verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.5830 - accuracy: 0.7865 - val_loss: 0.5803 - val_accuracy: 0.7819
Epoch 2/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.3876 - accuracy: 0.8607 - val_loss: 0.5290 - val_accuracy: 0.8055
Epoch 3/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.3417 - accuracy: 0.8757 - val_loss: 0.4409 - val_accuracy: 0.8329
Epoch 4/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.3224 - accuracy: 0.8836 - val_loss: 0.4393 - val_accuracy: 0.8370
Epoch 5/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.3097 - accuracy: 0.8900 - val_loss: 0.4315 - val_accuracy: 0.8379
Epoch 6/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2997 - accuracy: 0.8927 - val_loss: 0.4283 - val_accuracy: 0.8452
Epoch 7/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2944 - accuracy: 0.8938 - val_loss: 0.4000 - val_accuracy: 0.8514
Epoch 8/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2907 - accuracy: 0.8967 - val_loss: 0.4203 - val_accuracy: 0.8428
Epoch 9/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2797 - accuracy: 0.9010 - val_loss: 0.3741 - val_accuracy: 0.8618
Epoch 10/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2835 - accuracy: 0.8986 - val_loss: 0.4227 - val_accuracy: 0.8424
Epoch 11/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2748 - accuracy: 0.9006 - val_loss: 0.3786 - val_accuracy: 0.8586
Epoch 12/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2764 - accuracy: 0.9018 - val_loss: 0.3736 - val_accuracy: 0.8668
Epoch 13/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2726 - accuracy: 0.9027 - val_loss: 0.3757 - val_accuracy: 0.8656
Epoch 14/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2737 - accuracy: 0.9023 - val_loss: 0.3790 - val_accuracy: 0.8589
Epoch 15/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2717 - accuracy: 0.9037 - val_loss: 0.3779 - val_accuracy: 0.8610
Epoch 16/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2689 - accuracy: 0.9049 - val_loss: 0.3768 - val_accuracy: 0.8643
Epoch 17/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2636 - accuracy: 0.9051 - val_loss: 0.3831 - val_accuracy: 0.8601
Epoch 18/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2686 - accuracy: 0.9045 - val_loss: 0.4098 - val_accuracy: 0.8484
Epoch 19/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2646 - accuracy: 0.9059 - val_loss: 0.3696 - val_accuracy: 0.8647
Epoch 20/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2630 - accuracy: 0.9078 - val_loss: 0.3510 - val_accuracy: 0.8728
Epoch 21/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2599 - accuracy: 0.9087 - val_loss: 0.3880 - val_accuracy: 0.8584
Epoch 22/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2626 - accuracy: 0.9072 - val_loss: 0.3749 - val_accuracy: 0.8673
Epoch 23/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2604 - accuracy: 0.9078 - val_loss: 0.3811 - val_accuracy: 0.8642
Epoch 24/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2619 - accuracy: 0.9088 - val_loss: 0.3790 - val_accuracy: 0.8585
Epoch 25/25
2110/2110 [==============================] - 13s 6ms/step - loss: 0.2629 - accuracy: 0.9075 - val_loss: 0.3693 - val_accuracy: 0.8688
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_06_04/output_14_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[0.2110530138015747, 0.9251000285148621]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;소스코드는 기존에 했던 코드와 차이가 없기 때문에, 코드에 대한 설명은 생략합니다. 그래프 역시, 안정적인 것으로 봐서는 과적합은 일어나지 않았습니다. 그리고, 결과 역시 기존 분류 성적 &lt;code&gt;91.69%&lt;/code&gt;보다는 성능이 향상된 &lt;code&gt;92.51%&lt;/code&gt;값을 얻었습니다.&lt;/p&gt;
&lt;p&gt;이렇게 해서 더 많은 레이어를 쌓는 것과 이미지 보강 기법을 통해서 모형을 성능시키는 것까지 배웠습니다.&lt;/p&gt;
&lt;h2 id=&#34;v-결론&#34;&gt;V. 결론&lt;/h2&gt;
&lt;p&gt;이번장에서는 가장 중요한 개념은 컨볼루션 레이어의 개념, 풀링 레이어의 개념, 그리고 드롭아웃 레이어의 개념입니다. 각각의 역할은 조금씩 상이하다는 것을 꼭 기억하기를 바랍니다.&lt;/p&gt;
&lt;h2 id=&#34;vi-연습-파일&#34;&gt;VI. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch6_4_improve_performance.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;vii-reference&#34;&gt;VII. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Teerapittayanon, S., McDanel, B., &amp;amp; Kung, H.T. (2017). Distributed Deep Neural Networks Over the Cloud, the Edge and End Devices. 2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS), 328-339. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch6.3 - Fashion MNIST with CNN 실습</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch6_3_fashion_mnist_with_cnn/</link>
      <pubDate>Tue, 21 Apr 2020 16:08:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch6_3_fashion_mnist_with_cnn/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.2 - 다항분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/&#34;&gt;Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/&#34;&gt;Tensorflow 2.0 Tutorial ch6.1-2 - CNN 이론&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요&#34;&gt;I. 개요&lt;/h2&gt;
&lt;p&gt;이번 장은 앞에서 이론만 설명했기 때문에 이번에는 실습 위주로 진행합니다. 컨볼루션 레이어와 풀링 레이어, 드롭아웃을 사용해서 분류 문제를 푸는데 어떻게 해야 성능이 개선 되는지 알아봅니다.&lt;/p&gt;
&lt;h2 id=&#34;ii-데이터-불러오기-및-정규화&#34;&gt;II. 데이터 불러오기 및 정규화&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/&#34;&gt;5장&lt;/a&gt;에서 배운 내용을 근거로 데이터를 불러오고 정규화를 진행합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
fashion_mnist &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;datasets&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fashion_mnist
(train_X, train_Y), (test_X, test_Y) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; fashion_mnist&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load_data()

train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_X &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz
32768/29515 [=================================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz
26427392/26421880 [==============================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz
8192/5148 [===============================================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz
4423680/4422102 [==============================] - 0s 0us/step
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;그런데, 6장에서는 &lt;code&gt;Conv2D&lt;/code&gt;레이어로 컨볼루션 연산을 수행해야 합니다. 이미지는 보통 채널을 가지고 있고(컬러 이미지는 &lt;code&gt;RGB&lt;/code&gt;의 3채널, 흑백 이미지는 1채널), &lt;code&gt;Conv2D&lt;/code&gt;레이어는 채널을 가진 형태의 데이터를 받도록 기본적으로 설정되어 있기 때문에 예제 6.5에서는 채널을 갖도록 데이터의 &lt;code&gt;Shape&lt;/code&gt;를 바꿔줍니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# reshape 이전&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)

train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# reshape 이후&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, test_X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;(60000, 28, 28) (10000, 28, 28)
(60000, 28, 28, 1) (10000, 28, 28, 1)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;Fashion MNIST&lt;/code&gt;데이터를 구성하는 흑백 이미지는 1개의 채널을 갖기 때문에 &lt;code&gt;reshape()&lt;/code&gt; 함수를 사용해 데이터의 가장 뒤쪽에 채널 차원을 추가합니다. 이 작업으로 데이터 수는 달라지지는 않습니다.&lt;/p&gt;
&lt;p&gt;데이터를 확인하는 시각화를 진행합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt

&lt;span style=&#34;color:#75715e&#34;&gt;# 전체 그래프의 크기를 width = 10, height = 10으로 지정합니다. &lt;/span&gt;
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;): 
  &lt;span style=&#34;color:#75715e&#34;&gt;# 4행 4열로 지정한 그리드에서 c+1번째의 칸에 그래프를 그립니다. 1~16번째 칸을 채우게 됩니다. &lt;/span&gt;
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(train_X[c]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;), cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

&lt;span style=&#34;color:#75715e&#34;&gt;# 훈련 데이터이 1~16번째 까지의 라벨 프린트합니다. &lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_Y[:&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_06_03/output_6_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[9 0 0 3 0 2 7 2 5 5 0 9 5 5 7 9]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;라벨의 정의는 아래와 같습니다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;라벨&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;범주&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;티셔츠/상의&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;바지&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;스웨터&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;드레스&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;코트&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;샌들&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;셔츠&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;운동화&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;가방&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;부츠&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;라벨의 정의와 비교해보면, 라벨이 잘 분류되어 있는 것을 확인할 수 있습니다. 이제 모델을 생성합니다.&lt;/p&gt;
&lt;h2 id=&#34;iii-딥러닝-모델-생성&#34;&gt;III. 딥러닝 모델 생성&lt;/h2&gt;
&lt;h3 id=&#34;1-컨볼루션-신경망-모델-정의&#34;&gt;(1) 컨볼루션 신경망 모델 정의&lt;/h3&gt;
&lt;p&gt;컨볼루션 신경망 모델 정의는 풀링 레이어 또는 드롭아웃 없이 정의된 모델을 말합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;),
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Flatten(), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;)                             
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(), 
              loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sparse_categorical_crossentropy&amp;#39;&lt;/span&gt;, 
              metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 26, 26, 16)        160       
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 24, 24, 32)        4640      
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 22, 22, 64)        18496     
_________________________________________________________________
flatten (Flatten)            (None, 30976)             0         
_________________________________________________________________
dense (Dense)                (None, 128)               3965056   
_________________________________________________________________
dense_1 (Dense)              (None, 10)                1290      
=================================================================
Total params: 3,989,642
Trainable params: 3,989,642
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;Conv2D&lt;/code&gt;의 인수에 대해 정리하도록 합니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;kernel_size&lt;/code&gt;: 필터 행렬의 크기를 말하며, 수용 영역(receptive filed)이라고 불리워집니다. 앞의 숫자는 높이, 뒤의 숫자는 너비이고, 숫자를 하나만 쓸 경우 높이와 너비를 동일한 값으로 사용한다는 뜻입니다.&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;filters&lt;/code&gt;: 필터의 개수를 의미하며, 네트워크가 깊어질수록 2배씩 늘려나갑니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;!&lt;/span&gt;nvidia&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;smi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Tue Apr 21 06:56:00 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |
| N/A   31C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;위 명령어는 현재 구글 코랩에서 지원하는 GPU의 성능입니다. &lt;code&gt;Tesla K80&lt;/code&gt;을 사용하고 있습니다.&lt;/p&gt;
&lt;p&gt;구글 코랩에서는 무료로 GPU를 사용할 수 있도록 도와줍니다. 하드웨어 가속기를 사용하려면 [메뉴]-[런타임]-[런타임 유형 변경]-[하드웨어 가속기]-[GPU]로 지정하면 됩니다.&lt;/p&gt;
&lt;h2 id=&#34;2-컨볼루션-신경망-모델-학습&#34;&gt;(2) 컨볼루션 신경망 모델 학습&lt;/h2&gt;
&lt;p&gt;신경망 모형을 학습하는데, 시간이 조금 소요되니 참고바란다. (약 10분)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_X, train_Y, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.4740 - accuracy: 0.8287 - val_loss: 0.3986 - val_accuracy: 0.8565
Epoch 2/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.3461 - accuracy: 0.8746 - val_loss: 0.3651 - val_accuracy: 0.8668
Epoch 3/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.2911 - accuracy: 0.8937 - val_loss: 0.3697 - val_accuracy: 0.8661
Epoch 4/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.2546 - accuracy: 0.9053 - val_loss: 0.3870 - val_accuracy: 0.8669
Epoch 5/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.2226 - accuracy: 0.9174 - val_loss: 0.4187 - val_accuracy: 0.8670
Epoch 6/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.1904 - accuracy: 0.9283 - val_loss: 0.4704 - val_accuracy: 0.8665
Epoch 7/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.1736 - accuracy: 0.9356 - val_loss: 0.4938 - val_accuracy: 0.8703
Epoch 8/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.1495 - accuracy: 0.9454 - val_loss: 0.5293 - val_accuracy: 0.8694
Epoch 9/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.1424 - accuracy: 0.9478 - val_loss: 0.5503 - val_accuracy: 0.8654
Epoch 10/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.1280 - accuracy: 0.9535 - val_loss: 0.6191 - val_accuracy: 0.8575
Epoch 11/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.1203 - accuracy: 0.9556 - val_loss: 0.7030 - val_accuracy: 0.8626
Epoch 12/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.1131 - accuracy: 0.9596 - val_loss: 0.7228 - val_accuracy: 0.8656
Epoch 13/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.1024 - accuracy: 0.9621 - val_loss: 0.8023 - val_accuracy: 0.8632
Epoch 14/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.1020 - accuracy: 0.9636 - val_loss: 0.7895 - val_accuracy: 0.8690
Epoch 15/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.0900 - accuracy: 0.9688 - val_loss: 1.0383 - val_accuracy: 0.8581
Epoch 16/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.0933 - accuracy: 0.9669 - val_loss: 0.8304 - val_accuracy: 0.8649
Epoch 17/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.0816 - accuracy: 0.9712 - val_loss: 1.0017 - val_accuracy: 0.8661
Epoch 18/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.0782 - accuracy: 0.9715 - val_loss: 0.9552 - val_accuracy: 0.8653
Epoch 19/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.0745 - accuracy: 0.9748 - val_loss: 1.0168 - val_accuracy: 0.8631
Epoch 20/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.0787 - accuracy: 0.9724 - val_loss: 1.0362 - val_accuracy: 0.8627
Epoch 21/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.0675 - accuracy: 0.9759 - val_loss: 1.1104 - val_accuracy: 0.8577
Epoch 22/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.0725 - accuracy: 0.9764 - val_loss: 1.2423 - val_accuracy: 0.8603
Epoch 23/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.0644 - accuracy: 0.9783 - val_loss: 1.2578 - val_accuracy: 0.8589
Epoch 24/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.0650 - accuracy: 0.9790 - val_loss: 1.3452 - val_accuracy: 0.8589
Epoch 25/25
1407/1407 [==============================] - 13s 9ms/step - loss: 0.0655 - accuracy: 0.9791 - val_loss: 1.2309 - val_accuracy: 0.8605
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;이렇게 생성된 모형은 시각화로 다시 확인한다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylim(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(test_X, test_Y, verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_06_03/output_14_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[1.3350350856781006, 0.855400025844574]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;왼쪽 그래프를 확인하면, &lt;code&gt;loss&lt;/code&gt;는 감소하고, 대신 &lt;code&gt;var_loss&lt;/code&gt;는 증가하는 전형적인 과적합의 형태를 나타냅니다. 이럴경우 모형에도 악영향이 있어서, 오히려 단순 딥러닝 모형의 성과가 더 좋은 것을 확인할 수 있습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;테스트 데이터의 85.21% Vs. 5.3장의 Dense Layer 88.5%&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;즉, 컨볼루션 레이어만 사용할 경우, 오히려 성능이 더 좋지 않은 것을 확인할 수 있었습니다. 이제 성능을 개선해봅니다.&lt;/p&gt;
&lt;h3 id=&#34;3-풀링-레이어-드롭아웃-레이어-추가-약-10분&#34;&gt;(3) 풀링 레이어, 드롭아웃 레이어 추가 (약 10분)&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;MaxPool2D(strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;MaxPool2D(strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Flatten(), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;), 
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout(rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;),
  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(units&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;)                             
])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(), 
              loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sparse_categorical_crossentropy&amp;#39;&lt;/span&gt;, 
              metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential_3&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_9 (Conv2D)            (None, 26, 26, 32)        320       
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 13, 13, 32)        0         
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 11, 11, 64)        18496     
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 5, 5, 64)          0         
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 3, 3, 128)         73856     
_________________________________________________________________
flatten_3 (Flatten)          (None, 1152)              0         
_________________________________________________________________
dense_6 (Dense)              (None, 128)               147584    
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_7 (Dense)              (None, 10)                1290      
=================================================================
Total params: 241,546
Trainable params: 241,546
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;이번에 추가된 인수는 &lt;code&gt;MaxPool2D(strides=(2,2)&lt;/code&gt;)와 &lt;code&gt;Dropout(rate=0.3)&lt;/code&gt;입니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;strides: 필터가 계산 과정에서 한 스텝마다 이동하는 크기입니다. 기본값은 (1,1)이고, (2,2) 등으로 설정할 경우 한 칸씩 건너뛰면서 계산하게 되니다. strides=1일 때와 2일 때의 결과 이미지의 크기에 영향을 줍니다.&lt;/li&gt;
&lt;li&gt;rate: 제외할 뉴런의 비율을 나타냅니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;여기서 확인해야 하는 개수 &lt;code&gt;Param&lt;/code&gt;의 개수입니다.&lt;/p&gt;
&lt;p&gt;기존 &lt;code&gt;3,989,642&lt;/code&gt;에서 &lt;code&gt;241,546&lt;/code&gt;으로 대폭 줄어든 것을 확인할 수 있습니다. 이는 &lt;code&gt;Flatten&lt;/code&gt;에 들어오는 &lt;code&gt;Params&lt;/code&gt;의 개수가 기존 &lt;code&gt;(None, 30976)&lt;/code&gt;에 비해 &lt;code&gt;(None, 1152)&lt;/code&gt;에 비해 크게 줄어들었기 때문입니다.&lt;/p&gt;
&lt;p&gt;다시한번, 풀링 레이어와 드롭아웃 레어는 모두 과적합을 줄이는 데 기여합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_X, train_Y, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.5203 - accuracy: 0.8106 - val_loss: 0.3570 - val_accuracy: 0.8688
Epoch 2/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.3569 - accuracy: 0.8722 - val_loss: 0.3304 - val_accuracy: 0.8747
Epoch 3/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.3195 - accuracy: 0.8839 - val_loss: 0.3127 - val_accuracy: 0.8853
Epoch 4/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.2880 - accuracy: 0.8950 - val_loss: 0.2926 - val_accuracy: 0.8943
Epoch 5/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.2712 - accuracy: 0.9011 - val_loss: 0.3001 - val_accuracy: 0.8897
Epoch 6/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.2548 - accuracy: 0.9080 - val_loss: 0.2878 - val_accuracy: 0.8975
Epoch 7/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.2383 - accuracy: 0.9123 - val_loss: 0.3031 - val_accuracy: 0.8920
Epoch 8/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.2232 - accuracy: 0.9164 - val_loss: 0.2987 - val_accuracy: 0.9005
Epoch 9/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.2132 - accuracy: 0.9200 - val_loss: 0.2983 - val_accuracy: 0.8980
Epoch 10/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.2086 - accuracy: 0.9219 - val_loss: 0.3241 - val_accuracy: 0.8949
Epoch 11/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1937 - accuracy: 0.9284 - val_loss: 0.3066 - val_accuracy: 0.9017
Epoch 12/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1828 - accuracy: 0.9320 - val_loss: 0.3199 - val_accuracy: 0.9020
Epoch 13/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1862 - accuracy: 0.9305 - val_loss: 0.3195 - val_accuracy: 0.9034
Epoch 14/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1720 - accuracy: 0.9360 - val_loss: 0.3504 - val_accuracy: 0.8995
Epoch 15/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1661 - accuracy: 0.9372 - val_loss: 0.3565 - val_accuracy: 0.8953
Epoch 16/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1626 - accuracy: 0.9396 - val_loss: 0.3508 - val_accuracy: 0.9031
Epoch 17/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1567 - accuracy: 0.9406 - val_loss: 0.4112 - val_accuracy: 0.8989
Epoch 18/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1558 - accuracy: 0.9410 - val_loss: 0.3937 - val_accuracy: 0.8933
Epoch 19/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1506 - accuracy: 0.9434 - val_loss: 0.3724 - val_accuracy: 0.9003
Epoch 20/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1444 - accuracy: 0.9461 - val_loss: 0.4128 - val_accuracy: 0.9000
Epoch 21/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1397 - accuracy: 0.9482 - val_loss: 0.4300 - val_accuracy: 0.8975
Epoch 22/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1373 - accuracy: 0.9492 - val_loss: 0.4505 - val_accuracy: 0.9008
Epoch 23/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1377 - accuracy: 0.9497 - val_loss: 0.5026 - val_accuracy: 0.8955
Epoch 24/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1383 - accuracy: 0.9498 - val_loss: 0.5038 - val_accuracy: 0.8881
Epoch 25/25
1407/1407 [==============================] - 10s 7ms/step - loss: 0.1293 - accuracy: 0.9516 - val_loss: 0.5226 - val_accuracy: 0.8945
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_accuracy&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylim(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(test_X, test_Y, verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_06_03/output_19_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[0.5307855606079102, 0.8906999826431274]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;var_loss는 여전히 증가하지만, &lt;code&gt;val_accuracy&lt;/code&gt;는 일정한 수준에 머무르고 있습니다. 분류 성적도 &lt;code&gt;89.06%&lt;/code&gt;로 약 &lt;code&gt;0.4%&lt;/code&gt; 높은 수치가 나옵니다 (종전: &lt;code&gt;88.77%&lt;/code&gt;). 그러나, 확실히 컨볼루션 레이어만 활용했을 때 보다는 확실히 좋은 결과가 나온 것을 확인할 수 있습니다.&lt;/p&gt;
&lt;p&gt;이보다 더 좋은 성과를 낼 수 있습니다. Fashion MNIST의 공식 깃허브 저장소에는 테스트 데이터 분류 성적이 95% 이상을 달성한 방법들도 존재합니다. &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h2 id=&#34;iv-연습-파일&#34;&gt;IV. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch6_3_Fashion_MNIST_with_CNN.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v-reference&#34;&gt;V. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;이 부분은 교재 p. 145~147에 이미지로 설명이 잘 되어 있으니 참고하기를 바랍니다. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/zalandoresearch/fashion-mnist#benchmark&#34;&gt;https://github.com/zalandoresearch/fashion-mnist#benchmark&lt;/a&gt; 파이썬 실력이 되시는 분들은 95%이상의 성능을 보유한 Repo에 있는 코드를 직접 가져와 응용하는 것도 큰 도움이 될 수 있습니다. &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch6.1-2 - CNN 이론</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/</link>
      <pubDate>Tue, 21 Apr 2020 10:08:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.2 - 다항분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/&#34;&gt;Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요&#34;&gt;I. 개요&lt;/h2&gt;
&lt;p&gt;교재 &lt;code&gt;Chapter 6.1&lt;/code&gt;과 &lt;code&gt;Chapter 6.2&lt;/code&gt;에 &lt;code&gt;CNN&lt;/code&gt;의 기본적인 이론 배경들이 있습니다. 교재를 구매해서 꼭 한번 읽어보시기를 바랍니다. 주요 키워드를 정리하면 다음과 같습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;특징추출&lt;/li&gt;
&lt;li&gt;컨볼루션 연산 = 합성곱&lt;/li&gt;
&lt;li&gt;수작업 필터 (수직선/수평선 검출, 흐림(blur)효과, 날카로운 이미지(sharpen)효과
&lt;ul&gt;
&lt;li&gt;수작업 필터를 적용하기에는 3가지 문제점 존재, 도메인 지식 + 시간과 비용 + 좁은 확장성&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;컨볼루션의 역할은 &lt;code&gt;네트워크가 특징을 추출하는 필터를 자동으로 생성&lt;/code&gt;해줌&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;어떻게 특징을 자동으로 추출하는 것일까요?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;ii-주요-레이어-정리&#34;&gt;II. 주요 레이어 정리&lt;/h2&gt;
&lt;p&gt;지금까지 이 책에 나온 레이어는 &lt;code&gt;Dense&lt;/code&gt; 레이어와 &lt;code&gt;Flatten&lt;/code&gt; 레이어 두 종류입니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Dense&lt;/code&gt;레이어는 신경망에서 가장 기본이 되는 레이어이며 각 뉴런이 완전 연결(&lt;code&gt;Fully-Connected&lt;/code&gt;) 레이어라고 불리웁니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Flatten&lt;/code&gt;레이어는 다차원의 이미지를 1차원으로 평평하게 바꿔주는 레이어입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_06_01_2/tutorial_01.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;위 그림&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;에서 볼 수 있는 것처럼 &lt;code&gt;CNN&lt;/code&gt;은 특징 추출기(&lt;code&gt;Feature Extractor)&lt;/code&gt;와 분류기(&lt;code&gt;Classifier&lt;/code&gt;)가 합쳐진 형태입니다. 이 때, 특징 추출기의 역할을 하는 것은 &lt;code&gt;CNN 레이어&lt;/code&gt;와 &lt;code&gt;Pooling 레이어&lt;/code&gt;이며, &lt;code&gt;Dense 레이어&lt;/code&gt;는 분류기의 역할을 합니다.&lt;/p&gt;
&lt;p&gt;이론적인 자세한 부분은 여기에서는 생략하기로 한다. (교재를 참고하라!) 대신, 각 레이어의 특징 및 역할만 짧게 요약합니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;컨볼루션 레이어
&lt;ul&gt;
&lt;li&gt;네트워크의 학습을 통해 자동으로 특징을 추출함&lt;/li&gt;
&lt;li&gt;코드에서 지정해야 하는 값은 필터를 채우는 각 픽셀의 값이 아니라 필터의 개수 정도임&lt;/li&gt;
&lt;li&gt;2차원 이미지를 다루는 컨볼루션 레이어를 생성하는 코드는 다음과 같음&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;conv1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;valid&amp;#39;&lt;/span&gt;, filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;각 인수에 대한 설명은 전체 코드 때 재 설명합니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;풀링 레이어
&lt;ul&gt;
&lt;li&gt;인접한 픽셀의 경우 중요한 정보만 남기기 위해 서브샘플링(&lt;code&gt;subsampling&lt;/code&gt;)이라는 기법을 사용합니다. 컴퓨터의 메모리 크기가 한정되어 있다는 걸 고려한 레이어이며, 과적합 방지에 도움을 줍니다.&lt;/li&gt;
&lt;li&gt;풀링 레이어에는 &lt;code&gt;Max 풀링 레이어&lt;/code&gt;, &lt;code&gt;Average 풀링 레이어&lt;/code&gt; 등이 있씁니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;pool1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;MaxPool2D(pool_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;각 인수에 대한 설명은 전체 코드 때 재 설명합니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;드롭아웃 레이어
&lt;ul&gt;
&lt;li&gt;뉴런의 부분집을 제거하여 뉴런들간의 공모(&lt;code&gt;conspiracy&lt;/code&gt;)를 막고 과적합(&lt;code&gt;overfitting&lt;/code&gt;)을 감소시키는 것입니다.&lt;/li&gt;
&lt;li&gt;뉴런들은 결과값에 의해 서로 같은 영향을 받기 때문에, 결과값은 한쪽으로 치우치게 됩니다. 이러한 방지책으로 드롭아웃 레이어를 사용합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;pool1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout(rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;간단한 코드이지만 &lt;code&gt;AlexNet&lt;/code&gt;, &lt;code&gt;VGG&lt;/code&gt;, &lt;code&gt;GoogleNet&lt;/code&gt;, &lt;code&gt;DenseNet&lt;/code&gt; 등 거의 모든 주요 CNN에서 사용됩니다.&lt;/p&gt;
&lt;h2 id=&#34;iii-결론-및-정리&#34;&gt;III. 결론 및 정리&lt;/h2&gt;
&lt;p&gt;컨볼루션 신경망은 크게 3가지 레이어로 구성됩니다. 컨볼루션 레이어, 풀링 레이어, 드롭아웃 레이어입니다. 각 레이어의 역할은 조금씩 다릅니다. 컨볼루션 레이어는 특징을 추출하는 역할, 풀링 레이어는 중요 정보만 남기로 불필요한 연산 줄여주는 역할, 드롭아웃 레이어는 과적합을 방지하는 역할로 구분됩니다.&lt;/p&gt;
&lt;p&gt;이제 &lt;code&gt;Fashion MNIST&lt;/code&gt; 데이터세트에 &lt;code&gt;CNN&lt;/code&gt;을 적용하고, &lt;code&gt;88%&lt;/code&gt;대의 성능을 올려봅니다.&lt;/p&gt;
&lt;h2 id=&#34;iv-reference&#34;&gt;IV. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
&lt;p&gt;Ujjwal, Karn. “An Intuitive Explanation of Convolutional Neural Networks.” KDnuggets, 2016, &lt;a href=&#34;http://www.kdnuggets.com/2016/11/intuitive-explanation-convolutional-neural-networks.html/3&#34;&gt;www.kdnuggets.com/2016/11/intuitive-explanation-convolutional-neural-networks.html/3&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Hinton, G. E., Srivastava, N., Krizhevsky, A., Sutskever, I. &amp;amp; Salakhutdinov, R. R. (2012). Improving neural networks by preventing co-adaptation of feature detectors. CoRR, abs/1207.0580.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Karn, U. (2016)이 작성한 원서 논문에는 비교적 상세하게 CNN의 원리에 대해 설명하고 있다. 그러나, 한가지 아쉬운 부분은 드롭아웃 레이어에 대한 설명이 누락 되었기 때문에 드롭아웃 레이어에 관한 자세한 설명은 제프리 힌튼 교수팀의 논문을 참조하거나, 교재를 참조하기를 바란다. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
  </channel>
</rss>