<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>초해상도 on Data Science | ChloEvan</title>
    <link>https://chloevan.github.io/tags/%EC%B4%88%ED%95%B4%EC%83%81%EB%8F%84/</link>
    <description>Recent content in 초해상도 on Data Science | ChloEvan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 07 May 2020 07:20:30 +0900</lastBuildDate>
    
        <atom:link href="https://chloevan.github.io/tags/%EC%B4%88%ED%95%B4%EC%83%81%EB%8F%84/rss.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch9.4 - 초해상도</title>
      <link>https://chloevan.github.io/python/tensorflow2.0/ch9_4_super_resolution/</link>
      <pubDate>Thu, 07 May 2020 07:20:30 +0900</pubDate>
      
      <guid>https://chloevan.github.io/python/tensorflow2.0/ch9_4_super_resolution/</guid>
      <description>&lt;h2 id=&#34;공지&#34;&gt;공지&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;본 Tutorial은 교재 &lt;code&gt;시작하세요 텐서플로 2.0 프로그래밍&lt;/code&gt;의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/book.jpg&#34; alt=&#34;&#34;&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/googlecolab/&#34;&gt;Google Colab Tensorflow 2.0 Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/&#34;&gt;Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.1 - 선형회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/&#34;&gt;Tensorflow 2.0 Tutorial ch4.2 - 다항회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/&#34;&gt;Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.1 - 분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/&#34;&gt;Tensorflow 2.0 Tutorial ch5.2 - 다항분류&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/&#34;&gt;Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/&#34;&gt;Tensorflow 2.0 Tutorial ch6.1-2 - CNN 이론&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_3_fashion_mnist_with_cnn/&#34;&gt;Tensorflow 2.0 Tutorial ch6.3 - Fashion MNIST with CNN 실습&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch6_4_improve_performance/&#34;&gt;Tensorflow 2.0 Tutorial ch6.4 - 모형의 성능 높이기&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (1)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (2)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_3_sentimentanalysis/&#34;&gt;Tensorflow 2.0 Tutorial ch7.3 - 긍정, 부정 감성 분석&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration1/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (1) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration2/&#34;&gt;Tensorflow 2.0 Tutorial ch7.4 - (2) 단어 단위 생성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_1_tensorflow_hub/&#34;&gt;Tensorflow 2.0 Tutorial ch8.1 - 텐서플로 허브&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_2_transfer_learning/&#34;&gt;Tensorflow 2.0 Tutorial ch8.2 - 전이 학습과 &amp;amp; Kaggle 대회&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_3_1_texture_synthesis/&#34;&gt;Tensorflow 2.0 Tutorial ch8.3.1 - 컨볼루션 신경망을 사용한 텍스처 합성&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch8_3_2_neural_style_transfer/&#34;&gt;Tensorflow 2.0 Tutorial ch8.3.2 - 컨볼루션 신경망을 사용한 신경 스타일 전이&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch9_1_auto_encoder/&#34;&gt;Tensorflow 2.0 Tutorial ch9.1-2 - 오토인코더 &amp;amp; MNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chloevan.github.io/python/tensorflow2.0/ch9_3_k_means_clustering/&#34;&gt;Tensorflow 2.0 Tutorial ch9.3 - 클러스터링&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-개요&#34;&gt;I. 개요&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;저해상도에서 고해상도의 이미지로 변환하는 것은 어려운 연산입니다.&lt;/li&gt;
&lt;li&gt;픽셀로 구성된 이미지는 고해상도로 변환(확대)하면 이미지에서 사각형이 두드러져 보이는 것이 바로 초해상도(&lt;code&gt;Super Resolution&lt;/code&gt;) 작업입니다.&lt;/li&gt;
&lt;li&gt;전통적으로는 &lt;code&gt;interpolation(보간)&lt;/code&gt; 등의 기법이 있지만, 선명함을 잃고 흐릿해지는 단점이 있습니다.&lt;/li&gt;
&lt;li&gt;오토인코더로 초해상도 작업을 하는 과정을 진행합니다.&lt;/li&gt;
&lt;li&gt;이 때, &lt;code&gt;REDNet&lt;/code&gt;이라는 네트워크를 사용합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ii-rednet1&#34;&gt;II. REDNet&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;REDNet&lt;/code&gt;은 &lt;code&gt;Residual Encoder-Decoder Network&lt;/code&gt;의 약자이며, &lt;code&gt;Residual&lt;/code&gt;은 &lt;code&gt;ResNet&lt;/code&gt;등에서 사용하는 건너뛴 연결(&lt;code&gt;skip-connection&lt;/code&gt;)입니다.&lt;/li&gt;
&lt;li&gt;다수의 레이어가 중첩되는 구조에서 앞쪽의 정보를 잃어버리기 않기 위해 뒤쪽에 정보를 그대로 전달해줄 때 건너뛴 연결이 사용됩니다.&lt;/li&gt;
&lt;li&gt;논문에서 사용한 이미지는 &lt;code&gt;BSD (Berkeley Segmentation Dataset)&lt;/code&gt; 이며, 책에서도 동일하게 사용합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 텐서플로 2 버전 선택&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
    &lt;span style=&#34;color:#75715e&#34;&gt;# %tensorflow_version only exists in Colab.&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;tensorflow_version &lt;span style=&#34;color:#ae81ff&#34;&gt;2.&lt;/span&gt;x
&lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Exception&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;pass&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow_hub &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; hub
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; cv2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;iii-데이터-불러오기&#34;&gt;III. 데이터 불러오기&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;tf.keras.utils.get_file()&lt;/code&gt; 데이터를 불러옵니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/bsd_images.zip&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://bit.ly/35pHZlC&amp;#39;&lt;/span&gt;, extract&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from http://bit.ly/35pHZlC
37527552/37520292 [==============================] - 0s 0us/step





&#39;/content/bsd_images.zip&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;!&lt;/span&gt;unzip &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;content&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;bsd_images&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zip
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Archive:  /content/bsd_images.zip
   creating: images/
   creating: images/test/
  inflating: images/test/100007.jpg  
  inflating: images/test/100039.jpg  
  .
  .
  .
  .
  inflating: images/val/97033.jpg    
  inflating: images/val/Thumbs.db    
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;이미지 경로 저장 및 확인을 합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pathlib
image_root &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pathlib&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Path(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/images&amp;#39;&lt;/span&gt;)
all_images_paths&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;list(image_root&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;glob(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;*/*&amp;#39;&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(all_images_paths[:&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[PosixPath(&#39;/content/images/val/62096.jpg&#39;), PosixPath(&#39;/content/images/val/361010.jpg&#39;), PosixPath(&#39;/content/images/val/Thumbs.db&#39;), PosixPath(&#39;/content/images/val/54082.jpg&#39;), PosixPath(&#39;/content/images/val/87046.jpg&#39;), PosixPath(&#39;/content/images/val/38082.jpg&#39;), PosixPath(&#39;/content/images/val/156065.jpg&#39;), PosixPath(&#39;/content/images/val/33039.jpg&#39;), PosixPath(&#39;/content/images/val/14037.jpg&#39;), PosixPath(&#39;/content/images/val/159008.jpg&#39;)]
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;각 이미지의 경로는 &lt;code&gt;root&lt;/code&gt; 디렉터리에서 &lt;code&gt;glob()&lt;/code&gt; 함수를 사용해 하단의 모든 파일을 불러올 수 있습니다.&lt;/li&gt;
&lt;li&gt;각 파일의 경로는 &lt;code&gt;PosixPath&lt;/code&gt;라는 객체가 되는데, 이 객체에서 경로를 가져오기 위해서는 문자열로 변환하는 &lt;code&gt;str()&lt;/code&gt;함수를 사용합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;1-이미지-시각화&#34;&gt;(1) 이미지 시각화&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;matplotlib.pyplot&lt;/code&gt;으로 확인합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; PIL.Image &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; Image
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;):
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(all_images_paths[c]))
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(all_images_paths[c])
  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axis(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;off&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;/img/tensorflow2.0/tutorial_09_04/output_7_1.png
&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_04/output_7_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;데이터를 보면 아시겠지만, 가로와 세로 길이가 모두 다릅니다. 또한, 이미지의 내용은 사람, 동물, 자연등으로 다양합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-이미지-경로-분리-저장&#34;&gt;(2) 이미지 경로 분리 저장&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;BSD500&lt;/code&gt;은 200장의 훈련 데이터, 100장의 검증 데이터, 200장의 테스트 데이터로 구성되어 있습니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;를 각 데이터세트마다 만듭니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train_path, valid_path, test_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [], [], []

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; image_path &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; all_images_paths:
  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; str(image_path)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;jpg&amp;#34;&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;continue&lt;/span&gt;
  
  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; str(image_path)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;train&amp;#39;&lt;/span&gt;: 
    train_path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(str(image_path))
  &lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; str(image_path)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val&amp;#39;&lt;/span&gt;:
    valid_path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(str(image_path))
  &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
    test_path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(str(image_path))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;3-원본-이미지-조각-추출-입력-출력-데이터-변환-함수-정의&#34;&gt;(3) 원본 이미지 조각 추출, 입력, 출력 데이터 변환 함수 정의&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;현재의 이미지는 고해상도이기 때문에, 저해상도는 일부러 낮추고 원본과 함께 반환하는 함수를 만듭니다.&lt;/li&gt;
&lt;li&gt;원본 이미지에서 조각을 추출해서 입력, 출력 데이터를 생성하는 구조에 관한 이미지는 교재 360페이지를 확인해봅니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_hr_and_lr&lt;/span&gt;(image_path):
  img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;io&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_file(image_path)
  img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;decode_jpeg(img, channels&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
  img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convert_image_dtype(img, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)

  hr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random_crop(img, [&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;])
  lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(hr, [&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;])
  lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(lr, [&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;])

  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; lr, hr 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;JPEG&lt;/code&gt; 이미지는 &lt;code&gt;tf.io.read_file()&lt;/code&gt;로 불러올 수 있습니다.&lt;/li&gt;
&lt;li&gt;이미지를 불러온 후 &lt;code&gt;decode_jpeg()&lt;/code&gt; 함수를 사용해서 프로그램이 이해할 수 있는 데이터 형태로 만들어야 하고, &lt;code&gt;convert_image_dtype()&lt;/code&gt;함수로 데이터 타입을 딥러닝에서 가장 범용적으로 사용하는 &lt;code&gt;float32&lt;/code&gt; 데이터 타입으로 바꿉니다.&lt;/li&gt;
&lt;li&gt;가로 X 세로 50픽셀의 이미지를 &lt;code&gt;random_crop()&lt;/code&gt;이라는 함수로 쉽게 얻을 수 있습니다.&lt;/li&gt;
&lt;li&gt;마지막의 3은 컬러 채널의 수를 의미합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;4-train-valid-dataset-정의&#34;&gt;(4) &lt;code&gt;train, valid Dataset 정의&lt;/code&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Dataset&lt;/code&gt;를 정의할 차례이며, 학습 과정에서 사용할 훈련 데이터와 검증 데이터를 사용하는 &lt;code&gt;Dataset&lt;/code&gt;를 각각 정의합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;list_files(train_path)
train_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;map(get_hr_and_lr)
train_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;repeat()
train_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;batch(&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;)

valid_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;list_files(train_path)
valid_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; valid_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;map(get_hr_and_lr)
valid_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; valid_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;repeat()
valid_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; valid_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;batch(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;먼저 파일의 경로 리스트를 가지고 있다면 &lt;code&gt;tf.data.Dataset.list_files()&lt;/code&gt; 함수의 인수로 파일 경로 리스트를 넣어서 &lt;code&gt;Dataset&lt;/code&gt;를 쉽게 정의할 수 있습니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;get_hr_and_lr()&lt;/code&gt; 함수를 &lt;code&gt;map()&lt;/code&gt;함수를 적용해 새로운 &lt;code&gt;Dataset&lt;/code&gt;을 만듭니다.&lt;/li&gt;
&lt;li&gt;이렇게 연결되면 &lt;code&gt;Dataset&lt;/code&gt;는 먼저 &lt;code&gt;train_path&lt;/code&gt; 리스트의 이미지를 불러온 다음에 저해상도와 고해상도 조각인 &lt;code&gt;lr&lt;/code&gt;, &lt;code&gt;hr&lt;/code&gt;을 반환합니다. 여기까지 선언하면 쉽게 사용할 수 있는 &lt;code&gt;Dataset&lt;/code&gt;을 1차로 완성한 것입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;5-rednet-30의-정의&#34;&gt;(5) REDNet-30의 정의&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;REDNet-30&lt;/code&gt;에 대한 구조에 대한 설명은 교재 &lt;code&gt;362-363 p&lt;/code&gt;를 확인합니다. 다음 소스코드로 네트워크 정의를 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;REDNet&lt;/span&gt;(num_layers):
    conv_layers &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    deconv_layers &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    residual_layers &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []

    inputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Input(shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(None, None, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;))
    conv_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;))

    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(num_layers&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
        conv_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;))
        deconv_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2DTranspose(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;))

    deconv_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2DTranspose(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;))

    &lt;span style=&#34;color:#75715e&#34;&gt;# 인코더 시작&lt;/span&gt;
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; conv_layers[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;](inputs)

    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(num_layers&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; conv_layers[i&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;](x)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
            residual_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(x)

    &lt;span style=&#34;color:#75715e&#34;&gt;# 디코더 시작&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(num_layers&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:
            x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Add()([x, residual_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pop()])
            x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Activation(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;)(x)
        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; deconv_layers[i](x) 

    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; deconv_layers[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;](x)
    
    model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Model(inputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;inputs, outputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;x)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; model
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;위 함수를 통해서, &lt;code&gt;REDNet-10, REDNet-20, REDNet-30&lt;/code&gt;등 다양한 네트워크를 함수 호출 한 번으로 만들 수 있습니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;num_layers&lt;/code&gt;는 컨볼루션 레이어와 디컨볼루션 레이어의 수입니다. 같은 수의 컨볼루션 레이어가 존재하기 때문에, &lt;code&gt;REDNet-30&lt;/code&gt;이라면 &lt;code&gt;num_layers=15&lt;/code&gt;를 입력하면 됩니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;conv_layers&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[]
deconv_layers&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[]
residual_layers&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;먼저 세 개의 리스트에 각각 컨볼루션 레이어, 디컨볼루션 레이어, 잔류(&lt;code&gt;residual&lt;/code&gt;)레이어를 저장합니다.&lt;/p&gt;
&lt;p&gt;각 레이어를 따로 저장할 리스트가 별도로 필요로 합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;
    inputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Input(shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(None, None, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;))
    conv_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;))

    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(num_layers&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
        conv_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;))
        deconv_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2DTranspose(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;))

    deconv_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2DTranspose(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;))
    &lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;먼저 입력 레이어를 정의합니다. 입력 레이어의 &lt;code&gt;shape&lt;/code&gt;에서 이미지의 높이와 너비를 &lt;code&gt;None&lt;/code&gt;으로 지정해서 어떤 크기의 이미지라도 입력으로 받을 수 있습니다.&lt;/li&gt;
&lt;li&gt;첫 번째 컨볼루션 레이어와 마지막 디컨볼루션 레이어를 제외한 레이어들은 &lt;code&gt;for&lt;/code&gt; 문 안에서 정의해서 각 리스트에 저장합니다.&lt;/li&gt;
&lt;li&gt;첫번째 컨볼루션 레이어와 마지막 디컨볼루션 레이어는 필터의 수가 다른데 이는 필터의 수로 &lt;code&gt;RGB&lt;/code&gt; 채널의 수인 &lt;code&gt;3&lt;/code&gt;을 그대로 받기 위함입니다. 나머지 레이어에서는 64개의 필터를 사용합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# 인코더 시작&lt;/span&gt;
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; conv_layers[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;](inputs)

    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(num_layers&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; conv_layers[i&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;](x)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
            residual_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(x)

    &lt;span style=&#34;color:#75715e&#34;&gt;# 디코더 시작&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(num_layers&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:
            x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Add()([x, residual_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pop()])
            x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Activation(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;)(x)
        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; deconv_layers[i](x) 

    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; deconv_layers[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;](x)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;여기에서는 &lt;code&gt;x&lt;/code&gt;라는 변수에 레이어를 계속 적용해서 함수형 &lt;code&gt;API&lt;/code&gt;를 사용합니다. 마지막에 &lt;code&gt;x&lt;/code&gt;는 모든 레이어가 적용된 결과가 되기 때문에 모델의 출력이 됩니다.&lt;/li&gt;
&lt;li&gt;이렇게 하나의 변수 이름을 재사용하여 레이어를 적용해나가는 방법은 케라스의 함수형 &lt;code&gt;API&lt;/code&gt;나 &lt;code&gt;torch&lt;/code&gt;에서 일반적으로 쓰이는 문법입니다.&lt;/li&gt;
&lt;li&gt;첫번째 명령인 &lt;code&gt;x = conv_layers[0](inputs)&lt;/code&gt;의 결과로 &lt;code&gt;x&lt;/code&gt;는 입력 레이어에 첫 번째 컨볼루션 레이어를 적용한 결과가 됩니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(num_layers&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; conv_layers[i&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;](x)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
            residual_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(x)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;그 다음으로는 &lt;code&gt;for&lt;/code&gt; 문 안에서 &lt;code&gt;x&lt;/code&gt;에 나머지 컨볼루션 레이어를 계속 적용시키며, 짝수번재 컨볼루션 레이어를 지날 때마다 &lt;code&gt;x&lt;/code&gt;를 잔류 레이어 리스트에도 저장합니다.&lt;/li&gt;
&lt;li&gt;잔류 레이어에 &lt;code&gt;x&lt;/code&gt;를 저장한 다음 스텝에서 &lt;code&gt;x&lt;/code&gt;는 다시 컨볼루션 레이어를 통과해서 새로운 값이 되지만 잔류 레이어에 이미 저장된 값은 사라지지 않습니다.&lt;/li&gt;
&lt;li&gt;교재 366페이지에 그림설명이 있기 때문에 한번 더 확인하시기를 바랍니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# 디코더 시작&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(num_layers&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:
            x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Add()([x, residual_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pop()])
            x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Activation(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;)(x)
        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; deconv_layers[i](x) 

    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; deconv_layers[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;](x)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;두 번째 &lt;code&gt;for&lt;/code&gt; 문 안에서는 홀수 번째의 디컨볼루션 레이어를 통과할 경우 잔류 레이어 리스트에 저장돼 있던 값을 &lt;code&gt;residual_layers.pop()&lt;/code&gt;으로 뒤에서부터 하나씩 가져옵니다. 그 다음 합연산과 &lt;code&gt;ReLU&lt;/code&gt; 활성화함수를 통과한 후 다음 디컨볼루션 레이어에 연결시킵니다.&lt;/li&gt;
&lt;li&gt;짝수 번째일 때는 디컨볼루션 레이어만 연결합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;model = tf.keras.Model(inputs=inputs, outputs=x)
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;tf.keras&lt;/code&gt;의 함수형 &lt;code&gt;API&lt;/code&gt;로 &lt;code&gt;Model&lt;/code&gt;을 만들기 위해서는 입력과 출력만 지정하면 됩니다.&lt;/li&gt;
&lt;li&gt;입력인 &lt;code&gt;inputs&lt;/code&gt;는 함수의 가장 앞에서 정의한 입력 레이어로, 출력인 &lt;code&gt;outputs&lt;/code&gt;는 지금까지 레이어 연산을 쭉 따라온 변수 이름인 &lt;code&gt;x&lt;/code&gt;로 넣고, &lt;code&gt;model&lt;/code&gt;을 반환합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;6-psnr-계산-공식-및-함수-정의&#34;&gt;(6) PSNR 계산 공식 및 함수 정의&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;고해상도 이미지가 잘 복원됐는지 알기 위해서 특별한 측정값을 컴파일에 추가해서 테스트할 수 있습니다.&lt;/li&gt;
&lt;li&gt;이 측정값은 &lt;code&gt;PSNR(Peak Signal-to-Noise Ratio)&lt;/code&gt;, 즉 &amp;ldquo;신호 대 잡임비&amp;quot;입니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;PSNR&lt;/code&gt;의 계산 공식은 다음과 같습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$PSNR = 20\ast log_{10}\frac{Max(pixel)}{\sqrt{MSE}}$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;여기서 &lt;code&gt;Max(pixel)&lt;/code&gt;은 픽셀의 최대값으로, 앞에서 &lt;code&gt;float32&lt;/code&gt;로 계산했기 때문에 이 값은 &lt;code&gt;1.0&lt;/code&gt;이 됩니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MSE&lt;/code&gt;는 우리가 잘 알고 있는 평균 제곱 오차(&lt;code&gt;Mean Squared Error&lt;/code&gt;)입니다.&lt;/li&gt;
&lt;li&gt;평균 제곱 오차가 로그의 분모에 있기 때문에 이 식은 평균 제곱 오차가 낮을수록 큰 값을 갖게 됩니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;psnr_metric&lt;/span&gt;(y_true, y_pred):
  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;psnr(y_true, y_pred, max_val&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Metric&lt;/code&gt;은 분류의 정확도(&lt;code&gt;accuracy&lt;/code&gt;)처럼 &lt;code&gt;tf.keras&lt;/code&gt;에 등록되어 있을 경우 그대로 사용하면 되지만 &lt;code&gt;PSNR&lt;/code&gt;은 지원하지 않기 때문에 함수를 만들어줍니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;y_true&lt;/code&gt;는 정답에 해당하는 값이고, &lt;code&gt;y_pred&lt;/code&gt;는 네트워크가 학습 결과 예측한 값입니다.&lt;/li&gt;
&lt;li&gt;이 둘의 &lt;code&gt;tf.image.psnr()&lt;/code&gt;을 계산해서 반환하는 것이 &lt;code&gt;psnr_metric()&lt;/code&gt; 함수의 역할입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;7-rednet-30-네트워크-초기화-및-컴파일&#34;&gt;(7) REDNet-30 네트워크 초기화 및 컴파일&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;이제 &lt;code&gt;REDNet()&lt;/code&gt; 함수로 네트워크를 초기화하고 컴파일합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; REDNet(&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;)
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.0001&lt;/span&gt;), loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mse&amp;#39;&lt;/span&gt;, metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[psnr_metric])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;컴파일된 네트워크 시각화를 작성해봅니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot_model(model)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;8-rednet-30-네트워크-학습&#34;&gt;(8) REDNet-30 네트워크 학습&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;이제 네트워크를 학습합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit_generator(train_dataset, 
                              epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;, 
                              steps_per_epoch&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;len(train_path)&lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;, 
                              validation_data&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;valid_dataset, 
                              validation_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;len(valid_path), 
                              verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;WARNING:tensorflow:From &amp;lt;ipython-input-15-11785503027a&amp;gt;:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
Please use Model.fit, which supports generators.
Epoch 1/1000
12/12 - 4s - loss: 0.2467 - psnr_metric: 7.6192 - val_loss: 0.2287 - val_psnr_metric: 8.1383
Epoch 2/1000
12/12 - 3s - loss: 0.1935 - psnr_metric: 8.8387 - val_loss: 0.0982 - val_psnr_metric: 11.4855
.
.
.
Epoch 998/1000
12/12 - 3s - loss: 0.0015 - psnr_metric: 32.7882 - val_loss: 0.0013 - val_psnr_metric: 32.6776
Epoch 999/1000
12/12 - 3s - loss: 0.0015 - psnr_metric: 32.2986 - val_loss: 0.0015 - val_psnr_metric: 32.9123
Epoch 1000/1000
12/12 - 3s - loss: 0.0015 - psnr_metric: 32.4111 - val_loss: 0.0014 - val_psnr_metric: 32.6642
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Dataset&lt;/code&gt;를 이용한 학습은 &lt;code&gt;fit()&lt;/code&gt; 함수 대신 &lt;code&gt;fit_generator()&lt;/code&gt; 함수를 사용합니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Dataset&lt;/code&gt;에 &lt;code&gt;repeat()&lt;/code&gt; 함수를 사용했기 때문에 한 번의 에포크에 몇 개의 데이터를 학습시킬지를 지정하는 &lt;code&gt;steps_per_epoch&lt;/code&gt;인수를 설정해야 합니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;batch size&lt;/code&gt;가 16이기 때문에 &lt;code&gt;steps_per_epoch&lt;/code&gt;는 &lt;code&gt;len(train_path)//16&lt;/code&gt;으로 훈련 데이터의 크기를 &lt;code&gt;batch size&lt;/code&gt;로 나눕니다.
&lt;ul&gt;
&lt;li&gt;//는 결과가 정수로 나오는 나눗셈을 의미합니다. 예를 들면 200//16의 결과는 12가 됩니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;verbose=2&lt;/code&gt;의 의미니느 출력제한에 걸리지 않도록 하며, 진행 상황 애니메이션은 생략하고 각 에포크의 결과만 출력합니다.&lt;/li&gt;
&lt;li&gt;학습 결과, 훈련 데이터의 &lt;code&gt;PSNR&lt;/code&gt;은 31~32, 검증데이터의 29-32정도가 나옵니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;9-네트워크-학습-결과-확인&#34;&gt;(9) 네트워크 학습 결과 확인&lt;/h3&gt;
&lt;p&gt;학습 겨로가를 확인합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;psnr_metric&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;psnr&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_psnr_metric&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_psnr&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_04/output_37_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;PSNR 수치 모두 학습할수록 증가하는 경향을 보입니다. 이렇게 학습된 데이터가 실제 이미지를 어떻게 복원하는지 확인합니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;io&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_file(test_path[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;decode_jpeg(img, channels&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
hr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convert_image_dtype(img, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)

lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(hr, [hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;])
lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(lr, [hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]])
predict_hr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(lr, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;psnr(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(predict_hr, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;), hr, max_val&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;psnr(lr, hr, max_val&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;tf.Tensor(26.110872, shape=(), dtype=float32)
tf.Tensor(24.853115, shape=(), dtype=float32)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;10-테스트-이미지에-대한-초해상도-결과-확인&#34;&gt;(10) 테스트 이미지에 대한 초해상도 결과 확인&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;테스트 데이터 중 첫 번째 이미지를 불러와서 저해상도 버전을 만든 다음 &lt;code&gt;REDNet-30&lt;/code&gt; 네트워크에 통과시켜서 복원 이미지를 얻어냅니다.&lt;/li&gt;
&lt;li&gt;결과에서 &lt;code&gt;PSNR&lt;/code&gt; 점수는 복원 이미지가 저해상도 이미지보다 아주 살짝 높은 것으로 나옵니다.&lt;/li&gt;
&lt;li&gt;이미지를 출력합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(hr)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;original - hr&amp;#39;&lt;/span&gt;)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(lr)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lr&amp;#39;&lt;/span&gt;)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(predict_hr, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sr&amp;#39;&lt;/span&gt;)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;첫번째 사진이 이미지의 원본이고, 두번째 사진이 저해상도, 세번째 줄이 복원된 이미지입니다.&lt;/li&gt;
&lt;li&gt;이 작업의 성능을 비교하기 위해 &lt;code&gt;Set5&lt;/code&gt;라는 데이터세트가 있습니다. 이 중에서도 자주 쓰이는 나비의 사진을 불러와서 확인합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;image_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;butterfly.png&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://bit.ly/2oAOxgH&amp;#39;&lt;/span&gt;)
img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;io&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_file(image_path)
img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;decode_jpeg(img, channels&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
hr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convert_image_dtype(img, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)

lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(hr, [hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;])
lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(lr, [hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]])
predict_hr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(lr, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;psnr(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(predict_hr, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;), hr, max_val&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;psnr(lr, hr, max_val&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;))


plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;))
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(hr)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;original - hr&amp;#39;&lt;/span&gt;)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(lr)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lr&amp;#39;&lt;/span&gt;)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(predict_hr, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sr&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from http://bit.ly/2oAOxgH
131072/127529 [==============================] - 0s 0us/step
tf.Tensor(20.3429, shape=(), dtype=float32)
tf.Tensor(20.217585, shape=(), dtype=float32)





Text(0.5, 1.0, &#39;sr&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_04/output_43_2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;벤치마크답게 &lt;code&gt;PSNR&lt;/code&gt; 점수에서 성능 차이가 뚜렷하게 드러납니다.&lt;/li&gt;
&lt;li&gt;조금 더 어려운 과제로는 확대 비율을 늘려볼 수 있습니다. 현재는 2배인데, 이를 4배로 늘려봅니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;11-확대비율-4배로-수정-이미지-보강-rednet-30-네트워크-학습&#34;&gt;(11) 확대비율 4배로 수정, 이미지 보강 REDNet-30 네트워크 학습&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Dataset&lt;/code&gt;에서는 쉽게 이미지 보강을 할 수 있습니다. 이미지에서 랜덤한 부분을 잘라서 고해상도와 저해상도 버전을 추출하던 &lt;code&gt;get_hr_and_lr()&lt;/code&gt; 함수를 다음과 같이 바꿉니다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; random
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_hr_and_lr_flip_s4&lt;/span&gt;(image_path):
  img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;io&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_file(image_path)
  img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;decode_jpeg(img, channels&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
  img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convert_image_dtype(img, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)

  hr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random_crop(img, [&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;])
  lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(hr, [&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;])
  lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(lr, [&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;])

  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random() &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;:
    hr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flip_left_right(hr)
    lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flip_left_right(lr)
  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random() &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;:
    hr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flip_up_down(hr)
    lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flip_up_down(lr)

  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; lr, hr 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;앞부분은 축소/확대 비율을 2배에서 4배로 바꾸는 부분을 제외하면 &lt;code&gt;get_hr_and_lr()&lt;/code&gt; 함수와 같고, 뒤쪽에서 &lt;code&gt;25%&lt;/code&gt;의 확률로 좌우 반전, 또 &lt;code&gt;25%&lt;/code&gt;의 확률로 상하 반전을 시켜줍니다.&lt;/li&gt;
&lt;li&gt;결과적으로 &lt;code&gt;Dataset&lt;/code&gt;을 다시 정의하고 바뀐 함수를 적용합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;12-rednet-30-네트워크-학습&#34;&gt;(12) REDNet-30 네트워크 학습&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;train_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;list_files(train_path)
train_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;map(get_hr_and_lr_flip_s4)
train_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;repeat()
train_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;batch(&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;)

valid_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;list_files(valid_path)
valid_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; valid_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;map(get_hr_and_lr_flip_s4)
valid_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; valid_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;repeat()
valid_dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; valid_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;batch(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)

model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; REDNet(&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;)
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.0001&lt;/span&gt;), loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mse&amp;#39;&lt;/span&gt;, metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[psnr_metric])

history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit_generator(train_dataset, 
                              epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4000&lt;/span&gt;, 
                              steps_per_epoch&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;len(train_path)&lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;, 
                              validation_data&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;valid_dataset, 
                              validation_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;len(valid_path), 
                              verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;12/12 - 3s - loss: 0.0046 - psnr_metric: 27.3362 - val_loss: 0.0050 - val_psnr_metric: 27.4308
Epoch 3548/4000
12/12 - 3s - loss: 0.0046 - psnr_metric: 26.8918 - val_loss: 0.0045 - val_psnr_metric: 26.7091
.
.
.
Epoch 3999/4000
12/12 - 3s - loss: 0.0048 - psnr_metric: 26.8295 - val_loss: 0.0055 - val_psnr_metric: 25.5176
Epoch 4000/4000
12/12 - 3s - loss: 0.0046 - psnr_metric: 27.5956 - val_loss: 0.0048 - val_psnr_metric: 27.2664
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;이미지 보강으로 데이터가 4배 정도 늘어난 것과 같은 효과이기 때문에 에포크를 1,000에서 4,000으로 늘렸씁니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Set5&lt;/code&gt;의 나비 이미지를 테스트해보면 다음과 같은 결과가 나옵니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;13-학습-결과-확인-및-set5-이미지-시각화&#34;&gt;(13) 학습 결과 확인 및 &lt;code&gt;Set5&lt;/code&gt; 이미지 시각화&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;psnr_metric&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b-&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;psnr&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(history&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;history[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_psnr_metric&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r--&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;val_psnr&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_04/output_52_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;image_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;butterfly.png&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://bit.ly/2oAOxgH&amp;#39;&lt;/span&gt;)
img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;io&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_file(image_path)
img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;decode_jpeg(img, channels&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
hr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convert_image_dtype(img, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)

lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(hr, [hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;])
lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(lr, [hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]])
predict_hr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(lr, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;psnr(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(predict_hr, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;), hr, max_val&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;psnr(lr, hr, max_val&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;))


plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;))
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(hr)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;original - hr&amp;#39;&lt;/span&gt;)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(lr)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lr&amp;#39;&lt;/span&gt;)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(predict_hr, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sr&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).


tf.Tensor(22.349665, shape=(), dtype=float32)
tf.Tensor(20.217585, shape=(), dtype=float32)





Text(0.5, 1.0, &#39;sr&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://chloevan.github.io/img/tensorflow2.0/tutorial_09_04/output_53_3.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이미지를 불러온 다음 각 이미지에 대한 저해상도 버전과 복원 이미지의 &lt;code&gt;PSNR&lt;/code&gt; 점수를 구해서 평균을 비교합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;image_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/Set5.zip&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://bit.ly/2MEG4kr&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;!&lt;/span&gt;unzip Set5&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zip
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Downloading data from http://bit.ly/2MEG4kr
860160/852576 [==============================] - 0s 0us/step
Archive:  Set5.zip
   creating: Set5/
 extracting: Set5/baby.png           
 extracting: Set5/bird.png           
 extracting: Set5/butterfly.png      
 extracting: Set5/head.png           
  inflating: Set5/woman.png          
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;set5_image_root &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pathlib&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Path(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/content/Set5&amp;#39;&lt;/span&gt;)
set5_image_paths &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; list(set5_image_root&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;glob(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;*.*&amp;#39;&lt;/span&gt;))

sr_psnr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
lr_psnr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; image_path &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; set5_image_paths:
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;io&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_file(str(image_path))
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;decode_jpeg(img, channels&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
    hr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convert_image_dtype(img, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)

    lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(hr, [hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;])
    lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(lr, [hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], hr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]])
    predict_hr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(lr, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))
    
    sr_psnr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;psnr(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(predict_hr, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;), hr, max_val&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy())
    lr_psnr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;psnr(lr, hr, max_val&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy())
    
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sr:&amp;#39;&lt;/span&gt;, sr_psnr)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sr mean:&amp;#39;&lt;/span&gt;, np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(sr_psnr))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;()
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lr:&amp;#39;&lt;/span&gt;, lr_psnr)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lr mean:&amp;#39;&lt;/span&gt;, np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(lr_psnr))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;WARNING:tensorflow:5 out of the last 5 calls to &amp;lt;function Model.make_predict_function.&amp;lt;locals&amp;gt;.predict_function at 0x7fc446f63158&amp;gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
sr: [28.628256, 22.349665, 25.808668, 27.925306, 30.419857]
sr mean: 27.026352

lr: [28.569517, 20.217585, 24.495182, 27.31659, 29.72251]
lr mean: 26.064276
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;복원 이미지의 &lt;code&gt;PSNR&lt;/code&gt; 점수가 저해상도 버전보다 전반적으로 높게 나타나는 것을 확인할 수 있습니다.&lt;/li&gt;
&lt;li&gt;4배 확대 초해상도에 대한 벤치마크 사이트에서 &lt;code&gt;REDNet-30&lt;/code&gt;은 &lt;code&gt;Set5&lt;/code&gt; 이미지에 대해 최고 31.51점의 &lt;code&gt;PSNR&lt;/code&gt;점수를 기록하고 있습니다.&lt;/li&gt;
&lt;li&gt;학습을 시킬수록 &lt;code&gt;PSNR&lt;/code&gt; 점수는 증가하는 경향을 보이기 때문에 과적합되지 않을 정도로 충분한 에포크 동안 학습시키고 입력 이미지를 다양하게 만들어서 더 좋은 &lt;code&gt;PSNR&lt;/code&gt;점수를 얻을 수 있을 겁니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;iv-연습-파일&#34;&gt;IV. 연습 파일&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch9_4_super_resolution.ipynb&#34;&gt;구글 Colab에서 직접 연습해보자&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v-reference&#34;&gt;V. Reference&lt;/h2&gt;
&lt;p&gt;김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;X. Mao, C. Shen, and Y. Yang. (2016, September 1). Image Restoration Using Very Deep Convolutional Encoder-Decoder Networks with Symmetric Skip Connections. Retrieved from &lt;a href=&#34;https://arxiv.org/abs/1603.09056&#34;&gt;https://arxiv.org/abs/1603.09056&lt;/a&gt; &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
  </channel>
</rss>