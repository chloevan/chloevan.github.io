<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Transformation on Data Science | DSChloe</title>
    <link>https://dschloe.github.io/tags/data-transformation/</link>
    <description>Recent content in Data Transformation on Data Science | DSChloe</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 12 Jul 2021 05:10:47 +0900</lastBuildDate><atom:link href="https://dschloe.github.io/tags/data-transformation/rss.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>엑셀 데이터 가공하기 변환</title>
      <link>https://dschloe.github.io/python/python_edu/02_datatransformation/excel_multipleheaders/</link>
      <pubDate>Mon, 12 Jul 2021 05:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/02_datatransformation/excel_multipleheaders/</guid>
      <description>개요  정리되지 못한 엑셀 파일을 불러와서 하나의 테이블을 만드는 과정을 진행해본다.   위 데이터를 원본 그대로 받아서 pandas 데이터 프레임에 추가한다. A3 셀에 있는 [시·도지사선거][서울특별시][강남구] 분리하여 각 column에 추가한다.  라이브러리 불러오기  3개의 라이브러리를 불러온다.  import pandas as pd import openpyxl import os 파일 확인  data 폴더 내 데이터를 확인한다. 추후, 엑셀 데이터만 추려서 반복문을 활용하여 동일하게 처리할 수 있도록 상상을 한다.  print(os.listdir(&amp;#39;data&amp;#39;)) [&#39;1 강남구-[2021년_재·보궐선거]_개표단위별_개표결과.</description>
    </item>
    
    <item>
      <title>(Python) Pandas Data Convert</title>
      <link>https://dschloe.github.io/python/pandas/pandas_data_convert/</link>
      <pubDate>Wed, 28 Apr 2021 14:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/pandas/pandas_data_convert/</guid>
      <description>1줄 요약  Pandas에서 데이터 형변환은 astype로 끝낸다.  참고자료  astype에 대한 공식 문서를 살펴본다.  참고자료: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html    예제  가상의 temp 데이터를 만든다. 모두 0, 1, 2 데이터이지만 각 데이터 타입은 모두 다르다.  import pandas as pd temp = pd.DataFrame({&amp;#34;A&amp;#34;: [0,1,2], &amp;#34;B&amp;#34;: [&amp;#34;0&amp;#34;, &amp;#34;1&amp;#34;, &amp;#34;2&amp;#34;], &amp;#34;C&amp;#34;: [0.0, 1.0, 2.0]}) temp.info() &amp;lt;class &#39;pandas.core.frame.DataFrame&#39;&amp;gt; RangeIndex: 3 entries, 0 to 2 Data columns (total 3 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 A 3 non-null int64 1 B 3 non-null object 2 C 3 non-null float64 dtypes: float64(1), int64(1), object(1) memory usage: 200.</description>
    </item>
    
    <item>
      <title>Pandas read_csv skiprows 활용</title>
      <link>https://dschloe.github.io/python/pandas/pandas_skiprows/</link>
      <pubDate>Sat, 20 Feb 2021 20:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/pandas/pandas_skiprows/</guid>
      <description>문제 개요  Kaggle 데이터 New York City Taxi Fare Prediction 데이터를 구글 코랩에서 Loading 하는 중 메모리 문제가 발생함 계통추출(Systematic Sampling)을 통해 데이터를 불러오기로 함  예제 실습  아래 예제를 통해서 실제로 데이터가 줄어드는지 확인을 해본다. 핵심 코드는 skip_logic 함수이며, skiprows = skiprows=lambda x: skip_logic(x, 3) 형태로 작성할 수 있다. IRIS 데이터는 https://www.kaggle.com/saurabh00007/iriscsv 에서 다운로드 받았다.  iris 데이터외에도 각자 데이터를 가지고 실습을 해도 좋다.    import pandas as pd def skip_logic(index, skip_num): if index % skip_num == 0: return False return True def main(): print(&amp;#39;**** skiprows 기본 옵션 ****&amp;#39;) iris = pd.</description>
    </item>
    
    <item>
      <title>KDX Competition Guideline</title>
      <link>https://dschloe.github.io/r/competition/blog_kdx_guideline/</link>
      <pubDate>Wed, 14 Oct 2020 09:10:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/competition/blog_kdx_guideline/</guid>
      <description>개요  본 수업을 듣는 수강생들을 위해 간단한 튜토리얼을 만들었다. 대회는 다음과 같다.  싸이트: 한국데이터거래소    /img/r/competition/blog_kdx_guideline_files/img 1단계 패키지 불러오기  데이터 가공 및 시각화 위주의 패키지를 불러온다.  library(tidyverse) # 데이터 가공 및 시각화 library(readxl) # 엑셀파일 불러오기 패키지  2단계 데이터 불러오기  데이터가 많아서 순차적으로 진행하도록 한다. 각 데이터에 대한 설명은활용데이터설명(PDF)을 참조한다.   먼저 제 개발환경은 아래와 같다.  Note: 윈도우와 Mac은 다를 수 있음을 명심하자.</description>
    </item>
    
    <item>
      <title>삼성카드 대회 Track-2 - matplotlib 막대 그래프</title>
      <link>https://dschloe.github.io/python/python_edu/competition/samsungcard20/samsung_card_track_2_2/</link>
      <pubDate>Wed, 02 Sep 2020 15:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/competition/samsungcard20/samsung_card_track_2_2/</guid>
      <description>대회 소개  삼성카드 데이터분석 공모전이 시행되고 있다.  대회에 처음 참여하는 아시아경제-수강생들을 위해 일종의 가이드라인으로 제안하고자 한다.   본 포스트에서는 기본적인 내용만 전달하고자 함을 밝힌다.  Track2 과정은 마케팅 전략 제안이 중요하다!    환경 세팅  먼저, 데이터가 모두 한글로 구성이 되어 있기 때문에 한글파일 설정부터 진행한다. 한글파일 설정이 완료되면 구글 드라이브와 연동한다. 데이터 시각화를 진행한다.  %config InlineBackend.figure_format = &amp;#39;retina&amp;#39; !sudo apt-get -qq -y install fonts-nanum fonts-nanum is already the newest version (20170925-1).</description>
    </item>
    
    <item>
      <title>삼성카드 대회 Track-2 데이터 고려 사항 (1)</title>
      <link>https://dschloe.github.io/python/python_edu/competition/samsungcard20/samsung_card_track_2_1/</link>
      <pubDate>Mon, 31 Aug 2020 01:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/competition/samsungcard20/samsung_card_track_2_1/</guid>
      <description>대회 소개  삼성카드 데이터분석 공모전이 시행되고 있다.  대회에 처음 참여하는 아시아경제-수강생들을 위해 일종의 가이드라인으로 제안하고자 한다.   본 포스트에서는 기본적인 내용만 전달하고자 함을 밝힌다.  Track2 과정은 마케팅 전략 제안이 중요하다!    환경 세팅  먼저, 데이터가 모두 한글로 구성이 되어 있기 때문에 한글파일 설정부터 진행한다. 한글파일 설정이 완료되면 구글 드라이브와 연동한다. 데이터 시각화를 진행한다.  %config InlineBackend.figure_format = &amp;#39;retina&amp;#39; !sudo apt-get -qq -y install fonts-nanum The following package was automatically installed and is no longer required: libnvidia-common-440 Use &#39;apt autoremove&#39; to remove it.</description>
    </item>
    
    <item>
      <title>DataFrame의 변수 추가 및 삭제</title>
      <link>https://dschloe.github.io/python/python_edu/02_datatransformation/chapter_4_6_datatransformation/</link>
      <pubDate>Sun, 30 Aug 2020 01:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/02_datatransformation/chapter_4_6_datatransformation/</guid>
      <description>데이터 개요  German Credit Card를 활용하여 데이터를 가공하도록 한다.  데이터셋에 대한 설명은 Kaggle에서 확인한다.    import pandas as pd print(pd.__version__) 1.0.5  url = &amp;#39;https://raw.githubusercontent.com/chloevan/kaggle2portpolio/master/datasets/german_credit_data.csv&amp;#39; german_credit = pd.read_csv(url) german_credit.head(3)  #customers { font-family: &#34;Trebuchet MS&#34;, Arial, Helvetica, sans-serif; border-collapse: collapse; } #customers td, #customers th { border: 1px solid #ddd; padding: 8px; } #customers tr:nth-child(even) { background-color: #f2f2f2; } #customers tr:hover { background-color: #ddd; } #customers th { padding-top: 12px; padding-bottom: 12px; text-align: left; background-color: rgb(175, 107, 76); color: white; }    Unnamed: 0 Age Sex Job Housing Saving accounts Checking account Credit amount Duration Purpose     0 0 67 male 2 own NaN little 1169 6 radio/TV   1 1 22 female 2 own little moderate 5951 48 radio/TV   2 2 49 male 1 own little NaN 2096 12 education      Pandas DataFrame은 Index와 나머지 열로 구성이 되어 있다.</description>
    </item>
    
    <item>
      <title>EDA with Pandas - Data Merge</title>
      <link>https://dschloe.github.io/python/python_edu/02_datatransformation/chapter_1_4_python_pandas_merge_solution/</link>
      <pubDate>Fri, 05 Jun 2020 13:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/02_datatransformation/chapter_1_4_python_pandas_merge_solution/</guid>
      <description>I. 개요  실무 데이터에서는 여러가지 데이터를 만나는 경우가 흔하다. 이 때, SQL에서 데이터를 직접 병합하는 방법이 좋다. 그러나, 현실적으로 DB에 접근하는 권한을 가진 경우는 흔하지는 않다. 현재 운영중인 서비스상에 DB를 직접 만지는 경우는 거의 없다 (DBA가 할지도..) 따라서, 데이터분석가는 흩어져 있는 데이터 Dump를 받게 될 가능성이 큰데, 이 때 Python에서 데이터를 병합하는 작업을 진행하게 된다. Kaggle이나 각종 경진대회에 출전하게 되면 서로 다른 데이터를 합쳐야 하는 경우가 매우 많다.  II.</description>
    </item>
    
    <item>
      <title>Data Transformation - Merging Data</title>
      <link>https://dschloe.github.io/python/python_edu/02_datatransformation/01_data_transformation_merging_data/</link>
      <pubDate>Fri, 29 May 2020 14:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/02_datatransformation/01_data_transformation_merging_data/</guid>
      <description>공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
 데이터는 코로나 데이터를 활용했다.  I. Data Transform Overview   데이터 변환은 데이터를 하나의 형식이나 구조에서 다른 형식이나 구조로 변환하는 데 사용되는 기법이다.
 Data deduplication 데이터 중복 제거에는 중복된 데이터 식별 및 제거가 포함된다. Key restructuring 의미가 내장된 모든 키를 일반 키로 변환하는 것을 포함한다.</description>
    </item>
    
    <item>
      <title>Python - Pandas 병렬처리</title>
      <link>https://dschloe.github.io/python/pandas/pandas_lambda_swifter/</link>
      <pubDate>Wed, 13 May 2020 14:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/pandas/pandas_lambda_swifter/</guid>
      <description>공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
지난 포스트에서는 lambda의 기본적인 개념에 대해서 익혔다면, 이제 본격적인 데이터 전처리와 관련된 예제를 올리려고 한다.
 Python - Lambda and List Comprehension  II. 가상의 데이터셋 만들기  25M 행과 5개의 열로 구성된 가상의 숫자 데이터 프레임을 만들어보자.  import pandas as pd import numpy as np from tabulate import tabulate pd_temp = pd.</description>
    </item>
    
    <item>
      <title>Automate Excel Reporting With Pandas</title>
      <link>https://dschloe.github.io/python/rpa/automate_excel_reporting_with_pandas/</link>
      <pubDate>Fri, 08 May 2020 01:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/rpa/automate_excel_reporting_with_pandas/</guid>
      <description>공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
 데이터는 코로나 데이터를 활용했다.  I. Overview 일부의 사람들이 R과 Python을 사용하지만, 대부분의 사람들은 엑셀을 사용한다. 피벗테이블은 모든 직장인이 알아야 하는 필수 용어로, 전체 데이터를 빠르게 요약해주는 일종의 skill이다.
오늘 배울 포스트는 피벗 테이블 작성과 파이썬에서 만들어진 그래프를 엑셀 파일에 포함하여 내보내는 예제를 준비하였다.</description>
    </item>
    
    <item>
      <title>pandas pivot table</title>
      <link>https://dschloe.github.io/python/pandas/pandas_pivot_table/</link>
      <pubDate>Tue, 05 May 2020 14:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/pandas/pandas_pivot_table/</guid>
      <description>공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
 데이터는 코로나 데이터를 활용했다.  I. Overview 일부의 사람들이 R과 Python을 사용하지만, 대부분의 사람들은 엑셀을 사용한다. 피벗테이블은 모든 직장인이 알아야 하는 필수 용어로, 전체 데이터를 빠르게 요약해주는 일종의 skill이다.
II. 피벗 테이블 만들기 예제  이제 본격적으로 피벗 테이블을 만들어보자.  (1) 데이터 가져오기 데이터는 코로나 데이터를 활용한다.</description>
    </item>
    
    <item>
      <title>Dealing with NA-01</title>
      <link>https://dschloe.github.io/python/transformation/dealing_with_na_01/</link>
      <pubDate>Sat, 02 May 2020 19:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/transformation/dealing_with_na_01/</guid>
      <description>공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
 원문: 6 Different Ways to Compensate for Missing Values In a Dataset (Data Imputation with examples)  I. Overview 실제 데이터를 다루다보면 여러가지 이유로 결측치와 마주하게 된다. 특별한 이유가 없다면, 현업에서는 당연히 NA를 처리해야 한다. 그렇지 않다면 데이터 분석(시각화, 통계, 머신러닝 모형)에 영향을 줄 수 밖에 없다.</description>
    </item>
    
    <item>
      <title>Pandas Dataframe</title>
      <link>https://dschloe.github.io/python/pandas/pandas_dataframe/</link>
      <pubDate>Sat, 18 Apr 2020 11:32:36 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/pandas/pandas_dataframe/</guid>
      <description>Overview 데이터프레임은 2차원 배열의 행과 열로 구성되어져 있다. 대부분의 사람들이 알고 있는 마이크로소프트사의 EXCEL, SQL Table 등을 생각하면 데이터프레임을 쉽게 이해할 수 있다. 판다스에서 가장 많이 사용되는 객체이며, 실제 파이썬을 활용한 데이터 분석을 하고 싶다면 필수적으로 알아야 하는 내용이다. 기본적으로 Python은 행렬 연산에 최적화된 언어라고 할 수 있지만, 판다스 라이브러리는 R의 데이터프레임에서 유래했다고 알려져 있다.
여기서 잠깐! 초급자 또는 입문자들이 가장 궁금해하는 것 중의 하나가 R과 Python에 대한 비교가 아닐까 싶다.</description>
    </item>
    
    <item>
      <title>Pandas Filtering</title>
      <link>https://dschloe.github.io/python/pandas/filter/</link>
      <pubDate>Fri, 03 Apr 2020 22:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/pandas/filter/</guid>
      <description>Overview 필터링은 특정 조건식을 만족하는 행을 따로 추출하는 개념이다. 특정 행의 값에 조건식 True/False을 판별하여 값을 추출하는 방법이다. 이 때, 비교 연산자 또는 조건식 (&amp;gt;, &amp;lt;, ==, ...)을 적용하면 행을 추출할 수 있다.
우선 데이터부터 확인한다. 아래 소스코드를 복사 붙여넣기 하면 데이터를 확인할 수 있다.
import pandas as pd url = &amp;#39;https://github.com/chloevan/datasets/raw/master/entertainment/movie_ticket_sales.xlsx&amp;#39; sales = pd.read_excel(url) print(sales.head())  theater_name movie_title ticket_type \ 0 Sumdance Cinemas Harry Plotter senior 1 The Empirical House 10 Things I Hate About Unix child 2 The Empirical House The Seaborn Identity adult 3 Sumdance Cinemas 10 Things I Hate About Unix adult 4 The Empirical House Mamma Median!</description>
    </item>
    
    <item>
      <title>Pandas sort_values()</title>
      <link>https://dschloe.github.io/python/pandas/sort_values/</link>
      <pubDate>Fri, 03 Apr 2020 20:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/pandas/sort_values/</guid>
      <description>I. Overview sort_values() 함수는 일종의 데이터의 정렬과 연관이 있다. 어려운 내용은 아니기 때문에 빠르게 소스 코드 구현 및 확인 하도록 한다.
II. Sample Tutorial 엑셀로 된 ticket_sales 데이터에서 ticket_quantity가 가장 많이 팔린 영화 Top3를 구하는 소스코드를 구해본다.
import pandas as pd url = &amp;#39;https://github.com/chloevan/datasets/raw/master/entertainment/movie_ticket_sales.xlsx&amp;#39; sales = pd.read_excel(url) print(sales.head())  theater_name movie_title ticket_type \ 0 Sumdance Cinemas Harry Plotter senior 1 The Empirical House 10 Things I Hate About Unix child 2 The Empirical House The Seaborn Identity adult 3 Sumdance Cinemas 10 Things I Hate About Unix adult 4 The Empirical House Mamma Median!</description>
    </item>
    
    <item>
      <title>Pandas With Excel</title>
      <link>https://dschloe.github.io/python/pandas/pandas_with_excel/</link>
      <pubDate>Mon, 30 Mar 2020 11:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/pandas/pandas_with_excel/</guid>
      <description>I. Overview 이번 포스트는 기존의 엑셀 사용자를 위해 준비했다. 엑셀에 익숙한 사람들에게 파이썬을 분석 용도로 사용하고자 하는 분들에게는 작은 도움이 되기를 바란다.
II. 데이터 입출력 판다스는 다양한 형태의 외부 파일을 읽을 수 있다. CSV, MS Excel, SQL, HDF5 Format과 같은 파일 포맷을 읽을 수 있다. 파일 포맷(File Format)에 따른 데이터 입출력 도구에 관한 자료를 요약하면 다음과 같다.
   파일 포맷 How to Read? How to Write?     CSV read_csv to_csv   MS Excel read_excel to_excel   SQL read_sql to_sql    그 외에 HTML, JSON, SAS 포맷과 같은 파일을 읽어오는 다양한 방법에 대해서는 Pandas 공식문서(PDF 다운로드)를 참조하기를 바란다.</description>
    </item>
    
    <item>
      <title>Pandas Lambda Apply 함수 활용</title>
      <link>https://dschloe.github.io/python/pandas/apply/</link>
      <pubDate>Mon, 23 Mar 2020 20:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/pandas/apply/</guid>
      <description>I. Iterrows, Itertuples 복습 이번 포스팅은 For-loop의 대안에 관한 함수 apply에 관한 내용이다. 본 포스트를 보고 학습하시기 전에 Pandas Iterrows 함수 활용과 Pandas Itertuples 함수 활용에서 학습 하기를 바란다.
지난시간과 마찬가지로 데이터는 동일한 것을 쓰도록 한다.
import pandas as pd import io import requests import pprint url = &amp;#39;https://raw.githubusercontent.com/chloevan/datasets/master/sports/baseball_stats.csv&amp;#39; url=requests.get(url).content baseball_stats = pd.read_csv(io.StringIO(url.decode(&amp;#39;utf-8&amp;#39;))) pprint.pprint(baseball_stats.head())  Team League Year RS RA W OBP SLG BA Playoffs RankSeason \ 0 ARI NL 2012 734 688 81 0.</description>
    </item>
    
    <item>
      <title>Pandas Itertuples 함수 활용</title>
      <link>https://dschloe.github.io/python/pandas/itertuples/</link>
      <pubDate>Sun, 22 Mar 2020 20:36:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/pandas/itertuples/</guid>
      <description>I. Iterrows 이번 포스팅은 Iterrows()의 확장개념입니다. 본 포스트를 보고 학습하시기 전에 Pandas Iterrows 함수 활용에서 학습 하기를 바란다.
II. Itertuples의 개념 itertuples()는 기본적으로 iterrows() 함수보다는 빠르다.
import pandas as pd import io import requests import pprint url = &amp;#39;https://raw.githubusercontent.com/chloevan/datasets/master/sports/baseball_stats.csv&amp;#39; url=requests.get(url).content baseball_stats = pd.read_csv(io.StringIO(url.decode(&amp;#39;utf-8&amp;#39;))) pprint.pprint(baseball_stats.head())  Team League Year RS RA W OBP SLG BA Playoffs RankSeason \ 0 ARI NL 2012 734 688 81 0.33 0.42 0.26 0 NaN 1 ATL NL 2012 700 600 94 0.</description>
    </item>
    
    <item>
      <title>Pandas Iterrows 함수 활용</title>
      <link>https://dschloe.github.io/python/pandas/iterrows/</link>
      <pubDate>Fri, 20 Mar 2020 20:32:10 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/pandas/iterrows/</guid>
      <description>I. Iterrows의 개념 데이터 전처리를 진행할 때, 데이터프레임에서 행에 반복적으로 접근을 하면서 값을 추출하거나 또는 그 값을 조작하는 일이 발생한다. 예를 들면, 특정 컬럼 A의 값에서 대문자 A를 찾아내 소문자 b로 변경한다고 가정해보자. 이런 경우에는 언제나 For-loop를 통한 반복문 코드 작성을 만들어야 한다.
이럴 때 보다 효율적으로 접근하는 방법 중 하나가 iterrows()를 사용하는 경우이다.
import pandas as pd import io import requests import pprint url = &amp;#39;https://raw.githubusercontent.com/chloevan/datasets/master/sports/baseball_stats.csv&amp;#39; url=requests.get(url).content baseball_stats = pd.</description>
    </item>
    
  </channel>
</rss>
