<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>텍스트 전처리 on Data Science | DSChloe</title>
    <link>https://dschloe.github.io/categories/%ED%85%8D%EC%8A%A4%ED%8A%B8-%EC%A0%84%EC%B2%98%EB%A6%AC/</link>
    <description>Recent content in 텍스트 전처리 on Data Science | DSChloe</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 22 Nov 2020 14:10:47 +0900</lastBuildDate>
    
	<atom:link href="https://dschloe.github.io/categories/%ED%85%8D%EC%8A%A4%ED%8A%B8-%EC%A0%84%EC%B2%98%EB%A6%AC/rss.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>텍스트 마이닝 - Bag of Words</title>
      <link>https://dschloe.github.io/python/nlp/ch02_bag_of_words/</link>
      <pubDate>Sun, 22 Nov 2020 14:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/nlp/ch02_bag_of_words/</guid>
      <description>I. 개요  문서가 가지는 모든 단어(Words)를 문맥이나 순서를 무시하고 일괄적으로 단어에 대해 빈도 값을 부여하여 피처 값을 추출하는 모델을 말한다. 아래와 같은 세 개의 문장이 있다고 가정해본다.  Doc 1: I love dogs. Doc 2: I hate dogs and knitting. Doc 3: Knitting is my hobby and passion.   위 문장을 각각의 행렬로 표현하면 아래와 같다.  BOW 모델의 장점은 쉽고 빠른 구축에 있기 때문에, 활용도는 높은 편이지만, BOW 기반의 NLP 연구는 잘 되지 않는다.</description>
    </item>
    
    <item>
      <title>텍스트 마이닝 - 텍스트 전처리</title>
      <link>https://dschloe.github.io/python/nlp/ch01_text_mining/</link>
      <pubDate>Wed, 18 Nov 2020 14:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/nlp/ch01_text_mining/</guid>
      <description>I. 개요  NLP(Natural Language Processing): 기계가 인간의 언어를 이해하고 해석하는 데 중점  활용예제: 기계 번역, 챗봇, 질의응답 시스템 (딥러닝)   Text Analysis: 비정형 텍스트에서 의미 있는 정보를 추출하는 것에 중점  활용예제: 비즈니스 인텔리전스, 예측분석 (머신러닝)   텍스트 분석의 예  텍스트 분류: 문서가 특정 분류 또는 카테고리에 속하는 것을 예측하는 기법 감성 분석: 텍스트에서 나타나는 감정/판단/믿음/의견 등의 주관적인 요소 분석하는 기법 텍스트 요약: 텍스트 내에서의 중요한 주제나 중심 사상 추출(Topic Modeling) 텍스트 군집화(Clustering)와 유사도 측정: 비슷한 유형의 문서에 대해 군집화를 수행하는 기법.</description>
    </item>
    
    <item>
      <title>텍스트 마이닝 - 희소행렬</title>
      <link>https://dschloe.github.io/python/nlp/ch02_bag_of_words_coo_csr/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dschloe.github.io/python/nlp/ch02_bag_of_words_coo_csr/</guid>
      <description>개요  피처 벡터화에 있어서의 희소행렬에 대해 배운다. BOW 형태를 가진 언어 모델의 피처 벡터화는 대부분 희소 행렬이다.  희소행렬  희소 행렬은 너무 많은 불필요한 0 값이 메모리 공간에 할당되어 메모리 공간을 많이 차지하는데 있다. 다음 그림을 살펴보자.  이러한 희소 행렬을 물리적으로 적은 메모리 공간을 차지할 수 있도록 변환해야 하는데, 이 때, COO와 CSR 형식이 존재한다.  (1) 희소 행렬 - COO  COO(Coordinate: 좌표) 형식은 0이 아닌 데이터만 별도의 데이터 배열(Array)에 저장하고, 그 데이터가 가리키는 행과 열의 위치를 별도의 배열로 저장 희소행렬 변환 위해 Scipy를 활용한다.</description>
    </item>
    
  </channel>
</rss>